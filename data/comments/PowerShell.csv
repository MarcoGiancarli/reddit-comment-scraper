PowerShell,3e5a2e,Frequentsy,4,Wed Jul 22 01:45:43 2015 UTC,Check your csv file. I could be misreading the error but it sounds like the column you are referring to as Surname is not actually called that in the file.
PowerShell,3e5a2e,VeteranKamikaze,1 point,Wed Jul 22 05:16:45 2015 UTC,That's how I interpreted the error as well
PowerShell,3e5a2e,opsready,1 point,Wed Jul 22 08:13:10 2015 UTC,"Try print the csv file to validate the content  foreach ($user in $csv) { $user.Surname }   And try the same Get-ADUser with a simple search:  Get-ADUser -filter {Surname -eq ""KnownSurname"" -or employeenumber -eq ""KnownEmployeenumber"" }   You might need a ""-Properties *"" to load all properties"
PowerShell,3e5a2e,BrianOverby,1 point,Wed Jul 22 06:03:56 2015 UTC,"I just did this and ran into the same issue.  I had to change the filter syntax from     -filter {field -eq property.value}     to      -filter 'field -eq ""$($property.value)""'    Don't have a good explanation as to why this is necessary, I have used the other filter format for years without this issue.  And if I use the former syntax with an actual value it works, so its something to do with the system.management.automation.pscustomobject"
PowerShell,3e5a2e,jbtechwood,1 point,Wed Jul 22 10:43:21 2015 UTC,"The problem is you're looking for the property sn, not surname and also variables expanding in your filter..which can be a pain.  There are a couple ways to skin this cat.  The easiest way might be to create a script block.  $csv = Import-csv .\file.csv  foreach ($user in $csv){     $surname = $user.surname     $empNo = $user.employeenumber     $filter = [scriptblock]::Create(""sn -eq '$surname' -or employeenumber -eq '$empNo'"")     Get-ADUser -Filter $filter }   Take a peek at this Hey Scripting Guy's post for more info."
PowerShell,3e69oq,Zurbinjo,4,Wed Jul 22 07:34:15 2015 UTC,"Sounds like a good case for a recursive function. Not sure if I can ELI5... it took me a while to wrap my head around it at first, but basically you have a function that calls itself until a base clause is met. In this case you'd keep calling the function until you've stripped off all the directories and you're acting on the root of the drive.  Here's a quick example, note that the function calls itself, passing in the parent of the previous path until the full name is also the full name of the root.  function Get-ParentPath {     param     (         $Path     )      $Item = Get-Item -Path $Path     if ($Item.FullName -ne $Item.Root.FullName)     {         Get-ParentPath -Path $Item.Parent.FullName          #Do stuff here... the below is included as an example         $Item.FullName     }     else     {         #This is the root of the drive, you can do stuff here too if needed.         $Item.FullName     } }   Now if you call that function on C:\test\a\b\c you see the following output:  PS C:\Users\TestUser> Get-ParentPath -Path 'c:\test\a\b\c' C:\ C:\test C:\test\a C:\test\a\b C:\test\a\b\c   Obviously you'd do your ACL/Permission work instead of just returning the paths, but hopefully that gets you on a track towards what you're trying to do."
PowerShell,3e69oq,WindosBK,1 point,Wed Jul 22 07:55:51 2015 UTC,"Oh, this looks pretty neat even if recursion appears kind of complicated to a like-5-old (me) :D  What I don't understand is, that c:\ is listed first and c:\test\a\b\c last. Shouldn't it be the other way around? (of course it shouldn't but I don't get it)"
PowerShell,3e69oq,WindosBK,2,Wed Jul 22 08:25:14 2015 UTC,"What is happening is it takes the path, gets the parent, and calls the function until it has the root. Think of it at this stage as if it has created a stack of paths.  It then works down the 'stack' and executes the actual code in the functions. The last thing on the stack (i.e. it was placed on top) is the first one to be acted on.   If you've played Magic The Gathering, think of it like that stack, the last played card is the first to resolve. If not, think of each directory like a dvd case. You're piling them up, and then opening them to... do something with the disk (the analogy sort of falls apart at that point haha.)  This is simply because re-calling the function is before the actual meat of what you're doing:  # Recall function Get-ParentPath -Path $Item.Parent.FullName  # Then do stuff here... $Item.FullName   You can flip these around, so you act on the directory first and then recall the function  # Do stuff here... $Item.FullName  # Then Recall function Get-ParentPath -Path $Item.Parent.FullName   The output you see when flipping the order is, well, flipped:  PS C:\Users\TestUser> Get-ParentPath -Path 'c:\test\a\b\c' C:\test\a\b\c C:\test\a\b C:\test\a C:\test C:\"
PowerShell,3e69oq,the_spad,1 point,Wed Jul 22 08:36:19 2015 UTC,"Thanks for your explanation, this is REALLY helpful to me. But actually it makes no difference if i flip it like this:  function Get-ParentPath { param (     $Path )  $Item = Get-Item -Path $Path if ($Item.FullName -ne $Item.Root.FullName) {     $Item.FullName     Get-ParentPath -Path $Item.Parent.FullName } else {     #This is the root of the drive, you can do stuff here too if needed.     $Item.FullName } }   I still get the root first!?"
PowerShell,3e69oq,the_spad,2,Wed Jul 22 08:57:18 2015 UTC,"Do you need to specifically grant just to each individual folder down the tree? Can you not just grant read on the root folder and allow inheritence to do the rest?  And your $parents doesn't work because Powershell is interpreting ""parent.parent"" as a single item (i.e. (get-item $path).""parent.parent"".fullname and there's not property on the object called ""parent.parent"".  A simpler solution would be to do a $path.split(""\"") and then enumerate the array if you need every element."
PowerShell,3e69oq,PowerShellStunnah,1 point,Wed Jul 22 07:38:51 2015 UTC,"Hi,  I can't inherit the permission, because that would inherit the permission on to many folders. In my example there could be a folder c:\test\a\secret\ that the user isn't allowed to see. With inheritance he would.  $path.split(""\"") looks like a good option, but I am not sure how to use it. It only returns the particular foldernames without path and backslashes.  Something like  for ($i; $path -ne "" ""; $i++) {$path= $path - path.split(""\"")[-$i]}   which obviously isn't working because I don't know the right syntax, yet. (But I would look after it, if this is the right thing to do ;) )"
PowerShell,3e66y9,Alaknar,2,Wed Jul 22 06:59:23 2015 UTC,"Not sure if this will have the same effect as rebooting the laptop (as that involves loading drivers, etc., etc.), but disabling and enabling the adapter could do the trick?  Pretty simple in PowerShell, though it does require Windows 8 or newer... there might be Windows 7 cmdlets I'm not aware of.  Firstly find out what your WiFi adapter is:  Get-NetAdapter   ID the interface by ifIndex or Name, and the pipe the Get cmdlet to the Restart cmdlet:  Get-NetAdapter -Name 'Random WiFi adapter' | Restart-NetAdapter   Restart-NetAdapter simply disables then enables the adapter. There are also Disable-NetAdapter and Enable-NetAdapter cmdlets if you prefer to do that with a little more control (or extra logic.)  Hope that helps in some way."
PowerShell,3e66y9,WindosBK,1 point,Wed Jul 22 07:15:42 2015 UTC,"Hmm... That one looks promising. I'll have to try that. Probably with the ""Disable-NetAdapter"" as there's a bridge involved, will have to probably restart every piece of it."
PowerShell,3e66y9,WindosBK,2,Wed Jul 22 08:00:56 2015 UTC,"If you want to be heavy handed/thorough, you could pipe all network adapters to Restart-NetAdapter by not specifying a name. Will try to do wired and any potential virtual NICs as well.  Best of luck."
PowerShell,3e66y9,WindosBK,1 point,Wed Jul 22 08:07:04 2015 UTC,"I know, I'm just not sure if they can be restarted in random order. If they need a particular order (like: Bridge -> WiFi/Ethernet and enable in reverse) then I'll need to use Disable, right?  Thanks for the tips!"
PowerShell,3e5v45,8bits1beard,2,Wed Jul 22 04:49:02 2015 UTC,As what account is the script running? Does that have admin or batch logon rights? Anything in eventlog when you run it? Can you start them manually?   Other solution might be to set the recovery options of the service to restart instead of scripting. If it doesn't halt too often in a day it'll just restart as needed.
PowerShell,3e5v45,da_kink,1 point,Wed Jul 22 06:38:34 2015 UTC,"Might pay to sanity check what's happening in the script as it runs.  I'd suggest outputting $arrService so you can make sure the content is what you expect it to be.  (If it works interactively but not in your scheduled jobs, try logging to a text file at various points in the script to see what the flow is when it runs.)"
PowerShell,3e5nzb,powpow44,3,Wed Jul 22 03:41:37 2015 UTC,"#use a variable for determining how long to loop     $exit = $false   Do {     $vDSUplink = Read-Host ""Are you using [C]isco or [O]ther Brand of Switch?""      <#-is operator compares Types, you are looking for string comparison.         Also, use correct variable.#>     If ($vDSUplink -eq ""C"")      {         $vDSLDP2 = ""CDP""         Write-Host ""Configuring CDP...""         $exit = $true     }     #if else does not exist as a statement for conditional logic      ElseIf($vDSUplink -eq ""O"")     {         $vDSLDP2 = ""LLDP""         Write-Host ""Configuring LLDP...""         $exit = $true     } } Until ($exit)   I used old school C formatting because it seemed like you were struggling with some key concepts and thought that this would be easier to read."
PowerShell,3e5nzb,JulionAmigo,1 point,Wed Jul 22 05:19:43 2015 UTC,This is really good and i can clearly understand it. Thank you.  Time to learn more powershell :D
PowerShell,3e5nzb,BlackV,1 point,Wed Jul 22 08:20:01 2015 UTC,you are setting $vDSUplink via read-host your IF is looking at $vDSLDP  I dont see you looking at $vDSUplink ever again?
PowerShell,3e5nzb,heartfullofsoul,1 point,Wed Jul 22 03:52:30 2015 UTC,"Why are you using -is and not -eq? (Noob here as well, I've never seen that)"
PowerShell,3e5nzb,zenmaster24,1 point,Wed Jul 22 04:15:06 2015 UTC,maybe change the way you are providing the info? http://jdhitsolutions.com/blog/powershell/2206/powershell-scripting-with-validateset/
PowerShell,3e3xji,nshpnc,6,Tue Jul 21 19:39:06 2015 UTC,"Hi there!  What sort of table are we talking? SQL? Excel? HTML? Here are a few options:   PSSQLite - A PowerShell module for working with SQLite. No server required. Invoke-SlqCmd2 - A PowerShell function that abstracts out T-SQL queries, can return PowerShell data, DataTables, etc. .NET DataTable class - If you prefer working with .NET yourself. PSExcel - A PowerShell module for working with Excel, that covers tables... HTML Notifications and Reports - Functions to convert arrays of objects into 'prettier' HTML.   Cheers!"
PowerShell,3e3xji,ramblingcookiemonste,2,Tue Jul 21 19:57:03 2015 UTC,PSExcell is fantastic
PowerShell,3e3xji,867530eight,2,Wed Jul 22 05:30:05 2015 UTC,"Great stuff, I'll have a look at these! I didn't intend to use any database functionality for this bit of work but it may actually make life easier if I do..."
PowerShell,3e3xji,joerod,2,Tue Jul 21 20:03:38 2015 UTC,"I think I'll give PSExcel a shot, I'm sick of CSVs."
PowerShell,3e3xji,bundyfx,1 point,Wed Jul 22 03:35:14 2015 UTC,"Hi Mate,  Some great suggestions in here so far, thought I'd quickly show you something that might help also:  Creating Custom headers with information from a CSV. Say you have a CSV that contains three columns. Name/OU/SCOM (for example). granted your Name column has the name of your servers already populated in it you could do something like this:  $csv = Import-csv C:\Servers.txt  $csv | select Name,@{Name='OU';Expression={Get-ADComputer -identity $_.name | select -ExpandProperty Distinguishedname}},@{Name='SCOM';Expression={Test-path ""\\$($_.Name)\C$\Program Files\System Center Operations Manager\Agent""}}   After that you could pipe it to Export-CSV and that would give you a full list to work with. Just another one of the many possible solutions."
PowerShell,3e3xji,Deathonus,1 point,Wed Jul 22 01:09:04 2015 UTC,Are you talking about the Format-Table command.  Or the other table like exports like ConvertTo-Html or Export-Csv.
PowerShell,3e3xji,KevMar,1 point,Tue Jul 21 19:53:25 2015 UTC,"The most basic requirement I have is to produce a table that lists our stores, with a column headers including the activity I've just completed on the store (DHCP reconfig, SCOM agent install) and whether the script was successful or failed. So need to make a basic table that references back to whether any of the scripts threw an error so the management folks can report on progress."
PowerShell,3e3xji,Deathonus,2,Tue Jul 21 20:05:22 2015 UTC,"This is very beautifully built into the language. The table you need is just a collection of object saved as a CSV or as HTML  So as long as you are working with objects, this just works. Even if you are not using objects yet, they are very easy to create."
PowerShell,3e5kb0,legendgodgod,1 point,Wed Jul 22 03:09:52 2015 UTC,"Let me get back t you on this, is use it on a monthly basis. But it will help if the csv's are in the same order, is that possible to do?"
PowerShell,3e5kb0,da_kink,1 point,Wed Jul 22 06:41:33 2015 UTC,Maybe some value here: http://ramblingcookiemonster.github.io/Join-Object/
PowerShell,3e4uow,mcw33,3,Tue Jul 21 23:39:51 2015 UTC,"Startup script should be running as SYSTEM, so why isn't that working? Any logs? What's your PowerShell execution policy?  Also, domain admin creds + logon scripts = a really bad time :)"
PowerShell,3e4uow,fonzie588,1 point,Wed Jul 22 04:01:07 2015 UTC,"Hi, I know its not best practice but its something which would be run once per machine and removed, I'm even happy to run it as a local admin account but just need something which works.  I don't know why its not working as system event viewer shows no traces of error or success or even informational.   Edit: Ran this from CMD as system and its installed both Windows-Features successfully. Script is located on C: drive"
PowerShell,3e4uow,fonzie588,1 point,Wed Jul 22 04:29:39 2015 UTC,"Saying the script is on C: is confusing, you added it to startup scripts in the GPO, right? It should be in SYSVOL, not pointed to something on the local computer. I don't know if that will make a difference, but you should be storing scripts directly in the GPO."
PowerShell,3e4uow,ioFAILURE42,3,Wed Jul 22 10:34:26 2015 UTC,"It always pains me to hear that people are using PSExec to do what remote powershell should be doing.  If I were in your position, I would be looking to enable remote powershell on the workstations (via psexec if need be) and then you can run the powershell script from your own machine with admin creds."
PowerShell,3e303j,sphinxpup,11,Tue Jul 21 15:50:45 2015 UTC,There is PoweLiks  https://blog.gdatasoftware.com/blog/article/poweliks-the-persistent-malware-without-a-file.html
PowerShell,3e303j,real_parbold,4,Tue Jul 21 16:31:35 2015 UTC,Holy crap that is a cool read.
PowerShell,3e303j,SirCaptainMitch,1 point,Tue Jul 21 17:50:20 2015 UTC,"It's a technically clever piece of work, and because Powershell is a 'native and trusted' part of the OS - this use has caused a few eyebrows and pulses to be raised.  Also consider https://blog.netspi.com/15-ways-to-bypass-the-powershell-execution-policy/  I personally don't think we have even seen the tip of the iceberg with PowerShell malware yet! However the MS team seem to be way ahead of the curve on this, actively trying to use PowerShell to be malicious and then building in security features to stop themselves. As with anything, it's a race - and it appears that MS are currently ahead. I hope it stays this way :)"
PowerShell,3e303j,real_parbold,1 point,Wed Jul 22 09:08:29 2015 UTC,"Sorry - by way ahead keeping PowerShell secure, just look at the new auditing controls that can be implemented against PowerShell so that commands and script block contents / context can now be logged into Event Viewer or sent to a centralised host.  I know I'm not phrasing this right - I'm tired; it's not a silver bullet - but it does make PowerShell activities more transparent and code easier to detect."
PowerShell,3e303j,real_parbold,4,Wed Jul 22 09:15:57 2015 UTC,It was only a matter of time before we started seeing these in the wild.  There are numerous ways to run the script even if the execution policy forbids it so disabling ps-remoting does not necessarily protect you.
PowerShell,3e303j,unknown_host,7,Tue Jul 21 16:20:25 2015 UTC,"Windows 10 has added parse-layer AV/malware hooks to PowerShell. Prior to that, AV only got a look in when a ps1 file is loaded. Now, all methods (api & cmdlet) go through the system registered AV/Malware APIs - this includes invoke-command, the call operator etc."
PowerShell,3e303j,x0n,1 point,Tue Jul 21 16:53:45 2015 UTC,Nice that's a welcome change
PowerShell,3e303j,unknown_host,4,Tue Jul 21 18:39:02 2015 UTC,"From ""Get-Help about_Execution_Policies""   The execution policy is not a security system that restricts user  actions.  For example, users can easily circumvent a policy by  typing the script contents at the command line when they  cannot run a script. Instead, the execution policy helps users to  set basic rules and prevents them from violating them  unintentionally.   The real problem is if the malware/virus manages to run with elevated permissions.  However, if that happens, you shouldn't really be worried the vector that they're using to monkey with the system, but the fact that they got elevated access."
PowerShell,3e303j,ryanbrown,1 point,Tue Jul 21 16:31:40 2015 UTC,Once Malware is on the system even with the logged on users credentials can attempt to escalate.  I do agree with you though great input.
PowerShell,3e303j,unknown_host,2,Tue Jul 21 18:41:13 2015 UTC,"Just like VB macros and VBScript snippets are popular payload vectors because of their ubiquity on Windows, so will PowerShell exploits become, it's not really that big of a surprise.  The same guiding principles (principle of least privilege, up-to-date anti-malware, monitoring etc.) still applies, nothing's really changed"
PowerShell,3e303j,PowerShellStunnah,2,Tue Jul 21 16:23:14 2015 UTC,Mr Snover linked to this the other day...  http://blogs.technet.com/b/mmpc/archive/2015/06/09/windows-10-to-offer-application-developers-new-malware-defenses.aspx
PowerShell,3e3xih,alcaron,2,Tue Jul 21 19:38:52 2015 UTC,Did you report this to https://connect.microsoft.com/ ?
PowerShell,3e3xih,Swarfega,1 point,Tue Jul 21 20:10:07 2015 UTC,So far I've only added it to the resources page on msdn but that is up next...  edit: https://connect.microsoft.com/PowerShell/feedbackdetail/view/1574517/msft-registryresource-psm1
PowerShell,3e2i3h,After_8,7,Tue Jul 21 13:28:54 2015 UTC,The endpoint needs to have the cmdlets that you're using. You can use PS5 to manage a PS2 machine as long as the commands you're running work on PS2.
PowerShell,3e2i3h,hibbyhoo,1 point,Tue Jul 21 16:07:49 2015 UTC,Cmdlets that use a -computername param work remotely but you cannot start a psremote session to a device running an earlier version of powershell and use the Cmdlets and parameters exclusive to newer versions.
PowerShell,3e2i3h,Kio_,1 point,Wed Jul 22 03:57:27 2015 UTC,I've never tested with 5.0 but for 3.0 to 2.0 in my experience they don't work.
PowerShell,3e2i3h,KevMar,1 point,Tue Jul 21 15:07:05 2015 UTC,I could see local cmdlets that target a computer working. I have not tested it myself.
PowerShell,3e2kb8,TechGuyAlan,4,Tue Jul 21 13:48:06 2015 UTC,Someone posted this yesterday.. Take a look? Sounds like your descriptions match.  http://www.reddit.com/r/PowerShell/comments/3dz4in/script_sharing_have_a_bunch_of_computer_ad/
PowerShell,3e2kb8,GLiMPSEiNATOR,1 point,Tue Jul 21 14:29:13 2015 UTC,Sweet! I will check this out thank you!
PowerShell,3e2fpf,Rezimx,3,Tue Jul 21 13:05:54 2015 UTC,"Read-host does not accept pipeline input, and passing input to it means that you must hit the enter key at some point.  It's basically impossible to go this route.  I'd just re-write your coworkers script!"
PowerShell,3e2fpf,1RedOne,2,Tue Jul 21 13:10:03 2015 UTC,"Oh ye of little faith.  I agree, /u/Rezimx's coworker screwed up; but, PowerShell gives us a lot of options for working around others' problems.    [Reflection.Assembly]::LoadWithPartialName('System.Windows.Forms') [System.Windows.Forms.SendKeys]::SendWait(""I'm a little teapot, short and stout!"" + [char]13)   PowerShell give you access to the whole .Net API.  Excepting a few weird outliers in the Win32 API, there isn't much it can't do."
PowerShell,3e2fpf,LandOfTheLostPass,2,Tue Jul 21 17:02:33 2015 UTC,"Oh lord, sendkeys...  I'm not disagreeing, just, consider this me making the sign of the cross to keep the devil away lol."
PowerShell,3e2fpf,alcaron,2,Tue Jul 21 19:49:03 2015 UTC,"Ya, won't blame you one bit for that.  It's a horrible solution to a bad problem.  But, sometimes ya gotta do what you gotta do.  EDIT: actually, I'm surprised no one's jumped on me for [reflection.assembly]::LoadWithPartialName yet.  It's deprecated; but, I just hate running down full names."
PowerShell,3e2fpf,LandOfTheLostPass,1 point,Tue Jul 21 21:11:27 2015 UTC,"Meh, I view that as they just decided ""we don't want to do it this way anymore""...style is style regardless of who decides it."
PowerShell,3e2fpf,alcaron,1 point,Tue Jul 21 21:40:27 2015 UTC,"Ah nice, didn't think about that.  I'll give it a shot."
PowerShell,3e2fpf,chriswastaken,1 point,Tue Jul 21 18:25:14 2015 UTC,I was afraid someone would say that.
PowerShell,3e2fpf,alcaron,3,Tue Jul 21 13:11:55 2015 UTC,He's right though. Have your coworker put in a check for null value like if(!$value){$value = read-host} then you can parameter the value without affecting it running alone.
PowerShell,3e2fpf,itsteve,1 point,Tue Jul 21 14:15:35 2015 UTC,Or he could stop being a godless heathen and setup params so that you can pass named parameters right to the script when you launch it...or even just check through $args[]...
PowerShell,3e2fpf,alcaron,2,Tue Jul 21 19:50:13 2015 UTC,One of my coworkers hard coded a read-host statement without accepting pipeline input.    It's time for an intervention.
PowerShell,3e2fpf,irescueducks,1 point,Tue Jul 21 18:00:23 2015 UTC,<grabs bat>
PowerShell,3e2fpf,KevMar,1 point,Tue Jul 21 19:50:59 2015 UTC,Here's a video from PowerShell Summit Europe 2014 on Expect http://m.youtube.com/watch?list=PLfeA8kIs7Coehjg9cB6foPjBojLHYQGb_&v=tKyAVm7bXcQ Could work.
PowerShell,3e2fpf,twoscoopsofpig,1 point,Tue Jul 21 16:23:31 2015 UTC,"Fix the script. If you can't touch the original, make a copy and call it 2.0.  Don't just replace the read-host with a parameter. Slice it into its functions pieces and make it a tool."
PowerShell,3e2fpf,wigrif,0,Tue Jul 21 20:28:44 2015 UTC,"Not a pure POSH solution, but try AutoHotkey.  Sure, it takes a little getting used to, and no, it doesn't scale well, and no, it's not terribly portable, but it would work for something like this. Unless, of course, the whole point is to let it run unattended.  Then you have a rewrite ahead of you."
PowerShell,3e2b53,eatchapucha,3,Tue Jul 21 12:20:38 2015 UTC,Why not use Get-ClusterGroup so that you get back your results as an object you can easily manipulate?
PowerShell,3e2b53,the_spad,1 point,Tue Jul 21 12:24:03 2015 UTC,"Get-ClusterGroup   didn't know about that command, thanks!  get-clustergroup | ft OwnerNode,State  OwnerNode State  Exchange1 Online  Exchange1 Offline   The last line is of no interest as this is a DAG cluster the storage will always appear offline.  So i could store my variables as follow:  $node = get-clustergroup | ? {$_.Name -eq ""Cluster Group""} | Select-Object OwnerNode  $status = get-clustergroup | ? {$_.Name -eq ""Cluster Group""} | Select-Object Status   But then my variable is not of the type i want (string)  $node | gm  TypeName: Selected.Microsoft.FailoverClusters.PowerShell.ClusterGroup   I would prefer the $node to be a simple string hat contains the server name only"
PowerShell,3e2b53,Feyh,1 point,Tue Jul 21 12:38:52 2015 UTC,"$node = get-clustergroup | ? {$_.Name -eq ""Cluster Group""} | foreach {$_.OwnerNode}   Another way which is more object oriented would be to get the value by using $node.OwnerNode"
PowerShell,3e2b53,Feyh,1 point,Tue Jul 21 12:42:54 2015 UTC,"$node = get-clustergroup | ? {$.Name -eq ""Cluster Group""} | foreach {$.OwnerNode}   Ok but i need to make a check on the server name something like     if ($node -eq ""Server1"" ) { do .... }  I cannot do it with ClusterGroup object or can i?"
PowerShell,3e2b53,Feyh,2,Tue Jul 21 12:59:48 2015 UTC,"If you are simply using   $node = get-clustergroup | ? {$_.Name -eq ""Cluster Group""}   you will get an object in your $node variable. You can now call all properties of it by writing ""$node.PROPERTY"".  So, for example:  $node = get-clustergroup | ? {$_.Name -eq ""Cluster Group""} if($node.OwnerNode -eq ""MyOwnerNode"") {     #DoStuff }   $Node | gm   will show you all properties which you can call by using $node.PropertyYouWantToUse. Those properties are mostly strings or can be converted to strings pretty easily (well, at least most of them):  [String]$MyOwnerNode = $Node.OwnerNode"
PowerShell,3e2b53,the_spad,2,Tue Jul 21 13:07:45 2015 UTC,Thanks that helps a lot!
PowerShell,3e2q0h,alluran,2,Tue Jul 21 14:35:11 2015 UTC,"So I worked out what I was doing wrong  Correct answer was a single backslash to escape - I was just running the replace on the wrong file  powershell -Command ""(Get-Content AllMatches.cs)  | Foreach-Object {$_ -replace '[][]','[]'} | Set-Content AllMatches.cs"""
PowerShell,3e2q0h,PowerShellStunnah,2,Tue Jul 21 14:49:45 2015 UTC,"[regex]::Escape could have helped you out here:  ForEach-Object {     $_ -replace [regex]::Escape('[][]'),'[]' }"
PowerShell,3e2q0h,Feyh,1 point,Tue Jul 21 20:05:27 2015 UTC,"Thanks, I'll note that down for future reference"
PowerShell,3e2q0h,Feyh,2,Tue Jul 21 21:38:30 2015 UTC,"Well, either I don't get your point or you are trying to overcomplicate this.  A simple  $MyText = ""[][]asdasdasd[][] hello dadbhjkasbdjkas d[][][][]"" $Newtext = $MyText.Replace(""[][]"",""[]"")   returned   ""[]asdasdasd[] hello dadbhjkasbdjkas d[] []"""
PowerShell,3e2nrq,CaptainRaj,1 point,Tue Jul 21 14:17:01 2015 UTC,Why not use lockoutstatus from the Microsoft tools?   https://www.microsoft.com/en-us/download/details.aspx?id=15201
PowerShell,3e2nrq,Kio_,1 point,Tue Jul 21 15:26:12 2015 UTC,I'm doing more with this than just finding the lockout status.  This is small snippet of a larger script.
PowerShell,3e2nrq,LordZillion,2,Tue Jul 21 15:44:08 2015 UTC,"Get-ADUser $username -Server $DC.Hostname -Properties * | select *lock*,@{N=Hostname;E={$DC.Hostname}}   That should work."
PowerShell,3e2nrq,Kio_,1 point,Tue Jul 21 14:29:00 2015 UTC,"@{N=Hostname;E={$DC.Hostname}   Tried that... I get:   select : The ""N"" key has a type, System.Management.Automation.PSObject, that is not valid; >expected type is System.String. At line:6 char:67 +         Get-ADUser $username -Server $DC.Hostname -Properties * | select lock, ... +                                                                   ~~~~~~~~~~~~~~>    + CategoryInfo          : InvalidArgument: (:) [Select-Object], NotSupportedException    + FullyQualifiedErrorId : >DictionaryKeyIllegalValue2,Microsoft.PowerShell.Commands.SelectObjectCommand"
PowerShell,3e2nrq,LordZillion,4,Tue Jul 21 14:36:38 2015 UTC,Don't remove the wildcards from the lock property.  ** Sorry that is wrong.   You can't do just hostname try @{N='Hostname';E={$DC.Hostname}}
PowerShell,3e2nrq,ryanbrown,1 point,Tue Jul 21 15:22:26 2015 UTC,"Kio, you genius.  Worked perfectly.  Thanks very much!!"
PowerShell,3e2nrq,ryanbrown,1 point,Tue Jul 21 15:36:45 2015 UTC,"Just for my knowledge I just missed the quotation marks, right?"
PowerShell,3e2nrq,ryanbrown,0,Wed Jul 22 09:04:55 2015 UTC,Can you try running the Get-ADDomainController and Get-ADUser cmdlets from the prompt and get the results you're looking for?  Is it possible that the powershell console is running under a user that doesn't have access to that information in AD?
PowerShell,3e2nrq,Navsta88,1 point,Tue Jul 21 15:02:40 2015 UTC,"I'm an Enterprise Admin, so have access to everything... every nook and cranny."
PowerShell,3e2nrq,ryanbrown,0,Tue Jul 21 15:17:54 2015 UTC,Did you try running the commands individually from the command line?  Did you get the data you expected?
PowerShell,3e2nrq,Navsta88,1 point,Tue Jul 21 15:27:11 2015 UTC,"Yup, I can... I'm an enterprise admin.  If I couldn't, I'd get different errors from the foreach loop above.  Kio_ came up with the answer and it's working like a charm now.  Thanks anyway."
PowerShell,3dzr8z,kittH,3,Mon Jul 20 21:13:04 2015 UTC,"So I am a little dumb as to what this could be used for with LoL, mind educating me, PM will be fine. Not sure at all what can be done with the LoL API is all."
PowerShell,3dzr8z,iwifia,3,Tue Jul 21 10:54:37 2015 UTC,"Just take a look at all those community created websites.Here are a few examples:   http://www.lolking.net/summoner/na/5908 (Links to the profile of a known Pro player to get some example data like game history, runes, masteries, KDA, ...) www.lolnexus.com (This is a web site that displays information about all 10 players that are currently in the same game. Commonly used to get some information about your enemies/team mates, like their rank, masteries, runes, Win-lose ratio, ...) www.elophant.com (Pretty much the same as lolking)"
PowerShell,3dzr8z,Feyh,2,Tue Jul 21 12:54:19 2015 UTC,Interested in this as well...
PowerShell,3dzr8z,TheDarkMike,2,Tue Jul 21 12:37:25 2015 UTC,"Great Question, feel a little dumb I didn't give more context originally.   The examples that Feyh gave are great, I would also point out sites like www.probuilds.com and especially www.champion.gg.   Those sites use the API to access the information and build their own data warehouses for historical data only using the API to get new/updated data (you can trigger this on demand on most sites for specific data, like your summoner info or recent matches).  I am working on some sample scripts to give some examples of what you can do. They're not done yet but I'll share a WIP script with you guys. http://pastebin.com/HPFc2ctj   I will eventually comment this script heavily to explain what I'm doing at each step, but here is an overview: The variables at the top PlayerIDs, Item, Region and GameType are the input parameters. As written this script will get a list of all challanger tier players in NA and locate all of the recent ranked solo queue games that they built a Liandry's Torment and output a flat list of those games with some statistics.   My intention was to build a script for finding high level ranked builds for specific items. Searching for an item that has recently been changed like Liandry's is one use, or maybe a niche item like Ardent Censer. Entering something like Infinity Edge probably isn't that interesting... until maybe it is if you add a filter  for $game.stats.playerPosition -ne 4. (4 is the code for bot lane)  This script outputs into a $results variable that you can interrogate further. The above example could be executed on the $results array via: $Results | where-object {$_.Position -ne 'Bot'}  Thanks for the feedback!"
PowerShell,3dzr8z,bundyfx,2,Tue Jul 21 14:01:14 2015 UTC,Nicely done! I had this idea a few months ago but never got around to getting API keys to make it a reality. awesome job mate!
PowerShell,3dzr8z,Cbatoemo,2,Mon Jul 20 22:27:17 2015 UTC,"Good stuff!  I had the idea of duplicating a post from earlier, that took the ranks of everybody active in the season, and dumping it into a database. Might use this to accomplish my goals; thanks OP."
PowerShell,3dzr8z,bundyfx,1 point,Tue Jul 21 14:52:47 2015 UTC,"That's a great idea, please let me know if you get anywhere with it, or if you need any help with the module."
PowerShell,3dzirb,Buzzb,3,Mon Jul 20 20:13:36 2015 UTC,This maybe of help:  https://github.com/darkoperator/Posh-SSH
PowerShell,3dzirb,savagedan,2,Tue Jul 21 02:15:25 2015 UTC,Have you tried /r/csharp?
PowerShell,3dxevs,joakimbs,3,Mon Jul 20 09:28:52 2015 UTC,"Nice, ill definitely be making use of this."
PowerShell,3dxevs,Theratchetnclank,2,Mon Jul 20 10:58:58 2015 UTC,"Cool script, +1 for a much more portable NMAP alternative for the windows camp."
PowerShell,3dzjzu,root-node,1 point,Mon Jul 20 20:22:23 2015 UTC,"I've been using this for a while.  I know it will catch a computer rename now, but I'm not sure about pending domain/workgroup changes."
PowerShell,3dzjzu,emeraldtears,1 point,Tue Jul 21 19:34:02 2015 UTC,"Thanks, but that only does the same checks as my script."
PowerShell,3dxuu7,charliecrocodile,1 point,Mon Jul 20 12:46:52 2015 UTC,"It should be noted that your script will work for people who have the AlphaFS binaries installed and loaded in their current session. Perhaps you could make a notification of that in your script as currently it just errors out on the following line:  [Alphaleonis.Win32.Filesystem.Directory]::Delete($outrecord, $True, $true)"
PowerShell,3dxuu7,JaapBrasser,1 point,Mon Jul 20 13:08:15 2015 UTC,Edited.
PowerShell,3dyimo,Tolje,3,Mon Jul 20 15:59:54 2015 UTC,"Getting the information from AD is the hard part.  In order to update your local computer description, you'll need to be running as an administrator, though.  Have a look at this and see if it does what you need:  # Obtain a reference to a DirectorySearcher for the current domain $domain = [System.DirectoryServices.ActiveDirectory.Domain]::GetCurrentDomain() $domainRoot = $domain.GetDirectoryEntry() $searcher = [System.DirectoryServices.DirectorySearcher] $domainRoot  # Set the search filter to an LDAP query for this machine's computer name $searcher.Filter = ""(sAMAccountName=$env:ComputerName`$)""  # Only load the distinguishedname property when returning search results $searcher.PropertiesToLoad.Add(""distinguishedName"") | Out-Null $results = $searcher.FindAll()  # There should only be one search result as long as your computer names are  # distinct, but this is a .NET collection, so we still need to loop through it foreach ($r in $results) {     # Now, we obtain a DirectoryEntry object for the computer     $dn = $r.properties.Item(""distinguishedName"")     $Computer = [ADSI]""LDAP://$dn""      # Get the computer's current description     [string]$adDescription = $Computer.description      # This method requires PowerShell 3.0 or greater.     Get-CimInstance -ClassName Win32_OperatingSystem | Set-CimInstance -Property @{       'Description' = $adDescription;     }      # Alternately, you can do this in PowerShell 2.0:     $wmi = Get-WmiObject -ClassName Win32_OperatingSystem     $wmi.Description = $adDescription     $wmi.Put()      # You can set a description here in AD if you want, too!     # Note that this requires the computer object to have Write access to      # its description in AD.     $Computer.description = ""My new description""     $Computer.SetInfo() }   Edit: A bit more info, since you mention you're learning, and I realize this code is a bit confusing at first:  PowerShell is built from the ground up to rely on the .NET framework.  That means it doesn't start up quite as fast, and the interpreter is a bit slower than something 100% native and portable, but it gives you a HUGE amount of power as a PowerShell developer / sysadmin / operator.  There are some native PowerShell cmdlets for working with Active Directory, in a PS module packaged up with RSAT.  The problem is that if you use that PowerShell module, your code depends on it...so in order to run that on a client machine, you'd need that PowerShell module  - and RSAT - on that client machine.  So basically, we're falling back on the .NET classes and methods for working with LDAP searches and objects.  These will be available anywhere PowerShell is available.  Working with .NET is a bit heavier on the ""development"" end of the spectrum than it is on the ""sysadmin"" end, so it can get a bit hairier than the rest of your work with PowerShell.  A lot of the things that make PowerShell so easy and friendly to use don't apply to .NET classes, since they weren't necessarily designed with PowerShell in mind.  However, having the ability to jump in and interact even this easily with the .NET framework is a great benefit, and it dramatically extends the amount of stuff you can do with PowerShell.  I hope that helps clear it up a bit.  Feel free to let me know if you've got any more specific questions; I'm always happy to help!"
PowerShell,3dyimo,replicaJunction,2,Mon Jul 20 16:55:06 2015 UTC,"I guess I've been doing it wrong. When I try to run powershell ise as a different user, it isn't elevating. I get an access denied message. I'll have to figure out how to elevate it so I can use the Put()."
PowerShell,3dy0ec,Cookernator,2,Mon Jul 20 13:39:07 2015 UTC,You need to be using Remove-ItemProperty rather than Remove-Item
PowerShell,3dy0ec,the_spad,1 point,Mon Jul 20 13:54:39 2015 UTC,"Thanks, that makes sense, although now I get an error.  Looks like I need to pass more information through to the remove-itemproperty command.  Remove-ItemProperty : The input object cannot be bound because it did not contain the information required to bind all mandatory parameters"
PowerShell,3dy0ec,neogohan,1 point,Mon Jul 20 14:46:09 2015 UTC,"One-liners are neat, but not for the sake of readability. If you're doing foreach loops with if statements nested in them, do yourself a favor and write it a bit more neatly.  That said, it looks like you may have misplaced a curly brace after the second instance of ""$_.PsPath"". Shouldn't the last brace be at the very end of the script? And then another one after it to terminate the foreach loop?"
PowerShell,3dy0ec,FlippityFlip,1 point,Mon Jul 20 17:46:50 2015 UTC,This post reminded me that I needed to do the exact same thing. Break it out into separate lines and don't forget Remove-ItemProperty requires the Path and the Name of the property being removed.
PowerShell,3dz6ps,lostmojo,4,Mon Jul 20 18:47:10 2015 UTC,"If the tasks don't need domain privileges, consider JitJea, it abstracts out much of the complexity.  If you don't have that option (e.g. these need to run as domain accounts), consider constrained, delegated endpoints.  These work out quite nicely once you get the hang of them. Boe Prox has an in depth series of articles on them, worth a look if you go this route!  There are certainly other options, and depending on the competency of the folks using these, you might need to wrap them in a simple GUI. Some GUI options here, and reasons why you might not want to provide this crutch...  Here's an example we have set up:   Overview: Allow appropriate teams access to migrate passwords using ADMT, without the high-level privileges typically required in both domains Endpoint: PowerShell remoting endpoint includes a single function that wraps ADMT.exe. This function is locked down to specific validated parameters. The endpoint runs with requisite privileges PowerShell function: Merge-ADMigrationPassword. This wraps a call to the function in the endpoint, but looks like a normal function for end users. GUI: A small PowerShell script using WinForms allows Service Desk folks to look up migrated accounts, click a button to migrate the password (this simply runs Merge-ADMigrationPassword)   So... I give support a module with this function. Support runs Merge-ADMigrationPassword. That calls an endpoint to run the actual ADMT command. This runs as an account with crazy privileges to allow the migration (hence, delegated). Nothing else can run with those crazy privileges (hence, constrained). This all gets logged.  Cheers!"
PowerShell,3dz6ps,ramblingcookiemonste,1 point,Mon Jul 20 18:57:23 2015 UTC,JitJea sounds promising. How long have you used it and what size tech crew / size organization were you using it for?
PowerShell,3dz6ps,neilthecellist,1 point,Tue Jul 21 06:41:47 2015 UTC,"Hi!  We stick to the technology underlying it (constrained, delegated endpoints) given that we use it more as a way to enable granular access control, where existing access controls do not. This usually means domain accounts running these endpoints, which JitJea doesn't support at the moment.  Don't quote me on this, but AFAIK Microsoft uses JitJea internally, and I've heard of other large organizations using it."
PowerShell,3dz6ps,ramblingcookiemonste,1 point,Tue Jul 21 10:37:58 2015 UTC,"How about using Get-Credential before running any admin functions? This way there support desk user will need to enter their AD credentials before proceeding. There should be a way to decide based on the user provided if access is granted or not.  Edit: Get-Credential was the first thing I thought of. I have not actually done this, yet. Most scripts I have shared with my colleagues generally did not have potential to break things."
PowerShell,3dz6ps,Golossos,1 point,Mon Jul 20 18:56:25 2015 UTC,For fixed tasks I have been looking at Jenkins with a Powershell plugin?
PowerShell,3dy626,Sn0zzberries,1 point,Mon Jul 20 14:25:51 2015 UTC,"So you're attempting to execute a script on a remote share,  correct?"
PowerShell,3dy626,SEA-Sysadmin,1 point,Tue Jul 21 02:35:56 2015 UTC,"Correct, a script which executes perfectly when a cmd session is established first.  The script still runs as well, only the Start-Job cmdlet fails. Due to trying to start a session in a network share or in a redirected desktop on a network share."
PowerShell,3dxsvs,Vortex100,1 point,Mon Jul 20 12:27:26 2015 UTC,"Try without declaring int before $partition.sizemax or I have seen this before when you have hit the partition size limit. Ex, you can't expand the partition past 16tb when using 4k allocation size on a 4k physical size disk."
PowerShell,3dy1b7,deemos,2,Mon Jul 20 13:47:12 2015 UTC,"Just as a thought, you could always pull a list of services on a machine and match it against a list of known services. If a service is found, then check if it's started, if not, do stuff.  For example:  $Svcs = (""Service1"",""Service2"",""Service3"") $Services = Get-Service -ComputerName $Server | Where-Object {$Svcs -contains $_.Name} ForEach($service in $Services) {      if($service.Status -eq ""Running"") { #do stuff } else { #do other stuff } }"
PowerShell,3dy1b7,LandOfTheLostPass,1 point,Mon Jul 20 16:45:31 2015 UTC,"Well, when you say it like that!  I like it, works just like i was wanting it to!"
PowerShell,3dufmy,misterpeguero,2,Sun Jul 19 16:11:23 2015 UTC,This looks super cool!!  Be sure to x-post to /r/sysadmin and /r/usefulscripts
PowerShell,3dufmy,Caseycrowe,1 point,Mon Jul 20 01:21:32 2015 UTC,"Needs more comments :)  Very nice script overall, also you should cite your code. Oddly enough I recognized the balloon tip function from earlier googling today."
PowerShell,3dvm8n,powershelln00b,5,Sun Jul 19 22:15:00 2015 UTC,Why take a specific logonid if you want to remove it everywhere anyways?  Resolve-Path C:\users\*\appdata\roaming\sun |%{ Remove-Item $_.Path -Recurse -Force }   Will find all user directories with the appdata\roaming\sun folder and remove them
PowerShell,3dvm8n,PowerShellStunnah,1 point,Sun Jul 19 23:04:40 2015 UTC,"Unfortunatly we have to keep it to a specific id.  I image it would be a variable of some sort, but can't seam to find how to actually do it."
PowerShell,3dvm8n,cooper2010,1 point,Mon Jul 20 04:47:21 2015 UTC,Can you run the script was system?  System should have the rights to delete file from user directories.
PowerShell,3dvx2z,theClutz,2,Sun Jul 19 23:47:40 2015 UTC,"This should work. I didnt try it out now since I dont have access to my labenv atm.  $Incident = ""xxxxxx""  $AffectedUser = Get-SCSMRelationshipClass System.WorkItemAffectedUser$  $AssignedToUser = Get-SCSMRelationshipClass System.WorkItemAssignedToUser$  Get-SCSMRelatedObject -SMObject $incident -Relationship $AssignedToUser | Select-Object Username, Displayname  Get-SCSMRelatedObject -SMObject $incident -Relationship $AffectedUser | Select-Object Username, Displayname"
PowerShell,3dvx2z,Cpt-BlowUpDoll,1 point,Mon Jul 20 05:12:29 2015 UTC,"What your looking for exists, but it's likely going to need to be tweaked to fit for your deployment, unless your classifications for Sr's mirror the classifications for your it's. A good place to start is going to be the blogs for creating an SR with powershell. Once you have that down its just a matter of getting the detail from the ir and closing."
PowerShell,3duoy8,featheredtar,2,Sun Jul 19 17:32:48 2015 UTC,Are all the images in numerical order?
PowerShell,3duoy8,catacombkid1,1 point,Mon Jul 20 00:52:17 2015 UTC,Yes.
PowerShell,3duoy8,midnightFreddie,2,Mon Jul 20 01:05:38 2015 UTC,"Edit 3: Updated code at https://github.com/midnightfreddie/theinternets/blob/master/ffmpeg-timelapse.ps1 . The reason the below doesn't work is apparently due to how pipelines are handled in ISE versus the console. In the updated version I pass ffmpeg a filespec instead of piping it files, avoiding the pipeline problem and making it work in Powershell console.  Edit 2: For reasons I don't yet understand, this works in Powershell ISE but not Powershell  Edit: FIXED! I was trying to pipe file names to ffmpeg, but it wants the content.  This isn't quite working yet. I was aiming to pipe the list of files to ffmpeg, but I'm having trouble getting the command launched that way.  This assumes that all jpg's / jpeg's in each folder belong to one time lapse sequence. Edit in your $RootPath for the videos and also $DestPath and $ffmpeg for the executable location.  I also hadn't figured out the output naming yet, so for now it's a simple incremented counter into an output folder, but if you run this and take a look at the output, see if it is grouping the files properly. Edit: It now names the video based on the original filename and depending on which $outputfilename line you comment/uncomment it can put the file in with the jpgs or put them all into a specified $DestFolder.  Also, what version of Powershell are you running? $PsVersionTable  $ffmpeg = ""C:\tools\ffmpeg-2.5.2-win64-shared\bin\ffmpeg.exe"" $RootFolder = ""C:\Temp\pics"" $DestFolder = ""C:\Temp\videos""  # Pipe a stream of folders to this and get an object with the jpgs in that folder and some other info filter Get-FfmpegCommands {     $Images = Get-ChildItem $_.Fullname |             Where-Object { -not $_.PsIsContainer } |             Where-Object { $_.Name -imatch '\.jpe?g$'} |             Select-Object -ExpandProperty FullName      if ($Images -ne $null) {         New-Object psobject -Property @{             Images = $Images             PathFullName = $_.FullName             PathName = $_.Name             OutputFileName = $Images[0].Split(""\/"")[-1] -replace '-?(\d+)?\.jpe?g$', '.mpg'         }     } }  # Given a folder, returns a stream of folders including this one and all recursive subfolders function Get-Folders {     param (         [Parameter(Mandatory = $true)]         $RootFolder     )     Get-Item $RootFolder     Get-ChildItem -Recurse -Path $RootFolder |         Where-Object { $_.PsIsContainer } }   # Beginning of script.  Get-Folders -RootFolder $RootFolder |     Get-FfmpegCommands |     ForEach-Object {          # Use this one to put the videos in $DestFolder         $outfilename = ""$DestFolder\$($_.OutputFilename)""          # Use this to put the videos in the path with the images         #$outfilename = ""$($_.PathFullName)\$($_.OutputFilename)""          # UNCOMMENT THE FOLLOWING LINE when you're ready to try for real         # Currently it will show a lot of red, but that's because ffmpeg is chatty.         # If running more than once, realize that ffmpeg will stop if the output file already exists         # Get-Content -Raw $_.Images | &$ffmpeg  -f image2pipe -c:v mjpeg -i - $outfilename          # This is just to see the output objects         $_ | Format-List     }   Sample output from my files which aren't time lapses. If my assumptions match your folder structure, the Images should be the correctly-ordered start of the timelapse image list, and PathFullName and Name are candidates for use in the output video name. Edit: After you're satisfied the Image sets are correct, uncomment the line that runs ffmpeg and it will make the videos.  Images         : {C:\Temp\pics\1\QjYYUc8.gif-0001.jpg, C:\Temp\pics\1\QjYYUc8.gif-0002.jpg, C:\Temp\pics\1\QjYYUc8.gif-0003.jpg, C:\Temp\pics\1\QjYYUc8.gif-0004.jpg...} PathFullName   : C:\Temp\pics\1 PathName       : 1 OutputFileName : QjYYUc8.gif.mpg      Images         : {C:\Temp\pics\2\ma6CVJk.webm-0001.jpg, C:\Temp\pics\2\ma6CVJk.webm-0002.jpg, C:\Temp\pics\2\ma6CVJk.webm-0003.jpg, C:\Temp\pics\2\ma6CVJk.webm-0004.jpg...} PathFullName   : C:\Temp\pics\2 PathName       : 2 OutputFileName : ma6CVJk.webm.mpg      Images         : {C:\Temp\pics\3\af3lcDl.webm-0001.jpg, C:\Temp\pics\3\af3lcDl.webm-0002.jpg, C:\Temp\pics\3\af3lcDl.webm-0003.jpg, C:\Temp\pics\3\af3lcDl.webm-0004.jpg...} PathFullName   : C:\Temp\pics\3 PathName       : 3 OutputFileName : af3lcDl.webm.mpg      Images         : {C:\Temp\pics\4\7Rs8Gvh.webm-0001.jpg, C:\Temp\pics\4\7Rs8Gvh.webm-0002.jpg, C:\Temp\pics\4\7Rs8Gvh.webm-0003.jpg, C:\Temp\pics\4\7Rs8Gvh.webm-0004.jpg...} PathFullName   : C:\Temp\pics\4 PathName       : 4 OutputFileName : 7Rs8Gvh.webm.mpg"
PowerShell,3duoy8,catacombkid1,2,Mon Jul 20 03:27:42 2015 UTC,Nice work dude
PowerShell,3duoy8,midnightFreddie,1 point,Mon Jul 20 21:13:36 2015 UTC,"I edited the above reply with working code. It will spew a bunch of red text, but it works. I downloaded some animated GIFs, manually used ffmpeg to turn them into jpg sequences and then used the script to create the mpg.  Edit: I want to see the time lapse videos! From your post history I'm guessing it's plants growing or similar."
PowerShell,3duoy8,midnightFreddie,1 point,Mon Jul 20 04:45:53 2015 UTC,"Here's my youtube channel.   https://www.youtube.com/momentaryvitality  Basically I scan plants as they dry up, and have probably over 1000 that I haven't even previewed as it takes time to compose the footage in Adobe After Effects. So I've really wanted a way to automate the previewing process. :) I usually have around 8 scanners running 24/7 at a time, and right now have a few dozen plants in the fridge waiting."
PowerShell,3duoy8,midnightFreddie,1 point,Mon Jul 20 15:31:24 2015 UTC,"Wow, thank you so much!! This is amazing. I think my ffmpeg exe is having trouble with the -f image2pipe flag, as I'm getting this message: ""pipe:: could not find codec parameters"". It's creating the .mpgs at my specified destination, but it's an empty container. Aside from adding info to the variables, I didn't change your script. My Powershell version output is as follows:  Name                           Value ----                           ----- PSVersion                      4.0 WSManStackVersion              3.0 SerializationVersion           1.1.0.1 CLRVersion                     4.0.30319.34014 BuildVersion                   6.3.9600.17400 PSCompatibleVersions           {1.0, 2.0, 3.0, 4.0} PSRemotingProtocolVersion      2.2   Here is my ffmpeg output:      ffmpeg version N-73818-g9ebe041 Copyright (c) 2000-2015 the FFmpeg developers   built with gcc 4.9.2 (GCC)   configuration: --enable-gpl --enable-version3 --disable-w32threads --enable-avisynth --enable-bzlib --enable-fontconfig --enable-frei0r --enable-gnutls --enable-iconv --enable-libass --enable-libbluray - enable-libbs2b --enable-libcaca --enable-libdcadec --enable-libfreetype --enable-libgme --enable-libgsm --enable-libilbc --enable-libmodplug --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-librtmp --enable-libschroedinger --enable-libsoxr --enable-libspeex --enale-libtheora --enable-libtwolame --enable-libvidstab --enable-libvo-aacenc --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxvid --enable-lzma --enabledecklink --enable-zlib   libavutil      54. 28.100 / 54. 28.100   libavcodec     56. 49.101 / 56. 49.101   libavformat    56. 40.101 / 56. 40.101   libavdevice    56.  4.100 / 56.  4.100   libavfilter     5. 25.100 /  5. 25.100   libswscale      3.  1.101 /  3.  1.101   libswresample   1.  2.101 /  1.  2.101   libpostproc    53.  3.100 / 53.  3.100 [mpeg2video @ 0000000004980040] Invalid frame dimensions 0x0.     Last message repeated 19 times [image2pipe @ 0000000004976680] decoding for stream 0 failed [image2pipe @ 0000000004976680] Could not find codec parameters for stream 0 (Video: mpeg2video, none(tv)): unspecified size Consider increasing the value for the 'analyzeduration' and 'probesize' options pipe:: could not find codec parameters Input #0, image2pipe, from 'pipe:':   Duration: N/A, bitrate: N/A     Stream #0:0: Video: mpeg2video, none(tv), 25 fps, 25 tbr, 25 tbn, 25 tbc   Images         : {K:\MV11T\Bacteria\Cyanobacteria\Nostocales\Nostocaceae\test\test-0001.jpg,              K:\MV11T\Bacteria\Cyanobacteria\Nostocales\Nostocaceae\test\test-0002.jpg,              K:\MV11T\Bacteria\Cyanobacteria\Nostocales\Nostocaceae\test\test-0003.jpg,              K:\MV11T\Bacteria\Cyanobacteria\Nostocales\Nostocaceae\test\test-0004.jpg...} PathFullName   : K:\MV11T\Bacteria\Cyanobacteria\Nostocales\Nostocaceae\test PathName       : test OutputFileName : test.mpg"
PowerShell,3duoy8,midnightFreddie,1 point,Mon Jul 20 06:58:03 2015 UTC,"I'm getting this message: ""pipe:: could not find codec parameters""   That's one of the messages I was getting when I was piping file names instead of the files to ffmpeg which leads me to think ffmpeg is seeing invalid data. Look at this line in your output:  [mpeg2video @ 0000000004980040] Invalid frame dimensions 0x0.     Last message repeated 19 times   I'm guessing there are 19 images in this test? Try opening one of them and make sure it's a valid image file.  I'll pm you my email in case you want to send me the test set of photos and see if they work for me. Here are the pics I used to test: http://midnightfreddie.com/testpics.zip (10 MB file)  Here's my output from a successful run:  ffmpeg.exe : ffmpeg version 2.5.2 Copyright (c) 2000-2014 the FFmpeg developers   built on Dec 30 2014 17:29:04 with gcc 4.9.2 (GCC)   configuration: --disable-static --enable-shared --enable-gpl --enable-version3 --disable-w32threads --enable-avisynth --enable-bzlib --enable-fontconfig --enable-frei0r --enable-gnutls  --enable-iconv --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libfreetype --enable-libgme --enable-libgsm --enable-libilbc --enable-libmodplug  --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-librtmp --enable-libschroedinger --enable-libsoxr --enable-libspeex  --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvo-aacenc --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp  --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxvid --enable-lzma --enable-decklink --enable-zlib   libavutil      54. 15.100 / 54. 15.100   libavcodec     56. 13.100 / 56. 13.100   libavformat    56. 15.102 / 56. 15.102   libavdevice    56.  3.100 / 56.  3.100   libavfilter     5.  2.103 /  5.  2.103   libswscale      3.  1.101 /  3.  1.101   libswresample   1.  1.100 /  1.  1.100   libpostproc    53.  3.100 / 53.  3.100 [mjpeg @ 000000000046b060] ignoring invalid SAR: 254/255 Input #0, image2pipe, from 'pipe:':   Duration:  N/ A , bitrate:  N/A     Stream #0: 0 : Video: mjpeg, yuvj420p(pc, bt470bg/unknown/unknown), 720x404 ,  25 fps,  25 tbr,  25 tbn,  25 tbc [swscaler @ 0000000000478da0]  deprecated pixel format used, make sure you did set range correctly [mpeg @ 000000000046ee60]  VBV buffer size not set, using default size of 130KB If you want the mpeg file to be compliant to some specification Like DVD, VCD or others, make sure you set the correct buffer size Output #0, mpeg, to 'C:\Temp\videos\7Rs8Gvh.webm.mpg':   Metadata:     encoder         :  Lavf56.15.10 2     Stream #0: 0 : Video: mpeg1video, yuv420p, 720x404, q=2-31, 200 kb/ s ,  25 fps,  90k tbn,  25 tbc     Metadata:       encoder         :  Lavc56.13.100 mpeg1video Stream mapping:   Stream #0:0 -> #0: 0  (mjpeg (native) -> mpeg1video (native)) frame=  120 fps=0.0 q=31.0 size=     276kB time=00:00:04.72 bitrate= 479.0kbits/s     frame=  243 fps=242 q=31.0 size=     444kB time=00:00:09.64 bitrate= 377.3kbits/s     frame=  369 fps=245 q=31.0 size=     746kB time=00:00:14.68 bitrate= 416.3kbits/s     frame=  375 fps=244 q=31.0 Lsize=     768kB time=00:00:14.96 bitrate= 420.6kbits/s     video:759kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.201396%"
PowerShell,3duoy8,midnightFreddie,1 point,Mon Jul 20 13:39:42 2015 UTC,"I updated Powershell to the April 2015 release of version 5, and have the latest 64 bit ffmpeg.exe, and have tried it with your images. I'm still getting the same problem. Any idea as to what else it could be?"
PowerShell,3duoy8,midnightFreddie,1 point,Mon Jul 20 15:37:15 2015 UTC,Hmm. I got my ffmpeg here: http://ffmpeg.zeranoe.com/builds/win64/shared/ffmpeg-2.5.2-win64-shared.7z . (It's the URL Chocolately uses for installing ffmpeg.) Try that version? I just unzipped the contents (using 7zip) to c:\tools; no install needed.  I'll try the latest beta against my files.
PowerShell,3duoy8,midnightFreddie,1 point,Mon Jul 20 15:43:25 2015 UTC,"It still works for me with this ffmpeg: http://ffmpeg.zeranoe.com/builds/win64/static/ffmpeg-20150720-git-9ebe041-win64-static.7z  Your test images are on a K: drive...is that network? Try running against a local drive. I wouldn't think this would matter, but I'm not seeing where the problem is. All my files are on C:."
PowerShell,3duoy8,midnightFreddie,1 point,Mon Jul 20 15:50:54 2015 UTC,"Ok I see a problem. I don't see where it is, but I see that it exists. I've been running my own code in my own session. I just copied and pasted it from this thread, saved it in a new location and ran it from a new Powershell session and it failed. Working on finding out why..."
PowerShell,3duoy8,houstonau,1 point,Mon Jul 20 15:54:46 2015 UTC,"https://raw.githubusercontent.com/midnightfreddie/theinternets/master/ffmpeg-timelapse.ps1  Ok, if I run this in Powershell ISE it works, but if I run it in regular Powershell it doesn't work. I've heard of this before.  Try running from Powershell ISE, and I'll see if I can remember what the difference is. Something about run mode or thread mode or something."
PowerShell,3du5wn,LtLawl,5,Sun Jul 19 14:33:24 2015 UTC,How about using start-process?
PowerShell,3du5wn,GoonerGuru,4,Sun Jul 19 16:43:21 2015 UTC,Hi!  There are usually better options than invoke-item. Take a peak at this wiki.  Invoke-Item basically launches a file with the default program.  Cheers!
PowerShell,3du5wn,ramblingcookiemonste,-2,Sun Jul 19 15:06:26 2015 UTC,"Thank you! This is very helpful.  I haven't gotten yet mostly because of the stupid $computer variable I'm trying to use.  Getting close using..     $Args = @('-c:', '-h:', '-m:', -a:1', '-md:', '-x:')"
PowerShell,3du5wn,activeknowledge,2,Sun Jul 19 18:18:02 2015 UTC,"Is there anything preventing you from using Start-Process? I use that exclusively in a function I had to create in order to invoke an EXE with arguments. There are a few resources on MS/Stack Overflow about it, I'd link them but I'm on mobile.  Good luck!"
PowerShell,3du5wn,activeknowledge,-2,Sun Jul 19 19:07:36 2015 UTC,"Nope, I'm just pretty new at Powershell and don't know what I'm doing.  $Computer = Read-Host ""Computer Name"" $Args1 = @('-c:', '-h:', '-m:') $Args2 = @(' -a:1', '-md:', '-x:') Start-Process '\server\folder\notakeylogger.exe' $Args1$Computer$Args2  Nailed it. Thanks guys."
PowerShell,3du5wn,Frequentsy,1 point,Sun Jul 19 19:18:28 2015 UTC,"Cool! Make sure to check out the ProcessStartInfo class in .Net, as it will allow you to control how that process is invoked in case you do have any restrictions down the line. Learning how to instantiate .Net classes using New-Object is a great skill to learn to open yourself up to the power of the .Net framework in PowerShell. Have fun learning!"
PowerShell,3du5wn,ramblingcookiemonste,1 point,Sun Jul 19 19:30:03 2015 UTC,What about notakeylogger.exe --% -c: -h: -m:$computer -x:
PowerShell,3du5wn,midnightFreddie,2,Sun Jul 19 16:09:01 2015 UTC,"You can't use --% in that situation. --% tells PowerShell to revert to old school non-powershell parsing after that operator. $computer would be meaningless in that context. If you set an environment variable beforehand, you could use %someEnvironmentVariable%  Omitting that though, yeah, that would work, given that there's no space in the path.  #Space in the path? Quote the path, use &  & ""\\server\folder\notakeylogger.exe"" -c: -h: -m:$computer -x:  # No space in the path? Don't quote it, just run it. \\server\folder\notakeylogger.exe -c: -h: -m:$computer -x:   Cheers!"
PowerShell,3drm4w,blood_baron3,11,Sat Jul 18 20:00:59 2015 UTC,"Check this out: https://technet.microsoft.com/en-us/library/Ff730952.aspx  Edit: this is for balloon tips, not toasts."
PowerShell,3drm4w,ficuswhisperer,1 point,Sat Jul 18 20:50:23 2015 UTC,Awesome find.  It works for me on a Windows 7 system.
PowerShell,3drm4w,34door,1 point,Sat Jul 18 21:39:26 2015 UTC,"Do WinForms popups appear as native notifications in Windows 8? I had thought about posting a link to that, but I wasn't sure how it would look."
PowerShell,3drm4w,nemec,3,Sun Jul 19 04:32:01 2015 UTC,Yeah toast notifications are doable but tricky.   https://github.com/guitarrapc/PowerShellUtil/blob/master/Windows8Toast/Windows8ToastTest.ps1 looks like a promising start. At least it will point you to the right APIs.
PowerShell,3drm4w,ficuswhisperer,5,Sun Jul 19 05:54:41 2015 UTC,"This thread made me realize that I have a number of scripts I'd really like to get Toast Notifications from. A lot of googling and reading of comments here and I started working on a script (eventually it'll be packaged as a module), BurntToast  The thing with these notifications are that they require an AppId of for a shortcut on the start screen (but not needed to be pinned.) I'm using the ID of powershell.exe. I've tested this on three PCs so I don't think the ID changes from system to system, but I'll make grabbing/setting the Id on the fly possible in a later revision.  In Windows 8 the notification will include the icon for the specified app (hence why I chose PowerShell), but this is currently absent in Windows 10.  Default template used is the one where there is an image, the first line is bold and the second line wraps onto the third, but you can specify which template you want.  Example:  New-BurntToastNotification -Image 'c:\images\random.png' -FirstLine 'Random Background Job' -SecondLine 'You background job has finished. This text is really long and wraps to the third line.'   (And yes, I will include an alias of New-ToastNotification eventually)  Edit: Now a module."
PowerShell,3drm4w,WindosBK,2,Sun Jul 19 09:53:16 2015 UTC,this is really cool thanks for sharing!
PowerShell,3drm4w,nemec,3,Sun Jul 19 23:38:14 2015 UTC,"From what I've read, only desktop apps can create toasts (not scripts), but you could try interfacing with this .Net library from PS. If all else fails, I've seen recommendations to compile a simple exe that takes in title, body, image as its inputs and creates the toast for you.  You could also try Pushbullet, but it doesn't use the built-in notification system."
PowerShell,3drm4w,catacombkid1,2,Sat Jul 18 20:53:07 2015 UTC,"Definitely seconding PushBullet. Use the API to get notified for script output. Mine are mostly for ""Job Complete"" and ""Torrent Done"""
PowerShell,3drm4w,jonconley,1 point,Sun Jul 19 03:36:44 2015 UTC,"Same here. We have notifications on Pushbullet, Boxcar, Growl/Prowl via powershell. Very easy to set up. Notifications on pc/mac/phone/web/iOs device, etc.  I agree that native would be a plus, too, though."
PowerShell,3dsqdw,nik_41tkins,1 point,Sun Jul 19 02:25:31 2015 UTC,I don't get what the purpose is here other than you are just sharing it. Does the function not work or are you trying to get around locked files?
PowerShell,3dsqdw,ShwnStrmn,1 point,Sun Jul 19 07:47:44 2015 UTC,This is just part of a larger script that I am having some issues with open file locks and deleting files.  The larger script has a scriptblock which is run on a remote system via invoke-command.   I have to copy a large amount of data over a WAN link and the time it take to copy 100`s of basically 10MB CSV files is currently unacceptable I am using some built in .net 4.5 functions from the class system.io.compression to compress the files into one zip and then the main portion of the script moves the file from Remote Server -> Application Server.  There is where the problem was yesterday and I just got around it by adding 15 second sleep statements between closing file and trying to move it.  I also have the same issue when I am uncompressing the files locally and trying to delete/move the zip. This function is a slightly more robust solution to that problem and I will be bolting it on the the larger script today.  The only people who may find this useful is when you need to delete a file -Force parameter is not cutting it.
PowerShell,3dr573,Taiman,1 point,Sat Jul 18 17:36:11 2015 UTC,"In the installation phase check to see if the program is installed. If not, run the installer; if it is, exit."
PowerShell,3dr573,Freon424,1 point,Sat Jul 18 17:45:41 2015 UTC,Yeah but I'm just not sure how I could do that in powershell?                 [string]$installPhase = 'Installation'      $apptoinstall = get-itemproperty hklm:\software\microsoft\windows\currentversion\uninstall\* | select UninstallString | where { $_.UninstallString -match “mymsi”}     if (!$apptoinstall) {     # Install the base MSI and apply a transform     Execute-MSI -Action Install -Path 'mymsi.msi' -Transform 'msitransform.mst'     # Install the patch         Execute-MSI -Action Patch -Path 'mymsipatch.msp'
PowerShell,3dr573,Freon424,1 point,Sun Jul 19 02:20:41 2015 UTC,"Instead of looking for the MSI in Uninstall, check for the DisplayName instead of your app instead. Also, you're missing a closing bracket at the end."
PowerShell,3dr573,Freon424,1 point,Sun Jul 19 13:14:59 2015 UTC,The only reason I'm suggesting the DisplayName is in case the MSI is misconfiguring it's MSI Uninstall string.
PowerShell,3dr573,houstonau,1 point,Sun Jul 19 13:22:31 2015 UTC,"Ok cool thanks good to know.  I've cheated to get it working straight away.  Launch with bat:  if exist ""c:\domain\programx.txt"" goto skip @powershell -ExecutionPolicy Bypass -File Deploy-Application.ps1 :skip exit   and in ./Toolkit\AppDeployToolkit\AppDeployToolkitMain.ps1  If ($installSuccess) {         If (Test-Path -Path $regKeyDeferHistory -ErrorAction 'SilentlyContinue') {             Write-Log -Message 'Remove deferral history...' -Source ${CmdletName}             Remove-RegistryKey -Key $regKeyDeferHistory -Recurse             **Copy-Item n:\repository\programx.txt c:\domain             Write-Log -Message 'Copied programx.txt' # programx.txt**         }   I'll keep playing when I have more time.  Thanks for your help."
PowerShell,3drlsg,root-node,2,Sat Jul 18 19:57:57 2015 UTC,"You could use a HashTable instead:  function Expand-PoundSign {     [CmdletBinding()]      param(         [Parameter()]         [string]$Line = '<tr><td class=""line"" colspan=""5"">#</td></tr>',          [Parameter(Mandatory=$true)]         [ValidateSet('acc','com','drv','net','reg','sec','sys','vrt')]         [string]$Abbreviation     )      $Dictionary = @{         'acc' = 'Accounts'         'com' = 'Compliance'         'drv' = 'Drives'         'net' = 'Network'         'reg' = 'Regional'         'sec' = 'Security'         'sys' = 'System'         'vrt' = 'Virtual'     }      return $Line.Replace('#',$Dictionary[$Abbreviation]) }   And then use it like this:  PS C:\> Expand-PoundSign -Abbreviation reg <tr><td class=""line"" colspan=""5"">Regional</td></tr> PS C:\> Expand-PoundSign -Line '<span>#</span>' -Abbreviation drv <span>Drives</span>   etc."
PowerShell,3drlsg,PowerShellStunnah,1 point,Sat Jul 18 20:21:29 2015 UTC,"I use hash tables a lot in my script, I never thought to use it for this.  Thanks"
PowerShell,3drlsg,PowerShellStunnah,1 point,Sat Jul 18 21:29:23 2015 UTC,"I ended up with this, much smaller, and cleaner.  Thanks  $dictonary = @{'acc' = 'Accounts'; 'com' = 'Compliance'; 'drv' = 'Drives'; 'net' = 'Network';     'reg' = 'Regional'; 'sec' = 'Security'  ; 'sys' = 'System'; 'vrt' = 'Virtual';     'ahs' = 'AHS Specific'; } [string]$line = '<tr><td class=""line"" colspan=""5"">' + $dictonary[$inputItem] + '</td></tr>' Return $line"
PowerShell,3drlsg,midnightFreddie,4,Sat Jul 18 21:49:51 2015 UTC,You could also use the -f operator:  $Line = '<tr><td>{0}</td></tr>' -f $dictionary[$inputItem]
PowerShell,3dqnpi,mathui,8,Sat Jul 18 14:51:42 2015 UTC,Because foreach is an alias for ForEach-Object only when used in a pipeline.  http://blogs.technet.com/b/heyscriptingguy/archive/2014/07/08/getting-to-know-foreach-and-foreach-object.aspx
PowerShell,3dqnpi,PowerShellStunnah,1 point,Sat Jul 18 15:06:17 2015 UTC,Busted! Thanks.
PowerShell,3dq7ps,Finbel,3,Sat Jul 18 11:24:02 2015 UTC,I normally use xampp portable when I need a local quick webserver
PowerShell,3dq7ps,neztach,1 point,Sat Jul 18 11:34:57 2015 UTC,"Thank's for your reply! It also turned out that I forgot to close and re-open powershell (which you need to do when adding new path-ways to the environment variable).  Now I have some other issue with ""CLI stopped working"" but I'll prolly delete this thread."
PowerShell,3dq7ps,GoodShitLollypop,2,Sat Jul 18 11:39:38 2015 UTC,Thank's     COMPILER ERROR: UNFAMILIAR USE OF PUNCTUATION
PowerShell,3dq7ps,Keninishna,1 point,Sat Jul 18 23:27:52 2015 UTC,What? Thank's: short for thank is?
PowerShell,3dq7ps,GoodShitLollypop,0,Sun Jul 19 10:02:32 2015 UTC,you could always just install ubuntu on the new computer.
PowerShell,3dq7ps,midnightFreddie,1 point,Sat Jul 18 16:15:04 2015 UTC,Yeah but I thought that I've paid for windows now and I might as well learn it since I might very well come to work in a Windows environment in the future.    It turned into a different problem but I eventually got it working through this: http://stackoverflow.com/questions/31491276/php-cli-has-stopped-working/31491992#31491992
PowerShell,3dq7ps,GoodShitLollypop,1 point,Sat Jul 18 17:47:25 2015 UTC,VMware workstation
PowerShell,3dq7ps,Did-you-reboot,4,Sat Jul 18 23:28:22 2015 UTC,"Actually, Win8 and later have Hyper-V built in. And besides, Vagrant is the ""cool"" thing now."
PowerShell,3do01i,anonymousamish,38,Fri Jul 17 20:48:02 2015 UTC,out-gridview
PowerShell,3do01i,graemejevans,12,Fri Jul 17 20:57:47 2015 UTC,"Can't upvote this hard enough, apart from  out-gridview -passthru    http://blogs.msdn.com/b/powershell/archive/2007/12/17/out-gridview.aspx?PageIndex=2  http://blogs.msdn.com/b/powershell/archive/2009/03/12/out-gridview-revisited.aspx http://powershell.com/cs/blogs/tips/archive/2012/08/21/out-gridview-grows-up.aspx"
PowerShell,3do01i,butthole-scientist,3,Fri Jul 17 21:16:59 2015 UTC,"Wow, I've always known about out-gridview, but not -passthru. That's awesome."
PowerShell,3do01i,neilthecellist,1 point,Sat Jul 18 16:05:10 2015 UTC,Thank you! This is very helpful.
PowerShell,3do01i,Dizzybro,2,Tue Jul 21 08:21:02 2015 UTC,My god.
PowerShell,3do01i,EL337,1 point,Sat Jul 18 15:27:28 2015 UTC,get-awesome | ogv
PowerShell,3do01i,WindosBK,61,Sat Jul 18 00:10:39 2015 UTC,Test-ComputerSecureChannel -Credential example.com\admin -Repair  It's actually shocking how much time this has saved me... I wish I knew about it when I was working helpdesk.  It repairs the trust relationship between a computer and the domain. Without requiring a reboot.
PowerShell,3do01i,sooka,6,Sat Jul 18 02:32:31 2015 UTC,What?! I've always ended up rejoining the computer to the domain to solve this.
PowerShell,3do01i,jakesomething,2,Sat Jul 18 16:37:26 2015 UTC,"You can also use the ADUC ""Reset Account"" option when you right click on the computer giving you the error."
PowerShell,3do01i,sooka,1 point,Mon Jul 20 22:49:03 2015 UTC,"thank you for the suggestion, I'm a local IT and do not have access to Active Directory (I'm in ""read mode only"")."
PowerShell,3do01i,occamsrzor,4,Tue Jul 21 20:10:39 2015 UTC,I believe you have won all the internets for today
PowerShell,3do01i,jsmcnair,2,Sat Jul 18 20:09:18 2015 UTC,Nice!
PowerShell,3do01i,nits3w,2,Sat Jul 18 07:55:15 2015 UTC,That is awesome.  Wish I could upvote harder.
PowerShell,3do01i,midnightFreddie,2,Sat Jul 18 14:17:38 2015 UTC,Need a button technology that understands enthusiasm.
PowerShell,3do01i,Quicknoob,2,Sun Jul 19 17:22:25 2015 UTC,This is awesome!  Thank you.
PowerShell,3do01i,jmulvey,23,Sat Jul 18 16:37:27 2015 UTC,"I find Get-Member (alias: ""gm"") essential when interrogating an object for what other methods or properties exist, that I might not know about.  Example:  $x = ""hi there"" $x | Get-Member   -or-  $x = ""hi there"" $x | gm   Now I know all the things I can do or see with $x."
PowerShell,3do01i,LordZillion,2,Fri Jul 17 21:47:23 2015 UTC,The only thing that bugs me sometimes is that you have to use -Force to actually get ALL the things you can do with it.
PowerShell,3do01i,Ch13fWiggum,1 point,Sun Jul 19 10:52:31 2015 UTC,"So much this, if you start looking at stuff with .net it makes life so much easier"
PowerShell,3do01i,creamersrealm,1 point,Fri Jul 17 22:12:32 2015 UTC,Get-Member is absolutely great! I used it today when writing a reporting script for SCOM. Plus it great for troubleshooting when they abbreviate note propertys.
PowerShell,3do01i,Mindflux,1 point,Fri Jul 17 22:25:24 2015 UTC,What drives me whacky is $x | gm and gm -inputobject $x can give you entirely different results.   I've found articles on WHY but damn it's annoying.
PowerShell,3do01i,wtgreen,3,Fri Jul 17 23:47:03 2015 UTC,"Because a container object put on the pipeline is usually opened and the contents are sent down the pipeline instead.   So for instance if $x is an array, when $x | gm is executed, the elements of $x are put on the pipeline so gm displays their properties, not the properties of $x.  Since gm -input $x doesn't use the pipeline, gm interrogates $x directly."
PowerShell,3do01i,EL337,12,Sat Jul 18 15:42:01 2015 UTC,"PS Profiles.  Every time i launch PS, my profile imports a bunch of modules I wrote for common tasks and daily use in my job.  It also sets some other stuff like window/buffer size, location, and additional alias', etc.    My $Home drive is on a network share, so my PS profile and modules follow me to any domain pc.  It's amazing.    Check out this The Scripting Guy post for great info on PS Profiles."
PowerShell,3do01i,theseb,7,Sat Jul 18 00:09:25 2015 UTC,"Overriding the prompt() function is also extremely handy. Right now, my prompt shows me my current user context, current connected machine, current directory, and if I've got connections to other places based on a number of custom factors. Also, the time!  Putting this in your profile means your PS prompt is always customized to how you want it, showing you information relevant to you."
PowerShell,3do01i,astraljack,3,Sat Jul 18 00:55:59 2015 UTC,I'm interested in doing exactly this. How is yours set up?
PowerShell,3do01i,evetsleep,0,Sat Jul 18 03:25:11 2015 UTC,Take a look at Get-Help about_Prompts.  A lot of good stuff in there.
PowerShell,3do01i,switchbladecross,13,Sat Jul 18 14:49:05 2015 UTC,"While there are definitely other good ones here I would have mentioned,  seeing as I am later to the party...  | Clip   Will place command output to the Windows clipboard."
PowerShell,3do01i,rug-muncher,4,Sat Jul 18 02:44:20 2015 UTC,This works in standard cmd if people did not know. I.e 'ipconfig /all | clip'
PowerShell,3do01i,Honkykiller,2,Sat Jul 18 07:28:09 2015 UTC,"4 years of windows IT, 4 F**KING YEARS, I honestly had no idea about this.  If I had reddit gold, I'd give it to you guys."
PowerShell,3do01i,halr9000,7,Mon Jul 20 14:12:09 2015 UTC,ii .   Is nifty.
PowerShell,3do01i,8375456,3,Sat Jul 18 04:19:15 2015 UTC,What does it do?
PowerShell,3do01i,kivle,3,Sat Jul 18 12:52:55 2015 UTC,"ii = Invoke-Item  ""Invoke-Item ."" opens explorer at the current directory"
PowerShell,3do01i,dji386,2,Sat Jul 18 13:32:56 2015 UTC,Or ii anyfile.ext
PowerShell,3do01i,ekulnz,2,Sat Jul 18 07:29:09 2015 UTC,zomg its the start . of cmd .. ty!!
PowerShell,3do01i,Sinisterly,7,Mon Jul 20 07:52:16 2015 UTC,Ctrl-J in the PowerShell ISE
PowerShell,3do01i,jfractal,2,Fri Jul 17 22:08:49 2015 UTC,So... What does it do?
PowerShell,3do01i,Sinisterly,2,Sat Jul 18 17:44:46 2015 UTC,"When you're in the scripting pane, ctrl-J brings up a list of snippets that you can pop into your script (functions, loops, conditionals, etc.). Really helps ensure you get the syntax right."
PowerShell,3do01i,ShwnStrmn,1 point,Sat Jul 18 21:36:14 2015 UTC,Ctrl-J in the PowerShell ISE   Even better when you make your own!
PowerShell,3do01i,siecer,1 point,Fri Jul 17 22:12:41 2015 UTC,Had no idea this existed.  Thanks!
PowerShell,3do01i,evetsleep,7,Sat Jul 18 00:17:06 2015 UTC,Since I didn't see it mentioned yet here is my absolute favorite one:  #<Some string><tab for results>  Searches your PowerShell history for matches.  For example:  Get-ChildItem c:\temp\ cls   Now type in #temp and then tab through the results.  By far my favorite PS CLI trick and one that I use daily to find stuff I did an hour ago where I only know part of the line\string.
PowerShell,3do01i,weedv2,1 point,Sat Jul 18 14:44:41 2015 UTC,This is really handy! My guess is that # invokes a sort of string search from the contents of Get-History and you can then press Tab to cycle through the result.
PowerShell,3do01i,KevMar,5,Sat Jul 18 14:57:39 2015 UTC,Loading.net assemblies
PowerShell,3do01i,techstress,5,Fri Jul 17 23:03:21 2015 UTC,"ForEach-Object   and a close second on 2003/XP:   Get-WMIObject   Bam, power beyond control with those commands. Not so much a tip or trick to any of us. But man, give those to a new guy. Let those click and you see the light bulb go on."
PowerShell,3do01i,KevMar,1 point,Fri Jul 17 23:10:40 2015 UTC,"regarding foreach-object, less typing with the default alias %  '$x|% { ..do stuff.. }'"
PowerShell,3do01i,1RedOne,8,Fri Jul 17 23:24:10 2015 UTC,A cool tip is that there are some situations where you can even drop the $_ and {}  $x | % tostring  ls | % length
PowerShell,3do01i,KevMar,2,Sat Jul 18 00:32:07 2015 UTC,Shut the front door! How did I not know about this?
PowerShell,3do01i,i_me_me,2,Sat Jul 18 04:48:34 2015 UTC,We tend to learn the more advanced stuff from people that blog and share a lot of code. It is kind of an expectation that they don't use shorthand notation like this. It tends to confuse new scripters.  I found it by reading the language specification and had the same reaction you did.
PowerShell,3do01i,evetsleep,4,Sat Jul 18 10:51:10 2015 UTC,Just don't put it in anything that you save that others may use/edit
PowerShell,3do01i,da_chicken,3,Sat Jul 18 03:59:39 2015 UTC,^ This X1000.  When I see this in scripts that I code review it really makes me grumpy.
PowerShell,3do01i,zaboobity,5,Sat Jul 18 14:51:01 2015 UTC,"I'm not writing the aliases here, but I do use them.  Get-Help -ShowWindow Get-Help -Online   Open help in another window.  No more scrolling the current window back up just to see the doc!  $x | Get-Member   Pretty obvious.  First thing you should learn about learning to teach yourself Powershell.  $x | Format-List -Property *   Gets you the values, which is often very useful.  $x.GetType().Fullname   Copy the type name, Google it, and pull up the MSDN doc.  Powershell tends to truncate the actual object name much too often.  Also useful when you want to instantiate a new object of the same type.  Also, taking the type name and typing in:  [<Typename>]::   And then hitting tab a bunch to see what methods and properties are exposed on the type this way.  Try it with [System.Math]::!  Indeed, even typing:  [<partial type name>   And hitting tab to do completion just to see what types exist is often great.  For the stuff I do with databases, learning that [System.Nullable[datatype]] exists and [System.String]::IsNullOrEmpty() has been very helpful.  If you've ever done this:  [int]$x = $null   And been irritated that $x is now 0, you'll understand what I mean."
PowerShell,3do01i,BoardWithLife,1 point,Sat Jul 18 01:32:32 2015 UTC,Get-Help <cmdlet-name> -ShowWindow  Get-Help <cmdlet-name> -Online   Wow. Cannot believe I haven't used these before... ty!
PowerShell,3do01i,IamBabcock,2,Sat Jul 18 03:31:10 2015 UTC,I like to get help and then pipe to clip while in the ISE and paste to the script pane. Makes it easy to read and copy the examples.
PowerShell,3do01i,Fridge-Largemeat,5,Sun Jul 19 12:49:41 2015 UTC,This thread just confirmed how much I still need to learn about powershell.  =(
PowerShell,3do01i,midnightFreddie,3,Sat Jul 18 01:52:04 2015 UTC,Learn get-command and get-help and you'll be able to teach yourself with less Google
PowerShell,3do01i,IamBabcock,2,Sat Jul 18 11:05:42 2015 UTC,If you already knew it all then you'd be at your top potential pay right now. So this is good news.
PowerShell,3do01i,Frequentsy,1 point,Sun Jul 19 17:23:57 2015 UTC,I just feel like I know next to nothing when reading these. Good stuff to start looking at though.
PowerShell,3do01i,IReallyHadToComment,4,Sun Jul 19 17:32:27 2015 UTC,"Using ""--%"" after external commands to pass through parameters that have complex syntax."
PowerShell,3do01i,RiPont,4,Sat Jul 18 02:04:29 2015 UTC,Try{} Catch{} Finally{}
PowerShell,3do01i,mautobu,4,Sat Jul 18 07:20:57 2015 UTC,"[CmdletBinding] and all the stuff in advanced_parameters for writing scripts.  Array slicing.  Say you've got $allRecords and it's got 200,000 items in it.  You want to play with the next step in your script, but you don't want to actually try it on all 200,000 records  $sample = $allRecords[3..10] $sample | fl *   And then there's the awesome power of writing your own functions that take pipeline input with BEGIN / PROCESS / END.  Makes efficiently chugging through mass amounts of data so easy.  Edit:  Oh, and one more.  All hail [pscustomobject].  All the ""but bash is so much better than anything on Windows"" parrots live out their sorry little lives thinking ""everything is a string"" is a modern and useful concept.  How about ""everything is an object"", eh?  So in general in powershell, you Import into objects at the first step, do all your processing, then Output or Write back to strings as your final step.  Sometimes, you're stuck dealing with string data from multiple sources that you want to stick into one object.  Or you've got objects that have properties you don't want and other properties you wish they had but can calculate.  [pscustomobject] to the rescue!  Turn any hashtable into an object.  Let's say you wanted to associate each file in a directory with a random number and export it to a CSV with exactly 3 columns.  $files = ls | ForEach-Object { $f = $_;  $r = Get-Random; [pscustomobject]@{""Name""=$f.Name; ""rand""=$r; ""CreationTime""=$f.CreationTime} $files | Export-Csv ""StupidHomeworkAssignment.csv"" }"
PowerShell,3do01i,jsmcnair,9,Sat Jul 18 17:51:29 2015 UTC,Get-help
PowerShell,3do01i,citruspers,2,Fri Jul 17 21:47:14 2015 UTC,Get-Help <command> -ShowWindow  Or  Get-Help <command> -Online  Good for reference while you're writing out a command
PowerShell,3do01i,dcpDarkMatter,2,Sat Jul 18 07:56:53 2015 UTC,Also: get-help command -examples
PowerShell,3do01i,sid351,3,Sat Jul 18 10:19:03 2015 UTC,"Being able to pass in a stored, secure password into PS' Get-Credential command.  My company finally segmented administrative rights away from all users, including us admins.  With the amount of AD moves or changes I do daily, typing in my user name/password was eating up more time that I could really spend.  I've created the function below to eliminate the need once the file is set up correctly.  Function Get-LogonInfo {     If (Test-Path ""$env:HOMEDRIVE\FileName.txt"") {     $UserName = ""$env:USERDOMAIN\a-$env:username""     $Pass = Get-Content ""$env:HOMEDRIVE\FileName.txt"" | ConvertTo-SecureString     $Global:Cred = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $UserName,$Pass         } Else {     $Global:Cred = Get-Credential $env:USERDOMAIN\a-$env:username     } }"
PowerShell,3do01i,dcpDarkMatter,5,Sat Jul 18 03:20:44 2015 UTC,"Careful. Your password in cleartext is a simple $Cred.GetNetworkCredential().Password away (might have typo'd - on mobile, will check later and confirm).  Edit: Came back later and fixed my typo."
PowerShell,3do01i,midnightFreddie,1 point,Sat Jul 18 05:45:11 2015 UTC,"Yeah, it's inherently partly insecure, so I do as much obfuscation as possible by using read-host -assecurestring | convertfrom-securestring | out-file FileName.txt and storing it in an out of the way location."
PowerShell,3do01i,sid351,1 point,Sat Jul 18 11:16:10 2015 UTC,"But only if they do it on your login. That's what's cool about it. You could `Export-CliXml' the credential and post it on the internet and nobody (non-government, anyway) could get your password from it.  It's as secure as anything else you do while you're logged in."
PowerShell,3do01i,BoardWithLife,1 point,Sun Jul 19 17:26:11 2015 UTC,"It's also only that user on that PC that can decrypt it, but my point was that a credential object isn't as secure as you might initially think, nor are SecureStrings (as objects anyway) because of the GetNetworkPassword() method."
PowerShell,3do01i,hypercube33,1 point,Sun Jul 19 20:38:04 2015 UTC,"I have $Cred = Get-Credential in my ISE profile. It prompts me every time I start a new session, but I always have it available for any work I do that day."
PowerShell,3do01i,tehjimmeh,3,Sun Jul 19 12:54:44 2015 UTC,"-whatif  Shows you what would happen if the command ran, great to test out and not poop all over your system if you fat-finger something.  http://www.computerperformance.co.uk/powershell/powershell_whatif_confirm.htm"
PowerShell,3do01i,techstress,3,Sat Jul 18 07:27:25 2015 UTC,"$env:PATH -replace "";"",""`n"""
PowerShell,3do01i,uspeoples,2,Sun Jul 19 18:04:25 2015 UTC,copy ise settings to another profile  $path = (resolve-path -Path $env:localappdata\microsoft_corporation\powershell_ise*\3.0.0.0).Path  Dir $path explorer $path #then copy user.config there
PowerShell,3do01i,Vortex100,2,Fri Jul 17 23:43:54 2015 UTC,. .\yourscript.ps1 will pass that scripts variables and their values to the PS command line. This is great for troubleshooting.
PowerShell,3do01i,captainironhulk,2,Sat Jul 18 05:59:32 2015 UTC,"For the amount I use it, It's gotta be calculated properties on a select-object statement. Simple example:  get-wmiobject -Class Win32_PerfFormattedData_PerfProc_Process | select-object -property Name,@{N=""CPU"";E={$_.PercentProcessorTime}},@{N=""PID"";E={$_.IDProcess}},@{N=""WorkingSet (MB)"";E={""{0:N2}"" -f ($_.WorkingSet/1MB)}}"
PowerShell,3do01i,EL337,2,Sat Jul 18 10:29:30 2015 UTC,Calculated properties. https://technet.microsoft.com/en-us/magazine/ff394367.aspx  And filters. https://4sysops.com/archives/the-powershell-filter
PowerShell,3do01i,midnightFreddie,2,Sat Jul 18 19:05:45 2015 UTC,"Searching for WMI classes  gwmi -li * | ogv   you can then use the filter to search WMI classes by keyword, or use the keywords in the search e.g.  gwmi -li *printer*"
PowerShell,3do01i,Waxmaker,2,Sat Jul 18 21:37:18 2015 UTC,"Object pipelining.  If you're storing input/output in variables or writing out formatted text, stop it now. If you craft your scripts to emit objects you have a lot more extendability, flexibility, scalability, and resource efficiency.  Many, many code examples consist of creating an empty array and adding to it for output and/or formatting output string lines. Putting that data into objects and emitting them is much better. Also in most cases stop foreach ($item in $items) {} as that implicitly waits for the $items variable to be complete—and fully in memory—before commencing the loop. Piping objects to Foreach-Object {} starts the loop when the first object arrives."
PowerShell,3do01i,midnightFreddie,1 point,Sun Jul 19 17:31:52 2015 UTC,"Not necessarily. Pipelining objects requires extra processing overhead, and if your data set is sufficiently large (reading large text files, log files, or large AD or SQL queries), you may find that pipelining slows your scripts down significantly rather than the reverse. Best to stay flexible and use different methods as appropriate. Measure-Command is your friend there.  http://powershell.com/cs/blogs/tobias/archive/2010/11/30/speeding-up-your-scripts.aspx"
PowerShell,3do01i,Waxmaker,1 point,Mon Jul 20 17:49:45 2015 UTC,"if your data set is sufficiently large (reading large text files, log files, or large AD or SQL queries), you may find that pipelining slows your scripts down   Speed is not the only constraint. The problem with foreach ($item in $items) {} is that it loads $items fully into memory before processing. If your data set is truly large then you're taking up lots of memory to process a loop. Pipelining inherently allows parallel processing, too. With pipelining the process loop can be processing and outputting while the input stream is still collecting.  Certainly there is always by-case needs, but the problem I see most often here is that data sets are so big it takes up all available memory and/or takes so long because the input collection, processing and output are three separate flows that have to wait for the previous one to complete.  That linked article gives sub-second examples. I don't think it's very relevant to real-world large-dataset issues."
PowerShell,3do01i,mrcrassic,2,Mon Jul 20 18:22:36 2015 UTC,"Easily view useful information about all properties on any object using the hidden '.psobject.properties'.  Example:  $user = Get-ADUser Administrator -Properties * $user.psobject.properties | Select Name, Value, TypeNameOfValue, isSettable   Knowing exact property types helps avoid tricky edge cases with improper type casting and assists in designing functions that only accept parameters in the correct type.   ""IsSettable"" often returns useful information about what can and can't be set manually."
PowerShell,3do01i,real_parbold,2,Mon Jul 20 18:33:03 2015 UTC,$ofs
PowerShell,3do01i,mrcrassic,2,Fri Jul 17 23:15:01 2015 UTC,"I had to google this ..  http://blogs.msdn.com/b/powershell/archive/2006/07/15/what-is-ofs.aspx  PSMDTAG:FAQ: What is $OFS  $OFS is a special variable that contains the string to be used as the Ouptut Field Sperator.   This string is used when an array is converted to a string.  By default, this is "" "" but you can change it."
PowerShell,3do01i,SteveMI,1 point,Mon Jul 20 12:49:24 2015 UTC,"So I used $OFS a lot before I learned about Join-String because it was a really fast (albeit dangeorus) way to concatenate a serialized array; it's probably faster than Join-String since it doesn't have the overhead of getting passed into a cmdlet, but the speed-up is insignificant most times"
PowerShell,3do01i,Skibo1219,-4,Mon Jul 20 13:40:39 2015 UTC,To use it.
PowerShell,3do3q0,LtLawl,2,Fri Jul 17 21:17:15 2015 UTC,"Remove ""Format-Table"" from the end of your New-Object line, like so:  New-Object -TypeName PSObject -Property $Properties | Format-Table   You're using formatting cmdlets too early.  Put Format-Table outside the loop and you'll get what you're looking for.   Filter Left, Format Right"
PowerShell,3do3q0,speeding_potato,0,Sat Jul 18 02:11:39 2015 UTC,WOW.  Thank you !!
PowerShell,3do3q0,techstress,1 point,Sat Jul 18 04:11:57 2015 UTC,worth a read  Technet Windows PowerShell: Filtering and Formatting Data
PowerShell,3dnkqs,scotchlover,2,Fri Jul 17 18:53:17 2015 UTC,"You already have a where clause; just add another for the name. I like this better than wildcards/filtering in the original gci cmdlet; anecdotal evidence tells me the pipelining and where-object are more efficient at scale.  | Where-Object { $_.Name -like ""pattern*"" } |   or  | Where-Object { $_.Name -imatch ""^pattern"" } |   Edit: If you're only removing empty folders, why keep -Recurse on Remove-Item? Might as well take it off. Remove-Item is working on a stream of file(folder) objects and will delete everything it's passed without the -Recurse."
PowerShell,3dnkqs,midnightFreddie,1 point,Fri Jul 17 19:36:06 2015 UTC,"I had -Recurse in place because there could be nested folders that are empty within the directory. This way multiple passes would ensure that they are cleared out, unless I don't need that."
PowerShell,3dnkqs,FiordlandPenguin,1 point,Fri Jul 17 20:16:22 2015 UTC,you could do something like this:     (Get-ChildItem C:\test\null -r -Filter 'ss*'| ? {$.PSIsContainer -eq $True}) | ? {$.GetFiles().Count -eq 0} | Remove-Item -WhatIf
PowerShell,3dnkqs,techstress,1 point,Fri Jul 17 19:18:25 2015 UTC,"i did something similar today  gci $paths -Directory|% { write-host ""$($_.fullname) - $((gci $_.fullname).count)""     if ($((gci $_.fullname).count) -eq 0) {          remove-item $_.FullName}     }"
PowerShell,3dnp7h,ShiftNick,1 point,Fri Jul 17 19:26:12 2015 UTC,"Hello, you will need one that sends keys  I know this is a PowerShell subreddit - but I could suggest AutoIt, this has SendKeys feature - and - a wait window event (load I.E wait until page has loaded)   that said  [void] [System.Reflection.Assembly]::LoadWithPartialName(""'Microsoft.VisualBasic"") [Microsoft.VisualBasic.Interaction]::AppActivate(""Test.ps1 - Notepad"")  [void] [System.Reflection.Assembly]::LoadWithPartialName(""'System.Windows.Forms"") [System.Windows.Forms.SendKeys]::SendWait(""ABCDEFGHIJKLM"")   from https://technet.microsoft.com/en-us/library/ff731008.aspx"
PowerShell,3dogly,chrono13,3,Fri Jul 17 23:02:30 2015 UTC,"Hi!  It looks like you figured this out on your own, nice job!  So, long story short, Select-Object does not return the same type of object.  Details:   Run Get-Help Unlock-ADAccount -full. Look at the pipeline details for each parameter. Notice that the only pipeline input is Identity, and this is by value (i.e. not a property name, but an object type). Run Get-Member against raw Search-ADAccount output. Now run it against Search-ADAccount piped to Select-Object. You will find the type has changed to Selected.OriginalTypeName.   Here's an example with a FileInfo object:  get-item C:\windows\explorer.exe | gm      # TypeName: System.IO.FileInfo  get-item C:\windows\explorer.exe | select -Property * | gm      TypeName: Selected.System.IO.FileInfo   That's pretty much it. By selecting an object, you've destroyed any ability to pipe it to a command you want to use with pipeline input by value.  You can still send these to functions that run pipeline input by property name.  You can get around this I suppose... Can't test this out, but something like this might work:  Search-ADAccount -LockedOut |     Select-Object * |     Out-GridView -PassThru |     Foreach-Object { Unlock-ADAccount -Identity $_.DistinguishedName -WhatIf }   Cheers!"
PowerShell,3dogly,ramblingcookiemonste,1 point,Sat Jul 18 19:24:44 2015 UTC,The error in this case is: Unlock-ADAccount] The input object cannot be bound to any parameters for the command either because the command does not take pipeline input or the input and its properties do not match any of the parameters that take pi peline input.
PowerShell,3dogly,midnightFreddie,1 point,Fri Jul 17 23:10:21 2015 UTC,"Simplified: Search-ADAccount -LockedOut | Select-Object * | Unlock-ADAccount -WhatIf  Any Select-Object breaks using the object. I suspect it is recreating the object and omitting necessary data that Unlock-ADAccount uses, but I can't find out what or why."
PowerShell,3dntkm,rug-muncher,2,Fri Jul 17 19:58:32 2015 UTC,"I had a similar requirement and I just built myself a function to generate a random password and check it against several regexes. With the -complex switch, this gives one upper case letter, one lower case letter and one digit for a password of given length:  function Get-RandomString {     Param (         [Parameter(             Position = 0,             Mandatory = $false         )]         $Length = 20,         [Switch]$Complex     )     $Rng = New-Object System.Security.Cryptography.RNGCryptoServiceProvider     $Sb = New-Object System.Text.StringBuilder     $Bytes = New-Object byte[] ($Length * 2)     $Rng.GetBytes($Bytes)     for($i = 0; $i -lt $Bytes.Length; $i += 2) {         $SubBytes = $Bytes[$i..$i+1]         # Limiting the possible values to only 32 through 126 for useful ASCII values         $Char = [BitConverter]::ToUInt16($SubBytes, 0) % 95         # Shift to the useful ASCII values         $Char += 32         $Sb.Append([char]$Char) | Out-Null     }     $Rtn = $Sb.ToString()     if($Complex) {         $Chk = 0         if($Rtn -match ""[A-Z]"") { $Chk++ }         if($Rtn -match ""[a-z]"") { $Chk++ }         if($Rtn -match ""\d"" ) { $Chk++ }         if($Chk -lt 3) {             $Rtn = Get-RandomString $Length -Complex         }     }     return $Rtn }"
PowerShell,3dntkm,LandOfTheLostPass,1 point,Fri Jul 17 20:49:35 2015 UTC,"Thanks. I would not be able to come up with something like that yet :). I'll try implement some of this in my script.  I was going to go with the easy option of just re-running the script to make sure all passwords are OK, as it only fails 1/5 times."
PowerShell,3dntkm,LandOfTheLostPass,1 point,Sat Jul 18 17:30:47 2015 UTC,"I was going to go with the easy option of just re-running the script to make sure all passwords are OK   That's actually what I am doing in this script (sort of).  The lines  if($Chk -lt 3) {     $Rtn = Get-RandomString $Length -Complex }   essentially test if the password generated meets the complexity requirements and if not, just reruns the function recursively and passes the result of that run up.  Since each run of the function runs that check, it'll recurse until it gets a valid result.  Technically, this means that you could end up in an infinite loop (e.g. $Length = 2 and $complex = $True); but, it seems like such a ridiculous edge case to bother testing for."
PowerShell,3do685,mastamind229,3,Fri Jul 17 21:36:44 2015 UTC,"I think the issue stems from a domain user logging into a local PC is not using the local security authority subsystem of the local PC. They're logging into a DC and just accessing the PC, so the properties you're looking into in the WMI class you referenced are empty.  Try this script:  https://gallery.technet.microsoft.com/scriptcenter/Get-LastLogon-Determining-283f98ae#content  It's basically checking the Win32_UserProfile class and returning when the profile was last used, which will often be the last logged on user. Network logons will make this not 100%, but it may lead you to the info you're looking for.  Note: when I downloaded this script via the download link, there were some odd encoding issues with the .ps1 file and text. I'd recommend you copy/paste the scriptblock below the download link and paste that into the console or a new .ps1 file and use that."
PowerShell,3do685,zaboobity,1 point,Sat Jul 18 05:03:33 2015 UTC,This works great. Thank you.
PowerShell,3do685,creamersrealm,1 point,Sat Jul 18 06:23:06 2015 UTC,Get-aduser properties lastlogontimestap  Take that data value from the timestamp and parse it like this.  I'm not on a computer so use auto fill if need be.  You can also use this with get-adcomputer  Is this what you were looking for?
PowerShell,3dle5r,neilthecellist,5,Fri Jul 17 05:26:16 2015 UTC,Get-Content. Foreach. Pipe to Out-File. Convertto-HTML. Pipe to Out-File.  Can probably be done in a one liner.
PowerShell,3dle5r,topherrr,1 point,Fri Jul 17 06:27:12 2015 UTC,"Hi topherrr, thank you very much for your help on this. This actually helped, and I was able to use the Get-Help CMDLET -ex  to make my own workable code happen.  Best, Neil"
PowerShell,3dle5r,Not2original,3,Sun Jul 19 01:44:54 2015 UTC,"Use the Powershell help 'examples' for Get-content, Foreach, and out-file"
PowerShell,3dle5r,highfiveman27,3,Fri Jul 17 12:07:24 2015 UTC,Mind if I ask what class you are in? I'm having trouble learning powershell on my own and I think taking a class at the local community college could help me.
PowerShell,3dle5r,Shadowspot,1 point,Fri Jul 17 13:03:45 2015 UTC,I take Intro to Powershell at Estrella Mountain Community college in Arizona. It's part of the Maricopa Community Colleges network. CIS121AH is the class number. Recommend Wolfe as professor.
PowerShell,3dle5r,the_spad,-2,Sat Jul 18 04:47:37 2015 UTC,From what I see you haven't been paying attention in class lol. If you already have a list of file names in a text file all you would need to do is get-content of the file list store it in a variable and than loop through with a for loop and write-host the file names
PowerShell,3dle5r,chreestopher2,2,Fri Jul 17 05:58:08 2015 UTC,"Well, a foreach loop. You could probably even pipeline it but I can't remember off the top of my head if New-Item accepts pipelined input or not."
PowerShell,3dle5r,da_kink,2,Fri Jul 17 06:04:39 2015 UTC,"wether it does or not, parenthetical expressions can allow any cmdlet to take pipeline input, by explicitly expanding the property you want to use as input to the cmdlet arguments....  Also, foreach and write-hosting wont redirect to a file  Write-host = dead puppies, deformed unicorns write-output = Happy puppies, beautiful unicorns spreading double rainbows across the universe!"
PowerShell,3dle5r,dogfish182,-6,Fri Jul 17 14:22:58 2015 UTC,"$files = get-content files.txt $filescreated = @()  Foreach($file in $files){ New-item -name $file -path somewhere $filescreated += $file }  New-item -name html -path somewhere Add-content ""html body etc""    For each line in $filescreated{ Add-content ""<li>$line</li> }  Add-content ""html closing tags etc""  Is my first guess."
PowerShell,3dle5r,Already__Taken,3,Fri Jul 17 06:21:34 2015 UTC,didnt he specifically ask for not answers?
PowerShell,3dle5r,da_kink,1 point,Fri Jul 17 14:51:49 2015 UTC,"That's fine, this is not a good way to go about this problem."
PowerShell,3dle5r,dogfish182,1 point,Fri Jul 17 17:07:55 2015 UTC,I can guarantee that it will most likely not work.
PowerShell,3dltev,danblank000,1 point,Fri Jul 17 08:49:11 2015 UTC,X-post Subreddit Link: /r/ExchangeServer
PowerShell,3dltev,XPostLinker,1 point,Fri Jul 17 08:54:09 2015 UTC,"This thing is stupid. If it can't send a link to the actual post, there's not much point in sending a link to the sub when it's mentioned in the subject line."
PowerShell,3dltev,DueRunRun,1 point,Fri Jul 17 18:23:35 2015 UTC,"For anyone interested, the offline address book also needed updating."
PowerShell,3dltev,justthisgreatguy,2,Fri Jul 17 09:12:51 2015 UTC,The OAB updates itself once every 24 hours IIRC. If you have a small office you can get everyone to force an update but in the gran scheme of things you just have to let it happen naturally
PowerShell,3dltev,stupidusername,1 point,Fri Jul 17 09:18:08 2015 UTC,You really have to weigh the benefit of clearing these users from everyone's address immediately versus the amount of work required to rebuild the oab and push out an update.  Frankly I'd pass. They'll be gone tomorrow on their own.
PowerShell,3di6hm,ramblingcookiemonste,8,Thu Jul 16 13:52:30 2015 UTC,"Hi all!  Version Control systems are becoming more and more important in the world of IT. You can use this for config files, scripts, tools, you name it; heck, I got started using GitHub to track changes for a school project and related materials.  In the PowerShell community, we're seeing it grow in prevalence as well. Microsoft actually open sourced the DSC Resources, and many community PowerShell projects are hosting their code on solutions like GitHub.  We're also seeing more solutions and tools that assume you have a version control system in place. Declarative configuration management solutions like DSC, moving towards Infrastructure-As-Code, and continuous integration and delivery (CI/CD) all pretty much require a version control system.  Watch the CI/CD space, I have a feeling this might help motivate IT to use version control; for example, I can push a change to a PowerShell module or script, a CI/CD solution will see this, run some Pester tests, and deliver it if they succeed (perhaps copying to a network share). No interaction whatsoever on my part, I just commit the code to version control : ) A few links to CI/CD posts are included at the repo.  So, back to the submitted link... Gave my first webinar Tuesday; was both terrifying and fun! The link is to a GitHub repository that includes the presentation slides and notes, demo notes, links to references, and a link to the youtube video on PowerShell.org's Youtube Channel.  I mentioned a few updates in the 'notes' section of that GitHub page:   The description of HEAD was a bit shaky. Feel free to check out the resources I provide, but there's a good chance you won't need to know what HEAD is. For most use cases, including contributing to the DSC resources, you can forget nearly all of the branch / HEAD discussion. Just know that for the MS DSC Resources, you need to work on the dev branch and submit your pull request (proposed changes) to Microsoft's dev branch. I mentioned that there weren't many options for a Windows based Git server. Turns out I was wrong, SCM-Manager looks interesting. If you're a non-profit or charitable organization, do consider Atlassian's community license, Stash and other solutions might be free for you : )   Cheers!"
PowerShell,3di6hm,gwyden,2,Thu Jul 16 13:52:38 2015 UTC,We were the team that suggested SCM-Manager to you.  It is fanastic  and works very well for us. Great presentation all around.
PowerShell,3di6hm,ngetchell,1 point,Fri Jul 17 01:46:36 2015 UTC,The talk was great Warren.
PowerShell,3di6hm,begoodnow,1 point,Thu Jul 16 20:33:39 2015 UTC,Thanks for sharing! I can't wait to check all of this out (Yay for ro-Friday)
PowerShell,3di6hm,ButterCupKhaos,1 point,Thu Jul 16 22:35:16 2015 UTC,"Can't wait to watch, we should throw up a sidebar/wiki link to some shared DSC resources. More tutorials/resources in this space will hopefully get Windows SysAdmins on board."
PowerShell,3di6hm,tangobravoyankee,1 point,Fri Jul 17 02:46:19 2015 UTC,"I've got a few resource suggestions. Free private hosting is available from Atlassian BitBucket (5 users) and Fogcreek Kiln (2 users). For self-hosting, Atlassian Stash is installable on Windows and only $10 for the first 10 users.  I also think that Subversion is worth a look for SCM newbies. I think it has a lot less friction for people who just want to get the benefits of an SCM without thinking too much about it."
PowerShell,3di6hm,tangobravoyankee,1 point,Fri Jul 17 13:28:48 2015 UTC,"Thanks for sharing! Yeah, that's a solid offering from BitBucket, assuming you're comfortable using a hosted service and you don't plan to scale beyond 5 (or you want to get folks used to it, and sell them later!). You also have a spot to push to if China continues shenanigans against GitHub.   Not sure about Subversion though : ) I know it's a bit simpler, but... that comes at a cost. Maybe I drank the Torvalds koolaid, but I tend to agree with him on centralized version control systems - there's no room for them. Particularly when a distributed version control system can still allow for a central source of truth.  Initial thoughts:   It's subversion. We also tend to avoid deploying Server 2003 : ) It's subversion. At some point, you'll move to a better solution, and need to re-learn the operational bits, and learn the new distributed architecture bits, etc. Same goes for any system, but it will happen sooner than later with subversion, a legacy VCS using an outdated architecture. It's subversion. If you choose this, folks on your team who are actually interested in using version control, and who might already be using it... might not be happy. I can tell you I would not be happy if someone had rolled out a subversion system rather than Stash here : )   Sorry! Not trying to be harsh, and I might be way off base. I just started imagining subversion being pushed at $work and it got me a bit worked up, because I'm stubborn : P  Cheers!"
PowerShell,3di6hm,alabamachaser,1 point,Fri Jul 17 14:44:32 2015 UTC,Linus is a very special case. Open Source and other large-scale development efforts are a special case. There are several great reasons for them to choose a DVCS over a centralized SCM.   Most everyone else ends up using a DVCS exactly like it was a centralized SCM. Git isn't doing anything for them that Subversion couldn't. The rest of Atlassian's stack works just as well with Subversion as Stash/Git. There's no special class of tools that only work with Git -- if something doesn't also support Subversion there is a competing product that does.  Getting people to start using an SCM is far more important than the particular software they choose.
PowerShell,3dkb60,houstonau,4,Thu Jul 16 23:26:29 2015 UTC,You might just want to use powershell to perform the FTP actions  https://stackoverflow.com/questions/1867385/upload-files-with-ftp-using-powershell  I believe there's even someone who wrote a module to work with FTP.
PowerShell,3dkb60,Stoffel_1982,1 point,Fri Jul 17 07:28:14 2015 UTC,"I had looked into that module, and there is also another one floating around Technet as well that does something similar. Our web proxy seemed to mess with requests using the .NET methods but not with the FTP.exe method.  My other comment."
PowerShell,3dkb60,chriswastaken,3,Sun Jul 19 23:01:36 2015 UTC,This is tough to think about because it absolutely depends on the way the ftp -s: parses the incoming information. If it's looking for a file system then it'll error getting a string.
PowerShell,3dkb60,nakade4,1 point,Fri Jul 17 04:47:54 2015 UTC,"True, a simple string doesn't suffice. I was thinking there might be some mechanism that I wasn't aware of, like parsing it through a PS Provider or .NET provide to creat like a 'virtual file' if you know what I mean? It's a hard thing to try and describe.  It's working for me at the moment but was just a curiosity!"
PowerShell,3dkb60,nakade4,2,Fri Jul 17 05:03:05 2015 UTC,"Just tried a quick experiment to use Named Pipes (i.e. \.\pipe\houstonau) but ftp.exe failed trying to open the named pipe  Would take /u/stoffel_1982's suggestion of doing this natively through PowerShell, however instead there's a module here on TechNet's gallery that does the hard lifting for you, unless you prefer the .NET System.Net.FtpWebRequest module (if it works, it works!)  https://gallery.technet.microsoft.com/scriptcenter/PowerShell-FTP-Client-db6fe0cb  sample code:  Import-Module PSFTP  Set-FTPConnection -Credentials mgajda -Server ftp://ftp.server.org -Session MyTestSession -UsePassive  $Session = Get-FTPConnection -Session MyTestSession   New-FTPItem -Session $Session -Name TestRootDir  New-FTPItem -Session $Session -Name TestDir1 -Path /TestRootDir  New-FTPItem -Session $Session -Name TestDir2 -Path /TestRootDir  New-FTPItem -Session $Session -Name TestDir11 -Path /TestRootDir/TestDir1   Get-FTPChildItem -Session $Session -Path /TestRootDir -Recurse -Depth 2   ""Test File"" | Out-File TestFile.txt  Get-ChildItem TestFile.txt | Add-FTPItem -Session $Session -Path /TestRootDir  Get-ChildItem TestFile.txt | Add-FTPItem -Session $Session -Path /TestRootDir -Overwrite  Get-ChildItem TestFile.txt | Add-FTPItem -Session $Session -Path /TestRootDir/TestDir1   Get-ChildItem TestFile.txt | Add-FTPItem -Session $Session -Path /TestRootDir/TestDir2 -BufferSize 5  Add-FTPItem -Session $Session -Path /TestRootDir/TestDir1/TestDir11 -LocalPath TestFile.txt"
PowerShell,3dkb60,alcaron,1 point,Fri Jul 17 16:39:15 2015 UTC,"I encountered a problem with using the FTP module and even the built in .NET webrequest.  We are running ContentKeeper appliances as our web proxy and it seems to intercept FTP requests and proxy them, returning it's own HTTP page, rather than an actual FTP session. I haven't had time to dig further into it but I needed this script to be super portable so hard coding exceptions into CK wasn't going to work.  The CK issue didn't seem to exist with the FTP.exe method so I just went with that for expedience.  I might revisit once I have time (in the middle of a VoIP roll out at the moment).  Thanks for the write up though!"
PowerShell,3dkb60,RiPont,1 point,Sun Jul 19 23:00:07 2015 UTC,"Understandable.. wonder if it's because of Internet Explorer settings (i.e. FTP proxy is set due to GPO, and .NET framework honoring that setting)  I vaguely recall FTP.exe didn't pay attention to that... more testing required indeed..."
PowerShell,3dkjda,ekulnz,2,Fri Jul 17 00:36:47 2015 UTC,"Oh god, not the eventlog...anything but that, lol...  Honestly in this case you are probably going to need to call wevutil to do the work. I don't think the PS cmdlets for the eventlog (if they are even on the OS you are using) do an export in that format."
PowerShell,3dkjda,alcaron,1 point,Fri Jul 17 00:41:23 2015 UTC,"This grabs the application log the day before, so If i did this on Monday, it would grab the log from Sunday. The query part just google wevtutil and look it up. I think this is the easiest way, so just use wevtutil it runs in powershell so why not? BTW I don't think Get-winevent export as evtx.  $hostname = $env:computername $after = (Get-Date).AddDays(-2).ToString(""yyyy-MM-d"") $before =  (Get-Date).AddDays(-1).ToString(""yyyy-MM-d"") $filename = $hostname+""_application_"" +$before+ "".evtx"" $query = ""/q:*[System[TimeCreated[@SystemTime>='$($after)T16:00:00.000Z' and @SystemTime<='$($before)T16:00:00.999Z']]]"" wevtutil epl Application c:\temp\$filename $query ""/ow:true"""
PowerShell,3dkjda,jc1412,1 point,Fri Jul 17 08:21:26 2015 UTC,Thank you for your reply. I have done some research have written a similar script.. It amazes me that Powershell V5.0 is about to come out and this functionality is still not there  thanks again
PowerShell,3dkjda,PowerShellStunnah,1 point,Fri Jul 17 10:33:11 2015 UTC,"Instead of wevtutil, you could use EventLogSession.ExportLogAndMessages:  $ES = New-Object System.Diagnostics.Eventing.Reader.EventLogSession $ES.ExportLogAndMessages(""Application"",""LogName"",$query,""C:\temp\$filename"")"
PowerShell,3dkjda,PowerShellStunnah,1 point,Fri Jul 17 10:35:05 2015 UTC,"Hmmm  PS C:\Windows\system32> $ES = New-Object System.Diagnostics.Eventing.Reader.EventLogSession $ES.ExportLogAndMessages(""Application"",""LogName"",$query,""C:\temp\$filename"") Exception calling ""ExportLogAndMessages"" with ""4"" argument(s): ""The specified query is invalid"" At line:2 char:1 + $ES.ExportLogAndMessages(""Application"",""LogName"",$query,""C:\temp\$filename"") + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : NotSpecified: (:) [], MethodInvocationException     + FullyQualifiedErrorId : EventLogException"
PowerShell,3dk7s6,tech4edu,3,Thu Jul 16 22:58:54 2015 UTC,"Somewhere someone out there is teaching PS and telling people that you need to expand ALL THE THINGS...you really don't. :)  Get-ChildItem ""C:\Users"" -Exclude @(""Public"",""Default"") | Copy-Item -Path <source> -Destination $_.FullName""\Desktop""   You can make that into a scriptblock and pass it to Invoke-Command if you want, even -AsJob it to do it asynchronously."
PowerShell,3dk7s6,alcaron,2,Fri Jul 17 00:37:03 2015 UTC,"Maybe it's something I don't know about (wouldn't be the first time) but you reference: ""$_"" without a foreach, does that work?"
PowerShell,3dk7s6,LordZillion,1 point,Fri Jul 17 08:39:09 2015 UTC,"Hah! No, long day...good eye...  Get-ChildItem ""C:\Users"" -Exclude @(""Public"",""Default"") | %{ Copy-Item -Path <source> -Destination ($_.FullName+""\Desktop"") }"
PowerShell,3dk7s6,alcaron,2,Fri Jul 17 13:12:09 2015 UTC,"I'm doing something similar to copy a test shortcut to each profile desktop.  I need the test shortcut so I can use another script I wrote that will match old server paths and replace with new server paths for every single lnk file on any user desktop.  Basically, if the user has a lnk file pointing at the old server location it will replace the unc and share portion of the string with the new paths and share.  It works flawlessly and I can update the target path of lnk files matching my old server share.  I've done enough testing and will likely deploy across 900 computers over the weekend.  My users wont even know their public folder shares have moved.  Im not at work to share my code but basically, I export a computer ou container to a text file.  The script then hits each computer in order, exporting a list of c:\user directories.  This is my user list for that computer.  I have a foreach loop applied to the computer list with an inner for each loop applied to the user list.  The script recreates the user list for each new computer.  The inner foreach loop running against the user list gets each shortcut and does a regex match against a string containing the old server path and shares..  If the LNK files TARGET path matches It replaces the old with the new and saves the lnk file before moving to the next lnk file."
PowerShell,3dk7s6,s3xynanigoat,2,Thu Jul 16 23:40:13 2015 UTC,"(Get-ChildItem C:\Users -Directory -Exclude ""Default"",""Public"") | %{$Path = ""$($_.FullName)\Desktop""; If ( Test-Path $Path ) { Copy-Item C:\test.txt $Path } }   Or with line breaks:  (Get-ChildItem C:\Users -Directory -Exclude ""Default"",""Public"") | %{       $Path = ""$($_.FullName)\Desktop""       If ( Test-Path $Path ) {           Copy-Item C:\test.txt $Path       }   }"
PowerShell,3dk7s6,Bongoots,2,Fri Jul 17 10:29:46 2015 UTC,"That works, thanks. I'll have to wrap my head around some it but I gave it a test run."
PowerShell,3dk7s6,LordOwnatron,1 point,Mon Jul 20 16:49:42 2015 UTC,Use group policy preferences to copy the file.
PowerShell,3dhwn0,logicaldiagram,5,Thu Jul 16 12:18:26 2015 UTC,"I have not taken it, but I've seen a sample question and it's not something you can guess your way through. You have one hour to write a script and it has to be completely correct. Some more information will be provided over the next couple issues of the  http://powershell.org/wp/newsletter/. Go sign up if you want to learn more and get some good study advice."
PowerShell,3dhwn0,michaelshepard,3,Thu Jul 16 13:46:34 2015 UTC,"I took it and passed back in march of 2013.  I thought the test was a good test of practical powershell skills, focusing on good scripting practice.  I can't give details on what was covered specifically due to the terms of the test, but I think if you know PowerShell well, you wouldn't have much trouble.  I was surprised when I heard that there was a low pass rate, but then again, I'm surprised by the PowerShell questions I see on stackoverflow every day."
PowerShell,3dhwn0,michaelshepard,3,Thu Jul 16 20:22:06 2015 UTC,"I should note that I didn't take it for interview purposes.  I've been in the same job for 15 years and use PowerShell often.  I had been teaching PowerShell and thought it would be a good test to make sure I was doing things the right way.  As the scripting games showed a couple of years ago, there was a huge difference between what different people thought was good PowerShell and best practices hadn't been established in the community.  Just kind of a level-check."
PowerShell,3dhwn0,PsTakuu,2,Thu Jul 16 20:25:23 2015 UTC,"Also I think you should check out these posts:  http://powershell.org/wp/2014/12/29/the-future-of-powershell-orgs-verified-effective-program/  http://powershell.org/wp/2015/06/02/verified-effective-self-assessment/  As far as I understand, the exam isn't even offered anymore and refunds were given if you hadn't taken the test as of February 2015.  If you hurry you might be able to sign up for the self-assessment.  edit* I know you were just looking for people who had taken it, but if your goal is to find out how you can pass it.. I don't even think that's an option anymore."
PowerShell,3dhwn0,alcaron,0,Thu Jul 16 20:41:45 2015 UTC,"If you are effective with Ps then I don't think you need an exam or an exam grade to fairly accurately guage a persons skill level when it comes to PS. My personal opinion is that certs are a great way for the people selling them to make money.  Never having seen the exam though, you can't really make a judgement about it, just, in general, I don't have a high opinion of certs."
PowerShell,3dhwn0,PsTakuu,1 point,Thu Jul 16 14:06:43 2015 UTC,"The cert is to get your foot in the door/prove to potential employers that you know how to work and have experience with a product.  Then at the interview you can flourish with all the stuff you actually know; the cert doesn't prove anything, but it does give you a better chance.  If certs were really just for making money, that industry would've fallen long ago.  I don't mean to argue but I do want people to know the value of certifications."
PowerShell,3dhwn0,alcaron,0,Thu Jul 16 15:56:21 2015 UTC,"I could not disagree more, I have zero certs and have never had a problem getting an interview (or a job). I have never been an interviewer in an instance where certs made or broke someones chances of getting their foot in the door.  The kind of people who will give you a shot because you have a cert are not the kind of people I want to work for.   If certs were really just for making money, that industry would've fallen long ago.   That is just you saying something, there is no evidence of that whatsoever. People buy into certs, there are a LOT of bad managers in IS, and certs, they think, do their job for them.  Though to be perfectly honest, the ""industry"" isn't doing as well as it used to, when 5 day MCSE bootcamps were something any ""serious"" IS person aspired to. I don't think there is a cert in our entire IS dept... And in large part because people realized that brain dumping your way into a cert, or even just having a lot of book knowledge doesn't yield a smart practical employee.  And aside from that, didn't they stop offering the exam because there wasn't a market for it?  Are there some places that certs will help you? Absolutely. I wouldn't work there though. And no amount of certs on your resume is going to do a better job than me sitting in front of you asking you practical, intelligent questions.  From both sides of the fence, certs are not worth the trouble. If you have the experience to legitimately pass the cert you have enough experience for the EXPERIENCE on your resume to matter much, much, more.  And you didn't have to pay someone for it."
PowerShell,3dhwn0,PsTakuu,3,Thu Jul 16 16:10:11 2015 UTC,"I still feel like you are bashing on certs more than is necessary.  Yes of course the people who know their worth, can prove it, and have the experience on their resume are going to get interviews and will have no issues.  The other portion of the IT population may need a resume booster to make up that lack of time spent with a product or in a certain area.  And with the type of recruiting that is done through hiring companies and hiring managers who are comparing hundreds of resumes... there's no way I'll be convinced that certs are not necessary.  It's totally fine that you personally do not value certs and I fully believe you have no problems at interviews with no certs (I'm in same boat), but I still gotta try to make it known that they aren't for nobody, they just may not be for everyone."
PowerShell,3dhwn0,alcaron,-2,Thu Jul 16 17:09:57 2015 UTC,"I still feel like you are bashing on certs more than is necessary.   And...I do not...   Yes of course the people who know their worth, can prove it, and have the experience on their resume are going to get interviews and will have no issues.  The other portion of the IT population may need a resume booster to make up that lack of time spent with a product or in a certain area.   Unless you believe certs mean you REALLY know something vs. are good at taking exams then what you are saying is effectively that certs are not for people who are good with...whatever the cert covers.  There is a reason why experience reigns supreme in IS and that is because you can't fake it, you can't cheat it, you can only marginally not deserve it above a certain level.   make up that lack of time spent with a product   For powershell this is ABSOLUTELY key. I do not know a single person who doesn't have either a) time with powershell or b) time with scripting/programming in general who should be hired to ""do powershell"".  If you want someone who is good with powershell, they NEED to have experience. I bet almost all of the people who passed that exam had enough experience with PS on their resume to show it without the cert.  If you want someone entry level who knows what PS is and wants to follow that path, again, the resume should have all that information right there in front of your face.   And with the type of recruiting that is done through hiring companies and hiring managers who are comparing hundreds of resumes   The type of recruiting? And you just hit on it once again, your resume is the most important part. The format first and foremost, and the content second (which is dumb, yes, but how it is).   there's no way I'll be convinced that certs are not necessary.   That is the definition of unreasonable, no argument could be made to sway your opinion...then why did you reply to me? To tell me I'm wrong and nothing I say can change that?  How many people have you actually interviewed or hired btw? Because I'm sorry but I've sat interviews with both consulting firms and corporations and I'm telling you, only the ones with people who didn't know their a$$ froma  hole in the ground cared about certs.  And again, I can look around this room and see dozens of six digit and up heads, and not a single cert.  If your point is that certs are good for beginners...eh, maybe, still wont do half as much for you as learning how to interview well...if your point is that certs are good...nope.  And giving someone else money to do the least beneficial thing for your resume...sorry, don't see that as a good thing.  Focus on the format of your resume (no more than 2 pages, keep it succinct, MORE than one page, yadda yadda), the way you dress and the way you interview (confidence, knowing answers, not bs'ing when you don't know an answer) and you will get a job you are qualified for.  If you aren't qualified for it a cert may fool BAD managers into hiring you, but that is a strike against certs, not for."
PowerShell,3dhwn0,chreestopher2,3,Thu Jul 16 17:44:41 2015 UTC,"I agree that certs are not very important, but they do serve a few purposes, one being to allow a recruiter to place an arbitrary cutoff on the applications they have to read...   Also, this is a bit of a logical fallacy, you are assuming that only inexperienced people get certifications, and only to bypass having to get experience.  Basically Certs are a way to show that you care enough about what  you do to not only be good at it, and experienced in it, but to actually be willing to pay someone to sort of kind of validate it, even though that validation is pretty much crap.  If you have two potential candidates, experience matches up, resume formatting / content matches up ...  But one has a certification directly related to the position...  Who is most likely to get the interview first?  If you are The Most Highly Qualified candidate for a position that you apply to, you are probably applying for the wrong position."
PowerShell,3dhwn0,PsTakuu,2,Thu Jul 16 19:32:41 2015 UTC,Yea dude I'm with ya on all of that! Thanks for understanding :)
PowerShell,3dhwn0,alcaron,1 point,Thu Jul 16 20:37:02 2015 UTC,"one being to allow a recruiter to place an arbitrary cutoff on the applications they have to read...   How is it that I am very well employed and never even worried about my job through 08-09 without ever having a cert to my name?  I have never been a part of hiring or interviewing with anyone who cared. Yes, there are plenty of people who buy into certs and diplomas, and I've never met one of them that was worth a damn.  If your goal it to work for any old a-hole, then, yeah, a cert is going to help, it's a shortcut, plain and simple. You can work your way up, or you can get a cert and find an idiot who thinks it matters and then, you are now working for an idiot...  It's going to be rough on the liver but hey, you made it!   Also, this is a bit of a logical fallacy, you are assuming that only inexperienced people get certifications, and only to bypass having to get experience.   No I'm not. For starters, nobody I know has a cert, none of the people I work with, nor for, the people I know who run a consulting company, their staff, literally not a cert in sight...the fact there aren't certs for most areas of IS alone kind of makes relying on certs to discern skill impossible.  We are literally in a forum for a topic that has no reputable certs...nothing backed by the company who writes the software, the only one kind of sort of popular died out for lack of interest/validity.  I mean...come on...yet we are still arguing that certs matter. This entire FIELD is proof they don't. Because it survives just fine and dandy without it.   Basically Certs are a way to show that you care enough about what you do to not only be good at it, and experienced in it, but to actually be willing to pay someone to sort of kind of validate it, even though that validation is pretty much crap.   As I said in the other post, that is shit logic, it was applied to diplomas back in the day before everyone realized that all a diploma meant was you've been drunk, made some bad decisions and could take an exam or two.  I mean, for pete sake, if after four years of studying and exams the expectation is that you be ready for entry level what exactly do you think imparts great value to ONE test...?  Your logic was formed by the people who SELL certs, just like that logic back then was formed by people who sell diplomas.   Who is most likely to get the interview first?   Have you ever hired someone? There are studies that suggest the first person to get interviewed statistically is less likely to get the job. Not only that but you act like you interview one guy and if it seems legit, that is your person...it just doesn't work like that.  You interview people, you keep the submission window open, when you stop getting candidates you base your choice off the INTERVIEW.  If they both match up and cert boy knew his shit and the other guy BS'd you or couldn't answer the questions then there you go.   If you are The Most Highly Qualified candidate for a position that you apply to, you are probably applying for the wrong position.   What? We aren't talking about the helpdesk. At this level, you better know your shit, you better REALLY know your shit. You better know your shit better than EVERYONE else who applied.  That is just nuts..."
PowerShell,3dhwn0,chreestopher2,1 point,Thu Jul 16 23:11:05 2015 UTC,"Enjoy being the smartest guy in the room? probably in the wrong room.  Aptitude is vastly more important than experiential knowledge.  Applying for positions that give tons of room for the applicant to grow is very common, So is getting hired for them.  Im not saying a cert is everything, or that everyone should ""fake it till they make it"" or just get certs and not seek experience, but im saying It CAN make a difference, just because you are happy where you are at, doesnt mean you couldnt have been happier had you gotten called back by that company that automatically limits out candidates without the required certification, because as you have been so proud to mention, you dont have a single certification, how could you possibly know what it would be like to work for any of those companies?  A cert is not a complete replacement for experience, and skill obviously, and no one is saying that, but.... and this is the biggest point you dont seem to get:  People who are fresh into IT, with a cert, will have much more of a chance getting hired into a position that will let them start getting the experience they need to continue to grow as they desire than people who are fresh into IT without any certs.  To say that they are meaningless or worthless is not just nuts, but batshit crazy.  Just because they arent needed, doesnt mean they are worthless.  Of course its better to a have a more experienced candidate, with the same or greater aptitude and ambition than it is to have a less experienced candidate with a certification, but all the geniuses who are experts in their field, and are so amazing that certs are completely irrelevant, are like you, already happily employed. So to employers and potential employees, regardless of your inability to see it, Certifications can and do make a difference. I would rather have a go getter with a cert and little experience by my side any day, than to have to work with dinosaurs who already know everything, and are jaded as fuck.  btw, this is IT, your fucking nuts if you think everyone is an expert in whatever field they work in.... the industry as a whole is still figuring out how to do IT properly.  Do you go to an accountant without a degree? a doctor without one? yet they dont matter at all?   get over your opinion and admit they are at the absolute WORST case scenario marginally effective, and at BEST can dramatically speed up the path to your dream career, when used to get a foot in the door to a position you arent currently the most qualified for, but can very quickly become the best candidate they could have chosen if given exposure to the challenges."
PowerShell,3dhwn0,alcaron,1 point,Fri Jul 17 13:18:29 2015 UTC,"Aptitude is vastly more important than experiential knowledge.   Well since you've laid down the law...  Natural ability is good, proven ability to do something is better.   but im saying It CAN make a difference   And I have REPEATEDLY said likewise, it CAN make a difference, but the kind of person who will hire you or not based on a cert, is not someone I want to work for.   A cert is not a complete replacement for experience   Or a minor, partial, or any amount of replacement.   and this is the biggest point you dont seem to get:   Yeah that is my problem, I don't get it, I just don't get it, otherwise I would agree with you. The only reason I don't agree with you, because you are right and I am definitely wrong, is that I don't get something you get.   People who are fresh into IT, with a cert   Shouldn't have a cert...or the cert wasn't very hard to get, I mean, I'm sorry...really, again you guys don't seem to be playing in reality, the powershell.org cert (you know, the one we were talking about because it's the topic of the thread) was renowned for being very difficult to pass.  MCSE's were not known for being easy, CCNA's were not A+'s...if someone fresh into IS can pass them then what the fuck does that tell you about the cert? That literally just about anyone can get them.  Not to mention I have repeatedly also stated that MAYBE entry level is the difference, MAYBE that is where they MIGHT be worth it, but frankly at entry level you don't really need a lot and it STILL comes down to your experience and your interview. And you STILL aren't going to get ""weeded out by some HR person"".  You have to construct such a narrow hypothetical reality for certs to MAYBE be worth it and at the end of the day, it just isn't how hiring works.  Even on our helpdesk, a job posting gets listed, an application window established (say, two weeks) and HR just forwards the applicants resumes, the manager of the help desk determines who to interview and who not to.  And again I hate to keep beating a dead horse here but this place, my last place, over 40 help desk people (not including everyone who ever worked there) and not a SINGLE one of them have certs.  So again, you can hypothesize all you want, but in the real world, CERTS DON'T MATTER.   To say that they are meaningless or worthless is not just nuts, but batshit crazy.   Again with the ad hominem...thanks pal. :)  They are meaningless, and worthless, and aside from saying ""nuh uh"" you haven't made an argument for why that isn't true.   Just because they arent needed, doesnt mean they are worthless.   Batshit crazy huh...   So to employers and potential employees, regardless of your inability to see it   And regardless of reality wherein nobody has a cert...  Lemme ask you guys this, what certs do you have? Since they are so awesome, what certs do you have?  Oh shit, right, yeah not the least of which because we're talking about PS and there ARE no certs...  So again, what certs do you have, and how many people have you hired?  Me? None and ~15.   btw, this is IT, your fucking nuts   You are getting real fuckin' rude real fast and it's getting old, start acting like you can be civil or I wont bother replying anymore ok? I don't mind us disagreeing but I damn sure mind you being disrespectful about it. I don't talk shit about you or your job, I think you can do the same.   dinosaurs who already know everything, and are jaded as fuck.   Again, dancing a fine line pal, hysterical given I would love to see your face if you knew how old I was lol. Hahaha.   if you think everyone is an expert in whatever field they work in   Oh no, there are a TON of people in IS who shouldn't be in IS, and as I said before, certs are great for them.   Do you go to an accountant without a degree? a doctor without one? yet they dont matter at all?   Yeah because that is what I said, I said that because degrees in IS are nearly worthless and not sought after no degree for anything is worth it.  Try harder.   get over your opinion and admit they are at the absolute WORST case scenario marginally effective   Again, fuck me, fuck my opinion, I WILL agree with you, I WILL so help you GOD I will.   and at BEST can dramatically speed up the path to your dream career   You sound like a fucking ITT Tech commercial, and about as realistic as one too.  So I'll just keep sitting here being well paid surrounded by a complete dearth of people with certs and you can keep telling people to spend money they might not have on something people who interview people (like me) don't give two fucks about.  And lest you say ""its just you"" NOBODY, in all the times I've interviewed people, NOBODY has ever mentioned certs, not HR, not the others on the panel NOBODY.  It has literally NEVER come up."
PowerShell,3dhwn0,chreestopher2,1 point,Fri Jul 17 14:22:18 2015 UTC,"so which is, ""For starters, nobody I know has a cert, none of the people I work with, nor for, the people I know who run a consulting company, their staff, literally not a cert in sight...""  or ""I've known so many people who got their MCSE that couldn't admin their way out of a paper box it isn't funny, the only competent person I know who had an MCSE did so because his employer literally paid him to take a week off for a four day course and then paid for the exam, and he was good enough he didn't even need the course.""  I can no longer believe this is anything beyond you wanting an argument.  init before mention of ""know vs known"" bs  I know first hand, certificates have been very valuable for me, I was able to hire on as a field tech due to a cert I had that the company requires, and very quickly moved up to be in charge of monitoring, Tools, and Automation across all clients of a very large MSP... I now have the freedom and responsibility I desired in my career, a challenging workload that constantly changes, and wouldnt have been able to possibly get this opportunity at this company if it werent for the cert that I happenned to have, because i chose to get it, because it has value.  Yeah, it wasnt a powershell cert, and I didnt get hired on to do powershell, but I got my foot in the door because I had the required cert, and quickly moved up from foot in door to exactly where I wanted to be.... and I simply wouldnt have ever had this chance, without having that cert.  Thats at least one really awesome challenging place to work that requires everyone to have atleast one particular cert depending on what department they work in. You might not want to work for them, but i certainly love it. As do alot of the other employees I work with.   And are you completely ignoring Partner Programs?  We get tons of licensing benefits of various products due to our staffs amount of certifications from both vendor specific, and vendor neutral certification organizations.  The benefits to our company from partner programs, are so great, that the company pays for ANY certification  that is relevant to a workers responsibilities , as well as paying incentive bonuses of hundreds to thousands of dollars for the cert.  That is a big part of why lots of companies demand employees with certifications.  We literally get to make use of hundreds of thousands of dollars worth of products for our customers, free of charge, because of our certifications qualifying for partner programs.  I seriously wonder if you work in in-house IT for a non IT company? or if you work for a MSP?, or consultancey?, in the external IT services realm, with enterprise clients, certs are a big thing, I have only ever worked a few in house IT jobs, and earlier in my career, and do feel like in that niche, apprenticeship is more relevant and certs less of a concern, but I really dont have enough exposure to know if that is the case for sure"
PowerShell,3dhwn0,PsTakuu,2,Fri Jul 17 15:27:26 2015 UTC,"Unless you believe certs mean you REALLY know something vs. are good at taking exams then what you are saying is effectively that certs are not for people who are good with...whatever the cert covers.   I didn't say any of that.   I do not know a single person who doesn't have either a) time with powershell or b) time with scripting/programming in general who should be hired to ""do powershell"".   I'm sure there are lots of people who you haven't met who might fit that category...  Certs are good for proving knowledge.  Even if that's just enough knowledge to pass the test.  Maybe the person who just understands Cisco networking products doesn't want to have to work a low level networking job for 5-7 years before a company looking for an intermediate networking position 'requiring' that much experience.  Maybe there's a way to prove they know their shit even though they've only been on the job two years.  Of course experience is still king and they'll get that anywhere they are at.  Unless they want to get there sooner.     If you aren't qualified for it a cert may fool BAD managers into hiring you, but that is a strike against certs, not for   I'm not suggesting the cert allows people unqualified for a job to just get it.  I'm saying it can prove to employers that they are serious about their profession and have invested intellectual, and possibly monetary, efforts into acquiring it.  I'm on board with you that experience and resume are your first priorities.  I'm not on board with how you are being almost entirely dismissive of certs as a blanket statement.    Plus you then have those companies who, say, require a Bachelor's degree so that they can spout their X% of their company have higher education and blah blah.  Theoretically there will be a company out there that wants all their people to have certs :)    To tell me I'm wrong and nothing I say can change that?   I'm not saying you are wrong to think certs aren't good for you.  I'm not looking for you to change any of my opinions.  I'm saying that many people and businesses put time and effort into certs and hold value to them.    How about... ""For me, certs aren't necessary as I have X years of experience in this field with these products and currently I have no desire to be employed in something I'm not specifically trained in."" Great.  That workflow is pretty solid.  What about people working at a position that they need but not exactly what they want to do?  Still need the money for bills... Gotta get experience to get the job they want though.  Guess I can train myself and toss on resume.. oh but my current job has nothing to do with Y so they'll wonder how I learned that stuff, or potentially have my resume weeded out by some HR hiring person (I said potentially!).  Or cert over the top of it and solidify that you know and have a drive to do that stuff."
PowerShell,3dhwn0,alcaron,-1,Thu Jul 16 20:19:04 2015 UTC,"I didn't say any of that.   Which is why I didn't say you did.   I'm sure there are lots of people who you haven't met who might fit that category...   So, you think hiring someone with a cert who doesn't have on the job experience with PS or a background in scripting/programming is a good hire?  That makes you different from every recruiter (who wasn't desperate) I know and every interview panel I've been a part of, but ok.  If you wanted someone who was entry level, who you were willing to essentially pay to train on the job (and whom you wouldn't pay very much), sure, that is absolutely a thing that happens. Not really prime cert territory either though.   Certs are good for proving knowledge.   Again, just a statement, funny you should mention the king of brain dumps, CCNA, I guess the queen would be MCSE.  I've known so many people who got their MCSE that couldn't admin their way out of a paper box it isn't funny, the only competent person I know who had an MCSE did so because his employer literally paid him to take a week off for a four day course and then paid for the exam, and he was good enough he didn't even need the course.  So, for $5k his employer got...a whoooole lot of nothing...MS and the training course provider made out well in the deal.   Even if that's just enough knowledge to pass the test.   Which in the real world means that person can do fuck all for your business.   I'm saying it can prove to employers that they are serious about their profession and have invested intellectual, and possibly monetary, efforts into acquiring it.   You realize you are making the same busted ass argument about certs that people used to make about BS's in compsci right? That a BS meant that you were serious, check, that it meant you could stick with it, check, that you are willing to invest your own capital in it, check.  And again...if I was still at work I'd be sitting near some three dozen people with less than half a dozen diplomas amongst them and not a single one of those diplomas was IS related.   I'm not on board with how you are being almost entirely dismissive of certs as a blanket statement.   That is fine, but I'm not hypothesizing, I'm not saying ""maybe"" I'm not saying ""it can"" or ""it might""...I'm saying I have hired people (and I never once hired them alone), I HAVE gotten jobs, I DO work, and certs don't mean shit.  Yes, I understand why they are created, it is a REALLY good idea.  But it is virtually meaningless in practice and only serves bad managers and poor candidates. Anyone with a brain is going to be just fine (given they can actually do the job) if the person doing the hiring likewise has a brain in their skull.  And if you don't think that the person hiring and the person applying both need to have a brain in their skull for things to not suck...  shrug   Plus you then have those companies who, say, require a Bachelor's degree so that they can spout their X% of their company have higher education and blah blah.   ...you mean the ones only the shit IT people work for because they hear that and think ""you guys are fucking dumb...""?  They can do whatever they want, it's like tagging themselves as stupid, IF the market ever gets bad enough that I have no choice but to work for them, you know what, for my health I'd change careers, it wouldn't be worth the early grave.   Theoretically there will be a company out there that wants all their people to have certs :)   And in theory there could be employers who only employ wizards and if you don't know the secret handshake to gain access to the never-never they wont hire you.  Also, see above.   I'm not saying you are wrong to think certs aren't good for you.   Man, try to keep up, I didn't say certs are bad for me I said certs are bad, you said you disagree (which means you think that is wrong) and that you wont change your mind.   I'm not looking for you to change any of my opinions.    I kind of got that by the whole ""I wont change my mind"" thing, wasn't the point I was making really...  For context this is what was said...    there's no way I'll be convinced that certs are not necessary.   That is the definition of unreasonable, no argument could be made to sway your opinion...then why did you reply to me?  How about...   how about no because that isn't what I believe, I believe certs are a waste of time and money and only benefit the company doing the certification unless you are either a) hiring someone and you don't have the capability to determine if they are fit for the job or b) someone with no or little experience.  Also...   ""For me, certs aren't necessary as I have X years of experience in this field with these products and currently I have no desire to be employed in something I'm not specifically trained in.""   Should ANYONE be employed in something they are not trained in? I mean...really? You are a half step away from conflating a cert with training.  Again...if you have the ""training"" that will be reflected on your resume. Probably through experience (most people start out doing one thing and go from there, this is not strange or rare) and MAYBE through college courses (though again I still don't know anyone who doesn't walk into entry level out of college in IS, this isn't business management ffs).   That workflow is pretty solid.   That workflow? Really?   What about people working at a position that they need but not exactly what they want to do?   You mean like...everyone...ever...  My first job was working in a restaurant, I went from there to McDonalds and also worked as a part time web designer (you know, back when notepad was totally enough to do the job lol) do you think I liked flipping burgers? No. Shit even the web stuff was boring pretty fast, HTML wasn't super deep back then, CSS was this ""thing coming soon"" for the most part.  You think most of the jobs I had were the jobs I wanted? No, they were the jobs I needed to prove that I could do what I do know, where nobody questions me because if I was a fuckup I'd have been bounced by somebody by now.  I have sat neither at pay nor title for more than a couple of years since I started working. It's how things work.  If you don't like what you do, make moves to get to where you want to be, and before you say ""CERT!!!!"" again I would like to remind you that I neither have certs, nor a diploma, in fact I don't even have a HS diploma or a GED.  You do not need a cert for ANYTHING you described. If you want to spend your money on it that is fine, but again as a person who has hired people and currently works, a certification or a lack thereof has never, once, mattered.  No theories, no maybes, flat out, has not mattered.   Or cert over the top of it and solidify that you know and have a drive to do that stuff.   Again...you are just pretending like saying that makes it true. In EXPERIENCE, it never has.  Yeah, it's going to be hard to get into a career you want when your current career has nothing to do with it, but if you think joe iron worker is going to land a job doing automation for a company because he has no experience and a cert, you are delusional..."
PowerShell,3dhwn0,mav_918,1 point,Thu Jul 16 23:00:12 2015 UTC,"I'm sorry but I couldn't read your entire comment because it was too long but I think I understand what you are saying.  I would pose to you a question. What do you do to challenge yourself in your career? I believe if you are a driven person and find challenges on your own outside of your day to day duties that good for you! However, I believe certifications are a way to challenge yourself in IT because they keep you relevant. Experience is very important, don't get me wrong.. most companies pay for training but if they pay for it they expect you to get certified because it helps your company.   Just my 2 cents. I think they are both important but certifications only help you in your career. They are not worthless."
PowerShell,3dhwn0,alcaron,-2,Thu Jul 16 21:44:48 2015 UTC,"I'm sorry but I couldn't read your entire comment because it was too long   lol...ok...   What do you do to challenge yourself in your career?   I'm not even sure how you would answer that question, my career IS the challenge, I mean what do you do for a living? Do you make widgets? It's not like my job is to stamp out the same shape over and over, my job is literally ""nobody has a solution for this, but we need this to work""...   I believe if you are a driven person and find challenges on your own outside of your day to day duties that good for you!   Again...what do you do for a living? I have a folder chock full of solutions to problems that either a) nobody else has tried to solve or b) nobody else has solved, some of which, yes, were on my own free time, like the home automation stuff (voice stuff and weird crap like that, I bet most of that stuff has also been solved but is also being sat on lol). When I get bored, I look for a new job. Getting a cert just means that at some point you got bored and decided to learn how to take an exam, it tells me literally nothing else about you from a practical standpoint. Not how well you think on your feet, not how analytical you are, not how driven you are, not how adaptive you are, not how innovative you are. Nothing.  At least if I've seen you were in a job DOING this stuff for five years and when I ask you a question you don't either lie to me or start crying I can gauge your skillset.   However, I believe certifications are a way to challenge yourself in IT because they keep you relevant.   I'm confused, are they a way to challenge yourself or do they keep you relevant?  How does a cert developed years ago make you relevant with the new version of...whatever it is?  How does that make you more relevant than being able to answer a technically question in an interview?  Again if your point is that they benefit people without the knowledge to find good people of their own accord...ok, maybe, not even sure about that but again, why would you want to be in a position where you work for people who don't know as much as you?  Shit, it's bad enough as it is, I don't need to filter FOR technically deficient people.   Experience is very important...most companies pay for training...they expect you to get certified   a) no...experience is EVERYTHING... b) training -ne experience c) just based on the virtue of the fact you can get powershell training but not powershell certified kind of disproves that one.  And yes, I know, this post is too long for you to read. Luckily I type fast so I don't mind the wasted effort."
PowerShell,3dhwn0,mav_918,0,Thu Jul 16 22:31:17 2015 UTC,"Getting a cert just means that at some point you got bored and decided to learn how to take an exam, it tells me literally nothing else about you from a practical standpoint.   That is so far from the truth its scary. It means you care enough about your Career (not your job - there is a big difference between your career and your job) to learn enough about a particular technology to care about how the manufacturer of that technology says to do things.   I'm confused, are they a way to challenge yourself or do they keep you relevant?   They do both - you should take one sometime and learn how challenging they are. They keep you relevant because in IT technology changes everyday - certifications expire. They need to be renewed or you need to take a delta exam...  I think you are missing the point of a certification. Its not a magic piece of paper that gets you a job. Neither is a bachelors degree. Neither is experience. The truth is there is no magic piece of paper that gets you a job.   why would you want to be in a position where you work for people who don't know as much as you?    Sometimes the point of people hiring you is because they dont know as much as you. Thats why they hired you in the first place..   I'm sorry to say this but your posts are kind of brash and defensive about certifications in general. This debate happens in IT a lot and I know I'm not going to change your mind here on reddit. I would say that if your attitude about certifications is any reflection on your attitude in the workplace - you may need to make some adjustments."
PowerShell,3dhwn0,alcaron,-1,Thu Jul 16 23:33:32 2015 UTC,"That is so far from the truth its scary.   Followed by one persons interpretation of what certs symbolize...   to care about how the manufacturer of that technology says to do things.   uhhhhh...you do realize powershell.org isn't MS right? Not to mention, that argument, it isn't even an argument. So, you learned how a manufacturer (?) says to do things, ok...again, in what job is that useful? Low level crap, sure, but again might I remind you that you are in a thread discussing a cert from someone who ISN'T the ""manufacturer"", for a language which there IS NO cert.  So does that mean that nobody who does PS cares how MS says to do things? How would you even apply that to scripting? In a world full of unique tasks where nobody can even agree when you should and shouldn't use the pipeline...  And even then, lets say we've gotten past that.  So what?  Again, entry level, sure, yeah, you have a familiarity with this system, hooray. Now what are people actually paid to do? Use systems as they were intended when they work as intended? At entry level sure, but VERY quickly the job becomes ""this doesn't work as intended, make it work"".  I don't even know how you would apply ""how MS says to do things"" to PS.  Apparently neither do they, because there isn't a cert for PS from them.   They do both - you should take one sometime and learn how challenging they are.   lol   They keep you relevant because in IT technology changes everyday - certifications expire. They need to be renewed or you need to take a delta exam...   Ok so again aside from the fact we are once again talking in a PS forum where there literally is no cert, you just assume that a cert means you are current in this topic.  Which, is great...if the certs actually do that.  But they don't.  Or are you saying that in a world where, and I quote, ""IT technology changes everyday"" (p.s. what do you think the T stands for?) a cert, developed by a company, tested, written materials printed, etc. etc. etc. keeps pace with that...?  Even though the MCSE and CCNA (and the waning importance of certs literally across the board) speaks volumes to the contrary...  Sometimes the point of people hiring you is because they dont know as much as you. Thats why they hired you in the first place..   Sometimes the point of people hiring you is because they dont know as much as you. Thats why they hired you in the first place..   So your argument is that a certification is as good as having a person who knows a thing interview people...?  You so vastly overinflate certs it isn't funny.  And why don't you answer some of my questions? Like:  What do you do for a living? Why is your job not challenging? If it's not challenging why don't you get a better paying one that is? If it isn't challenging and you don't want a different one what good is a cert to you anyway? If it is challenging then what makes you think you are ready to move up if you are still challenged at your current level?  Where does a cert fall into that at all?   I'm sorry to say this but your posts are kind of brash and defensive about certifications in general.   Well that's just, like, your opinion man. Aside from the fact I find it kind of annoying I'm not allowed to have my opinion without the ""uh, just so everyone knows, this guy doesn't get certs, and I think it is important that people understand how valuable they are"" post, I really don't care.  Again, I have a well paying job, I'm good at what I do, I've been directly involved in the hiring process and have worked for at least two companies that, almost regardless of where you live on this planet you WILL have heard of them.  Defensive makes it seem like I have something to lose here. I don't. I come here to answer PS questions, I gave my opinion on these certs, and that wasn't ok, and replying is free so...  I mean, I'm sorry to say this but your comments kind of seem like you've never really been involved in hiring people.  Most of the comments I've seen in response to my statement read like someone who gives and gets advice on ""how to get an IT job""...even little things, like being ""filtered out by some HR person""...I'm absolutely sure that some place DO that. But I've yet to work for one, big and small HR's job was always to collect the resumes and pass them on, we decided who to interview and who not to, the only time HR tells us what to do is in regards to practices (no solo interviews) verification (in the applicants case, that their info is at least valid at-a-glance, in our case that we don't have some obvious conflict) and if there is some sort of blacklist (i.e. we excluded them because they worked with blah or we can't hire from blah).  Other than that, they do the paperwork, that is about it. We decide who to see, who to see again, who to hire.  And I would stress, again, that at entry level, things may very well be different, but at entry level, a cert and no experience a) has nothing to do with all the ""further your career"" crap and b) is almost ASSUREDLY just you being able to test well.   I would say that if your attitude about certifications is any reflection on your attitude in the workplace - you may need to make some adjustments.   That is a semi-polite way of going ad-hominem but the net effect remains the same. My job is fine thanks."
PowerShell,3dhwn0,mav_918,0,Fri Jul 17 00:32:41 2015 UTC,We obviously have completely different views of what to do in a career in IT. We are both entitled to our opinions and I just dont care enough to spend my free time replying to you tonight.
PowerShell,3dhwn0,alcaron,-1,Fri Jul 17 00:47:27 2015 UTC,He says while replying to me tonight...  Kind of surprised you passed up the chance to take another shot at my job...seems like an opportunity missed...
PowerShell,3djucs,techstress,2,Thu Jul 16 21:16:37 2015 UTC,Works in just about every Microsoft application. SSMS and VS for example.
PowerShell,3djucs,Raethrius,2,Thu Jul 16 21:19:37 2015 UTC,how the hell did i not know this?  lol.  thanks.
PowerShell,3djucs,GLiMPSEiNATOR,2,Thu Jul 16 22:27:41 2015 UTC,Notepad++ and most other simple ide's do this also. Pretty standard stuff but good to post so all are aware ;-)
PowerShell,3dil8o,acre_,3,Thu Jul 16 15:48:56 2015 UTC,"It get deleted ad renamed because the it's the responsibility of winlogon.exe to create a new account from the Default User profile and create a new registry key from the authenticated user security identifier S-1-5-11. As there is not a S-1-5-11 class SID (the actual users SID is of class S-1-5-11) already present in the SAM, it will create a new folder (or delete if one is already present) by the name of the user UPN. If the SID already exits in the SAM, but has errored in some way (become invalid), then winlogon.exe will create a new user folder by the name of UPN.NetBIOS(WINS)Domain Master Browser record  There's no solution to your issue that I'm aware of, but perhaps you're doing this out of order. Your needs are the reason Microsoft created the User State Migration Tool which is really just the Enterprise version of the Easy Transfer Wizard. Enterprise class tools are more or less synonymous with ""scriptable""  The account still needs to be created first."
PowerShell,3dil8o,occamsrzor,2,Thu Jul 16 17:52:42 2015 UTC,"USMT creates the profiles without creating the user. If it can do it, there must be a way manually, but while earlier versions of the USMT were a huge PITA the last couple I have generally seen work well. (With remaining issues on ODBC driver settings, especially if migrating from a 32-bit machine to 64-bit.)"
PowerShell,3dil8o,midnightFreddie,1 point,Thu Jul 16 23:38:14 2015 UTC,Have fun with that proc mom cap
PowerShell,3dil8o,occamsrzor,1 point,Thu Jul 16 23:47:50 2015 UTC,"USMT is a nightmare to work with, i finally was able to find a chm help file that had good info about the scripting language used in USMT (which from my experience was really more of a set of placeholder variables to refer to various locations / types of items than it was a scripting language) but if your using SCCM, and things like user-device-affinity, USMT will definitely solve this problem for you. But really, you should just place the files onto the new system after the user logs in....   Maybe you could copy their old home dir to a network share, and use a logon script or runonce or whatever to copy those files on first login...."
PowerShell,3dil8o,chreestopher2,2,Thu Jul 16 19:05:41 2015 UTC,"Earlier versions of USMT gave me fits, but the last two or three seemed pretty reliable, especially if you focus on the files and emails.  Most of the more recent problems I had was due to 32bit-64bit migration. A sideways backup/restore should be pretty painless."
PowerShell,3dil8o,midnightFreddie,2,Thu Jul 16 23:41:09 2015 UTC,Put the files in an alternate local folder owned by the user and have them moved into place as a run-once logon process?
PowerShell,3dil8o,GoodShitLollypop,3,Thu Jul 16 18:40:29 2015 UTC,I was talking about this with someone higher up and we came to this conclusion. I can just add a task in my initial move.
PowerShell,3dil8o,Frequentsy,1 point,Thu Jul 16 19:44:47 2015 UTC,"Are you saying the profile gets injected into the image .wim file? Or there is a task sequence in SCCM running a script that deploys an OS and th ecopying of the profile (which technically isn't imaging)? Also I've used this program in the past for profile transfer, it works fine. https://www.forensit.com/move-computer.html"
PowerShell,3dij9e,Aperture_Kubi,2,Thu Jul 16 15:34:16 2015 UTC,Since you already have good answers I thought I would ask if maybe there is a different way to tackle this. Would you be able to accomplish what you're trying to do using an Out-GridView -OutputMode Multiple? If this is part of a larger GUI and not a 1 off just ignore this comment but I use that all the time for quickly allowing the user to pick one or many items. It will allows you to multi-select and will return the records selected. It even supports adding a title at the top and allows filtering and sorting.
PowerShell,3dij9e,jwhaley58,1 point,Sun Jul 19 17:35:03 2015 UTC,"Hmm, maybe. As long as out-gridview puts out some kind of array that you can pipe.  Honestly this is the first time I've heard of it so I'll have to try it out Monday at work."
PowerShell,3dij9e,jwhaley58,2,Sun Jul 19 17:39:32 2015 UTC,"So for example   $output = @(1,2,3,4,5) | Out-GridView -OutputMode Multiple -Title 'test'   would give you an output like this: example. I ctrl clicked 1-3 and when I click okay at the bottom, it's going to assign $output to an array containing 1,2,3.   PS C:\Users\jwhaley> $output 1 2 3"
PowerShell,3dij9e,barinvon,2,Sun Jul 19 17:53:30 2015 UTC,"Well, Out-gridview simplifies things for me.   Though the only thing left is to see if I can limit what shows up in the OGV window (or at least change the order of the columns) but still preserve the rest of the data so I can pipe it elsewhere.  ninja: scratch that, I just need to read what I'm piping to accepts better.   Hell OGV just replaced 64 lines of vb code with a one-liner."
PowerShell,3dij9e,ryanbrown,1 point,Mon Jul 20 14:10:41 2015 UTC,Check out this link: http://blogs.technet.com/b/heyscriptingguy/archive/2014/08/02/weekend-scripter-fixing-powershell-gui-examples.aspx
PowerShell,3dij9e,kusumuk,1 point,Thu Jul 16 15:51:08 2015 UTC,"To add to this, $x only exists in the scope of that script block, so you won't be able to access $x anywhere outside of that Add_Click definition unless you do something like   $script:x=$objListBox.SelectedItem   You can learn more about scopes by typing the following at the powershell prompt:  Get-Help about_Scopes -ShowWindow"
PowerShell,3difvo,Blu3f1r3,2,Thu Jul 16 15:08:24 2015 UTC,"Silverlight is a pain with powershell... just like dynamic websites in general.  It would be probably better to find out another way to install the out of browser version of the plugin.  With dynamically generated websites (javascript, silverlight, etc) the only way to really automate (if they dont offer an API) is by finding the DOM elements and executing their click events or whatever.....  maybe you can manually install the application, then find the installer in your temp files and just distribute that.... dont know how the system is put together so i cant really say for certain."
PowerShell,3difvo,chreestopher2,1 point,Thu Jul 16 17:25:02 2015 UTC,I was afraid that might be the case but thanks for the reply. Unfortunately this app stores information associating each username with an app ID and will prompt to update if it wasn't downloaded by that user. I'll try searching the DOM elements for what I need but may settle on opening the browser and letting the users do the rest.
PowerShell,3diffd,krayziepunk13,3,Thu Jul 16 15:05:01 2015 UTC,"You can use -replace, -f, or any other string substitution method"
PowerShell,3diffd,chreestopher2,1 point,Thu Jul 16 15:47:05 2015 UTC,Thanks! That was a nice simple solution I didn't even think of.
PowerShell,3diffd,Deutscher_koenig,2,Thu Jul 16 16:00:57 2015 UTC,Take a look at this:  Ss64.com/PS/syntax-f-operator.html
PowerShell,3di6um,lostmojo,2,Thu Jul 16 13:55:45 2015 UTC,"Was going to whip something up but the wheel had already been invented.  http://technodrone.blogspot.com/2010/04/monitor-ad-replication-status-with.html  Saw some mistakes in his code and inefficiencies.  Here is a working version i've created from his.      function Send-Mail { [CmdletBinding()] param( [Parameter(ValueFromPipeline=$True)][string]$emailbody, [string]$mailserver, [string]$emailto, [string]$subject, [string]$emailfrom, [string]$mailattachment) $ErrorActionPreference = ""silentlycontinue"" $sender = $emailfrom $recipient = $emailto $mailserver = $mailserver $subject = $subject $body = $emailbody $msg = new-object System.Net.Mail.MailMessage $sender, $recipient, $subject, $body $attachment = new-object System.Net.Mail.Attachment $mailattachment $msg.CC.Add($CC) # Uncomment to send BCC # $msg.BCC.Add($BCC) $msg.Attachments.Add($attachment) $client = new-object System.Net.Mail.SmtpClient $mailserver $client.Credentials = [System.Net.CredentialCache]::DefaultNetworkCredentials $client.Send($msg) $attachment.Dispose() }  $workfile = repadmin.exe /showrepl * /csv  $results = ConvertFrom-Csv -InputObject $workfile   #Here you set the tolerance level for the report $results = $results | where {$_.'Number of Failures' -gt 0 }  if ($results -ne $null ) {     $results = $results | select ""Source DSA"", ""Naming Context"", ""Destination DSA"" , ""Destination DSA Site"" ,""Number of Failures"", ""Last Failure Time"", ""Last Success Time"", ""Last Failure Status"" | convertto-html     }  else {     $results = ""There were no Replication Errors"" }  #email code here with body as $result    $result | Send-Mail -mailserver mail.company.com -emailto recipient@company.com -subject ""Replication Status"" -emailfrom sender@company.com"
PowerShell,3di6um,Theratchetnclank,1 point,Thu Jul 16 14:59:43 2015 UTC,What exactly do you mean by 'synchronized'?  Are you referring to a new promotion being finished or something else?
PowerShell,3di6um,evetsleep,1 point,Thu Jul 16 14:52:35 2015 UTC,"As you are using 2012r2 you can simply use Get-ADReplicationFailure:  Get-ADReplicationFailure dc01.example.com   This is literately all I do in my Sensu check on each DC in my domain.  If you wanted to do this centrally (perhaps to construct a nightly email report or store metrics) then you would need to change the scope   Get-ADReplicationFailure -Target ""ad.example.com"" -Scope Domain   Then parse objects you get back."
PowerShell,3di6um,InvisibleTextArea,1 point,Thu Jul 16 15:21:28 2015 UTC,"It's not a script, but there is actually a tool for this. AD Replication Status Tool.   https://www.microsoft.com/en-us/download/details.aspx?id=30005"
PowerShell,3di57p,zdmilot15,5,Thu Jul 16 13:41:26 2015 UTC,"You should probably replace all those ""elseif"" blocks with Switch statements as it'll make it quicker to run. It's odd because you've mixed and matched Switch and elseifs throughout the script but I can't see any reason why you've chosen to use the elseifs where you have.  Also if the New User path is going to be the same irrespective of department then there's no point setting it in the same block as you're setting the department, just set it globally for any user instead.  Not really major but as an aside, don't do stuff like:  Write-Warning ""An Error Has Occurred.""   Because it's pointless. It doesn't help the user understand why the script failed and it doesn't help the author debug why the script failed. Either provide an error message that is of benefit to the user or author or don't provide one at all."
PowerShell,3di57p,the_spad,1 point,Thu Jul 16 14:33:59 2015 UTC,"Thank you for your reply! The elseif statements might need to be changed to some switch statements in the future, and I do thank you for taking the time to review this and get back to me. I also totally forgot that I had placed that warning in there and am totally with you that it needs to be more descriptive to help troubleshoot the issue if it ever does appear in front of the user."
PowerShell,3di57p,m0po,1 point,Mon Jul 20 14:07:58 2015 UTC,you're letting users run this? are you giving each user domain admin and exchange admin?
PowerShell,3di57p,m0po,1 point,Mon Jul 20 06:32:23 2015 UTC,"Interesting question, and one I have thought of trying to come up with a solution to before, but what I might do is remote into our server, and sign in with admin credentials. Any thoughts on making this better let me know."
PowerShell,3di3u6,JrAdminIT,1 point,Thu Jul 16 13:29:18 2015 UTC,Remove the < and > signs from $userphoto
PowerShell,3di3u6,PowerShellStunnah,1 point,Thu Jul 16 13:52:57 2015 UTC,"Wow. I can't believe it was that simple. Thank you so much!  Clearly I'm new with PS.  Can you explain the ""Line:3 Char:1"" error?  According to that its the ""S"" in ""Set-UserPhoto"", no?"
PowerShell,3di3u6,PowerShellStunnah,1 point,Thu Jul 16 14:07:47 2015 UTC,"Well yes, assigning a string with the character < in it to $userphoto is not in itself a problem, but the statement that starts at ""Line:3 Char:1"" (The invocation of Set-UserPhoto) fails because of an error in one of the arguments"
PowerShell,3dgkrh,HSChronic,2,Thu Jul 16 02:40:01 2015 UTC,There are a few ways to do it ranging from the very simple to the slightly more useful. This appears to be another take on the same approach.
PowerShell,3dgkrh,the_spad,1 point,Thu Jul 16 09:19:10 2015 UTC,"Thanks, I didn't realize this was going to be such a pain in the ass. I hope the Hyper-V side isn't that much of a pain in the ass."
PowerShell,3dgkrh,WindosBK,2,Thu Jul 16 13:44:15 2015 UTC,"You may be able to pull something useful out of an old function of mine, Get-SemiUsableDiskInfo. The name is a joke for the benefit of my boss, so excuse that and also anything that isn't really best practice... I was still pretty new to PowerShell when I wrote it.  Example use:  [110] PS G:\> Get-SemiUsableDiskInfo -computername Script | ft  VMwareDiskName WindowsDiskNumber TotalSize SCSIController Filename                             -------------- ----------------- --------- -------------- --------                             Hard disk 1                    0        40 0:0            [lhsas-2t] script/script-000001.vmdk Hard disk 3                    1         5 0:1            [lhsas-2t] script/script_2.vmdk      Hard disk 2                    2       100 1:0            [lhsas-2t] script/script_1.vmdk        It only returns Windows' disk numbers, but you can plug that into other commands to get the drive letter(s) if needed:  [117] PS G:\> get-disk -CimSession script -Number 1 | Get-Partition | Select PartitionNumber, DriveLetter, Size  PartitionNumber DriveLetter       Size --------------- -----------       ----               1           E 5365563392   Hope something in there is useful/gets you on the track to your solution."
PowerShell,3dhi67,stormy_rawr,2,Thu Jul 16 08:59:53 2015 UTC,"Sure you can interact with Word through COM to open the documents and save a plaintext .txt copy. You could script it to trawl through an entire fileshare saving a .txt copy of every Word document.  You could probably even script it to upload them to Sharepoint directly, though I have no experience with that."
PowerShell,3dhi67,picklednull,1 point,Thu Jul 16 12:37:21 2015 UTC,"Doing a little bit of digging, I was originally going to use Get-Content but will probably end up using StreamReader because some of the files are huge... Presumably out-file would still be fine.  The problem is, if it does this, I'd like to find a way to trigger a ""image goes here"" kind of warning - which seems to be impossible :( It's getting thrown into an Enterprise Wiki, so while I'd love to be able to just upload the files, that isn't going to happen either...  Ah well, time to see if I can learn PS!"
PowerShell,3dhi67,alcaron,2,Thu Jul 16 14:04:06 2015 UTC,"He is saying do something like this:  $path = ""<pathto>.doc""  $word = New-Object -ComObject Word.Application $word.Visible = $true [ref]$format = [Enum]::Parse([Microsoft.Office.Interop.Word.WdSaveFormat], ""wdFormatText"") $document = $word.Documents.Open($path) $document.SaveAs([ref]$path.Replace("".doc"","".txt""), $format) $document.Close() $word = $null"
PowerShell,3dhi67,alcaron,2,Thu Jul 16 14:31:45 2015 UTC,"Ok, I'll try that :D Thanks for the help!"
PowerShell,3dhi67,alcaron,1 point,Thu Jul 16 15:56:57 2015 UTC,"Just to pick your brain some more, would something like:  $path = Split-Path -parent $MyInvocation.MyCommand.Path   and then a ForEach-Object { open, save as, close } block work ok, provided I was using essentially a 'holding folder' and swapping the docs out?"
PowerShell,3dhi67,alcaron,2,Fri Jul 17 13:24:15 2015 UTC,Split-Path -parent $MyInvocation.MyCommand.Path   Are you wanting to dump the .doc's in a folder and batch convert them?
PowerShell,3dfkpx,ephos,5,Wed Jul 15 21:48:59 2015 UTC,This is by design and it is configurable. You need to look into the LocalConfigurationManager:  LocalConfigurationManager {                      RebootNodeIfNeeded  = $True                     }
PowerShell,3dfkpx,MetaVoo,1 point,Wed Jul 15 23:56:37 2015 UTC,"Hmm, I have tried to have RebootNodeIfNeeded set to both $true or $false but get the same results where the configuration job stops due to needing a reboot.   It does seem to reboot itself when its set to $true after a few minutes but this isn't want I want to happen, I want it to process all the package installs without rebooting or stopping because its pending a reboot.  As it stands I have to run the push 4 separate times and then reboot at the end to get the state I want."
PowerShell,3dfkpx,alcaron,2,Thu Jul 16 13:59:12 2015 UTC,"I have a snippet of code at work that I use to get around this, it doesn't make me happy but it gets the job done, I wont lie, it is on provisioned servers, running as the bootstrap, if this is an ongoing problem for you...then you may have bigger problems.  Until I can snag the code I would suggest you also try appending Reboot=ReallySuppress to the end of your MSI's.  I will also say I've noticed it thinks it needs reboots more when run manually as opposed to when the SchTask runs it..."
PowerShell,3dfkpx,MetaVoo,1 point,Fri Jul 17 00:48:30 2015 UTC,"DSC does not work that way. If it does something that needs a reboot, it will reboot and then continue. So in your case, it will reboot 4 times. So push it once and let it finish.  What we want and what DSC does are often not the same thing."
PowerShell,3dfkpx,alcaron,2,Thu Jul 16 19:17:42 2015 UTC,Better hope he isn't using provisioned servers.
PowerShell,3dfkpx,MetaVoo,1 point,Fri Jul 17 00:46:34 2015 UTC,It would work for provisioned servers. The issue is he watching and waiting for it. A few extra reboots on a provisioned VM is nothing.
PowerShell,3dfkpx,alcaron,2,Fri Jul 17 01:11:35 2015 UTC,"Provisioned as in PVS. On which case yes, reboots would be bad."
PowerShell,3dfkpx,MetaVoo,1 point,Fri Jul 17 01:56:39 2015 UTC,"Ok, I'm tracking with you then. In those cases I would use DSC to configure the gold image. When you push into VDI or personal VMs, DSC leaves a lot to be desired.   None of the community resources rely configure user space."
PowerShell,3dfkpx,alcaron,1 point,Fri Jul 17 02:07:41 2015 UTC,"Well the problem there is we want to have as few images as possible and things like flash aren't baked in so we don't have to either generate a new image or open the existing image except in rare instances, so what I ended up doing, and again this is really only suited for a bootstrap, not an ongoing basis (which honestly probably matters less because it may run it, get to your thing and stop, but in all reality you probably only added that one thing and the next time it runs it will just sail right by, so, in production, past initial config, it shouldn't be a big deal):  # Run DSC and keep running until no more ""reboots"" are detected. $complete = $false while($complete -eq $false) { $proc.Start() $proc.WaitForExit() Start-Sleep -Seconds 5 if((Get-WinEvent -LogName ""Microsoft-Windows-Dsc/Operational"" -ErrorAction SilentlyContinue | ?{ $_.Id -eq ""4160"" }).Count -lt 1){ $complete = $true }else{  } & wevtutil cl ""Microsoft-Windows-DSC/Operational"" gps wmi* | ?{ $_.Modules.ModuleName -like ""*DSC*"" } | Stop-Process -Confirm:$false -Force }   Oh my sweet baby jesus that appears to have REAMED the formatting lol...ugh...  Basically I just watch/flush the DSC event log and when I stop seeing ""HAI GUIS I NEED A REBUUT!"" I stop running DSC again.  It doesn't make me happy, but it does work, so...that makes me happy. I would much rather they add a setting to ignore reboots."
PowerShell,3dfkpx,MetaVoo,1 point,Fri Jul 17 14:42:04 2015 UTC,Use a script resource and put the four msi installs inside it.
PowerShell,3dfkpx,alcaron,1 point,Fri Jul 17 15:04:54 2015 UTC,"Sadly this is not the culprit, WMF4 DSC is pretty stupid about MSI's, I have one config that literally half the MSI's DSC claims need reboots, I assure you, they do not...  That setting just configures whether or not it WILL reboot. But it will not allow you to ignore what it thinks is a reboot."
PowerShell,3dfkpx,MetaVoo,2,Fri Jul 17 00:45:30 2015 UTC,DSC checks four registry keys to see if a reboot is needed. The annoying one is the pending delete on next reboot. I see installers put a stub in there if a pending delete is needed or not.   One solution that is easier than than you think is a custom resource. Have it do the install and clean up those keys after it is done. You would have to make it a full resource and not a composite resource.
PowerShell,3dfkpx,alcaron,1 point,Fri Jul 17 01:08:07 2015 UTC,As I've made several resources I wouldn't be surprised. But I would say a script resource would be easier. Check for its existence and go from there.
PowerShell,3dfkpx,MetaVoo,2,Fri Jul 17 01:58:10 2015 UTC,"That is a good idea.  I am starting to get a little OCD about my configurations and I have created this unhealthy aversion to script resources if they are more than a line or two long. On the plus side, I am getting very quick at creating new resources."
PowerShell,3dfkpx,alcaron,1 point,Fri Jul 17 02:04:53 2015 UTC,"Yeah...I dunno, I'm torn, I definitely think script resources can get WAY out of hand way too quickly, but everytime I make a resource to avoid it I kind of feel like I'm just hiding all that code and the maintenance of it somewhere else, but it is still there."
PowerShell,3dh8hm,powpow44,3,Thu Jul 16 06:42:15 2015 UTC,Load all the arguments into a single variable declared as a string and then use that variable as the parameter for argumentlist.  I've seen this behaviour before and that's how I worked around it.
PowerShell,3dh8hm,Theratchetnclank,1 point,Thu Jul 16 06:56:45 2015 UTC,"Thanks I will give it a shot, makes it even trickier when the arguments have quotations on some of them due to spaces."
PowerShell,3dh8hm,Theratchetnclank,3,Thu Jul 16 07:44:54 2015 UTC,"Note sure if you know but you can do stuff like this.  $args = ""-filepath {0} -destination {1}"" -f ""C:\some file\path.txt"",(read-host ""destination path"")   The values in the curly braces are replaced with the values on the right of the -f (these values can be a variable,string,integer or command such as get-date)."
PowerShell,3dh8hm,Theratchetnclank,1 point,Thu Jul 16 07:56:48 2015 UTC,"This is perfect, all my users inputs are working perfectly now. Thank you!"
PowerShell,3dfzq0,mulliganx,1 point,Wed Jul 15 23:45:20 2015 UTC,"On mobile, you need a nested for each, your pipeline only passes in the data from $CompList, you cannot then reference stuff from your $KBList array (it would have to be a string only)  Try something like.  Foreach ($Comp in $CompList) {     foreach ($KB in $KBList) {      get-Hotfix -id $KB -ComputerName $Comp     } }  You should also make a PS Object for easier manipulation/export but that's to much for me to type on my phone :)"
PowerShell,3dfzq0,ButterCupKhaos,1 point,Thu Jul 16 00:40:42 2015 UTC,"Also on mobile, but there is an easier/better way.   Have both lists in an array and remove one array from the other and see what's left."
PowerShell,3de4ty,737000,7,Wed Jul 15 15:45:19 2015 UTC,$session = New-PSSession -ComputerName $computer Invoke-Command -Session $session -ScriptBlock {msg username 'This is a test message.'}   Where username is the username of the person the message should pop up for.
PowerShell,3de4ty,FlippityFlip,1 point,Wed Jul 15 20:59:09 2015 UTC,Do you need the session part of that? I'm not sure but you should be able to do that just by specifying that invoke-command -computername.
PowerShell,3de4ty,veggie124,1 point,Wed Jul 15 23:30:56 2015 UTC,Session part is not required though I prefer it that way in case you need to use credentials. You can create the session with those credentials and then you won't need to enter them again when running something in that session.
PowerShell,3de4ty,FlippityFlip,1 point,Thu Jul 16 15:56:41 2015 UTC,"Thanks, this is a simpler way of doing it.. i'll do this cheers!"
PowerShell,3de4ty,da_kink,3,Thu Jul 16 10:22:41 2015 UTC,"What I use on server 2012 is this.    Send-RDUserMessage -MessageTitle ""Message from Support"" -MessageBody "" maintenance will begin. Please save your work""  You can use get-rdusersession to get a list of logged in people.   Not exactly what you're looking for I think."
PowerShell,3de4ty,geostude,1 point,Wed Jul 15 16:48:01 2015 UTC,"Not exactly what you asked for, but here is how to do it from your local machine...  https://www.reddit.com/r/PowerShell/comments/306mcn/wtsenumeratesessions/"
PowerShell,3de4ty,Frequentsy,1 point,Wed Jul 15 19:57:50 2015 UTC,"msg also has /server parameter if you want to utilize that in any other way msg /SERVER:pc1234 * /TIME:05 ""This is a test message"""
PowerShell,3de4ty,tommymaynard,1 point,Wed Jul 15 20:48:49 2015 UTC,"PS Remoting completely removes the ability to use any graphical elements. In fact, try it yourself. Connect to a remote computer with PowerShell and enter Show-Command Get-Help. You'll get an error that says, ""Show-Command does not work in a remote session."""
PowerShell,3de4ty,Laser_Fish,1 point,Wed Jul 15 16:27:16 2015 UTC,"It also removes the ability to use the text to speech process, meaning that I can't pull off what would have been the best prank ever at work."
PowerShell,3de4ty,i_me_me,1 point,Wed Jul 15 22:24:39 2015 UTC,"I've used it before,  it seems like I was using the speech assembly in a pssession."
PowerShell,3de4ty,alcaron,1 point,Thu Jul 16 00:35:37 2015 UTC,"yar, it isn't entirely impossible, but there is fuckery involved, think that was before the days of storing my snippets on pastebin though as I cannot find it."
PowerShell,3de4ty,alcaron,1 point,Fri Jul 17 00:57:24 2015 UTC,"lol...Invoke-WMIMethod...  ok...why that over, say...Start-Process, or Invoke-Command or..."
PowerShell,3de4ty,Shiznot,1 point,Thu Jul 16 14:12:03 2015 UTC,"IIRC because we can't use PSRemoting in our environment due to policy, but WMI still works... That said I could be an idiot."
PowerShell,3de4ty,alcaron,1 point,Fri Jul 17 01:01:08 2015 UTC,I don't think you are an idiot.  But I'm pretty sure -ComputerName uses WSMan no matter what the cmdlet... Could be wrong.
PowerShell,3de4ty,Shiznot,2,Fri Jul 17 01:41:50 2015 UTC,"Again I don't remember specifics... We couldn't get Invoke-Command or start process to work, I think I assumed at the time that it was because the WinRM service was disabled etc... Someone just dug up that example and found it worked and didn't investigate further into the issue.  I'd like to use invoke-command for other stuff if I could get it to function. Does the fact that we are on powershell 2.0 change anything?"
PowerShell,3de4ty,alcaron,1 point,Fri Jul 17 01:55:49 2015 UTC,"If it wasn't spitting an error but just not working then you are not alone, I've found that some things...just refuse to run some ways in PS...there is no ""right way"" to run things because there is no single way that will DEFINITELY run everything.  Uninstalling flash the other day, had to use system.diagnostics.process because NOTHING else would run it right...shrug...I was mostly just curious because I honestly don't think I've seen it before.  End of the day if it works and isn't hurting anyone who gives a shit. :)"
PowerShell,3de4ty,Shiznot,2,Fri Jul 17 02:18:15 2015 UTC,"I double checked this morning. I can't use Invoke-command in our environment because WinRM is disabled(The error tells me so specifically), Invoke-WMIMethod works without it. Honestly I kind of prefer our kludge method of sending a messages using it doesn't rely on having WinRM configured and I wouldn't want to have to make a change on a few thousand systems for this.  Scripting flash installs just sucks in my experience. For uninstalling why not just use the WMI Uninstall method in Win32_Product, I seem to remember it working in the past for me."
PowerShell,3de4ty,alcaron,1 point,Fri Jul 17 14:36:38 2015 UTC,"huh...wow...I never would have guessed that, good that it works, bad that it is yet another example of PS inconsistency...-Computername uses this to do that, except for when it doesn't...  Janky...  Good to know..."
PowerShell,3dew6b,posyden81,4,Wed Jul 15 18:57:44 2015 UTC,"Yep pretty close.   If the IPs are unique and you're looking for a one-liner I'd probably make use of a hashtable  get-content C:\ip_list.txt | foreach-object{ @{ $_ = ""$(([system.net.Dns]::GetHostByAddress($_)).hostname)"" } }   You can then dump it out however you like and do lookups against the IP key.  Edit:  Actually, thinking about it some more, i'd probably go down the custom object route.  It'll be easier to manipulate and output in whatever format you want  Get-Content C:\sample\ip.txt.txt | ForEach-Object { New-Object -TypeName PSObject -Property @{ IP = $_; Name = $(([system.net.Dns]::GetHostByAddress($_)).hostname) } }"
PowerShell,3dew6b,opsready,1 point,Wed Jul 15 19:46:36 2015 UTC,That is sooooo FAST
PowerShell,3dew6b,target,1 point,Wed Jul 15 20:16:36 2015 UTC,"I modified it to work off file variable and threw a gridview on it ..   $serverlist = ""C:\Temp\serverlist.txt"" Get-Content $serverlist | ForEach-Object { New-Object -TypeName PSObject -Property @{ IP = $_; Name = $(([system.net.Dns]::GetHostByAddress($_)).hostname) } } | Out-GridView"
PowerShell,3dew6b,target,1 point,Thu Jul 16 12:22:54 2015 UTC,I love you guys.. :)
PowerShell,3dew6b,opsready,1 point,Thu Jul 16 13:36:03 2015 UTC,Works great. I just need it to ignore the ip's that have no  hostname associated with it (mainly because they are network devices).
PowerShell,3dew6b,target,1 point,Thu Jul 16 13:39:06 2015 UTC,"I'm not near a machine to test this, but I think this should do it  Get-Content C:\sample\ip.txt.txt | ForEach-Object { New-Object -TypeName PSObject -Property @{ IP = $_; Name = $(([system.net.Dns]::GetHostByAddress($_)).hostname) } } | Where { $_.Name -ne $null }    Edit: formatting"
PowerShell,3dew6b,GoodShitLollypop,1 point,Thu Jul 16 18:19:02 2015 UTC,"How can you get information?  DNS? Remote connection, WMI maybe?"
PowerShell,3dew6b,target,1 point,Wed Jul 15 19:42:39 2015 UTC,"Preferably DNS, maybe WINS"
PowerShell,3dew6b,GoodShitLollypop,1 point,Thu Jul 16 03:19:20 2015 UTC,The one that opsready post works great and is SUPER fast.
PowerShell,3den19,trueimage,3,Wed Jul 15 17:55:11 2015 UTC,Had to do something similar recently and made use of the accepted solution here using Start-Job http://stackoverflow.com/questions/8781666/run-n-parallel-jobs-in-powershell  edit: Actually made it back to a proper keyboard.  Something like this should work (where urls.txt has the urls on their own line)  $maxConcurrentJobs = 8 $content = Get-Content c:\sample\urls.txt  foreach ($url in $content) {     $running = @(Get-Job | Where-Object { $_.State -eq 'Running' })     if ($running.Count -le $maxConcurrentJobs) {         Start-Job {              Invoke-RestMethod -Uri $using:url         }     } else {          $running | Wait-Job -Any     }     Get-Job | Receive-Job }
PowerShell,3den19,opsready,1 point,Wed Jul 15 18:49:15 2015 UTC,"Thank you, I'll give this a try asap"
PowerShell,3den19,opsready,1 point,Wed Jul 15 20:56:15 2015 UTC,"I get this error:  Invalid URI: The hostname could not be parsed.     + CategoryInfo          : NotSpecified: (:) [Invoke-RestMethod], UriFormatException     + FullyQualifiedErrorId : System.UriFormatException,Microsoft.PowerShell.Commands.InvokeRestMethodCommand     + PSComputerName        : localhost   but if I run the command on a url directly, it works  Invoke-RestMethod -Uri ""http://webserver:8080/blah/blah/services/create?server=BLAH&e1user=BLAH&newblahNum=899&sourceblahNum=0&tagNum=blah-blah-blah""   in my text file each url is on its own line and has quotes at start and end."
PowerShell,3den19,opsready,2,Wed Jul 15 21:12:42 2015 UTC,"your file path has a space in it so add quotes around it  $content = Get-Content ""C:\Temp!working\MWO URL Calls\urls.txt"""
PowerShell,3den19,opsready,1 point,Wed Jul 15 21:47:25 2015 UTC,"I figured out that one, I'm getting a different error now and probably updated the post before you refreshed :)"
PowerShell,3den19,opsready,2,Wed Jul 15 22:02:30 2015 UTC,"Hard to tell without seeing the script, but make sure you're prefixing your variable in the Start-Job script block with $using, I.e. $using:url, or making use of the -argumentlist parameter (the code I posted above makes use of $using)."
PowerShell,3den19,midnightFreddie,1 point,Wed Jul 15 22:11:50 2015 UTC,"no worries, I just basically copied what you posted. Mind If I post this over on stack exchange?"
PowerShell,3den19,alinroc,2,Wed Jul 15 23:35:49 2015 UTC,Of course not!
PowerShell,3den19,opsready,2,Thu Jul 16 05:13:17 2015 UTC,Just re read that the Urls have quotes around them in the text file. Try removing those
PowerShell,3den19,mcwidget,1 point,Thu Jul 16 05:54:49 2015 UTC,"in my text file each url is on its own line and has quotes at start and end.   Then:  Get-Content c:\sample\urls.txt | ForEach-Object {     $Uri = $_.Trim('""')     Write-Output $Uri } | Do-Cool-Parallel-Thingy-That-Takes-Uris-Via-Pipeline   And note that I didn't Get-Content of a 500k-line file into a variable. For the love of RAM, don't do that! The way coded above will start feeding the target function/filter while it's still reading and not have to load everything into memory at once.  Powershell can be a tool for this I think, but the standard job paradigm I have not found to be usable so far for spawning a bunch of parallel tasks. I have started a time or two to try, but my jobs have been small enough that splitting the input file into 4-10 files and opening 4-10 Powershell windows and kicking off the processes has been faster than coding dispatcher/slave functions.  Also, in this case I might avoid using Invoke-Restmethod and use Invoke-WebRequest -UseBasicParsing. -UseBasicParsing prevents it from doing any of the fancy interpreting, and this function gives you access to the status code and headers which might be handy info to filter on to look for problems. If the reply is JSON, simply $PowershellObject = $Result.Content | ConvertFrom-Json.  Edit: This works, except for the cool, parallel part.   filter Do-Cool-Parallel-Thingy-That-Takes-Uris-Via-Pipeline {     # TODO: Cool-Parallel-ness     $Uri = $_     Invoke-WebRequest -UseBasicParsing $Uri |         Select-Object @{ Name = ""Uri""; Expression = {$Uri} }, StatusCode, StatusDescription, Content, Headers } Get-Content c:\sample\urls.txt | ForEach-Object {     $Uri = $_.Trim('""')     $Uri } | Do-Cool-Parallel-Thingy-That-Takes-Uris-Via-Pipeline   Edit 2: Updated to include the Uri in the output.  Edit 3: One thing led to another, and so I put it on GitHub: https://github.com/midnightfreddie/powershell-parallel-http/blob/master/parallel-http.ps1 . It's still not parallel, but I'm getting close to trying to parallel-ify it."
PowerShell,3den19,alinroc,2,Thu Jul 16 03:53:04 2015 UTC,"PowerShell may not be the most appropriate tool for this task. Using start-job as /u/opsready pointed out is definitely one way to go, but it's still going to be a massive resource drain on whatever system you run it on. Starting jobs isn't free.  You may be better off with something that's lighter-weight than spawning PowerShell jobs, in an environment that natively supports async stuff. I'm thinking Go, node.js, etc.  Edit: Thinking about it some more, check out ATP episodes 101, 102 & 104 wherein Marco Arment talks about using Go to do a lot of parallel processing involving web requests."
PowerShell,3den19,chreestopher2,2,Wed Jul 15 19:30:01 2015 UTC,Yar - 500k jobs is going to be a resource sync for sure
PowerShell,3de7op,whiskeyjackets,1 point,Wed Jul 15 16:06:26 2015 UTC,"Hey mate,   As always there are tons of way to do this in PoSH. Heres a simple and effective way:  $x = Get-Content C:\blah\Computers.txt Foreach($item in $X){  Copy-item -Path ""\\$item\C$\blah\*.txt"" -Destination \\servershare\d$\blah -Recurse  }   Remember if you are using Copy-item on Files rather than a folder you need to make sure that destination folder is present. alternatively, you can just make it (the folder) with a prior command.  Let us know how you go."
PowerShell,3de7op,bundyfx,1 point,Wed Jul 15 22:59:56 2015 UTC,"Thank you for this, but this copies the actual files while i'm trying to copy the output of list."
PowerShell,3defs9,whatchuknowbout,1 point,Wed Jul 15 17:04:16 2015 UTC,"Without seeing the code, it's hard to say. Here's a binary cmdlet I built a while back.  https://github.com/cdhunt/WindowsAudioDevice-Powershell-Cmdlet/blob/master/AudioDeviceCmdlets/DefaultAudioCmdlets.cs  Do you have Cmdlet attributes on your classes?"
PowerShell,3defs9,logicaldiagram,1 point,Wed Jul 15 17:15:29 2015 UTC,Right now all I have is a sort of hello world equivalent to get in. Followed MSDN's Get-Proc example.  Here is what I have in VS right now.
PowerShell,3defs9,logicaldiagram,2,Wed Jul 15 17:29:08 2015 UTC,"I'm not sure if Namespace plays any part in it, but you may want to match the dll name with the namespace. That's all I can think of."
PowerShell,3defs9,squid808,1 point,Wed Jul 15 17:41:37 2015 UTC,"Hey, I just tried it out myself and I'm not having any issues. Where is your .dll file location, and what is your working directory for PowerShell? Try doing a import-module with the full path to the .dll file, for example:  Import-Module ""C:\Users\YourUserHere\Documents\visual studio 2012\Projects\PSTest01\PSTest01\bin\Debug\PSTest01.dll"""
PowerShell,3defs9,squid808,1 point,Thu Jul 16 00:58:21 2015 UTC,Ugh I just don't understand. Tried full path with same result. I've tried when the .dll was located in the project's Release and Debug folders.
PowerShell,3defs9,mr_furious7,1 point,Thu Jul 16 04:02:16 2015 UTC,"That shouldn't matter. Just a thought, maybe it's because you named it Powershell? Perhaps it's conflicting with some other existing PowerShell.dll that has already been loaded? I know there are plenty of Powershell.dll files (based on a search) but it couldn't hurt to try.  That said, if it still doesn't work maybe it's one of the dependency files you're having an issue with. Try adding in the code for assembly resolution, you can see an example in my code here (starting line 58 - OnImport()).  Once you have that in place, you can launch PowerShell, start debugging on it through Visual Studio, set a breakpoint in your assembly resolution and then import the module in PowerShell - hopefully that will help you catch what is going on. I have to run, but let me know if I can help out more."
PowerShell,3defs9,MetaVoo,1 point,Thu Jul 16 17:58:46 2015 UTC,I have seen this when the library is 32-bit and gets called in 64-bit powershell.  Have you tried launching in in powershell x86?
PowerShell,3ddord,MDFreaK76,1 point,Wed Jul 15 13:37:32 2015 UTC,"#To test overall health [bool](1..10 | ForEach-Object {Test-Path -Path ""\\192.168.1.$_\Share"" })  #To spit out the failures 1..10 | %{if(!(Test-Path -Path ""\\192.168.1.$_\Share""){""'\\192.168.1.$_\Share' is not accessible"" } }"
PowerShell,3ddord,JaapBrasser,1 point,Wed Jul 15 14:05:39 2015 UTC,"Alternatively you can create a PowerShell custom object for this purpose:  1..10 | ForEach-Object {     [pscustomobject]@{         Path = ""\\192.168.1.$_\Share""         Result = Test-Path -Path ""\\192.168.1.$_\Share""     } }"
PowerShell,3ddord,alcaron,2,Wed Jul 15 14:31:48 2015 UTC,"When I first started out in my career, I'd make troubleshooting issues really complicated. Needlessly complicated. For the longest time, I put a sticky note on my monitor that read ""LAYER 1.""  Your post makes me think I should put ""PSCustomObject"" up on the next post-it.   Thanks man!"
PowerShell,3ddord,alcaron,1 point,Wed Jul 15 14:47:55 2015 UTC,"It seems like heading back towards the ""needlessly complicated"" direction IMO..."
PowerShell,3ddord,alcaron,1 point,Wed Jul 15 14:52:05 2015 UTC,"It could be. That view is definitely valid. However, in almost any case where I've found myself stumped, I could've used a PSCustomObject to sort it all out."
PowerShell,3ddord,alcaron,1 point,Wed Jul 15 15:00:01 2015 UTC,"Honestly in this case I'm not sure it would help you with the root problem. I think you need a more in depth experience with the pipeline, it's a weird thing at first, and there are still times I find myself going ""why the eff..."" but creating a basic object doesn't really do anything for you. In this case it will spit out an object, but it's also instantiating that object, as long as you don't keep it then whatever is whatever for the most part, but if what you want is to see the name of the share you just tested that is a formatted string, or even just using the pipeline variable if you don't care about being pretty, not an object with labels."
PowerShell,3ddord,alcaron,1 point,Wed Jul 15 15:14:14 2015 UTC,"What would you suggest as an alternative? I tried piping Test-Path to Get-Member, but couldn't find anything to give me the path and redirect the boolean result."
PowerShell,3ddord,midnightFreddie,2,Wed Jul 15 15:17:31 2015 UTC,"1..10 | %{ ""192.168.1.$_"" } | %{ ""Results for {0} are {1}"" -f $_,($_Test-Path -Path \\$_\Share) }   What I already posted in this thread. :)  You already have the path $_, when you do your Test-Path you are using the path, so just, use it again to write out to the screen.  ; is used for ""the things after are a new line"" btw.  So you could (shouldn't, but could) do something like:  $test = ""foo"";$name = ""bar""   Or in this case you can use it for your one liner, to do multiple things instead of one:  $_;Test-Path ""\\$_\Share"";""""   Which will output:  10.1.25.8 True  10.1.25.9 False   Which is what it sounds like you want. But lets say you wanted to write it all out to a file, yeah? Then you have to put it in an object right? So on a new line you can:  Out-File -Path C:\results.txt -Value $results   But even then, at the end of your pipeline you should be able to:  | Out-File C:\results.txt"
PowerShell,3ddord,alcaron,1 point,Wed Jul 15 15:38:09 2015 UTC,"This is really handy. One quirk with the one-liner is that it returns False, even if I run it by hand for one IP and it's True.   $;Test-Path ""\$\Share"";""""  I'm good with what the semi colons do, but the ;"""" bit is confusing to me. Very cool, though."
PowerShell,3ddufx,commiecomrade,2,Wed Jul 15 14:26:28 2015 UTC,I'm not sure how with a CSV; it's geared toward a flat hashtable representation. Can you use XML or JSON?  They are far superior in representing this type of data structure.
PowerShell,3ddufx,PsTakuu,1 point,Wed Jul 15 14:44:33 2015 UTC,If it's a file that allows for proper formatting of this array then I can use it.
PowerShell,3ddufx,PsTakuu,1 point,Wed Jul 15 14:54:59 2015 UTC,$foldersfound | ConvertTo-Json  You can use the -depth parameter to adjust how far you want it to go.  Play around with it or Export-CliXml
PowerShell,3ddufx,PsTakuu,1 point,Wed Jul 15 15:31:18 2015 UTC,"Actually that's just getting it to the file. Then if you need it later:  $mystuff = ConvertFrom-Json -InputObject (Get-content C:\temp\myjson.txt -Raw)   $stuff = @(@(0,1),@(2,3))  $stuff | export-csv C:\temp\mycsv.csv -NoTypeInformation #doesn't look good  $stuff | ConvertTo-Json | out-file C:\temp\myjson.txt #looks shit but is 100% functional  #I guess you can also use .json as the file extension, visually is the same as .txt  $mystuff = ConvertFrom-Json -InputObject (Get-content C:\temp\myjson.txt -Raw)"
PowerShell,3ddufx,PsTakuu,1 point,Wed Jul 15 15:46:13 2015 UTC,"Would I be using both commands? PowerShell apparently doesn't recognize ConvertTo-Json.  EDIT: I realize our company is on PowerShell v1.0. I'll see if I can update it quickly.  When I just use Export-CliXml, it seems to work correctly but adds a bunch of formatting that no program knows how to parse.  Here's what I'm using:  Export-Clixml -InputObject $FoldersFound -Path .\$output.xml"
PowerShell,3ddufx,alcaron,1 point,Wed Jul 15 15:46:37 2015 UTC,"Ohhhh dude. PS 1.0! Hotdamn. No you wouldn't be using both commands.  Use either JSON or XML.  Either way you will have a serialized object format file that will have to be processed by something.  Which program are you using that doesn't know how to parse it?  If your goal is to get your objects into an Excel file, you are looking more at what /u/alcaron is saying below.  Write a custom function to dump that data.  You may also want to look at using .NET objects for Office Applications; it may be over the top but would come in handy in the future.  Here's something I got but unfortunately don't have a link to the source :(  It must have been on a forum somewhere.  ""This will be where I will compile all the knowledge I've gained about working with Excel through Powershell.  Some examples from real projects will be used.  Feel free to borrow functions and code sections if you see fit.  The following structures are important to the subject and will be discussed here:  Objects:     1. The Excel object.     The application while running has an object of the ComObject type.  To create and start a new instance of Excel, do the following:  A good source of information can be found at https://msdn.microsoft.com/en-us/library/office/ee861528.aspx  2. The Workbook object. The workbook is stored in a workbook object.  One can create a new workbook or open an existing one.   The workbook object is detailed on the following page: https://msdn.microsoft.com/en-us/library/office/ff835568.aspx  3. The Worksheet interface. The worksheet interface represents the tabs of the workbook.  They can be referenced as follows:  The worksheet interface is described here: https://msdn.microsoft.com/en-us/library/vstudio/Microsoft.Office.Tools.Excel.Worksheet%28v=vs.100%29.aspx   Cells, ranges, and the like:  -Jake"""
PowerShell,3ddufx,alcaron,2,Wed Jul 15 16:05:49 2015 UTC,"Yeah, Powershell now looks pretty updated, haha!  I'll see what I can do going the Excel route. Apparently, people are saying that writing to excel requires referencing specific cells. That's not bad to me!"
PowerShell,3ddufx,alcaron,2,Wed Jul 15 16:18:38 2015 UTC,"You've never tried to dump thousands of cells worth of data into it then. ;)  I actually have a trick for doing it super fast, think it's on pastebin somewhere...  $indSheet = $workbook.Worksheets.Add() $count = $arSub.Keys.Count     $array = New-Object 'object[,]' $count,2     $arRow = 0     foreach($y in $arSub.Keys) {             if($y -ne ""depName"" -and $y -ne ""duration"" -and $y.Length -gt 1) {                     $t = 0                     $array[$arRow,$t] = $y                     $t++                     $array[$arRow,$t] = $arSub[$y]                     $arRow++             }     }     $rng = $indSheet.Range(""A1"",(""B""+$count))     $rng.Value2 = $array   Value2 lets you dump an object into a whole range of cells all at once, but it ONLY takes one specific very basic type of object, at least it did back then...  But if you know the height and width of your data, you can dump absolute f-tons of data into a sheet at once, rather than doing it cell by cell."
PowerShell,3ddufx,alcaron,2,Wed Jul 15 20:35:42 2015 UTC,I'll see if I can translate this tomorrow when I get back. Thanks!
PowerShell,3ddufx,alcaron,2,Wed Jul 15 20:44:30 2015 UTC,"Export-CSV expects a square array so if you have goofy or complex arrays, you are best off just iterating through them and writing out your own .csv file.  The reason you got the results you got was because, lets say I have an array:  $test = @(1,2,3,4,5,6,7,8,9,0)   When you write this out it writes one item per line...so you get:  1 2 3 4 5 6 7 8 9 0   But again, even if you use Export-Csv -NoTypeInformation unless the contents of the arrays are the same length you are likely to have problems. And a multi array in and of itself may just be a no go.  Export-Csv is not the most robust thing in the world."
PowerShell,3ddufx,alcaron,1 point,Wed Jul 15 14:44:52 2015 UTC,"I should not have made a limitation on the file type to be exported to. I can use any file format that allows a table of this multidimensional array. Are there other, better options?"
PowerShell,3ddufx,alcaron,2,Wed Jul 15 14:59:28 2015 UTC,"Roll your own at this point sadly.  Be it a XML or CSV or just plain old text, one you start getting beyond simple/base objects you are going to most likely just write your own function to output it.  PS does many things for you, but not everything sadly. :("
PowerShell,3ddufx,midnightFreddie,1 point,Wed Jul 15 15:10:13 2015 UTC,"I made a nested loop that exports the values of the array to Excel very nicely! However, there is one last problem I'm facing to make sure this is well formated. Whenever there is a path written in the cell, instead of the following:  C:\path\to\file   It writes this:  Value  ------------  C:\path\to\file   This makes the height of the cells too tall to read easily. Using echo $FoldersFound produces the same sort of output. Is there a way I can just export the value itself?  EDIT: I'm using the function $ACE.IdentityReference to return permissions on folders. I believe it is this function that is actually adding the ""value"" text."
PowerShell,3ddl06,MajormonkeyAtWork,1 point,Wed Jul 15 13:02:23 2015 UTC,"No idea, I've just tested it and it works fine for me."
PowerShell,3ddl06,the_spad,1 point,Wed Jul 15 13:12:12 2015 UTC,Doh! I was logged in as a local user on one of my test machines.
PowerShell,3ddl06,MDFreaK76,1 point,Wed Jul 15 13:19:09 2015 UTC,i think you're missing an equals sign in there...  $NewComputerList =
PowerShell,3ddl06,kaluce,1 point,Wed Jul 15 13:13:19 2015 UTC,"Shot in the dark, Why not just disable the user account so it can't log in?"
PowerShell,3ddr9q,Shazam1269,2,Wed Jul 15 14:00:25 2015 UTC,"If you didn't add a model field to AD then you wont find that information from the domain.  If you have SCCM running in your environment this is MUCH simpler.  If you don't then you are going to need to:  Get-ADComputer -Filter ""*"" | select name | % { if(Test-Connection $_.Name){ $_.Name;(gwmi Win32_ComputerSystem -ComputerName $_.Name).Model;"""" } }   Note I haven't debugged that..."
PowerShell,3ddr9q,alcaron,1 point,Wed Jul 15 15:05:27 2015 UTC,Do you have a list of machine names?  Or do you want to do a network sweep and try every responding IP address?   Or do you want to query AD for a list of machines?  gwmi -computername <computer> win32_computersystem
PowerShell,3ddr9q,MDFreaK76,1 point,Wed Jul 15 14:36:18 2015 UTC,Do not have a list of names. I don't think the AD query will work as the machine info isn't in AD.
PowerShell,3ddr9q,chreestopher2,1 point,Wed Jul 15 16:34:26 2015 UTC,how large a network are you wanting to scan?
PowerShell,3ddr9q,chreestopher2,1 point,Wed Jul 15 19:33:57 2015 UTC,"honestly, if the machines arent in AD, unless you have the local credentials for the machines, powershell isnt going to be good for this.  something like nmap or emco might be a better fit, though if you are looking for rogue machines, without credentials that you know, its going to be harder to find anything that will work.  edit:  or were you just saying the model information isnt stored in AD? but they are AD domain joined machines?"
PowerShell,3dew4v,88monte,1 point,Wed Jul 15 18:57:26 2015 UTC,"Try:  $Files = Get-Childitem $Targetfolder -include $Extension | where {$_.LastwriteTime -le ""$Lastwrite""}   I've got a script that does something similar (generates a report of all files in a common folder that are older than 14 days so they can be flagged for deletion later that week) and when checking their creation date I need to compare it as -le against the current date. I could be wrong in this case, but give it a shot."
PowerShell,3dew4v,Stevenger,1 point,Wed Jul 15 19:46:51 2015 UTC,"You could do something as basic as:  gather files older than 10 days:  $Files = Get-Childitem C:\Blah | where {$_.LastwriteTime -le (Get-date).AddDays(-10)} | Select Fullname,LastWriteTime   email that content example is with gmail but you can change that:          $SMTPServer = ""smtp.gmail.com""         $SMTPPort = ""587""         $Username = ""blah@gmail.com""         $Password = ""password""          $to = ""Blah@yourcompany""         # $cc = """"         $subject = ""Files older than 10 days""         $body = ""$files""         $attachment = $null         $message = New-Object System.Net.Mail.MailMessage         $message.subject = $subject         $message.body = $body         $message.to.add($to)         # $message.cc.add($cc)         $message.from = $username         #$message.attachments.add($attachment)          $smtp = New-Object System.Net.Mail.SmtpClient($SMTPServer, $SMTPPort);         $smtp.EnableSSL = $true         $smtp.Credentials = New-Object System.Net.NetworkCredential($Username, $Password);         $smtp.send($message)   You can always use Send-Mailmessage cmdlet also for emails. both work well just up to you."
PowerShell,3dew4v,bundyfx,1 point,Wed Jul 15 23:11:55 2015 UTC,"I have no issues doing the emailing part, it just that i can't get this part to work. I need to check for files that are older than 1 hour (if they are still there after 1 hour it means they didn't get processed by another application and need to send an alert)  I'll try your suggestions tomorrow and see what happens. Thanks"
PowerShell,3dew4v,cmorrall,1 point,Wed Jul 15 23:59:12 2015 UTC,"Just a hunch, I'm not too experienced with PowerShell myself. Should $Extension not be "".txt"" instead of ""*.txt""?"
PowerShell,3dew4v,Bongoots,1 point,Thu Jul 16 04:28:56 2015 UTC,"As others have said, you need to use -le (less than or equal to) instead of -ge (greater than or equal to).    This is because the date/time stamp is like a number (such as 1437060766 which is a recent Unix time stamp).    You want to find files older than a certain point, which is 'less than' that number (i.e., before) - unless say you want to find files newer than a certain point (e.g., within the last hour), in which case -ge is used of course."
PowerShell,3dets5,Prozac500,1 point,Wed Jul 15 18:41:18 2015 UTC,"Pssst:  $xmlObject = [xml](Get-Content .\source.xml) $xmlObject.PropagationConfig.Endpoints | ForEach-Object {     $Parameters = @{         Uri = ""https://{0}/AppStoreService.ashx"" -f $_.Endpoint.Trim()         Body = ""Test Body""         Method = ""Post""         ContentType = ""text/plain""     }     $curl = Invoke-WebRequest @Parameters     $curl.Content }   Don't construct the loop. Let Powershell do the work for you.  Also, parameter splatting is very handy. Depending on the web API you're calling, you might look into Invoke-Restmethod instead of Invoke-Webrequest, although the former is basically (Invoke-Webrequest).Content | ConvertFrom-Json"
PowerShell,3ddrlk,MajormonkeyAtWork,1 point,Wed Jul 15 14:03:02 2015 UTC,try using $NewComputerList.Name
PowerShell,3ddrlk,MDFreaK76,1 point,Wed Jul 15 14:08:42 2015 UTC,Thanks! That did the trick.
PowerShell,3ddrlk,alcaron,1 point,Wed Jul 15 14:12:28 2015 UTC,"Pipelines are your friend...  $myuser = ""mike"" Get-ADComputer -Filter 'name -Like ""*PC*""' -Properties Name | Get-WmiObject -ComputerName $_.Name -Class Win32_ComputerSystem -Filter ""UserName LIKE '%$myuser%'"" -Property UserName,Name | Select-Object -Property UserName, Name   The reason being that you aren't loading gobs and gobs of crap into memory, most of which will stay there until you close the host/session.  I don't know if that code will run verbatim, the second pipe might be unneeded. But the point remains that it can all be done without keeping the information in memory. I also could be wrong but don't really see why the -ExpandProperty is needed."
PowerShell,3dce4b,butthole-scientist,4,Wed Jul 15 04:18:30 2015 UTC,Use start-process and parse the extra commands in the argumentlist parameter.  Start-process 'file.exe' -argumentlist '\\server\filename.cvs /q /noreboot'
PowerShell,3dce4b,Theratchetnclank,2,Wed Jul 15 07:05:44 2015 UTC,"Sadly,  start process makes stream capturing a cruddy experience especially if you want the exit code too."
PowerShell,3dce4b,gospelwut,1 point,Wed Jul 15 14:45:35 2015 UTC,"Not really.  $process =  start-process C:\file.exe -ArgumentList ""/parameter"" -wait -passthru if (!(($process.hasexited -eq $true) -and ($Process.exitcode -eq 0))) {""we have an error"" }"
PowerShell,3dce4b,Theratchetnclank,1 point,Wed Jul 15 15:46:29 2015 UTC,"Notice the -wait? So, consider logging something like a JDK process which could essentially run forever. Using the explicit parameters to write stdout/stderr to files directly has mixed results depending on the binary."
PowerShell,3dce4b,gospelwut,1 point,Wed Jul 15 17:30:50 2015 UTC,That's the same with scripting any executable. You cannot get the exit code unless the application exits.
PowerShell,3dce4b,Theratchetnclank,1 point,Wed Jul 15 17:53:04 2015 UTC,"Right. But you can also just redirect the executable output into powershell, which can use redirection (*>) to log output WHILE the process is running. You can still capture the exit code with $LASTEXITCODE  e.g.  & ""java.exe"" ""$xmx"" ""-jar"" ""$jar"" ""-role"" ""$role"" ""-port"" ""$port"" ""-nodeConfig"" ""$nodeConfig"" 2>&1 | output-log  if ($LASTEXITCODE -ne 0) { output-log ""Process exited with code $LASTEXITCODE"" }"
PowerShell,3dce4b,gospelwut,1 point,Wed Jul 15 20:33:14 2015 UTC,"To avoid confusion, its argumentlist instead of arguementlist ;)"
PowerShell,3dce4b,Rugtert,0,Wed Jul 15 08:32:34 2015 UTC,Thanks I typed the UK English way by accident.
PowerShell,3dce4b,Theratchetnclank,2,Wed Jul 15 09:04:23 2015 UTC,arguement is not UK English ;)
PowerShell,3dce4b,real_parbold,1 point,Wed Jul 15 10:35:55 2015 UTC,This. Try start-process and see how it goes.
PowerShell,3dce4b,SteveMI,2,Wed Jul 15 12:05:18 2015 UTC,Is filename.cvs a typo?
PowerShell,3dce4b,GLiMPSEiNATOR,1 point,Wed Jul 15 11:20:59 2015 UTC,"Not sure if it's working, but try this:  cmd /c 'program.exe ""\\server01\whatever\filename.cvs"" /q'"
PowerShell,3dce4b,maragam,1 point,Wed Jul 15 07:03:50 2015 UTC,"No, no no...no, dammit, we are not calling one shell from another because we can't figure out arguments.  I'd even rather:  $proc = New-Object System.Diagnostic.Process $proc.StartInfo.FileName = ""c:\foo.exe"" $proc.StartInfo.Arguments = ""-nocmdslashc"" $proc.Start() $proc.WaitForExit()   Don't make me roll up a newspaper dammit. ;)"
PowerShell,3dapin,LagunaGTO,7,Tue Jul 14 20:30:45 2015 UTC,"Pipe the results into the ""Get-ADUser"" cmdlet and specify the properties to retrieve, like so:  Get-ADGroupMember 'AdGroupName' | Get-ADUser -Properties Company | select Name,SamAccountName,Company"
PowerShell,3dapin,psyc0des,4,Tue Jul 14 20:53:05 2015 UTC,You're the bees knees. Thanks man.
PowerShell,3dapin,Vino84,2,Tue Jul 14 20:57:31 2015 UTC,"As an add to this, the issue was that the returning object from Get-ADGroupMember did not have the Company attribute. Piping Get-ADGroupMember to get-member will show the available Properties and methods     TypeName: Microsoft.ActiveDirectory.Management.ADPrincipal  Name              MemberType ----              ---------- Contains          Method Equals            Method GetEnumerator     Method GetHashCode       Method GetType           Method ToString          Method Item              ParameterizedProperty distinguishedName Property name              Property objectClass       Property objectGUID        Property SamAccountName    Property SID               Property"
PowerShell,3da0qc,DueRunRun,4,Tue Jul 14 17:43:22 2015 UTC,"Get-ADUser <user> -Properties NTSecurityDescriptor | %{ $_.SAMAccountName;$_.NTSecurityDescriptor.AreAccessRulesProtected;"""" }   eidt: This btw has the benefit of not making two AD queries per user and not storing anything in memory because it uses the pipeline."
PowerShell,3da0qc,alcaron,1 point,Tue Jul 14 18:49:08 2015 UTC,"I couldn't get this one to work directly, but I'll be sure to investigate your method later. Thanks though, appreciate it."
PowerShell,3da0qc,alcaron,2,Tue Jul 14 18:56:19 2015 UTC,"Did you make sure to replace <user> with either a specific user or -Filter ""*"" ?"
PowerShell,3da0qc,alcaron,1 point,Tue Jul 14 19:05:24 2015 UTC,"Yes, actually i tried my $user variable first, maybe i misunderstood. Let me try again."
PowerShell,3da0qc,alcaron,1 point,Tue Jul 14 19:10:06 2015 UTC,"Dude, that is slick, but I'm lost on what the script is doing. How is it piping to the % and all of a sudden it's expanding the object as necessary?"
PowerShell,3da0qc,throwaway09563,1 point,Tue Jul 14 23:18:40 2015 UTC,% is an alias for ForEach-Object so when you have an object and you pass it to the pipeline it's represented as $_  So the script is essentially the same as setting get-aduser to a variable and doing a foreach on it but because you kept it the pipeline when the script is done running it doesn't still have the information for every single user still loaded into memory.
PowerShell,3da0qc,throwaway09563,2,Wed Jul 15 00:20:39 2015 UTC,"If it helps, the above is, functionally, identical to the following:  $users = Get-ADUser -Properties NTSecurityDescriptor -Filter ""*""  foreach($user in $users) {     $user.SAMAccountName     $user.NTSecurityDescript.AreAccessRulesProtected }   It's just that, again, using | is a way of telling PS ""take the object created by this statement (in this case: Get-ADUser -Properties NTSecurityDescriptor -Filter ""*"") and put it into the pipeline.  Once in the pipeline you have to do something with it so we want to do something for each ""item"" in the object so we do %, if we wanted to effectively filter, say to only show AD accounts that had AreAccessRulesProtected set to $true we would:  <statement> | ?{ $_.NTSecurityDescriptor.AreAccessRulesProtected -eq $true } | select SAMAccountName   So in that case we are saying get an object that contains the information for every AD user, pass it into the pipeline, where we are going to ? (alias for Where-Object) and only the ones that match our comparison will pass through to the next stage of the pipeline where we call select (Select-Object) and just display the property we care about, in this case the SAMAccountName.  Feel like that makes it clear as mud...heh...oh well, hopefully you can grok something useful from that."
PowerShell,3da0qc,Mindflux,1 point,Wed Jul 15 01:18:28 2015 UTC,All your script does is report the flag value for the descriptor value. It isn't actually reporting the name.
PowerShell,3da0qc,chreestopher2,1 point,Tue Jul 14 18:08:30 2015 UTC,I know... hence the post.
PowerShell,3da0qc,chreestopher2,2,Tue Jul 14 18:32:13 2015 UTC,"Sorry, I was on the phone and couldn't write up something more useful.  I see solutions below, but you might also think about the fact that your original script is the same as this one-liner:  ($u in (get-aduser -filter * -properties NTSecurityDescriptor)){$u.NTSecurityDescriptor.AreAccessRulesProtected}       My quick and dirty version if I understand what you want is  (get-aduser -filter * -properties NTSecurityDescriptor)|%{'""'+$_.name+'"",""'+$_.NTSecurityDescriptor.AreAccessRulesProtected+'""'}   (Not as pretty but it gets the job done!)"
PowerShell,3da0qc,chreestopher2,1 point,Tue Jul 14 20:27:26 2015 UTC,"Because you have it all wrapped up in parens like that, it's using that method for Get-ADUser and not listing the name and NTSecurityDiscriptor from your properties.  Foreach ($u in $users) { Get-AdUser $u.SamAccountName -Properties Name,NTSecurityDescriptor  }   Might be more of what you want?"
PowerShell,3da0qc,KevMar,1 point,Tue Jul 14 18:46:15 2015 UTC,"Unfortunately NTSecurityDescriptor is one of those values (string maybe, sorry still learning) that doesn't output correctly if its just listed, comes out as ""System.DirectoryServices.ActiveDirectorySecurity"" instead of the true or false value i'm trying to get from ntsecuritydescriptor.areaccessrulesprotected."
PowerShell,3da0qc,FlippityFlip,2,Tue Jul 14 18:49:01 2015 UTC,"strings output correctly.  Its nested objects that dont.  This is because NTSecurityDiscriptor refers to a nested object, with nested properties. Powershell can not automatically expand all layers of nested objects into a textual representation that would make sense and be vissually appealing, instead you just get the type name of the object being refered to.  You can use select-object -expandproperty NTSecurityDescriptor to expand that property out, but to acomplish this smoothly, without advanced knowledge of how many layers properties will be nested, is rather difficult as you must expand one layer at a time...  I find it much easier to store a refference to the object(A variable) im trying to reach, then use dot notation to access the property that i am trying to get to.  Parentheticals have their place, but its not where you need more than exactly one property from the same object."
PowerShell,3da0qc,FlippityFlip,1 point,Tue Jul 14 19:25:00 2015 UTC,"foreach ($u in $users) {     $user = get-aduser $u.samaccountName -properties name, nTSecurityDescriptor | select Name, ntSecurityDescriptor     $obj = new-object psobject -property @{AreAccessRulesProtected=$user.nTSecurityDescriptor.AreAccessRulesProtected; Name=$user.name;}     write-output $obj }"
PowerShell,3da0qc,FlippityFlip,1 point,Tue Jul 14 18:48:56 2015 UTC,"Awesome, so it's best to work with strings or arrays (maybe I'm not using the right terms there) with a new object after I've gathered all the data and expanding the string after the fact?"
PowerShell,3da0qc,FlippityFlip,2,Tue Jul 14 18:55:53 2015 UTC,"I prefer to keep a reference to whatever objects I need, and then build a custom object with just the data i need in it.  This isnt always the most efficient way, but resources are rarely the limiting factor of my capabilities, and I for one would much rather be able to easily see what im doing in a script (or what someone else is doing), than to have a barely human noticeable performance boost.  It could have been done as a oneliner with somethign like:  $users |foreach {get-aduser $_.samaccountName -properties name, nTSecurityDescriptor -PipelineVariable user | select @{n=""AreAccessRulesProtected"";e={$user.nTSecurityDescriptor.AreAccessRulesProtected;}}, @{n=""Name"";e={$user.name}}}   But I personally find it always better to be as explicit as possible with your intentions."
PowerShell,3da770,alcaron,2,Tue Jul 14 18:26:46 2015 UTC,So you want a list of cmdlets with parameters that accept pipeline input?
PowerShell,3da770,Waxmaker,1 point,Tue Jul 14 19:10:19 2015 UTC,Yes.
PowerShell,3da770,alcaron,2,Tue Jul 14 19:42:26 2015 UTC,"Something like this?  (Get-Help Get-Service).parameters.parameter | Where { $_.pipelineInput -like ""true*"" }"
PowerShell,3da770,chreestopher2,2,Tue Jul 14 19:17:03 2015 UTC,"Beat me to it...  Get-Command | %{ (Get-Help Get-Service).parameters.parameter | Where { $_.pipelineInput -like ""true*"" } }   edit: Or you know, if you want to see the CMDLet name...  Get-Command | %{ $_.Name;(Get-Help Get-Service).parameters.parameter | Where { $_.pipelineInput -like ""true*"" } }"
PowerShell,3da770,alcaron,1 point,Tue Jul 14 19:22:16 2015 UTC,You're the man!
PowerShell,3d9pl1,badtasteic,3,Tue Jul 14 16:26:51 2015 UTC,"Get-ADGroup -Filter {name -like ""*TEST*""} | %{ $_.Name;(Get-ADGroupMember $_.Name).Count;"""" }   edit: The reason to do it this way is when you use the pipeline, you don't store things in memory, plus you can do it in fewer steps with fewer lines of code so ultimately it should be easier to read/maintain."
PowerShell,3d9pl1,alcaron,2,Tue Jul 14 17:15:36 2015 UTC,Very cool. Thanks for the tip!
PowerShell,3d9pl1,aytch,1 point,Tue Jul 14 17:28:32 2015 UTC,Nice to see someone else using Powershell the way it was intended!
PowerShell,3d9pl1,speeding_potato,2,Wed Jul 15 06:43:04 2015 UTC,"In the first example, $groups only contains the Name property from the AD group objects.  Inside the foreach loop, your code then tries to reference the distinguished name, which is not present, and you get errors.    Try removing ""Select Name"" from the end of your AD group search.  Like so:  $groups = Get-ADGroup -Filter {name -like ""*TEST*""}   When you do that, $groups contains complete AD group objects.  I didn't get any errors testing that way."
PowerShell,3d9pl1,Bongoots,1 point,Tue Jul 14 16:54:54 2015 UTC,This works. Thank you very much.
PowerShell,3da8jo,thechipdangler,3,Tue Jul 14 18:36:21 2015 UTC,"You need to put parentheses after ""cut"" and ""paste"", so that they're ""Cut()"" and ""Paste()"""
PowerShell,3da7db,_Unas_,1 point,Tue Jul 14 18:27:57 2015 UTC,"Thanks for sharing this.   We currently respond to these spam manually by actually removing the messages from our Exchange data store - this way our users won't even have a chance to click the URL.  I'll be looking at your code, and possibly integrating it into our strategy.   If I get time, I may attempt to merge the ""search and destroy"" functionality into the Git"
PowerShell,3da7db,twentymosquito,1 point,Tue Jul 14 19:04:08 2015 UTC,"Instead of manually exporting the items to .msg, you may want to look into leveraging EWS. Then you could fwd the items to an abuse mailbox and have the script auto parse/respond."
PowerShell,3d9zk8,Proxiconn,3,Tue Jul 14 17:35:26 2015 UTC,"1) Unless it doesn't play nice there isn't really a reason to not use Start-Process and -ArgumentList  2) If you are worried about it overwriting the file just use PS to coy the file in question to a new name, using, say Get-Date to timestamp it.  That being said, if you set the SourceCMDPath there isn't really a reason to Push-Location, just Start-Process using that path with the exe name appended."
PowerShell,3d9zk8,alcaron,3,Tue Jul 14 19:38:25 2015 UTC,"Seconded.  Also, I believe these are errors:   There's a typo in your ""else"" statement: you're missing an 'x' in 'C:\Program Files (x86)' You're missing a pipeline operator after ""For-EachObject {$_.Name} After that pipeline operator, change ""$.Name"" to ""$_"""
PowerShell,3da0gp,fortunate_man,2,Tue Jul 14 17:41:42 2015 UTC,"If it is always the ""@"" symbol, you should be able to do this,  Import-Csv c:\file.txt -Delimiter ""@"" -Header ""1"", ""2""  This will get your data separated. I haven't figured out how to do the math yet. I believe you can do it with [int] and [convert]. I look more after work."
PowerShell,3da0gp,thesunisjustanadmin,2,Tue Jul 14 19:00:23 2015 UTC,"You could use regex for this, just an example:  $TestData = @"" 00009821775827123456789.12@45454545454545 00002404198621123656789.12@38421457651633 00003246574123123756789.12@63573217423136 00007862110852123856789.12@32165873211333 ""@ #Option 1 using regex: $TestData.Split(""`n"") | %{[regex]::Match($_,""(\d{9}\.\d{2})(?=@)"").Value}  #Option 2 using split and substring: $TestData.Split(""`n"") | %{$_.Split(""@"")[0].Substring(14)}   edit: added additional option"
PowerShell,3da0gp,LordZillion,1 point,Tue Jul 14 19:24:19 2015 UTC,"I also went regex:  Get-Content .\mytextfile.txt |     ForEach-Object {         $_ -match '(?<=^.{14}).{12}' | Out-Null         [decimal]$Matches[0]     } |     Measure-Object -Sum   Also, why not grab some other stats? Replace the last line with this:      Measure-Object -Sum -Average -Minimum -Maximum"
PowerShell,3da0gp,midnightFreddie,2,Thu Jul 16 03:23:12 2015 UTC,"Here's an easy way to do it:  $fileContent = Get-Content C:\mytextfile.txt $sum = 0 ForEach ($line in $fileContent) {     $stringNum = $line[14..22] -join ''     [int]$intNum = [convert]::ToInt32($stringNum, 10)     $sum += $intNum } Write-Output $sum   '$stringNum = $line[14..22] -join '' gets the 15th through the 23 characters of the current line as a text string. The next line converts that text string to an integer.  Edit: Edited to use the more reliable [convert] + added clarity."
PowerShell,3da0gp,Waxmaker,2,Tue Jul 14 19:39:59 2015 UTC,"With a little massaging, this is exactly what I needed.  $fileContent = Get-Content C:\mytextfile.txt $sum = 0 ForEach ($line in $fileContent) {     $stringNum = $line[13..24] -join ''     $intNum = $stringnum -as [decimal]     $sum += $intNum } Write-Output $sum   Thank you so much!"
PowerShell,3da0gp,LordZillion,1 point,Tue Jul 14 20:45:52 2015 UTC,"For when you're bored and you like oneliners:  Get-Content C:\mytextfile.txt | % -B {$S=0} {[decimal]$S += ($_.Split(""@"")[0].Substring(14))} -End {$S}"
PowerShell,3da0gp,alcaron,1 point,Wed Jul 15 09:24:39 2015 UTC,"Since it comes from a file a Get-Content will have each line as it's wn element in an array basically so if you have two numbers, and they are always delimited by ""123456789.12@"" and anything before that is one number and everything after is the other, you could just:  Get-Content ""filepath"" | %{ [double]($_.Substring(14,12))+[double]($_.Split(""@""))[1] }   You may run into a bigger problem which is...how to get a number like ""45454668911334.12"".  Try as I might I can only get it to do a single decimal point...so as long as rounding that to the nearest decimal isn't a problem for you it should be fine...if you need two decimal places though...good luck..."
PowerShell,3da0gp,alcaron,1 point,Wed Jul 15 01:42:42 2015 UTC,duh...the [decimal] type...
PowerShell,3d8g3r,real_parbold,2,Tue Jul 14 09:11:33 2015 UTC,"Top Google result for powershell local user password never expires:  https://social.technet.microsoft.com/Forums/windowsserver/en-US/e4e96a5e-3b28-4673-8c61-d4abdf8f2426/win-7-setting-the-option-password-never-expires-for-a-specific-local-user?forum=winserverpowershell  Regarding PowerShell remoting; if the machines' IP addresses are changing, how do you know what to connect to, and why can't you feed the source of that information into your scripts?"
PowerShell,3d8g3r,After_8,1 point,Tue Jul 14 12:26:03 2015 UTC,"This is on Amazon Web Services.  From my management box, I can discover where the instances are, and can connect to them.  What I cannot do, is have a 'trusted remoting source' configured on the target boxes to my management box. The management box could be restarted (new IP), rebuilt (new GUID) etc - because then I'd have to go to every instance and 'revoke' the remoting source that is no longer valid.  This is not on an AD, so I can't use that - and if it were ; creating the users would be irrelevant :O  I'm currently playing with Ed Wilsons Local User Management Module and will extend it to use the linked code  $user = [adsi]""WinNT://$env:computername/administrator"" $user.UserFlags.value = $user.UserFlags.value -bor 0x10000 $user.CommitChanges()   Although this is very familiar, and I'm sure that last try - it didn't do it. I got so frustrated with the script I deleted it on the intent to go at it again with a clearer mind, absorbed learnings and none of the circular though paths I was stuck in at the time :)  I'll let you know :D"
PowerShell,3d8g3r,jbtechwood,2,Tue Jul 14 13:10:50 2015 UTC,Your reasoning for not putting in a trusted connection on your targets is what elastic ips are for in AWS.  Might help to have that on the management node at least.  Also you might want to look into a configuration management tool/technology.  It would make configuring and ensuring that configuration stays in place.
PowerShell,3d8g3r,LandOfTheLostPass,1 point,Wed Jul 15 10:55:12 2015 UTC,I already employ EIPs for my management boxes - maybe I have not thought this through quite properly; this aspect of management is a 'as and when time permits' priority :/
PowerShell,3d8g3r,KevMar,1 point,Thu Jul 16 08:38:05 2015 UTC,I've manage to get the account creation (and deletion) working  The account expiry bit works :) thank you  Just have to work out why I can't add the user to the group when talking to a remote machine.
PowerShell,3d8g3r,KevMar,2,Tue Jul 14 13:51:14 2015 UTC,"Seems that you have to use the actual name of the remote machine, not the IP Address.  Awkward - because AWS refer to them as instances with an i-xxxxxxxx name, and the internal names can be the same as others, or auto-changed to IP-0A0001 (the hex version of its IP address) and neither need to be related to the DNS name in use externally  Next challenge, is to take our internal reference, connect to the remote machine - work out what it thinks it is, pass that name and its internal IP address back to the script so that it can temporarily fake the DNS record to allow the script to communicate to it via it's internal name to the right IP address so that WinNT://${boxname}"" works  Urgh - perhaps just use PSExec to run the whole script 'locally' on the remote boxes."
PowerShell,3d8g3r,mythicnap,2,Tue Jul 14 14:00:16 2015 UTC,"I'm fairly certain that you can use Get-WMIObject against an IP address and that can get you the hostname, ala:  $Name = $(gwmi -Class 'win32_ComputerSystem' -ComputerName '192.168.1.1'  -Property 'Name').Name"
PowerShell,3d8g3r,dindenver,1 point,Tue Jul 14 19:50:27 2015 UTC,Works Perfectly :) thanks
PowerShell,3d5ymf,chreestopher2,6,Mon Jul 13 20:00:42 2015 UTC,"It really depends on your crowd.  I've taught some people as well, but it was on a one by one basis, which is much easier.  Personally if they are in the technology field, they only need to learn a couple key points.   Everything is an object Pipe The rest of the operands Get-Help Get-Member Get-Command ForEach Where Select   Obliviously there is way more, but i would not go into depth on the actual syntax of individual commands that aren't used every time you open a shell.  I use the Get-Ad* commands all the time, but i wouldn't spend any time on them since the help explains it well enough.  Get-WmiObject is really useful to mention, but actually using it is more of a WMI learning course.  I guess what I'm saying is with 6 hours, you are better of teaching them how to teach themselves with what powershell offers.  With some mentions on weird gotcha stuff, like how powershell doesn't look in the current directory for stuff, ect.  Literally your 5th paragraph is gold.  Some 3rd party integration would be a plus."
PowerShell,3d5ymf,Deathonus,3,Mon Jul 13 22:23:16 2015 UTC,"I would say manage you expectations, do NOT expect anyone to walk out of 6 hours of training with much more than an itch and a general direction.  The best way to learn powershell is to do. And do.  And do a lot more.  Focus on basics, most of which honestly don't even apply solely to PowerShell. Proper formatting, understanding the difference between the shell and a script.  For your last class, go practical. Get-Process, Sort-Object, Get-Date, -f, Stop-Process, Select-Object.  If the last thing you can do it show them one really good example of WHY powershell matters, then anyone who was ever going to get into it will have as much motivation as you can give them in 6 hours.  IMHO, showing is WAY better than telling when it comes to teaching things that are just, way, way, too complex for 6 hours of training. You could take a college course on PowerShell (and programming in general) so you can't hope to make anyone anything more than really interested in 6 hours.  There all kinds of fun things you could give them for examples of what is cool about PS...  gps powershell -IncludeUserName | select id,username,processname | %{ $foo = Read-Host (""Wanna kill {0}'s instance of {1}?"" -f $_.UserName,$_.ProcessName);if($foo.ToUpper() -eq ""Y""){ Stop-Process $_.id } }"
PowerShell,3d5ymf,alcaron,3,Mon Jul 13 22:48:49 2015 UTC,"I know the topic is huge, but I havent even touched on WMI, or the other fundamental technologies that people need to be familiar with to really benefit from powershell (Activedirectory, hyperv, etc)   You should strongly consider avoiding Active Directory and HyperV as anything other than examples in your course. All practical work should be done with files, WMI or other items.  When I learnt PowerShell, I was working for a very large enterprise. They had an entire team that did Active Directory work. I had very few permissions in AD - I could make basic modifications with users within certain OUs that I was responsible for, but not much else. (Everything else could be done via a request with the AD team, so this wasn't an issue for my job.)  The first couple of books I got on AD were crammed full of AD exercises. None of which I could complete, so those books were fairly frustrating for me to try and follow. I didn't really get PowerShell until I used it for non-AD things that were more relevant to my job.  Keep it simple and generic. Use technologies you know will be available to all your attendees - maybe ask around to see what technologies people are using/have access to?   I figure I will need to do atleast a brief section on interacting with 3rd party technologies via powershell, but I just dont know how much I should go into detail on such topics. I feel like if i dont touch on them at all, then people will likely not see any real value to using powershell as the integration with these technologies is part of what makes powershell so awesome...   Avoid 3rd party technologies, keep it simple. Remember, PowerShell's not all that damned great. Sure, you think it is. Most people in this subreddit think it's great - and I know that saying PowerShell's not that great is probably a bad idea here. But bear with me, as I'm making a serious point - a lot of what it does has traditionally been done by WSH and VBScript/JScript. Some of what you're going to teach might look to older hands like very old news - they might have been doing half of what you try to teach years ago via WSH!  That sounds harsh, but you should anticipate that some people will have had experience with WSH/bash/Perl/Python/4NT/Take Command/KiXtart - they therefore may be a little jaded or hostile towards PowerShell.   Ideally, I would like everyone to come out of the class knowing how to retrieve objects, sort, filter, convert to various outputs, execute methods of objects, and to be able to build useful pipelines (so there will be some emphasis on parenthetical operations and string manipulation in order to pull out a specific property of an item in the pipeline etc) as well basic control flow (if, else, while, 1..10), comparisons, etc ...and above all else I want to teach them the art of discovery via reflection.   Those kinds of basics should be the focus, and you should use the registry or data from files in your examples. That shows how versatile Get-ChildItem can be...  Instead of a focus on AD or 3rd party tools, files are a good teaching tool and have practical real-world use. The skills learned there are generic enough that they're always going to find a use in the future. Import-CSV/Export-CSV will probably impress your students and keep their attention. And ""[xml]$MyVar = Get-Content file.xml"" and then searching and extracting from the resulting data structure will certainly show off PowerShell's prowess. (Lots of enterprise applications end up using XML config files or outputting summaries/logs in XML, so that's a genuinely useful tool for reporting and troubleshooting. Not to mention something that's easier in PowerShell than just about any other environment!)  I hope that helps."
PowerShell,3d5ymf,philipstorry,1 point,Tue Jul 14 08:57:52 2015 UTC,"I'm actually taking a powershell class right now at Estrella Mountain Community College here in Arizona. The textbook resource that we use is: Windows Powershell 2.0 for the Absolute Beginner  Also, what someone else said, just keep doing PS. Do PS. And continue doing PS.  What I want to stress is that in any PS textbook, your student will get bored with the fundamentals (chapter 1-7 in the textbook we use). It isn't until Chapters 8 and 9 (""Managing Files & Folders"" and ""Basic System Administration"") that a student will really begin to see relevance in how PS applies to their job."
PowerShell,3d5ymf,neilthecellist,1 point,Mon Jul 13 22:17:09 2015 UTC,Wish i could attend this class myself : (   I'm sure you'll do great OP.
PowerShell,3d5ymf,CrossXFire,1 point,Tue Jul 14 06:00:18 2015 UTC,Im half way through the 'Learn PowerShell in a month of Lunches' videos and book.  Loads of content on youtube and in the book. Im a complete beginner by the way
PowerShell,3d5ymf,jamin100,1 point,Tue Jul 14 13:35:19 2015 UTC,"Thank you all for the replies.  I mostly agree that the focus should be on the basics of powershell, not teaching specific cmdlets, or external technologies. But I know the audience I will be teaching will mostly be help desk agents who spend most of their time unlocking accounts and resetting passwords, and I know showing some basic AD management via powershell just might be enough to keep their interest.  I agree on using file system operations is a good place to show off some of the power of the shell in a way that almost everyone can immediately understand.  I think this class is going to mostly be green helpdesk agents, and engineers who have experience doing things manually, or maybe little bits of batch and vb, but not people with extensive scripting backgrounds by any means.  Along with teaching basic syntax, operators, objects, pipelines, etc, I would also like to give a good focus on how to think about a task in terms of automation. How to break apart a task into scriptable steps, and how to go from interactive shell session to script, in a logical way, as well as how to confirm your results.  Once you have those concepts down, and are familiar with get-command, get-member, get-help, and get-childitem, the sky is the limit.  Please keep the suggestions / thoughts / resources coming...  I would also like to include some quick challenge problems that I could have everyone form into groups to try to accomplish, and / or solve as a group with the whole class.  I would really like it if i could ahead of time ask students for a task or process they would like to automate (something easy, like cleaning temp files, generating project directory structures, parsing a log file and sending an email with the data, etc), and then have students vote on which task they want to script, and then collectively walk through the creation of the script, as I know I would have really liked that when I was learning. Though, in 6 hours, I know there isnt time for that...   But with that in mind, If anyone can send me some scenarios that might make for a fun 15 to 30 minute challenge, that would be awesome.  Like I said, Ive got 6 to 8 weeks to finalize the class, but I want the end result of this to be something I could post online as a free resource, that would include slides, examples, practice questions/challenges, etc   If I have more material than time to teach it, I could always include the extras as a homework / where to go next kind of thing."
PowerShell,3d5ymf,PsTakuu,1 point,Tue Jul 14 14:36:31 2015 UTC,"Wanna do something extra fun (come on you have 3 hours a day for  6-8 weeks.. you can do extra!)?    When you do you lab, make them use Start-Transcript and Stop-Transcript so that both you and them have a copy of what they did in the lab. 1) They use a cmdlet and immediately see a file created as a result.  2) You can review what they typed and give feedback (if time allows).  3) They will have a permanent record to look back at."
PowerShell,3d5ymf,alcaron,1 point,Tue Jul 14 15:37:33 2015 UTC,"He has 3 2hr courses, not 3hrs a day for 6-8 weeks.  Transcripts are great for generating a script based on your shell activity but yeah effectively grading them...eesh..."
PowerShell,3d5ymf,PsTakuu,2,Tue Jul 14 16:23:38 2015 UTC,"I have been told to develop one 3 day, 2 hours/day course for complete noobs, and one 3 day, 2 hours/day course for intermediate powershell.   I must have misunderstood what he meant when he said:  I have been told to develop one 3 day, 2 hours/day course for complete noobs, and one 3 day, 2 hours/day course for intermediate powershell.  And then later said:    PS, I have 6 to 8 weeks to develop the curriculum, and can probably devote about 3 hours a day to developing the course..  It's cool to see how we different understanding of the same words huh!? (seriously no sarcasm, it's definitely possible you understand that differently than I did.).  I suppose it'd be more for objective development, rather than for 'grading'."
PowerShell,3d5ymf,alcaron,2,Tue Jul 14 17:07:04 2015 UTC,"yeah, I should have been more clear, I meant I have about 3 hours a day to devote to developing the course, for 6 to 8 weeks, where the course will then be 3 2 hour sessions"
PowerShell,3d5ymf,alcaron,2,Tue Jul 14 18:23:31 2015 UTC,"Maybe I misunderstood what you meant, I took what you said to mean he had more time for cooler in-class events because he has 6-8 weeks 3hrs a day, but I think now you meant he has more time to develop cool things FOR the class.  Chalk it up to a parsing problem. ;)"
PowerShell,3d5ymf,dindenver,1 point,Tue Jul 14 18:45:01 2015 UTC,"Don't get too carried away with it, like for instance, the idea of asking them for things they would like to automate is good, having them vote though...another step AND they may choose the most confusing one for you to write in front of them.  Ask for ideas, then choose one or two that make sense, write them before, comment the hell out of them, and walk through it, last thing you want it to debug code you wrote with a half dozen or whatever people staring at you. Just going to eat up time. You can comment and use that to explain your thought process after the fact.  Same for group challenges, you may luck out and they may all be at a similar pace, or they may not be and the whole thing will either be a one man show or just fall flat. Just give them simple takeaway challenges to do when they get back to their desks. No time pressure, and they are the only factor involved in their success.  As for some challenges:   Get the current state of the primary network adapter.   This is fun because it illustrates you have to be mindful of when things are NOT like they should seem. Your inclination will be to use -Filter but there isn't a really clean way of finding only the adapters with MAC's using -Filter because you can't use -eq -like etc.   Create and add a simple alias to the current users profile.   Handy because it uses both file system and the profile. Test-Path, New-Item, the $profile variable.   Calculate how much CPU time Chrome has used on your machine.   Obviously this assumes you use chrome primarily but...  $statvar = 0 foreach($proc in (Get-Process chrome)) { $statvar = $statvar + $proc.CPU }  $statvar2 = 0 foreach($proc in (Get-Process)) { if($proc.Name -ne ""chrome"") {     $statvar2 = $statvar2 + $proc.CPU } }  Write-Host (""Chrome used {0} seconds of CPU time, everything else used {1} seconds of CPU time...save the planet, stop surfing the web..."" -f $statvar,$statvar2)   And maybe some example of code that elucidates using the pipeline vs. setting a variable and foreaching through it. You could probably make that CPU time snippet into a one liner, haven't looked at it really."
PowerShell,3d5ymf,dindenver,2,Tue Jul 14 17:33:42 2015 UTC,"This was a great reply, thanks a bunch and keep it coming... I think ive got a rough outline coming together pretty nicely and will post it some time in the coming weeks to get some feedback, just want to flesh it out a little more first.  Powershell is really one of those 80 20 things.... 80% of the material takes 20% of the time to cover, then 20% of the material takes the remaining 80% of time to cover lol... but the entire thing is a giant chicken vs egg connundrum... Im finding that using mind mapping software is really helping me to whip things into proper order easily without breaking my flow."
PowerShell,3d6195,michaelshepard,3,Mon Jul 13 20:18:15 2015 UTC,Hello Guys. I'm the dev behind poshboard. I left my previous company but i will gladly post the latest version if the poshboard website is down. I Keep you updated tomorrow!
PowerShell,3d6195,Pilosite,2,Tue Jul 14 16:58:07 2015 UTC,Thanks for replying to my tweet!
PowerShell,3d6195,pshatmsft,1 point,Tue Jul 14 17:01:04 2015 UTC,"Nope, still down.  Sorry, I don't have a copy.  Internet archive maybe?"
PowerShell,3d6195,100percentGerman,1 point,Tue Jul 14 01:57:11 2015 UTC,quick look at codeplex.com site shows another link to http://devinfra.blogspot.ca/ ... maybe contact the dev there?
PowerShell,3d6195,ic3r,0,Tue Jul 14 03:27:43 2015 UTC,Seems to be back up now.
PowerShell,3d69on,uprightHippie,2,Mon Jul 13 21:17:48 2015 UTC,"Get-WMIObject is giving you an object back.  Even though you're formatting the output and you're seeing exactly what you think you want, the data is still in the form of an object.  Try something like this instead:  $d = Get-WMIObject -Class Win32_Volume | Where-Object { $_.Label -eq 'theVolumeLabel'} | Select-Object -ExpandProperty DriveLetter   ""Select-Object -ExpandProperty DriveLetter"" will make sure that you're only getting the DriveLetter property stored in your variable."
PowerShell,3d69on,ryanbrown,2,Mon Jul 13 21:33:56 2015 UTC,You can also achieve the same effect using Win32_LogicalDisk  PS C:\windows\system32> Get-WmiObject -Class Win32_LogicalDisk -computername somecomputer | Where-Object { $_.VolumeName -eq 'TheVolumeLabel' } | Select-Object -ExpandProperty DeviceID
PowerShell,3d69on,ExEvolution,1 point,Mon Jul 13 23:39:31 2015 UTC,"thanks for LogicalDisk, that's a great view into precisely the data set I was looking for."
PowerShell,3d5ldr,winter_mute,2,Mon Jul 13 18:28:39 2015 UTC,"Without running the code myself (I'm only on my phone at the moment), have you tried simple debugging to make sure $Choice is coming through correctly? And that $Key is correct? Then comparing them as you do. Copy that code into a separate file and test it as much as you can, fix it, then put it back."
PowerShell,3d5ldr,Bongoots,1 point,Mon Jul 13 18:51:53 2015 UTC,"Yeah, so I've outputted the contents of $selection.Keys which looks like a bunch of integers, which I expected.  $choice is a raw, unsanitised (at the moment) input from the user.  I've tried explicitly converting $choice into an int32 type to make sure, but the comparison statement seems to be off somehow.  Can I compare a hash table key like this?   Thanks for taking a look."
PowerShell,3d5ldr,Bongoots,2,Mon Jul 13 19:09:31 2015 UTC,"What about comparing to ""$Key"" to make it a string?"
PowerShell,3d5ldr,tommymaynard,2,Mon Jul 13 19:33:17 2015 UTC,"Read-Host will set the variable as a string, by default. You can cast this as an integer, if you want to store your value as a numeric. In both cases (as a string or an integer), I am able to get a closely-related chunk of code to work just fine. Even a string value, when it's a ""numeric,"" will match (be equal). I get the feeling (and I may have even read it somewhere before), that it's doing something under-the-hood so that the comparison can happen between a number entered as a string, and a numeric.  Even so, this doesn't explain why this isn't working for you. I'll dump the small script I've been working with here. Again, it doesn't matter if I cast the $Choice variable or not (although, it's cast in my example script). Maybe something here will help you.  Remove-Variable -Name * -ErrorAction SilentlyContinue  $Selection = @{1 = 'first share';2 = 'second share';3 = 'third share'} $Selection.GetEnumerator() | Sort-Object Name | Format-Table -HideTableHeaders -AutoSize  Do {     try {         [int]$Choice = Read-Host -Prompt 'Enter Choice'     } catch {         $Choice = 0     } } Until ($Choice -match '^(1|2|3)$')  Foreach ($key in $Selection.Keys) {     try {         If ($Choice -eq $key) {             Write-Output -Verbose ""$Choice is found ($key).""         } Else {             Write-Output -Verbose ""$Choice not found ($key).""         }     } catch {         Write-Warning -Message ""Checking for a choice has failed.""     } }"
PowerShell,3d5ldr,tommymaynard,1 point,Mon Jul 13 20:36:25 2015 UTC,"Read-Host will set the variable as a string, by default. You can cast this as an integer   This was the issue, thanks.  I was trying to use a string value to match a key expressed as an integer.  I cast the Read-Host variable to an int and it looks like it's working now.  Thanks for the help."
PowerShell,3d5ldr,alcaron,1 point,Tue Jul 14 07:03:18 2015 UTC,"Glad to hear that casting the variable worked for you. Be sure to use the try-catch in there, in case someone enters a string value. Without it, it will throw an error."
PowerShell,3d5ldr,sturmy81,2,Wed Jul 15 18:20:53 2015 UTC,"PowerShell is smart enough to know that ""1"" -eq 1 in almost every case so I wouldn't worry too much about that.  Try changing your comparison to:  if($selection.Keys -Contains $choice){ $foo }else{ $bar }   From there you know the choice was a valid menu number then to get the value of that hash just:  $selection[$choice.ToString()]"
PowerShell,3d5ldr,lemon_tea,2,Mon Jul 13 22:32:19 2015 UTC,check https://technet.microsoft.com/en-us/library/ff730939.aspx  and https://social.technet.microsoft.com/Forums/windowsserver/en-US/cca0601a-aee6-4d06-840d-05a820cbf6f1/i-want-to-create-powershell-console-menu-with-submenus for help with building a Menu.
PowerShell,3d5ldr,alcaron,1 point,Mon Jul 13 19:32:57 2015 UTC,"Thanks for the links.  I'm building the menu dynamically though, there will be a different number of options depending on the MDT configuration on the server.  I also need to be able to tie the menu number to the share it's referring to.  I can't think how I can easily just use a switch statement.  A hash table seems to fit my requirements; all I really want to do is lookup a key and retrieve a value."
PowerShell,3d5ldr,alcaron,2,Mon Jul 13 19:44:30 2015 UTC,"What exactly is happening, or not happening?  I can't run your script right now nor can I ensure my environment is the same as yours.  A bit of info would assist."
PowerShell,3d5ldr,tommymaynard,2,Mon Jul 13 21:41:01 2015 UTC,"I can definitely tell you came from another language. :) Welcome!  Sadly without being able to run it I don't really see anything. I mean...at ln96 I don't see anything overtly wrong, but you were pretty vague about what the error was, if you post the exact error I bet we could narrow it down real fast."
PowerShell,3d5ldr,sturmy81,2,Mon Jul 13 22:24:53 2015 UTC,"Ha, does it show that badly?!  Your suggestion of:  if($selection.Keys -Contains $choice){ $foo }else{ $bar }   got me further than I had got, in that it made the problem more obvious.  Read-Host was producing a string, which I was comparing to the hash key, which was an int.  I cast the Read-Host variable as an integer, and it seems to be working now, thanks."
PowerShell,3d5ldr,tommymaynard,1 point,Tue Jul 14 07:02:13 2015 UTC,"Huh...usually it is smart enough to be able to do that comparison...then again, PS is NOT consistent so...  p.s.: It was the little things like += to increment, and you don't see a lot of PS'ers do foreach's directly invoking functions...just something about the style, and its not a bad thing, the more the merrier! Welcome!!  Nice formatting btw!"
PowerShell,3d5ldr,lemon_tea,2,Tue Jul 14 14:11:47 2015 UTC,"Not to imply this is your fix, but this doesn't work in PowerShell.  if ($confirm -eq ""Y"" -or ""y"")   You'll need this (or use regex):  if ($confirm -eq ""Y"" -or $confirm -eq ""y"")   Edit: I'd probably use single quotes for these values. It's a best practice to only use single quotes, unless there's a need for double quotes: a string includes a single quote(s), or you need to expand a variable (display a variable's value)."
PowerShell,3d5ldr,creamersrealm,3,Mon Jul 13 18:43:24 2015 UTC,"if ($confirm.ToLower() -eq ""y"")"
PowerShell,3d5fq5,ne0trace,7,Mon Jul 13 17:49:17 2015 UTC,"You will probably need to install or enable ""DHCP server tools"" under Remote Server Administration Tools > Role Administration Tools.    Open Control Panel and search for ""windows features"" to open the dialog box.    (There's a way to do this in PS but I don't have my Server 2012 nearby)  Edit - found it:  Install-WindowsFeature -Name RSAT-DHCP"
PowerShell,3d5fq5,speeding_potato,3,Mon Jul 13 20:00:07 2015 UTC,"This should work.  Alternatively, you can start a session with a windows server that is already filling this role, and run your get there.  All depends on what works best for you."
PowerShell,3d5fq5,tehhiphop,2,Mon Jul 13 20:17:00 2015 UTC,Assuming the management features were installed on the server. Most of them are split out and can be opted out of when installing a role.
PowerShell,3d5fq5,ser_rhaegar,1 point,Mon Jul 13 20:44:30 2015 UTC,"Also, I think RSAT for the desktop would allow you to skip logging into one of the servers at all."
PowerShell,3d5fq5,SaladProblems,3,Tue Jul 14 19:11:43 2015 UTC,That worked. Thank you.
PowerShell,3d5fq5,speeding_potato,1 point,Mon Jul 13 21:16:34 2015 UTC,Great!  You're welcome
PowerShell,3d7h3p,heartfullofsoul,3,Tue Jul 14 02:55:11 2015 UTC,I think you just have some variable-name confusion going on...  What is $child in your inner-loop?  Try simply changing line 8 from:  forEach($cell in $cells){   To:  forEach($child in $cells){
PowerShell,3d7h3p,zaboobity,1 point,Tue Jul 14 03:50:29 2015 UTC,"Thanks! That's what I'd originally named the variable, and I guess it was too late at night for me to see that very obvious mistake..."
PowerShell,3d7h3p,midnightFreddie,3,Tue Jul 14 13:50:04 2015 UTC,"$child is not defined.  I may have some style and logic comments pending, but that's your biggest issue. In these two lines, replace $child with $cell and you'll get the output you're trying to code.          if($child.tagName -eq ""td""){             $thisRow += $child.innerText   Edit: Oh, that's exactly what /u/zaboobity said. I missed it the first time through because I was distracted by what I thought the problem was.  Edit 2: I'll forego my pipelining-over-arrays soapbox speech this time, but here are some minor modifications to your script:   I added a URL anyone can access to pull a sample table Instead of getting ""TR"" I am getting ""table"" elements. I then select the first table and use the .rows method. In your script, if there is more than one table it will parse all the TRs from all the tables, but in your case it might be irrelevant. I changed $child to $cell in two lines I changed to -imatch ""t[dh]"" because your code skipped ""TH"" header fields. This could also be done as ($var -eq ""td"") -or ($var -eq ""th""), but I like regex. I added -join "","" when you add the row to $table so it's a comma-separated line. I wanted to make a proper table for Export-Csv, but it turned into a bunch of trouble and wouldn't be close to what you did. [http://www.leeholmes.com/blog/2015/01/05/extracting-tables-from-powershells-invoke-webrequest/]( Here is an example of a table far being created from html input ).   Apparently I need some text between the bullet list and code, so here it is. And I can't figure out why that link formatting is hosed.  $r = Invoke-WebRequest http://www.w3schools.com/html/html_tables.asp $data = ( $r.ParsedHtml.getElementsByTagName(""table"") | Select-Object -First 1 ).rows $table = @() forEach($datum in $data){     if($datum.tagName -eq ""tr""){         $thisRow = @()         $cells = $datum.children         forEach($cell in $cells){             if($cell.tagName -imatch ""t[dh]""){                 $thisRow += $cell.innerText             }         }         $table += $thisRow -join "",""     } }  $table   Edit 3: Also, when using Out-File to manually generate your own CSV, set the encoding to ASCII or Excel will not recognize it as a CSV:  $table | out-file C:\test.csv -Encoding ascii"
PowerShell,3d7h3p,midnightFreddie,1 point,Tue Jul 14 04:52:25 2015 UTC,"Thanks, this is very helpful. Yeah, the page I'm getting has no <th> tags and only ever has one table, so my script didn't need that functionality.  I'm assuming you advocate piping things as you go because of resource efficiency? How would that work in this instance? I tried writing each table row to file separately but PS doesn't like that; it throws ""an empty pipe element is not allowed."""
PowerShell,3d7h3p,WascallyWabbit83,3,Tue Jul 14 14:10:11 2015 UTC,"I'm assuming you advocate piping things as you go because of resource efficiency? How would that work in this instance? I tried writing each table row to file separately but PS doesn't like that; it throws ""an empty pipe element is not allowed.""   Yes, however in this particular case it probably doesn't matter, The problem with:   Get lots of objects/lines/cells Iterate with a variable, assign to variable Output variable   Is that it creates unnecessary stopping points, and in the cases of large sets of data bloats memory. If you design a smooth pipeline, you can simultaneously read, process and output and often avoid bloating memory.  However, in this case the Invoke-Webrequest is a hard stop. There is no magic we can use to pipeline that faster. It has to completely load, then it has to create the DOM for Parsedhtml, and then we already have everything in memory, anyway. So truly in this case there is no efficiency in pipelining unless you put this in a loop to fetch 200 pages and assign all 200 results to a variable before iterating them for results.  Anyway, here's a remodification of your original posted script that successfully pipelines to the file:  $r = Invoke-WebRequest -Uri http://www.w3schools.com/html/html_tables.asp $r.parsedhtml.getelementsbytagname(""TR"") |     ForEach-Object {         $datum = $_         if($datum.tagName -eq ""tr""){             $thisRow = @()             $cells = $datum.children             forEach($cell in $cells){                 if($cell.tagName -eq ""td""){                     $thisRow += $cell.innerText                 }             }             $thisRow -join "",""         }     }  | Out-File -Encoding ascii out.csv   Here is a further reworking where I eliminate the explicit loops by where clauses and select statements:  $r = Invoke-WebRequest -Uri http://www.w3schools.com/html/html_tables.asp $r.parsedhtml.getelementsbytagname(""TR"") |     # Where-Object { $_.tagName -eq ""tr"" } | # This line is redundant     ForEach-Object {         ( $_.children |             Where-Object { $_.tagName -eq ""td"" } |             Select-Object -ExpandProperty innerText         )  -join "",""     } | Out-File -Encoding ascii out.csv   But if what you have works for your needs then it's good enough! I just like pointing out the alternatives because they usually scale much better. And I get to show somebody that cares that I know something at all about Powershell. :)  Edit: Oh, I forgot to point out how the data is getting into the file. In the $thisRow -join "","" statement and the ( <lines of code> ) -join "","" statements, notice I'm creating a value but not assigning it to a variable, so this value is emitted as output which I catch with the pipe to Out-File. In this case the emitted output is a stream of comma-delimited strings.  Another edit: I noticed we have redundant checks for ""tr"" rows in our code. I commented out the redundant bit in the last code block. You're using an if clause to check for ""tr"" tags, but by definition you are passing it only ""tr"" tags.  Yet another edit: Learn and love Select-Object -Expandproperty. I'll leave it at that.  A show-off edit:  $r = Invoke-WebRequest -Uri http://www.w3schools.com/html/html_tables.asp $r.parsedhtml.getelementsbytagname(""TR"") |     % { ( $_.children | ?{ $_.tagName -eq ""td"" } | % innerText ) -join "","" } |     Out-File -Encoding ascii out.csv   Because screw readability!"
PowerShell,3d7h3p,KevMar,1 point,Wed Jul 15 00:54:45 2015 UTC,"Oh wow, thanks for all the effort you put into this. It's a lot to chew on but I'm going to see if I can reconstruct everything you've done.  In the meanwhile I got things working by just calling Excel to open the HTML and save it as .csv, which seems to work a lot faster although it's not as ""clean"" or fancy. But of course grabbing the HTML instead of querying the backend database in the first place is fairly kludge-y."
PowerShell,3d613l,ExEvolution,3,Mon Jul 13 20:17:15 2015 UTC,"@{Name=""Free Space (GB)""; Expression={""$([math]::round($_.FreeSpace / 1GB,2))GB""}}   I wrote a recent post that you might want to read, as it tackled this problem. I didn't hard code GB into the result, but instead determine what should be appended (MB, GB, etc.) based on the length property. Check it out, if you think it might be helpful!  http://tommymaynard.com/script-sharing-return-file-sizes-in-bytes-kbs-mbs-and-gbs-at-the-same-time-2015."
PowerShell,3d613l,tommymaynard,1 point,Mon Jul 13 21:20:30 2015 UTC,"Thanks, I was on that track , but I had instead tried to add + ""GB"" and that messed up the table name."
PowerShell,3d4xx7,kcbwya77,1 point,Mon Jul 13 15:41:37 2015 UTC,Check out the Auto Task Community site: https://community.autotask.com/  Also this should point you in the right direction: https://community.autotask.com/forums/p/31350/68944.aspx#68944
PowerShell,3d4xx7,itsteve,1 point,Mon Jul 13 16:41:04 2015 UTC,Awesome thank you. If I finish it I'll post the result here for everyone
PowerShell,3d4xx7,itsteve,1 point,Mon Jul 13 16:53:58 2015 UTC,Update: it looks like it may not be possible the way I'm trying to do it. I can query the tickets modified with today's date and select the time spent in each one. BUT its queries ALL tickets and not just mine. There are a lot of fields missing from Auto Tasks API
PowerShell,3d4fyq,zdmilot15,1 point,Mon Jul 13 13:10:27 2015 UTC,"[regex]$regex = ""^(?:(?:\+?1\s*(?:[.-]\s*)?)?(?:\(\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\s*\)|([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\s*(?:[.-]\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\s*(?:[.-]\s*)?([0-9]{4})(?:\s*(?:#|x\.?|ext\.?|extension)\s*(\d+))?$""  ($regex.Match($phnmbr)).Success   You have these guys to thank for the regex, no use me reinventing the wheel.  http://stackoverflow.com/questions/123559/a-comprehensive-regex-for-phone-number-validation"
PowerShell,3d4fyq,alcaron,1 point,Mon Jul 13 13:34:16 2015 UTC,"That's awesome, but how would I implement it, I think I am lost. Plus they were talking about incorporating dashes, and parentheses, which is not something that would work to have   $Mobileph = (xxx) xxx-xxxx $MobilePhEntry = xxx.xxx.xxxx"
PowerShell,3d4fyq,alcaron,1 point,Mon Jul 13 13:42:17 2015 UTC,"If you've never used a regex before I'll give you a brief overview.  A regex is a regular expression, the name means nothing to most people so lets call it what it is. A search pattern. For instance lets say I have a string ""abcd1234"" and I want to find all the numbers in it, I would user a regex like this:  ""([0-9])""   That would give me 4 results when I match it to the string, 1, 2, 3 and 4.  Now lets say I want ever instance of two numbers in a string, I would use a regex like this:  ""([0-9]{2})""   That would give me ""12"" and ""34"" as matches.  Actually using it is comprised of two parts, first, in PowerShell when you create a variable since PS is ""loosely typed"" you don't need to give it a type for the variable, powershell will just guess, for instance:  $test = ""hello""   PowerShell creates a String object, for:  $test = 1   PowerShell creates an Int32, but if you KNOW you want something to be a certain type, you can define it when you create the variable. I know I want to create a regex (and gain access to all the methods and properties of a regex object) so I do this:  [regex]$reg = ""([0-9])""   Now I'f told powershell essentially the same thing as if I'd gone through the trouble of instantiating the object the hard way.  Same example applies to, lets say I want to get the contents of an XML file, I don't want it to be plain text when I read it in because I know it is an XML document but if I just:  Get-Content ""C:\test.xml""   It is going to give me a string that contains the contents of the XML document. That does me little good, I can't navigate it using XPATh, I can't .Save() after I modify, but if I:  [xml]$xml = Get-Content ""C:\test.xml""   Then I'm telling PowerShell ""this is an XML files, don't open it as a string"" and it imports it as an XML document and I can navigate with XPath to my hearts content.  Now back to the problem at hand.  Once you've created a regex object with your pattern of choice you can apply it to your string you want to validate.  So in this case:  [regex]$regex = ""^(?:(?:\+?1\s*(?:[.-]\s*)?)?(?:\(\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\s*\)|([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\s*(?:[.-]\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\s*(?:[.-]\s*)?([0-9]{4})(?:\s*(?:#|x\.?|ext\.?|extension)\s*(\d+))?$"" $phnmbr = Read-Host ""What is your phone number?""  if($regex.Match($phnmbr)){ ""Matched!"" }else{ ""No match found!"" }   Replace the test with doing whatever you would do if they did or did not provide a valid phone number.  You shouldn't need to worry about dots and dashes because if you test the regex it will find ANY type of phone number.  555-555-5555 (555) 555-5555 555.555.5555 5555555555  The point being that you don't want to rely on the users entering a phone number in a specific format, you want to be able to tell if they entered a valid phone number regardless of what format they put it in.  With modification you could even break it out into groups and not only validate they entered a valid number but also reformat it based on the output of the regex."
PowerShell,3d4fyq,alcaron,1 point,Mon Jul 13 15:50:12 2015 UTC,"Thank you so much for your help with this, but i had some issues with trying to put this into the code I am working with, maybe you have a different perspective, to see what I am doing wrong. (also fantastic job explaining I appreciate the time you took to do this. The link below is the image for the issue I am talking about  http://i.imgur.com/CVjj6Te.png"
PowerShell,3d4fyq,KevMar,1 point,Mon Jul 13 18:09:34 2015 UTC,"This is the best I can do.  If you don't mind me asking, what other programming language(s) do you come from? That is only the second time I've ever seen :serviceloop used.  [regex]$regex = ""^(?:(?:\+?1\s*(?:[.-]\s*)?)?(?:\(\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\s*\)|([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\s*(?:[.-]\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\s*(?:[.-]\s*)?([0-9]{4})(?:\s*(?:#|x\.?|ext\.?|extension)\s*(\d+))?$"" $v = $false $i = 1  while($i -eq 1) { if($v -eq $true){ Write-Host ""Invalid Mobile Number..."" -ForegroundColor Red } $MobilePh = (Read-Host ""Enter 10-digit Mobile Number, if no mobile number just leave blank and hit enter."").ToString() $MobilePh.Length $regex.Match($MobilePh) if($MobilePh.Length -eq 0) {     Write-Host ""No mobile number.""     Break }elseif($regex.Match($MobilePh).Success) {     $groups = ($regex.Match($MobilePh)).Groups     $mobile = ""({0}) {1}-{2}"" -f $groups[2].Value,$groups[3].Value,$groups[4].Value     $i = 0 }elseif($regex.Match($MobilePh).Success -eq $false) {     $v = $true } }  $mobile"
PowerShell,3d4fyq,alcaron,2,Mon Jul 13 18:38:30 2015 UTC,"There must be a guide out there that is teaching that. This is also the second time I have seen serviceloop: In a script (and both times it was from a new scripter). I had to research it last time.  I would still stay away from it, but it lets you label a loop and target it with a break statement. This would be handy when you have nested loops and want to use break to break to the correct one (and cleanly label it)."
PowerShell,3d4fyq,InvisibleTextArea,1 point,Wed Jul 15 13:23:38 2015 UTC,Good to know!
PowerShell,3d4fyq,InvisibleTextArea,1 point,Wed Jul 15 15:09:09 2015 UTC,"Sorry for the late reply, I was away. But my friend and I (he comes from a background of visual basic, java, and a whole slew of other languages) wrote the initial script, and I am trying to improve it.  Also I really couldn't figure out how to get that to work with A: Output that just shows the phone number with () - and B: output of a variable that just had . . in it to go into the New-ADuser cmdlet"
PowerShell,3d4fyq,sid351,0,Thu Jul 16 13:12:59 2015 UTC,"Ok, this regexp might be better then.  ^1?[-\. ]?(\(\d{3}\)?[-\. ]?|\d{3}?[-\. ]?)?\d{3}?[-\. ]?\d{4}$   The code /u/alcaron posted will return true or false, so you can just use an if block to validate."
PowerShell,3d4d0v,hematic,2,Mon Jul 13 12:39:52 2015 UTC,Looks pretty cool! I've used another similar script in the past. Check out this: http://poshpaig.codeplex.com/
PowerShell,3d4d0v,nonprofittechy,2,Mon Jul 13 13:04:13 2015 UTC,I typically use this one for our server build: https://gallery.technet.microsoft.com/scriptcenter/2d191bcd-3308-4edd-9de2-88dff796b0bc
PowerShell,3d3cfp,dlwyatt,2,Mon Jul 13 04:49:03 2015 UTC,"Awesome Dave, and thank you for your effort into this. the whole community appreciates it!"
PowerShell,3d3cfp,bundyfx,2,Mon Jul 13 07:44:57 2015 UTC,Can someone give an example of a pester test and a powershell function? I am having trouble figuring out what would be tested when using powershell to interact with other systems like exchange/AD
PowerShell,3d3cfp,cablethrowaway2,2,Mon Jul 13 13:57:52 2015 UTC,"You can do two types of tests there.  A ""unit test"" would involve using Pester's Mocking feature to isolate your code from Exchange / AD, so you're just testing whatever logic is in your PowerShell script.  Another type of test, which you might hear referred to as an ""integration test"" or ""acceptance test"" (which have very little distinction in PowerShell), would involve just running your code against a live Exchange or AD environment, and making sure that the script had the desired effect.  This type of test makes sure that you didn't make any poor assumptions about how your script would integrate with other environments.  Both unit tests and acceptance tests have value.  Unit tests run faster, and are cheaper (in terms of the infrastructure required.)  You would tend to run your acceptance tests after all the unit tests have passed.  I recently did a webinar for PowerShell.org where I talked about those types of tests in Pester:  https://youtu.be/0fFrWIxVDl0"
PowerShell,3d4ns8,tacos_pizza_beer,1 point,Mon Jul 13 14:22:13 2015 UTC,"There is limited information stored in the registry, have a look at the ContainerID and HardwareID properties. Perhaps those are what you are looking for:  Get-ItemProperty -Path ’HKLM:\SYSTEM\CurrentControlSet\Enum\USBSTOR\*\*’ | Select FriendlyName,ContainerID,HardwareID"
PowerShell,3d4ns8,JaapBrasser,1 point,Mon Jul 13 14:35:46 2015 UTC,Is there a way to make this easier to read like friendlyname?
PowerShell,3d4ns8,JaapBrasser,1 point,Mon Jul 13 14:45:14 2015 UTC,Can you give an example of how you would like the data to be formatted?
PowerShell,3d4ns8,FatManSmallEgo,1 point,Mon Jul 13 16:16:21 2015 UTC,"Get-ItemProperty -Path ’HKLM:\SYSTEM\CurrentControlSet\Enum\USBSTOR\*\*’ | Select FriendlyName,HardwareID | Format-Table -Wrap -AutoSize"
PowerShell,3d1uw0,joakimbs,1 point,Sun Jul 12 21:07:10 2015 UTC,"Nice script - I wrote something similar to evaluate NACL's and Firewall rules.  I would suggest that you add a 'Contains' / 'ValidateHost' method to your returned object  $mySubnet = .\PSipcalc.ps1 -Net ""10.20.30.40/18"" if ( $mySubnet.Contains(10.20.31.21) ) { Write-Out ""OK"" }   Whereby the response is true for a valid host in the subnet range :)"
PowerShell,3d1uw0,real_parbold,1 point,Tue Jul 14 12:15:14 2015 UTC,"Great idea. I just did almost that.  I thought about adding a script property method, as you suggest, but instead decided to use a parameter for the script itself, called -Contains (I was curious if that would conflict with the operator), which causes the script to return a bool for whether the (verified valid) IP is in the specified subnet. I threw in some examples in the article if you want to see how I thought you might use it.  Thanks for the feedback!"
PowerShell,3d14oj,davehull,3,Sun Jul 12 17:32:36 2015 UTC,This is probably the most interesting and mathematically sophisticated thing I've ever seen done with Powershell. I'm really impressed! mindblown.gif  Could you explain what each of the functions does and how it all ties together?
PowerShell,3d14oj,HalalVeggieBacon,3,Sun Jul 12 19:28:38 2015 UTC,"It's probably the most complicated PowerShell script I've written and certainly one of the most fun to work on. I went back through the code this afternoon and added a bunch of comments, I hope that makes it easier to follow what it's doing. If you have more specific questions, let me know."
PowerShell,3d14oj,HalalVeggieBacon,1 point,Mon Jul 13 03:12:49 2015 UTC,"Thanks! I'll read through it, and see if I can learn something."
PowerShell,3d14oj,jsmcnair,2,Mon Jul 13 03:13:43 2015 UTC,"I've seen these around and thought it might be quite interesting to give them a go. Do you find yourself digging into .NET libraries quite a bit?  Edit: just looked at your implementation of the problem, looks like the answer might be yes."
PowerShell,3d14oj,jsmcnair,3,Sun Jul 12 20:10:03 2015 UTC,"I rely on .NET for a few things, byte and bit conversions, some math stuff, etc. In other scripts where I need speed, I rely on .NET for reading and writing files and for regular expressions. All of these things are significantly faster in .NET than in PowerShell, in my experience.  As for the challenges, it's been fun and educational working through them so far. I'm definitely not rushing, but rather really trying to understand the concepts in depth. I spent a bunch of time figuring out why normalized average Hamming Distance is useful for figuring out the key size and that led me to figuring out that when you don't know the upper-bound on the key size, it's not that reliable, but if you can add a calculation to find the most frequently occurring greatest common denominator among the top n key sizes, then you can more accurately determine the correct key size.  If you've got some spare time, the challenges are fun and not terribly difficult, but 1.6 has lots of opportunities for fence-post/off-by-on errors."
PowerShell,3d14oj,BelgiumSysAdmin,2,Mon Jul 13 03:19:44 2015 UTC,"I'm a complete novice when it comes to cryptography, so most of that didn't make any sense. But I do know that PowerShell can be far from optimal in some of its command implementations.  If I were to do this I would probably be more inclined to do it in a Unix environment, perhaps as an excuse to learn Python or something."
PowerShell,3d2lh2,arusishere,2,Mon Jul 13 00:48:23 2015 UTC,"Give this a shot.  Not tested, just typed it out here, so pardon any errors.  $excelDir = 'c:\ExcelFiles\' $destDir = 'c:\XMLFiles\'  gci -path $excelDir -file | where{$_.Extension -eq '.xlsx'} | %{     $xlXMLSpreadsheet = 46     $Excel = New-Object -Com Excel.Application     $WorkBook = $Excel.Workbooks.Open(""$($_.FullName)"")     $WorkBook.SaveAs(""$destDir$($_.BaseName).xml"", $xlXMLSpreadsheet)     $Excel.Quit() }"
PowerShell,3d2lh2,sgnewman,1 point,Mon Jul 13 01:18:32 2015 UTC,"You sir, are awesome. Thanks for this. I had to delete -file in order to get it working otherwise it works like a charm!"
PowerShell,3d0l9s,Braber02,2,Sun Jul 12 14:33:37 2015 UTC,"I tried this:    Remove-Item -Path ""C:/test/*.dat"";  $SongToMove = $args[0];  Copy-Item $SongToMove -Destination ""C:/test"";   Then I made three .dat files in c:/test (test1.dat, test2.dat and test3.dat) and three other ones in c:/test2 (2test1.dat, 2test2.dat and 2test3.dat).  After running: "".\test.ps1 test2\*.dat"" while being in c:/, the .dat files of c:/test have been replaced by those that are in c:/test2 while leaving c:/test2 intact.  Your script works fine given the right arguments."
PowerShell,3d0l9s,MacGuyverism,1 point,Sun Jul 12 19:50:49 2015 UTC,"You spelled ""steamapps"" wrong in the second line ""streamapps"""
PowerShell,3d0l9s,checky,1 point,Sun Jul 12 15:01:06 2015 UTC,Sorry Kind of hard to copy from Vim to Reddit anyways it was spelled right in the script so that doesn't really fix my error :(
PowerShell,3d0l9s,checky,2,Sun Jul 12 15:17:46 2015 UTC,I'll take a look at it more when I get back on my Windows PC. Hopefully someone else can help you in the meantime :)
PowerShell,3d0l9s,thethwamp,1 point,Sun Jul 12 15:24:54 2015 UTC,Thanks :) I also do have GoW or GNU on Windows so I can write a Bash Script if this fails
PowerShell,3d0l9s,chafe,1 point,Sun Jul 12 15:25:43 2015 UTC,"I was under the impression that you did not need quotes at all. Unless you had like ""\server\program files"" or something like that."
PowerShell,3d0l9s,thethwamp,2,Sun Jul 12 15:30:01 2015 UTC,I do have C:/Program Files(x86)  in both paths
PowerShell,3d0l9s,thethwamp,3,Sun Jul 12 15:45:30 2015 UTC,"Could it be the lack of space in ""Program Files (x86)""?"
PowerShell,3cxr17,powershelltutorials,6,Sat Jul 11 18:52:59 2015 UTC,"There is a lot of good basic information here, but something that a lot of people don't really utilize often enough and that's error trapping and input control.  What happens if that file you're feeding in is not there?  What if someone just hits enter when your using Read-Host to get a user name (or what if they include a space before, in the middle, or after).  I think it would be a good thing to include examples which utilize try-catch:  try {     Set-ADAccountPassword $User -NewPassword (ConvertTo-SecureString -AsPlainText $User.MobilePhone -Force) -Reset -ErrorAction STOP     } catch {     Write-Warning ('Could not set password for {0}: {1}' -f $User,$_.exception.message)     return }   Or checking your input for your read host such as:  $more = $true while ($more){     $user = Read-Host 'Enter user name to reset password'     if ($user -notmatch '^\w{3}') {         Write-Warning ""You entered $user.  There must be at least 3 characters in the user name.  Try again.""         continue     }     elseif ($user -match '\s') {         Write-Warning ""You entered $user.  There must be no spaces in the user name.  Try again.""         continue             }     else {         $more = $false       } }   These are basic scripting\tool-making methodologies which pay off big time down the road for people who are creating scripts that others will use.  One thing that I'd recommend not doing is using -Properties * in Active Directory searches unless you absolutely have to.  From the examples I see in this tutorial really the only properties we're really looking for is the mobilephone attribute.  There really is no reason to return all the properties from Active Directory since we don't really care for them all (such as memberof, which can add a significant amount of overhead of a member of a lot of groups).  On top of that when asking AD for objects, when we're specific to what we want it'll run faster."
PowerShell,3cxr17,evetsleep,2,Sat Jul 11 20:56:28 2015 UTC,"Could you explain what's happening in your catch?  What is {0}:{1} referencing, and what is following the -f?"
PowerShell,3cxr17,ioFAILURE42,4,Sun Jul 12 00:24:05 2015 UTC,Sure.  So instead of re-inventing the wheel check out this informative post about it.
PowerShell,3cxr17,evetsleep,1 point,Sun Jul 12 01:30:37 2015 UTC,Anyone know a simplified way of doing DNS changes?
PowerShell,3cy67s,ramblingcookiemonste,5,Sat Jul 11 21:05:52 2015 UTC,"Hi all!  Will be giving a PowerShell.org TechSession on Git this Tuesday - sign up and stop by for the live session, or hit up the PowerShell.org YouTube channel afterwards. I'll try to post this and the materials after the session.  This will be one hour crammed with practical demos of the more common workflows in Git and GitHub. No promises, but an hour is short enough that you're not going to hear many unnecessary bits (e.g. history of Git, or what VCS was used for Linux before Git).  If you're in IT and you've been putting off learning and using version control, you're sadly not alone, but you should definitely stop by. There will be a few minutes of 'this is what a version control system is...' nonsense, but the rest will be practical what-you-need-to-know-to-get-started goodness.  Cheers!"
PowerShell,3cy67s,midnightFreddie,2,Sat Jul 11 21:20:42 2015 UTC,"For those who think ""version control"" sounds scary or a bit thing to learn, instead think of it s an undo/redo button for your script development.  If you've ever made multiple backup copies of a script to try out different changes so you could go back and start over, you really would gain by learning Git. Or any version control / source control software, but Git is the cool crowd for now and the foreseeable future."
PowerShell,3cy67s,midnightFreddie,1 point,Sat Jul 11 22:10:15 2015 UTC,"In fact just yesterday this saved my butt. I was doing last-minute style changes in a new script I was about to present to my coworkers, and it quit working. Luckily I was using Git and committing the code periodically.  I checked in my changes noting they were broken, did a diff to the last version and couldn't spot the problem, so I checked out the last known working version and ran it, and sure enough it still worked. I looked a little harder and realized I had used ""http"" instead of ""https"" when calling an API, and unexpectedly that caused the server to return a 500 error. I checked out the latest (& broken) version, fixed it, tested it, and it worked. Commit with ""fixed"". Undo/redo button saved the day."
PowerShell,3cy67s,halr9000,1 point,Sat Jul 11 22:15:10 2015 UTC,"Great idea, Warren!"
PowerShell,3cy67s,midnightFreddie,1 point,Sun Jul 12 04:01:19 2015 UTC,"Props for the idea go to Nick Getchell from powershell.org : )  I happened to be ranting about the lack of version control uptake among IT professionals when they were looking for someone.  Sadly, I don't think any amount of learning material will help. Problem seems to stem from management (value, or lack thereof, placed on version control), IT professionals (getting folks to learn PowerShell is hard enough...), and lack of a solid solution targeting the MSFT ecosystem (pricey hosted / on-prem solutions, or Linux based solutions like GitLab CE).  Back to last minute prep : ) See you around!"
PowerShell,3czpsx,mcsparklenuts,1 point,Sun Jul 12 06:32:03 2015 UTC,"I know its fun to do everything in PowerShell, but Microsoft made a screensaver that did this, without your limitations in like 1998.   I'm not trying to be rude, or belittle your work. But there is a better solution there.   Because the screensaver runs in the user context, it can pass the 'logoff' command to that user in that session.  Perhaps this script can be modified to be executed as a screensaver?  Also, Group Policy can be set to logoff RDP sessions, and Desktop sessions (with some jiggery pokery)  Good luck on your powershell quests :)  Edit: I too may have come across too brash, apologies - I have found a code sample that I have tested that will exit the ""current user"" session.  so should your script run as a logon script, and the user PC locked - well this logged my Win8.1 workstation out when I locked it manually.  $memberDefinition = @"" [DllImport(""user32.dll"")]  public static extern int ExitWindowsEx(int uFlags, int dwReason);  ""@  # Converted some C# to Windows PowerShell to use PInvoke to log off the user.  # There is no advantage to this over using WMI/Shutdown.exe...  # Just wanted to highlight the trick, and show off add-type's power.  Function Exit-UserSession([switch]$Force) {  $Win32ExitWindowsEx = Add-Type -Name 'Win32ExitWindowsEx' -namespace 'Win32Functions'   -memberDefinition $memberDefinition -passThru           $Win32ExitWindowsEx::ExitWindowsEx(4,0) }    Its from here http://blogs.technet.com/b/heyscriptingguy/archive/2010/06/10/hey-scripting-guy-how-can-i-log-out-a-user-if-they-launch-a-particular-application.aspx  I also reckon that you could slurp the popup window code from that sample - and have a systray... Notification Area popup - 1 hour remaining etc etc.  Within the Function Wait-NotifyUser([int]$Timeout) section of the code, remove the [void] tags - they error on newer PS scripts."
PowerShell,3czpsx,graemejevans,2,Sun Jul 12 10:56:38 2015 UTC,"Oh please don't color me naive. I definitely did do my research before beginning a powershell script. But you also have to bear in mind that with the diversity of visitors here, a solution that works for you may not work for someone else. Likewise, a solution that is inferior to your own, may be the best for someone else. So while I appreciate your input, and while it may be applicable to other visitors here, it is not applicable to my situation.  The winexit screensaver to which you are referring is out of support. It is a policy requirement that we only use software for which we can get vendor support. Furthermore, hacking the winexit screensaver to work on Win Vista+ was an unsupported configuration to begin with. And that is another network no-no.  Additionally, the options of using GPO RDP logoffs, scheduled tasks, and third party solutions were explored, but each option had it's own set of restrictions that made it impossible to implement in our environment. The fact of the matter was that we needed to bake up an in-house solution, and that's what I did.   Now, the problem with my script doesn't so much happen because the script isn't working in user mode, but rather that the WMI call doesn't allow session targeting. WMI wasn't my first go-to for this, but it was the option worked. shutdown.exe /l and logoff.exe didn't seem to want to play right if the console was locked for whatever reason. The WMI call targets the currently active session. If the script is running under user 1 and user 2 is logged in and active, the script will attempt to log off user 2, but it will fail because user 1 doesn't have permissions. When fast user switching is invoked you have the same problem in that the logged in session is nt authority\system. So long story short, running it as a screensaver won't solve my problems. There may be a way to target the correct session, I just haven't discovered it yet.  EDIT Maybe I should have waited before posting the script and this comment. I was actually able to figure out the answer to all of my problems. If I query the user session data, I can pass the session ID to logoff.exe and it will work just fine. The correct user is targeted when the limit is reached, regardless of who holds the active console session. Furthermore, the script has the added bonus of working on a per-user idle limit, so if user 2 is actively working on the machine and it has been X hours since user 1 was active, user 1 will still be logged out.  I've updated the script on bitbucket and re-linked it in my original post."
PowerShell,3czpsx,graemejevans,1 point,Sun Jul 12 16:19:40 2015 UTC,"Also on the update here, I saw QUSER and LOGOFF may be a possibility - but the real fun/challenge is getting it all ""native"" powershell avoiding calling exe's  In my edit, there is a code sample that may sort out the logoff bit, and quser in one swoop.  It's not my code, but I have edited it to remove the switch (sort of) and only choose the force logoff option. https://msdn.microsoft.com/en-us/library/windows/desktop/aa376868(v=vs.85).aspx"
PowerShell,3cvvmp,EL337,7,Sat Jul 11 05:20:44 2015 UTC,"Must be testing out Windows 10? Awesome find, never noticed this before (I was just really liking all the colours.)  That features actually coming to you courtesy of the PSReadLine Module that comes pre-installed on Win10 (and the Server Tech Preview? Haven't checked.)  This means if you're stuck with down level PowerShell, but you can install modules, you can get that functionality... which is awesome.  ![PSReadLine PSv4](http://iforce.co.nz/i/t2ihvgmo.dxo.png)  Also, if you install PowerShell 5 on Windows 8.1 (or 7 for that matter), you unfortunately miss out on this unless you manually install the module."
PowerShell,3cvvmp,WindosBK,2,Sat Jul 11 08:06:39 2015 UTC,"Also, if you install PowerShell 5 on Windows 8.1 (or 7 for that matter), you unfortunately miss out on this unless you manually install the module.   If you've already got WMF5 installed on your machine, all you have to do is run Install-Module PSReadline from an elevated prompt."
PowerShell,3cvvmp,joeyaiello,3,Sat Jul 11 15:52:56 2015 UTC,Check out PsEdit in the ISE in version 5.0.. you can remotely edit PowerShell scripts on other machines directly from the ISE. awesome stuff!
PowerShell,3cvvmp,bundyfx,1 point,Sun Jul 12 11:18:33 2015 UTC,Finally windows is catching up with the modern world.
PowerShell,3cvvmp,u4iak,2,Sun Jul 12 12:20:06 2015 UTC,PSReadLine is great.  If you do Set-PSReadlineOption -EditMode Emacs you get bash like tab completion.
PowerShell,3cvvmp,Prometheusx,1 point,Sat Jul 11 19:31:32 2015 UTC,I've not used it yet. Is it listing all the properties associated with a commandlet?
PowerShell,3cvvmp,Swarfega,3,Sat Jul 11 05:34:49 2015 UTC,"yes, type the cmdlet and a - then ctrl+space; the options magically appear as if one were working in the ISE!"
PowerShell,3cvvmp,NzNacer,1 point,Sat Jul 11 05:42:54 2015 UTC,Awesome Really like it thanks for the heads up
PowerShell,3cxdz3,jbohr,1 point,Sat Jul 11 16:59:49 2015 UTC,"The following blog posts from the, ""Hey, Scripting Guy! Blog"" should be able to help you out.   http://blogs.technet.com/b/heyscriptingguy/archive/2012/06/25/build-a-query-to-search-the-windows-index-from-powershell.aspx  http://blogs.technet.com/b/heyscriptingguy/archive/2012/06/27/customizing-powershell-output-from-windows-search.aspx"
PowerShell,3cv28t,KevMar,1 point,Sat Jul 11 00:36:04 2015 UTC,"How about you install the wsus managent console on your workstation? It may be more complex than that so if I've suggested the too obvious, I'm sorry"
PowerShell,3cv28t,jvniejen,1 point,Sat Jul 11 02:12:41 2015 UTC,"Oh I could. I was just using that as a reference to the type of problem I was trying to solve.   It could be a SQL install function or a set of PowerCLI commands. The problem is more having a subset of pester tests not run, except when you want them to run."
PowerShell,3cv28t,FinancialAdvicePleas,1 point,Sat Jul 11 04:41:54 2015 UTC,"I've been thinking about those problems for a while.  So far the best I've come up with is have a test vm somewhere. Checkpoint the vm, then push a dsc config to it. Run your test against the machine when its done, then revert the checkpoint. It takes a while and you then have to write dsc configs for all your test scenarios but it's pretty much the only way to really test some things.  Alternatively you can just have an actual ""dev"" environment that mirrors your production one... But good luck getting the budget for that."
PowerShell,3csto8,powershelltutorials,3,Fri Jul 10 14:17:21 2015 UTC,"Just want to add, as someone who does a lot of bulk AD operations, the bulk creation\change examples could use some try\catch elements.  You really do want to capture any errors that happen."
PowerShell,3csto8,evetsleep,1 point,Fri Jul 10 19:22:02 2015 UTC,"That is an excellent point and a great addition, thank you!"
PowerShell,3ctsjp,alejosolp,3,Fri Jul 10 18:41:31 2015 UTC,"gci -path c:\Folder1 -File | sort -descending -Property LastWriteTime | SELECT -first 1 | %{     copy-item $_.FullName ""c:\destinationFolder\Camera1.jpg"" -force }   Written directly in the form, so excuse any typos."
PowerShell,3ctsjp,sgnewman,1 point,Fri Jul 10 20:45:25 2015 UTC,"You could always do something like:  (Get-ChildItem -Path C:\Folder1 | sort -Descending -Property LastWriteTime)[0]  Get all the items, sort descenting and then grab the first object of the returned set."
PowerShell,3ctsjp,ardwin,1 point,Fri Jul 10 18:49:12 2015 UTC,Thanks ardwin will try. Any ideas on how to rename and move ?
PowerShell,3ctsjp,noz3r0,1 point,Fri Jul 10 18:56:41 2015 UTC,Rename-Item and Copy-Item would do the trick. You can type Get-Help [cmdlet] -full to get the full syntax and an example of how to use these if you aren't familiar with it.
PowerShell,3ctsjp,natesternberg,1 point,Fri Jul 10 19:18:25 2015 UTC,"It sounds like what you want to do is have make the most-recently-written picture available in Folder2.  Technically, you don't need to copy the file at all for this.  You can just make / update a hardlink...  $mostrecent = (gci c:\folder1\ | sort -Descending LastWriteTime)[0] & $env:WinDIR\system32\fsutil.exe hardlink create c:\folder2\camera1.jpg $mostrecent.FullName   (Not that there's anything wrong with the other approaches, just thought I'd mention it an alternative)"
PowerShell,3ctsjp,alejosol,-1,Fri Jul 10 21:05:01 2015 UTC,Thank you very much for you help!! I got it running !! Thanks Guys!
PowerShell,3cu6b6,justonemorevodka,1 point,Fri Jul 10 20:22:26 2015 UTC,"requires c:\holidays.txt to contain all holidays, one per line as specified as their day of the year. 7/4/2015 is day of the year 184.  (get-date -date 12/25/2012).DayOfYear to get the day of years.  Change 12/25/2012 to holidays of choice to built list.  $run = $true  $date = get-date  get-content -path c:\holidays.txt | ForEach-Object {if ($date.DayOfYear -eq $_){$run = $false}}  if ($run){""Not a Holiday""}  Edited for clarity."
PowerShell,3cu6b6,ardwin,1 point,Fri Jul 10 20:42:22 2015 UTC,"Thanks for your help.  Maybe I don't have it written correctly, but I'm getting unexpected token 'date' in expression or statement.  At line 1 char 19  Categoryinfo. :parsererror: (date:string)  parentcontainserrorrecordexception  FullyqualifiederrorId : unexpectedToken  Sorry I'm on mobile"
PowerShell,3cu6b6,ardwin,1 point,Fri Jul 10 21:22:40 2015 UTC,"Try it now, my one off might not have had an extra )."
PowerShell,3cu6b6,ardwin,1 point,Fri Jul 10 21:34:30 2015 UTC,"I think it is on the right track,  when I run it with PS  it just closes.  I have set it to open iexplorer.exe, but nothing happens.  I have the paths enclosed in """".  Something small is missing I think"
PowerShell,3cu6b6,mcsparklenuts,1 point,Fri Jul 10 21:55:22 2015 UTC,"Run it from a powershell window.  Change if ($run){""Not a Holiday""} to if ($run){""Not a Holiday""}else{""Holiday""} to see what is happening.  Replace the desired {} with the path to your .exe."
PowerShell,3ct0m3,ddreier,3,Fri Jul 10 15:13:21 2015 UTC,Just send a shut down command to the host the default action suspends the VMS anyway
PowerShell,3ct0m3,graemejevans,1 point,Fri Jul 10 22:20:43 2015 UTC,"This article gives a script to enumerate all the VMs running on a Hyper-V host and send them all the shutdown command individually then shutdown the host.   However, Hyper-V gives you the option of setting Automatic Stop Actions for your VMs as long as they are running integration services. With these, anytime the host OS is cleanly shut down, the guest does what you tell it. You can have it shut down the VM cleanly, save state(default), or turn off the VM. The host will wait for these actions before shutting itself down.  I don't know, however, if the -force option will negate this action. That would need testing."
PowerShell,3ct0m3,fatbastard79,1 point,Sat Jul 11 03:59:24 2015 UTC,"I don't know, however, if the -force option will negate this action. That would need testing.   That's my concern. Everything else I got. Initial testing would say that it doesn't, but that was on a spare host with only 1 VM."
PowerShell,3ct0m3,fatbastard79,1 point,Sat Jul 11 05:06:57 2015 UTC,It may be worth cloning your production VMs offline just to see what it does.
PowerShell,3ct0m3,Swarfega,-2,Sat Jul 11 05:09:05 2015 UTC,I doubt it. You'll need a script to shutdown each VM.  Once all VM's are showing they are not running issue the Stop-Computer command to the host.
PowerShell,3ct0m3,KevMar,1 point,Fri Jul 10 15:54:06 2015 UTC,"Well I have a very limited test case now, and the one VM (running SCCM PXE-booted WinPE) on the server did get stopped and restarted after running Stop-Computer -Force.  But it'll probably be safer to just stop the VMs first."
PowerShell,3cta7m,krese,4,Fri Jul 10 16:27:07 2015 UTC,"HomeDrive and HomeDirectory are extended properties.  More on that below  http://social.technet.microsoft.com/wiki/contents/articles/12037.active-directory-get-aduser-default-and-extended-properties.aspx  You can use the properties parameter to retrieve them  get-aduser Username -properties * | select-object... #to see all the properties  You can then  specify the properties by name -properties homedrive, homedirectory"
PowerShell,3cta7m,MKmsftFan,1 point,Fri Jul 10 17:48:14 2015 UTC,"oh, wildcard!  even better  thanks!"
PowerShell,3cta7m,the_spad,5,Fri Jul 10 18:33:20 2015 UTC,No! Bad wildcard.  Never use -properties * if you're planning on returning more than one result because it will dramatically slow down your scripts and load your DCs. Only request the properties you're working with.
PowerShell,3cta7m,kaluce,1 point,Fri Jul 10 18:44:33 2015 UTC,"you'd use the wildcard to ONLY get a list of properties you want to select from, but never put it in a script. It will bog down servers."
PowerShell,3cta7m,creamersrealm,1 point,Fri Jul 10 19:54:13 2015 UTC,No! Only use it to diagnose it for small amounts of data.
PowerShell,3cta7m,dathar,1 point,Sat Jul 11 01:30:18 2015 UTC,"I think that's because the default Get-AdUser doesn't return quite a few properties by default. When in doubt, try running it on one user and pipe it to Get-Member  > $me = get-aduser me > $me | gm  Name              MemberType            Definition ----              ----------            ---------- Contains          Method                bool Contains(string propertyName) Equals            Method                bool Equals(System.Object obj) GetEnumerator     Method                System.Collections.IDictionaryEnumerator GetEnumerator() GetHashCode       Method                int GetHashCode() GetType           Method                type GetType() ToString          Method                string ToString() Item              ParameterizedProperty Microsoft.ActiveDirectory.Management.ADPropertyValueCollection Item(string p... DistinguishedName Property              System.String DistinguishedName {get;set;} Enabled           Property              System.Boolean Enabled {get;set;} GivenName         Property              System.String GivenName {get;set;} Name              Property              System.String Name {get;} ObjectClass       Property              System.String ObjectClass {get;set;} ObjectGUID        Property              System.Nullable`1[[System.Guid, mscorlib, Version=4.0.0.0, Culture=neutral, ... SamAccountName    Property              System.String SamAccountName {get;set;} SID               Property              System.Security.Principal.SecurityIdentifier SID {get;set;} Surname           Property              System.String Surname {get;set;} UserPrincipalName Property              System.String UserPrincipalName {get;set;}   Then I tried   > $me = get-aduser me -Properties HomeDirectory > $me | gm      Name               MemberType            Definition ----               ----------            ---------- Contains           Method                bool Contains(string propertyName) Equals             Method                bool Equals(System.Object obj) GetEnumerator      Method                System.Collections.IDictionaryEnumerator GetEnumerator() GetHashCode        Method                int GetHashCode() GetType            Method                type GetType() ToString           Method                string ToString() Item               ParameterizedProperty Microsoft.ActiveDirectory.Management.ADPropertyValueCollection Item(string ... DistinguishedName  Property              System.String DistinguishedName {get;set;} Enabled            Property              System.Boolean Enabled {get;set;} GivenName          Property              System.String GivenName {get;set;}  HomeDirectory      Property              System.String HomeDirectory {get;set;} Name               Property              System.String Name {get;} ObjectClass        Property              System.String ObjectClass {get;set;} ObjectGUID         Property              System.Nullable`1[[System.Guid, mscorlib, Version=4.0.0.0, Culture=neutral,... PSShowComputerName Property              Microsoft.ActiveDirectory.Management.ADPropertyValueCollection PSShowComput... SamAccountName     Property              System.String SamAccountName {get;set;} SID                Property              System.Security.Principal.SecurityIdentifier SID {get;set;} Surname            Property              System.String Surname {get;set;} UserPrincipalName  Property              System.String UserPrincipalName {get;set;} WriteDebugStream   Property              Microsoft.ActiveDirectory.Management.ADPropertyValueCollection WriteDebugSt... WriteErrorStream   Property              Microsoft.ActiveDirectory.Management.ADPropertyValueCollection WriteErrorSt... WriteVerboseStream Property              Microsoft.ActiveDirectory.Management.ADPropertyValueCollection WriteVerbose... WriteWarningStream Property              Microsoft.ActiveDirectory.Management.ADPropertyValueCollection WriteWarning..."
PowerShell,3ctzw4,NewShinyCD,1 point,Fri Jul 10 19:34:37 2015 UTC,"I would tell you to use the file resource to keep the folders synced except the one running the service will be locked. DSC has this idea that you are defining the state that it has to get to. Adding a well timed reboot or service shutdown is not native to that idea. This is where script resources or custom resources come into play.  For a script resource, you need to create two scripts.  The test script needs to check the source file and the destination file and return true if it correct and false if it is not. Then your correction script needs to stop the service, copy the file, then start the service.  Script DeployFile {     TestScript = {         return $true     }      SetScript = {         Stop-Service ...         robocopy ...         Start-Service ...     }     GetScript = ""@{T=0}"" # Should implement this but nothing uses it yet. }   If you are going to use variables from outside the scope of those blocks, you will need to use the $using: scope to do so.   Now that I have written a few custom resources, I prefer them over using the script resource when given the change. This would make a great custom resource once you are ready for that. Imagine if your DSC script looked like this instead:  UpdateService OurService {     Name        = ""OurService""     Source      = $Source     Destination = $Destination }   Yes, you would have to write a whole lot more code in another file, but I like that clean look in my configurations."
PowerShell,3csxam,PSDevTA,1 point,Fri Jul 10 14:46:59 2015 UTC,"Is $form declared anywhere, or should it be $r.fields (or $r.Form.fields) in the Body Parameter?"
PowerShell,3csxam,ryanbrown,1 point,Fri Jul 10 16:35:46 2015 UTC,"Whoops, that line is actually supposed to be:  $baseUrl = ""https://online2.qbp.com/qbponlinestorefront"" Write-Host ""Logging into QBP..."" $url = Invoke-WebRequest $baseUrl -SessionVariable qbp $url.Forms[0].fields[""username""] = ""usernamehere"" $url.Forms[0].fields[""password""] = ""passwordhere"" $result = Invoke-WebRequest $baseUrl -WebSession $qbp -Body $url -Method Post   I had forgotten that I had different code saved elsewhere. With this I get an 'ok' status code. Where I'm running into issues is when I try to run another Invoke-WebRequest with a url (from a sheet of product url's) pointing to a product page:  Invoke-WebRequest $url -WebSession $qbp -Method Get   When I do this, I expect to get back the information from this product page since I am using the new, logged in websession with product page's url, but instead it returns the information from the login page that I was trying to get past. Whenever I do a statusdescription after the initial invoke-webrequest, I get 'ok', but I am wondering if I'm not going all the way through the login page?"
PowerShell,3csxam,ryanbrown,1 point,Fri Jul 10 19:16:49 2015 UTC,There might be a hidden field that needs to be set.  You'd probably have to use something like Fiddler to see it.  Here's an example I found: (http://stackoverflow.com/questions/13756065/powershell-invoke-webrequest-websession-not-working)  The only other thought would be if your username and/or password has a character(s) that Powershell is trying to interpolate.  Try putting single quotes (instead of double-quotes) around the username and password to make sure PowerShell is interpreting the username/password exactly as you've typed it.
PowerShell,3csxam,midnightFreddie,1 point,Fri Jul 10 21:06:25 2015 UTC,"The second request url isn't necessarily the same. It is probably supposed to be $r.Forms[0].action. Also, you have the second query body messed up in both the OP and the corrected comments version. Try this (untested):  $result = Invoke-WebRequest $r.Forms[0].action -WebSession $q -Body $r.Forms[0].Fields -Method Post   The variables are named as they are in the OP. In the example in your comments you're using $url and $qdp instead of $r and $q."
PowerShell,3csurw,Beatle_Matt,2,Fri Jul 10 14:26:12 2015 UTC,"Your Get-WMIObject object holds many elements, uniquely identified by their 'Index' property. Not all of the elements in win32_networkadapterconfiguration have a value in their 'macaddress' property; this explains the blank lines/carriage returns.   This is a better visualization of what's going on:  Get-WmiObject win32_networkadapterconfiguration -cn $COMPUTERNAME | select description, macaddress   What you probably want to do is return only the elements where the macaddress property is not null, and where the description is not equal to 'RAS Async Adapter'.  Expanding the 'macaddress' property would also work."
PowerShell,3csurw,itsteve,2,Fri Jul 10 14:45:59 2015 UTC,"You're getting output from each ""network adapter"", which includes a lot more than just physical adapters. You just need to filter out the Null data.  Try this.  Get-WmiObject win32_networkadapterconfiguration -cn $COMPUTERNAME | select macaddress | Where {$_.macaddress -ne $Null}| ft -HideTableHeaders"
PowerShell,3csurw,Shiznot,1 point,Fri Jul 10 14:50:22 2015 UTC,if I use  Where {$_.macaddress -ne $Null -and $_.description -notmatch 'RAS Async Adapter'}   ...it still pulls the RAS Async Adapter - unless my operators are wrong?
PowerShell,3csurw,Brekkjern,1 point,Fri Jul 10 14:59:47 2015 UTC,Try using -or?
PowerShell,3csurw,JaapBrasser,1 point,Fri Jul 10 17:16:55 2015 UTC,How about doing away with the Format-Table cmdlet alltogether for example:  Get-WmiObject win32_networkadapterconfiguration | select-object -ExpandProperty macaddress   Or:  (Get-WmiObject win32_networkadapterconfiguration).macaddress
PowerShell,3csurw,siecer,1 point,Fri Jul 10 14:40:15 2015 UTC,Both of those are closer to what I want - but returns:  A1:D2:C3:D4:E5:4D                                                                                                                                                   22:48:55:59:41:EF       Still returns the RAS Async Adapter address...which is strange! :)
PowerShell,3csurw,siecer,1 point,Fri Jul 10 14:58:06 2015 UTC,Get-WmiObject win32_networkadapterconfiguration | Where {$_.macaddress} | select -exp macaddress   or  Get-WmiObject win32_networkadapterconfiguration | Where {$_.macaddress -and $_.Description -ne 'RAS Async Adapter'} | select -exp macaddress
PowerShell,3csurw,cjluthy,1 point,Fri Jul 10 15:03:13 2015 UTC,"Strangely, this still returns two values:  A1:D2:C3:D4:E5:4D 22:48:55:59:41:EF   No spaces though! Getting closer!"
PowerShell,3csurw,apertur,1 point,Fri Jul 10 15:11:31 2015 UTC,"edited, see second example  There are two interfaces with MAC addresses.  You either have to filter the ones you don't want or specify the ones you do."
PowerShell,3cu4up,Said_The_Liar,3,Fri Jul 10 20:11:46 2015 UTC,"if ($adminCheck = ""False"")  should be  if ($adminCheck -eq ""False"")  Actually - I think you need to change most of those = signs to -eq in the if statements."
PowerShell,3cu4up,Donnie_Taylor,2,Fri Jul 10 20:17:00 2015 UTC,This or just cheat  If ($var1) {variable 1 is true} If (!($var1)) {variable 1 is not true}
PowerShell,3cu4up,creamersrealm,1 point,Sat Jul 11 01:38:59 2015 UTC,Why aren't you using something like this?  #Requires -RunAsAdministrator
PowerShell,3cu4up,theusernamewasfree,1 point,Fri Jul 10 20:17:59 2015 UTC,"While this is a valid option, for me this gives and ugly error message.  I prefer to handle it myself and display a nice warning to the user.  I use...:  # Check admin status If (-not ([Security.Principal.WindowsPrincipal] `           [Security.Principal.WindowsIdentity]::GetCurrent()).IsInRole( `           [Security.Principal.WindowsBuiltInRole] 'Administrator')) {     Write-Host '  You are not running this script as an administrator' -ForegroundColor Red     Write-Host ''     Break }"
PowerShell,3cu4up,root-node,1 point,Sun Jul 12 19:06:35 2015 UTC,"What's the ""ugly error message"", and what version of PowerShell are you running this under?"
PowerShell,3cu4up,lgwapnitsky,1 point,Mon Jul 13 17:31:09 2015 UTC,"This error message.  To a non-technical user, this block of red text is not a nice thing to see.  Granted, non-technical users should not be running admin scripts, but you get the point.  :)  .\Untitled1.ps1 : The script 'Untitled1.ps1' cannot be run because it contains a ""#requires"" statement for running as Administrator. The current Windows PowerShell session is not running as Administrator. Start Windows PowerShell by using the Run as Administrator option, and then try running the script again. At line:1 char:1 + .\Untitled1.ps1 + ~~~~~~~~~~~~~~~     + CategoryInfo          : PermissionDenied: (Untitled1.ps1:String) [], ScriptRequiresException     + FullyQualifiedErrorId : ScriptRequiresElevation"
PowerShell,3ctq3t,gingerbreaddave,1 point,Fri Jul 10 18:23:38 2015 UTC,"Sounds doable but an example of how the computer name relates to the OU would help.    Here's a quick made-up one based on the first 3 letters of the computer name:  # All computers for SALES start with SAL # All computers for MARKETING start with MAR  #Our OUs are Called Marketing Computers and Sales Computers.  $computers = 'SAL-COMP-1','MAR-COMP-13'  foreach ($computer in $computers) {      $filter = $computer.SubString(0,3)      Get-ADOrganizationalUnit -filter ""Name -like '$filter*Computers'"" |      Select-Object DistinguishedName  }   Output:  DistinguishedName                                                                   -----------------                                                                   OU=Sales Computers,OU=Sales,DC=contoso,DC=com                                       OU=Marketing Computers,DC=contoso,DC=com"
PowerShell,3csqap,zdmilot15,3,Fri Jul 10 13:48:54 2015 UTC,Does the new user directory structure already exist? That output looks like a mkdir output...
PowerShell,3csqap,mrkurtz,1 point,Fri Jul 10 18:37:14 2015 UTC,"Thank you, you were right, I had  [system.io.directory]::CreateDirectory(""C:\Users\$CurrentUser\Desktop\NewUsers"")   causing the output, and not the csv creation. I piped it to out-null like this  [system.io.directory]::CreateDirectory(""C:\Users\$CurrentUser\Desktop\NewUsers"") | Out-Null   and the script runs silently again!"
PowerShell,3csqap,JaapBrasser,2,Mon Jul 13 12:21:15 2015 UTC,Export-Csv does not create any output except the creation of the csv file. So can you share the code you are using then I can help you determine what you should change.
PowerShell,3csqap,RickSaysMeh,1 point,Fri Jul 10 13:58:41 2015 UTC,"Here is the code I have  New-Object -TypeName PSCustomObject -Property @{             ""Timestamp"" = $Timestamp             ""Username"" = $User             ""Last Name"" = $Last             ""First Name"" = $First             ""Department"" = $Dept             ""Job Title"" = $Title             ""Company"" = $Company             ""Address"" = $Address             ""State"" = $Local             ""City"" = $ServCity             ""Zip Code"" = $Zip             ""Extension"" = $Ext             ""Work Phone"" = $Phone             ""Mobile Phone"" = $MobilePh             ""Email Address"" = $EmailAddress         } | Export-Csv -Path ""C:\Users\$CurrentUser\Desktop\NewUsers\Newuser $(((get-date).ToUniversalTime()).ToString(""yyyyMMddThhmmssZ"")).csv"" -NoTypeInformation #-Append   And it outputs  Mode                LastWriteTime     Length Name ----                -------------     ------ ---- d----         7/10/2015   9:46 AM            NewUsers"
PowerShell,3csqap,Shiznot,1 point,Fri Jul 10 16:19:31 2015 UTC,"I even tried this to no avail  New-Object -TypeName PSCustomObject -Property @{             ""Timestamp"" = $Timestamp             ""Username"" = $User             ""Last Name"" = $Last             ""First Name"" = $First             ""Department"" = $Dept             ""Job Title"" = $Title             ""Company"" = $Company             ""Address"" = $Address             ""State"" = $Local             ""City"" = $ServCity             ""Zip Code"" = $Zip             ""Extension"" = $Ext             ""Work Phone"" = $Phone             ""Mobile Phone"" = $MobilePh             ""Email Address"" = $EmailAddress         } | Export-Csv -Path ""C:\Users\$CurrentUser\Desktop\NewUsers\Newuser $(((get-date).ToUniversalTime()).ToString(""yyyyMMddThhmmssZ"")).csv"" -NoTypeInformation  <#-Append#> | Out-Null   Also note that I am using PS 2.0 on Server 2008 R2"
PowerShell,3csqap,slyaces,1 point,Fri Jul 10 16:25:13 2015 UTC,This code by itself does not generate any console output... I replaced your variables with integers and strings and it worked as expected. I assume it is something else in your script that you have not shared with us that is causing the issue. Something to do with setting the variables.  I tested this on Windows 8.1 with PowerShell 4 and on Server 2008 R2 with PowerShell 2.
PowerShell,3csqap,Betterthangoku,1 point,Fri Jul 10 19:54:05 2015 UTC,"$somedata | Export-Csv $CSVfilepath  That should be silent, are you doing something different?"
PowerShell,3csqap,lostmojo,1 point,Fri Jul 10 14:01:01 2015 UTC,Look into out-null. Just pipe the output to it.   I do the same thing for a user creation script.
PowerShell,3ctb4x,ghazgul,1 point,Fri Jul 10 16:34:20 2015 UTC,Is enabling inheritance not an option?
PowerShell,3ctb4x,alcaron,1 point,Fri Jul 10 18:38:09 2015 UTC,"From what I'm guessing it seems when the permissions were applied, inheritance was not used.  So when the computer removing all the explicit permissions stalled, it left a portion with them still up.  Its not like you can inherit reverse permissions from the top folder.  You could attempt some weird garbage with denies, but you should really never use denies."
PowerShell,3ctb4x,Deathonus,1 point,Fri Jul 10 22:00:51 2015 UTC,"What kind of permissions did they try to apply? Was it like RW access for a particular user on the all the folders?  Was it to all the sub folders as well?  If we are talking explicit permissions down to files here is a rough draft at what you'd need the script to do.   You'd need to use something like get-childitem with recursion to get all the objects that need fixing. Iterate through them and pipe them over to the get-acl cmdlet. Then iterate through the access property of the object you got from get-acl and remove the entry/entries you don't want.  Each acl entry has a IdentityRefrence like ""BUILTIN\Users"" which you can use to figure out which entry/entries to delete. Then pipe the new shortened acl to set-acl for that file/folder   This would end up removing all acl's based on whatever IdentityRefrence you decided on, including the original user you ment to add.  So you'd have to doubt back for whichever user's folder and add them permissions, which would only take a couple of mins.  I haven't attempted anything risky like this in Powershell off hand, so I'd need to test it on some mock directory if you'd want me to try my hand at making it myself.  If no one with experience chimes in with a good example, I'll try my hand at putting something together."
PowerShell,3ct5r7,DougFinke,1 point,Fri Jul 10 15:53:05 2015 UTC,LOL total joke.
PowerShell,3ct5r7,u4iak,2,Sat Jul 11 03:31:47 2015 UTC,No at all. Deposits a being placed and call for speakers is coming soon.
PowerShell,3ct5r7,u4iak,1 point,Sat Jul 11 21:43:39 2015 UTC,"Wait, you mean this is acutally for powershell and a cruise?   EDIT: I wonder if I can expense something like that and take a spouse... EDIT2: Um HOLY SHIT my wife told me we have to sign up, but I'm not much of a speaker."
PowerShell,3ct5r7,u4iak,2,Mon Jul 13 01:15:08 2015 UTC,"This a business trip, and is a tax deduction."
PowerShell,3ct5r7,DollarStorePopTarts,1 point,Fri Jul 17 01:45:19 2015 UTC,"First off, my apologies - didn't know if you were a spam bot (you have little amount of posts) and I didn't take it seriously."
PowerShell,3ct5r7,DollarStorePopTarts,2,Sat Jul 18 11:38:24 2015 UTC,"Totally understood. It'd be great to have you on the cruise.  Don Jones and Jeff Hicks, authors of PowerShell in a Month of Lunches have booked their cabins and submitted several talks.   I written the book ""PowerShell for Developers"" and am looking forward to 7 days to the Bahamas geeking out as much as possible."
PowerShell,3cq83x,Gorstag,11,Thu Jul 9 22:11:38 2015 UTC,"Change   $databases = Get-mailboxdatabase | select GUID   to  $databases = Get-mailboxdatabase | select -ExpandProperty GUID   or  $databases = Get-mailboxdatabase  Foreach ($database in $databases) {    Get-itemproperty ""hklm:\System\CurrentControlSet\Services\MSExchangeIS\DB2\$($database.GUID)"" }"
PowerShell,3cq83x,Bobs16,1 point,Thu Jul 9 22:34:19 2015 UTC,Could you  $databases = (Get-mailboxdatabase).GUID   ? I typically use that over piping through select.
PowerShell,3cq83x,mcsparklenuts,2,Fri Jul 10 01:59:21 2015 UTC,"For versions above 2.0, yes. They both do the same thing.  Honestly,  the second half after the or is how it should be done. For long/advanced scripts you never know when you may need to refer back to  the entire object inside of your foreach loop."
PowerShell,3cq83x,Bobs16,4,Fri Jul 10 02:19:12 2015 UTC,"When you omit the -Expandproperty  switch parameter you will get back whichever datatype that the information is stored in. In this case the Guid is stored in a hashtable and that's exactly what is being returned. We can use -Expandproperty to convert that into a String which can then be used an input object again more easily.   You will notice this right away when you see @{information} as suggest by Bobs16, throw the expand in there and you should get back a nicely formatted string."
PowerShell,3cq83x,bundyfx,1 point,Fri Jul 10 01:58:54 2015 UTC,"You could also do   Get-ItemProperty (""hklm:\System\CurrentControlSet\Services\MSExchangeIS\DB2\{0}"" -f $database.GUID)"
PowerShell,3cq83x,dzdj,1 point,Fri Jul 10 01:52:56 2015 UTC,"Okay,  Thanks a bunch guys.  I see what the problem was.  I thought it was already a string because visually it looked like it on the screen.  But in fact I was not utilizing the correct commands.  Thanks for getting me over this hump."
PowerShell,3cqxzm,mcsparklenuts,1 point,Fri Jul 10 01:44:13 2015 UTC,"Nice script, how do you remove it after stopping said script?"
PowerShell,3cqxzm,oddie121,1 point,Fri Jul 10 14:24:37 2015 UTC,"So if the powershell window is closed, the bar will close. You may get a temporary screen artifact, but adjusting another window should fix that. Ideally this would be a permanent fixture though. You would run it as a logon script and the bar would terminate only when you logged off.  I know this only really responds well to that use case, though. If you were to use $Window.ShowDialog(), while you would be limited to a single window at a time, the script would wait until you closed the window, or if you continued to use $Window.Show() you could close the window programatically with $Window.Close().  https://msdn.microsoft.com/en-us/library/system.windows.window_methods(v=vs.110).aspx"
PowerShell,3crdlp,2girls1netcup,1 point,Fri Jul 10 04:00:16 2015 UTC,you try stepping it?
PowerShell,3crdlp,occamsrzor,1 point,Fri Jul 10 05:15:22 2015 UTC,"If you wrap the body if the function in a process block, then $computername will become your pipe object. Set the type to [string[]] for $computername.  If you start off with a foreach, then it doesn't matter if you have one item or an array or using the pipe. This lets you consolidate two sections of code.  foreach($computer in $computername){...}   Because I said add a process block, also add a begin block. Then put the kill job in that so we know it runs once.  This would be a good use case to learn workflows. It's a little more advanced, but you are basically writing your own multithreader and workflows do parallel processing without the complication of jobs.  I would have enabled psremoting and used invoke-command for this.  Invoke-command -computer $computerlist -asjob {...}   It will do 32 (?) jobs at once by default, but you can configure that."
PowerShell,3crdlp,KevMar,1 point,Fri Jul 10 12:36:31 2015 UTC,"with the process block and foreach, would I still be able to pass either an array of strings or an array of objects? I.e., getting an entire OU with get-adcomputer then piping it into my command."
PowerShell,3crdlp,KevMar,1 point,Fri Jul 10 12:50:55 2015 UTC,Would have to test it. ValueFromPipelineByPropertyName=$true should allow that but can't say for sure.  You could do this if it does not work.  get-adcomputer | % name | function
PowerShell,3crdlp,KevMar,1 point,Fri Jul 10 15:14:22 2015 UTC,Same problem with invoke-command.
PowerShell,3cq26i,powershelltutorials,1 point,Thu Jul 9 21:26:42 2015 UTC,i am currently learning this in my MSCE server infra 2012 R2 course.
PowerShell,3cq26i,leungclj,1 point,Fri Jul 10 01:36:58 2015 UTC,"Thats awesome, I bet its a fun course!"
PowerShell,3cpgdl,wigrif,6,Thu Jul 9 18:47:56 2015 UTC,"I just put this together because I'd never actually thought about using PowerShell to do something like that before.  Invoke-MoveCursorToLocation.ps1  The function lacks a lot of error checking (i.e. It doesn't currently prevent you from choosing an ""out of bounds"" coordinate), but it was really more a Proof-of-concept function that I threw together in 30 minutes. Feel free to expand on it if you want.  Also, the function does not block user input like AutoIT can, but it looks like you could do something like that with some P/Invoke code  Edit:  Whoops!  I forgot to add the System.Windows.Forms assembly in my script file.  I had already added it to my console session, so it was working without it when I was testing.  Github updated accordingly.... :)  Edit2:  This function is not accurate due to the way I'm currently calculating the delta numbers.  The cursor will not got directly to the point specified."
PowerShell,3cpgdl,ryanbrown,1 point,Thu Jul 9 20:35:30 2015 UTC,"So in effect you have taken the movement from A to B, and chopped it up into pieces (-NumberOfMoves).  I'm not sure if this will fool a touch interface of not.  Since you seem familiar with AutoIT, here is what i'm calling as a process and waiting for it to complete before moving on...   MouseClickDrag (""left"", 496, 338, 246, 192, 15)   that is a very fluid movement, is this achievable in PS???"
PowerShell,3cpgdl,ryanbrown,1 point,Thu Jul 9 21:20:00 2015 UTC,"I'm only really familiar with AutoIT by name and the basic functionality it can provide.  I haven't personally used it to do anything.    I imagine it would be possible to script a click-and-drag event, but you'd probably have to use the P/Invoke code I mentioned and import some of the mouse_event functions.  I'm not sure how you'd make the movement more fluid outside of playing with the NumberOfMoves and CursorDelay parameters, or just completely re-writing the function.  I also noticed that my function isn't exactly ""accurate"" due to the fact that my ""delta"" numbers are often fractional and I'm fairly certain that Powershell is just rounding the numbers automatically when I'm setting the cursor position.  I think the logic would need to be reworked to move the position a pixel (or more at a time).  I might be able to play with it some more when I get some downtime."
PowerShell,3cpgdl,pandiculator,1 point,Thu Jul 9 23:50:16 2015 UTC,Nice solution.    I came up with something similar using Start-Sleep and redrawing the position but I tried to implement it with a while loop.  Couldn't quite get it working though.
PowerShell,3cpgdl,ArmondDorleac,2,Thu Jul 9 21:21:48 2015 UTC,"Out of curiosity, what are you automating?"
PowerShell,3cpn6y,waygooder,3,Thu Jul 9 19:41:48 2015 UTC,I haven't seen it done any other way. This is my goto post each time I need to do storage stuff.
PowerShell,3cpn6y,thebeersgoodnbelgium,2,Thu Jul 9 19:51:59 2015 UTC,"Thanks, I was able to modify that code pretty easy to get what I wanted.  Ended up with this  Get-WmiObject Win32_Volume -Filter ""DriveType='3'"" | ForEach {             New-Object PSObject -Property @{                 Name = $_.Name                 Label = $_.Label                 FreeSpace_GB = ([Math]::Round($_.FreeSpace /1GB,2))                 TotalSize_GB = ([Math]::Round($_.Capacity /1GB,2))                 UsedSpace_GB = ([Math]::Round($_.Capacity /1GB,2)) - ([Math]::Round($_.FreeSpace /1GB,2))             }         }   Now I just need to pull this into PRTG ;)"
PowerShell,3cpn6y,alinroc,1 point,Thu Jul 9 21:42:01 2015 UTC,Is the only way to get it to subtract freespace from capacity?   That is the way to calculate it. You only need total capacity and either free space or used space to calculate the remaining value. Adding used space to the WMI object that's returned would be kind of redundant.
PowerShell,3cpn6y,bundyfx,1 point,Thu Jul 9 19:59:04 2015 UTC,"As mentioned Boe has a great write up on this. Another way to get this information would be creating a custom header in your select statement. As such:  $Disks = Get-WmiObject -Class Win32_logicaldisk -ComputerName $Computername |{$_.Deviceid -ne 'A:' -and $_.DeviceID -ne 'Z:'}| Select DeviceID,DriveType,@{n='Size (GB)';e={$_.Size / 1GB -as [int]}},@{n='FreeSpace (GB)';e={$_.FreeSpace / 1GB -as [int]}},@{n='Remaning Space (GB)';e={($_.Size / 1GB -as [int]) - ($_.FreeSpace / 1GB) -as [int]}}   As you can see we have a separate expression for each step but it's still a long one liner. It also trims them all to an Int for readability.  Hope this helps."
PowerShell,3cpn6y,alcaron,2,Thu Jul 9 21:27:32 2015 UTC,"lol wrote this, went to post, scrolled down, saw your post...I need to learn to scroll down first...  gwmi Win32_Volume | select Name,@{N=""Total"";E={[Math]::Round($_.Capacity /1GB,2)}},@{N=""Free"";E={[Math]::Round($_.FreeSpace /1GB,2)}},@{N=""Used (GB)"";E={[Math]::Round($_.Capacity /1GB,2)-([Math]::Round($_.FreeSpace /1GB,2))}} | Format-Table -AutoSize"
PowerShell,3cpn6y,Swarfega,1 point,Fri Jul 10 01:06:29 2015 UTC,"Your missing a ? or Where-Object after the first pipe.  I would also move the filter onto the initial commandlet for performance reasons and like above filter on DriveType 3.  Get-CimInstance -Class Win32_logicaldisk -Filter ""DriveType='3'"" | Select DeviceID,DriveType,@{n='Size (GB)';e={$_.Size / 1GB -as [int]}},@{n='FreeSpace (GB)';e={$_.FreeSpace / 1GB -as [int]}},@{n='Remaining Space (GB)';e={($_.Size / 1GB -as [int]) - ($_.FreeSpace / 1GB) -as [int]}}   You could also shove a % used in there...  @{n='Percent Used';E={ ($_.freespace / $_.size)*100 -as [int]}}"
PowerShell,3cpn6y,bundyfx,1 point,Thu Jul 9 22:11:21 2015 UTC,"Thanks for that. for some reason my copy and paste from my script left off the '?'.. Yes good point, you can have a -filter as suggest for performance reasons."
PowerShell,3cpn6y,frermanisawesome,-1,Fri Jul 10 01:55:11 2015 UTC,nope Windirstat
PowerShell,3cpn6y,neilthecellist,1 point,Thu Jul 9 20:57:43 2015 UTC,WinDirStat does not work well on large capacity servers with high I/O. At least in my experience and in other orgs I've worked at
PowerShell,3cpf81,lidorlg1,1 point,Thu Jul 9 18:38:17 2015 UTC,"I have a start of something but it's not completed :  .\LoadConfig scriptname.config  param($path = $(throw ""You must specify a config file"")) $global:appSettings = @{} $config = [xml](get-content $path) foreach ($addNode in $config.configuration.appsettings.add) {  if ($addNode.Value.Contains(‘,’)) {   # Array case   $value = $addNode.Value.Split(‘,’)   for ($i = 0; $i -lt $value.length; $i++) {      $value[$i] = $value[$i].Trim()      if $appSettings.value = $property_name then      $result = $result.Replace(""`$appSetting.value.$key"", $property_name.value[$key]);   }  }  else {   # Scalar case   $value = $addNode.Value  }  $global:appSettings[$addNode.Key] = $value }"
PowerShell,3cpf81,alcaron,2,Thu Jul 9 18:39:06 2015 UTC,"eek...  I de-mangled it but I'm not entirely sure what you are wanting to do.  param($path = $(throw ""You must specify a config file"")) $global:appSettings = @{} $config = [xml](get-content $path) foreach($addNode in $config.configuration.appsettings.add) {     if($addNode.Value.Contains(‘,’))     {     # Array case         $value = $addNode.Value.Split(‘,’)         for($i = 0; $i -lt $value.length; $i++) {             $value[$i] = $value[$i].Trim()             if($appSettings.value = $property_name) {                 $result = $result.Replace(""`$appSetting.value.$key"", $property_name.value[$key])             }         }     }else{         # Scalar case         $value = $addNode.Value     }      $global:appSettings[$addNode.Key] = $value }"
PowerShell,3co18v,Aperture_Kubi,2,Thu Jul 9 11:58:38 2015 UTC,"While sharing PS one liners, here are two of mine I threw in my PS profile.  function my-get-adgroup-membership ($adgrouptoget){     get-adgroupmember -recursive $adgrouptoget | get-aduser -property title,department | select -property name,surname,givenname,department,title | format-table }  function my-get-user-groupmembership ($usertoget){     Get-ADprincipalGroupMembership $usertoget | select -property name,distinguishedname | where-object distinguishedname -like ""*OU=[OU filter here if you need it]*"" | format-table }"
PowerShell,3cqp5v,Pestilent,2,Fri Jul 10 00:27:59 2015 UTC,":NextLine is a label   It allows a command such as   if ( $condition -eq $true ) { break :NextLine }   Which will force continuation at the :NetxLine label.  It is support for spaghetti coding and IMHO should be avoided in all but the most dire of edge cases :)  In the referenced script, something might cause program flow to jump to the label :NextLine at which point the foreach iterates through $PvsLines putting the current value in $Line during the iteration. The script block run against each line is empty {} so does nothing !"
PowerShell,3cqp5v,real_parbold,1 point,Fri Jul 10 11:48:13 2015 UTC,Thank you. This is exactly what I was looking for!
PowerShell,3cqp5v,alcaron,1 point,Fri Jul 10 12:56:25 2015 UTC,"I could be wrong but I'm pretty sure that is just a typo in the post...  I have literally never seen NextLine before lol.  edit: Who wrote this? lol there is no way a native PS'er wrote this...I mean who does this?  [Object]$Script:PvsObject = New-Object PSObject   It works, sure, but that is about the goofiest way of doing it I've ever seen."
PowerShell,3cqp5v,KevMar,1 point,Fri Jul 10 01:11:20 2015 UTC,"So I'm confused by this script because Martin from Citrix has a completely different development style, and I assume his knowledge of other code bleeds in to PowerShell in a confusing manner?  I don't really define things in scopes. probably because I feel it will just confuse me if I do. I will only reference $env:  I don't have any examples, but I thought I had seen other uses before ForEach used in the past.  Thanks for replying."
PowerShell,3cp481,Braber02,3,Thu Jul 9 17:17:21 2015 UTC,"I would think it kind of depends on what you are looking to do, it's like someone saying ""where do I get started with bash"", get started by using it. Do what you need to do with it.  You can google just about anything to find a relevant result, so just grow organically with it.  Unless you are new to scripting there isn't anything you will really ""need to understand"" so the learn by doing approach would probably suit you fine.  You can go the orielly route if you really want to, their books are prefectly good.  PowerShell blog is good, scripting guy blog is good..."
PowerShell,3cp481,alcaron,2,Thu Jul 9 17:41:08 2015 UTC,http://www.microsoftvirtualacademy.com/en-US/training-courses/getting-started-with-powershell-3-0-jump-start-8276  Seriously I would love to see a Unix guys perspective of PowerShell.  Personally I think it's way better than any shell on Unix.  Unix command line is great but PowerShell takes what is great from the CLI and builds on it way more than you can have imagined.
PowerShell,3cp481,Swarfega,2,Thu Jul 9 20:15:59 2015 UTC,"Powershell's great as a scripting language, but for interactive use give me bash or zsh all day every day. The powershell syntax is just a wee bit too verbose for it's own good and the ecosystem just doesn't have the sheer diversity of tools that *nix does (yet anyway, things are improving all the time)"
PowerShell,3cp481,Tireseas,3,Thu Jul 9 22:29:35 2015 UTC,the ecosystem just doesn't have the sheer diversity  of tools that *nix does   You are comparing apples to oranges.
PowerShell,3cp481,Bobs16,1 point,Thu Jul 9 22:49:52 2015 UTC,"Nah, I'm comparing several decades of tools and filters to a relatively new territory. Yeah you could compare shell to shell in a vacuum but shells by themselves aren't the whole story."
PowerShell,3cp481,Tireseas,2,Thu Jul 9 22:55:36 2015 UTC,"The powershell syntax is just a wee bit too verbose   That's why there are short aliases for things.  Get-ChildItem -Recurse -Filter ""*.mp4"" | ForEach-Object { Copy-Item -Path $_.FullName -Destination D:\backup\. }   vs.  ls -r -f ""*.mp4"" | % { cp $_ D:\backup\. }    and the ecosystem just doesn't have the sheer diversity of tools that *nix does   This is usually stated by people who still want everything done in string manipulation and don't follow the powershell way of importing into objects, doing your work in the object domain, and exporting back out to string only at the end.  Literally every common UNIX tool is available, as well.  (Thanks OSS)"
PowerShell,3cp481,RiPont,1 point,Fri Jul 10 09:49:19 2015 UTC,"I have recently completed the virtual academy course above and found it helpful, afterwards I read the book Learn Windows PowerShell 3 in a Month of Lunches - Don Jones & Jeffrey Hicks  I found the book extremely helpful and a good beginners guide"
PowerShell,3cp481,ekulnz,2,Thu Jul 9 23:57:32 2015 UTC,http://cecs.wright.edu/~pmateti/Courses/233/Labs/Scripting/bashVsPowerShellTable.html   This helped me a lot when learning Powershell after Bash.
PowerShell,3cp481,Meaven,1 point,Mon Jul 13 10:00:13 2015 UTC,Don Jones - this guy's video tutorials are great. He is linked to the MS powershell blog  http://www.youtube.com/playlist?list=PL6D474E721138865A
PowerShell,3cp481,brianvsshark,1 point,Fri Jul 10 03:26:30 2015 UTC,"One way to look at things is that linux is a file based OS and Windows is an API based OS. In linux you parse and manipulate text. In Powershell, you are working with objects. It's like the data is already tokenized for you.  One of the really powerful features that powershell has over linux is reflection. Every cmdlet has tab complete. If they added parameter validation, then tab complete on values becomes available. That validation also add verbose errors that are localized. Get-Help looks at the cmdlet and describes it.   Linux was here long before Powershell and it was a strong influence on the team. It also gave the team a chance to solve some old problems with new ideas. Powershell is good because Linux came first."
PowerShell,3cp481,KevMar,1 point,Fri Jul 10 22:35:41 2015 UTC,You would be amazed at how much linux just works in powershell.
PowerShell,3cp481,starknight123,1 point,Thu Jul 9 17:39:50 2015 UTC,"The base commands, yes... the switches, no."
PowerShell,3coe7h,15_Tries_All_Taken,2,Thu Jul 9 14:03:38 2015 UTC,"That's because while the the default parameter (Identity) takes pipeline input it expects the following types: GUID, DN, UPN, SMTP address, or Alias  [PS] C:\Windows\system32>help Set-CASMailbox -Parameter identity  -Identity <MailboxIdParameter>     The Identity parameter specifies the mailbox ID. You can use the following values:     * GUID     * Distinguished name (DN)     * User principal name (UPN)     * SMTP address     * Alias   Looking at the Inputs section of the full help for Set-CasMailbox it refers us to the following link (https://msdn.microsoft.com/en-us/library/ff326162.aspx) which says the following input types are acceptable * MailboxIdParameter * MailboxPolicyIdParameter * EwsApplicationAccessPolicy * MimeTextFormat * Fqdn * ProxyAddressCollection * SmtpAddress * Boolean * String  Looking at the help for get-aduser we see that it outputs the type Microsoft.ActiveDirectory.Management.ADUser, which is not a type Set-Casmailbox excepts  OUTPUTS     Microsoft.ActiveDirectory.Management.ADUser         Returns one or more user objects.          This cmdlet returns a default set of ADUser property values. To retrieve additional ADUser properties, use the         Properties parameter.          To get a list of the default set of properties of an ADUser object, use the following command:            Get-ADUser <user>| Get-Member          To get a list of the most commonly used properties of an ADUser object, use the following command:            Get-ADUser <user> -Properties Extended | Get-Member          To get a list of all the properties of an ADUser object, use the following command:            Get-ADUser <user> -Properties * | Get-Member   This is why you need to reference the property as a string in order for set-casmailbox to understand it"
PowerShell,3coe7h,Iczer1,2,Thu Jul 9 17:24:09 2015 UTC,Yeah you need to pipe to a foreach.  get-aduser someone | % {set-casmailbox[string]$_.name -someparameter }
PowerShell,3coe7h,Theratchetnclank,1 point,Fri Jul 10 09:30:03 2015 UTC,"early testing looks like the below will work.  $ImapEnabledDN = (Get-ADGroup imapenabled).distinguishedname  Get-ADUser -filter { -not (memberof -eq $imapenableddn) } -Properties msExchRecipientTypeDetails | ? {$.msexchrecipienttypedetails -eq ""1"" -or $.msexchrecipienttypedetails -eq ""4""} | foreach {Set-CASMailbox $_.name -ImapEnabled $false}"
PowerShell,3cojir,barbados-slim,3,Thu Jul 9 14:46:14 2015 UTC,"$MA_Daily = Get-ChildItem -Path (""F:\Daily\""+(Get-Date -Format MM\\dd\\yyyy))   SUPER useful resource...  https://technet.microsoft.com/en-us/library/ee692801.aspx  I totally biffed on reading the ""on mondays it's weird"" bit.  if((Get-Date -Format ddd) -eq ""Mon""){ Get-ChildItem -Path (""{0:MM\\dd\\yyyy}"" -f (Get-Date).AddDays(-3)) }   -f is for formatting a string btw, you essentially say ""My name is {0} and my function is {1}.) -f $$env:COMPUTERNAME,$jobfunction and it replaces the curly braced stuff with the value of the variables supplied.  This is a technical explanation of -f  http://www.computerperformance.co.uk/powershell/powershell_-f_format.htm"
PowerShell,3cojir,alcaron,1 point,Thu Jul 9 15:38:58 2015 UTC,"I would take a different approach. I would find the most recent folder by date created. Then test for each file I think should be there. Using the template folder is a good idea.  $MA_Daily = ls ""F:\Daily\*\MPI-MPI"" -Directory | sort CreationTime | Select -last 1 $MA_Template = Get-childitem  ""G:\Billy\Daily\MA""  Foreach($source in $MA_Template) {     $file = Join-Path $MA_Daily.fullname $source.name     if(!(Test-Path $file)){         Write-Warning ""Missing File: $file""     } }  # Samething using pester Describe ""Verify all files were created"" {      MA_Daily = ls ""F:\Daily\*\MPI-MPI"" -Directory | sort CreationTime | Select -last 1     $MA_Template = Get-childitem  ""G:\Billy\Daily\MA""      Foreach($source in $MA_Template)     {         $file = Join-Path $MA_Daily.fullname $source.name         it ""has file: $file"" {             $file | should exist         }     } }"
PowerShell,3cnqyu,danblank000,1 point,Thu Jul 9 09:41:22 2015 UTC,"I tested it here on my Exchange 2010 system and the try/catch works.  try { Get-Recipient -Identity IDoNotExist } catch { write-host ""Not Found"" }   Perhaps there is some other error in your code?"
PowerShell,3cnqyu,InvisibleTextArea,1 point,Thu Jul 9 10:13:03 2015 UTC,"thanks for getting back to me, I too am using Exchange 2010.    The full code I'm using is :  try{ $emailtest = get-recipient $email  } catch { }   the $email variable is set earlier on in the script but in this example contains an email address that does not exist in my domain.  When i run it the error i get is the one in my original post.  edit : I just tried running the code that you posted and i still receive the initial error I was getting.   I have been doing some reading and apparently it may have something to do with terminating / non-terminating errors.  Am a bit stumped to be honest."
PowerShell,3cnqyu,InvisibleTextArea,1 point,Thu Jul 9 10:21:56 2015 UTC,"To quote Microsoft:   Terminating Error: A serious error during execution that halts the command (or script execution) completely. Examples can include non-existent cmdlets, syntax errors that would prevent a cmdlet from running, or other fatal errors.  Non-Terminating Error: A non-serious error that allows execution to continue despite the failure. Examples include operational errors such file not found, permissions problems, etc.   It would also matter what $ErrorActionPreference is set as. Do you have it set to 'Stop' perhaps?"
PowerShell,3cnqyu,InvisibleTextArea,1 point,Thu Jul 9 11:26:54 2015 UTC,Just checked an $ErrorActionPreference is set to Continue
PowerShell,3coeai,jdgtrplyr,3,Thu Jul 9 14:04:29 2015 UTC,"How about:  $FileTypes = @( ""*.ade"" ,                 ""*.accdb"" ,                 ""*.accdr"" ,                 ""*.accda"" ,                 ""*.mdb"" ,                 ""*.mdf"" ,                 ""*.mde"" ,                 ""*.accde"" )  Get-ChildItem -Path c:\ -Include $FileTypes -Recurse -ErrorAction SilentlyContinue | Foreach {   Write-Host $( ""{0,-60},{1,10},{2,25},{3}"" -f $_.Name,                                                $_.Length,                                                $_.LastWriteTime,                                                $_.Directory ) # OR # Write-Host $( ""{0},{1},{2},{3}"" -f $_.Name, #                                    $_.Length, #                                    $_.LastWriteTime, #                                    $_.Directory ) }   You could of course build the files found into a list and then Out-CSV, or process them further instead of doing a Write-Host ... (PoC)  You can also wrap the block above so that it interrogates more than just the C:\ drive"
PowerShell,3coeai,real_parbold,1 point,Thu Jul 9 14:44:17 2015 UTC,"Awesome!! This works flawlessly, and I greatly appreciate your help!"
PowerShell,3cki73,derekhans,1 point,Wed Jul 8 16:54:21 2015 UTC,Nice post. Thank you!
PowerShell,3cki73,KTM_530_Durty,1 point,Wed Jul 8 17:07:30 2015 UTC,thanks
PowerShell,3cki73,iexsist,1 point,Thu Jul 9 02:09:51 2015 UTC,This is excellent. Very handy. Thank you.
PowerShell,3cki73,A13X_,1 point,Thu Jul 9 07:43:07 2015 UTC,Thank you!!  I was just thinking my previous quick reference guides were getting outdated last week but haven't gotten around to searching new ones out.
PowerShell,3ckdz4,invoke-ir,1 point,Wed Jul 8 16:24:25 2015 UTC,Definitely want more of this. Would have liked to see a little of the back-end code of how it grabs the MBR etc too instead of having to dig into the project.
PowerShell,3ckdz4,im_cody,2,Thu Jul 9 01:21:13 2015 UTC,"im_cody you can find the source on my github (https://github.com/Invoke-IR/PowerForensics_Source).  PowerForensics is a binary module, so the source is written in C# like many of the built in cmdlets.  Ultimatly to dump the MBR I use the CreateFile API to get a read handle to \.\PHYSICALDRIVE0 and parse out the first 512 bytes into an MBR class I defined based on Microsoft and the UEFI Forum."
PowerShell,3cmfyf,im_cody,1 point,Thu Jul 9 01:23:20 2015 UTC,Garbage Collection in .NET and thus Powershell is sometimes not automatically  forced until resources are demanded by another process/thread.  I have found that explicitly calling [GC]::Collect() to force Garbage Collection should help. Also be careful when saving objects from multiple servers to a variable.
PowerShell,3cmfyf,invoke-ir,1 point,Thu Jul 9 03:39:36 2015 UTC,What is the concern with saving multiple servers objects to a variable?
PowerShell,3cmfyf,lostmojo,1 point,Thu Jul 9 05:24:51 2015 UTC,"What is the concern with saving multiple servers objects to a variable?   PowerShell is terrible at releasing resources from variables, so if you are saving the output from thousands of hosts to a variable in a single PowerShell runspace then your memory consumption will skyrocket."
PowerShell,3cmfyf,invoke-ir,1 point,Thu Jul 9 13:12:28 2015 UTC,"I have noticed this can be an issue at times.  Have you really experienced the GC::Collect() helping when working with large scripts?  I have a few that house several hundred thousand records per variable in data tables, I use the remove-variable to help but that did not seem to make much of a difference."
PowerShell,3cmfyf,lostmojo,1 point,Thu Jul 9 13:43:36 2015 UTC,"For example if you are doing something like $output = Invoke-Command {Get-Process} -ComputerName (Get-Content hosts.txt)  Then your memory consumption will grow exponentially for each host listed in hosts.txt, and PowerShell will not automatically release memory resources even after the script has exited or moved on from the variable's scope.  Not that you can't save the output objects to a variable, but it is just something that you should be aware of."
PowerShell,3cmfyf,invoke-ir,1 point,Thu Jul 9 14:14:23 2015 UTC,"The same applies to background jobs, you can run a get-process on 150 servers and have memory shoot up to 3/4 of a GB pretty easily, even when you Get-Job | Receive-Job and then Remove-Job it still sits at the same memory usage, run [gc]::Collect() and it drops back down to ~300mb.  Still a lot of bloat in there but their response has typically been that using unused resources doesn't hurt anything, and I can't make any great arguments for why that isn't true.  As long as it is responsive about cleaning it up when it is needed, and doesn't impact performance (feels like it would in extreme cases) I guess it doesn't matter..."
PowerShell,3cjzsw,pvtskidmark,18,Wed Jul 8 14:39:23 2015 UTC,"LastAccessTime can be unreliable. I would use LastWriteTime and exclude sensitive folders. I wrote a script for this specific purpose a few years ago, perhaps it is interesting for you: Delete files older than x-days - Cleanup Script"
PowerShell,3cjzsw,JaapBrasser,7,Wed Jul 8 14:56:54 2015 UTC,LastAccessTime can be unreliable   Understatement. Tracking of this property isn't even enabled by default for several years now (the article says Vista but it's true on Server 2008+ as well AFAIK).
PowerShell,3cjzsw,alinroc,2,Wed Jul 8 17:42:12 2015 UTC,Wow!  That script is quite a bit handier than mine...thank you very much!
PowerShell,3cjzsw,JaapBrasser,1 point,Wed Jul 8 15:04:16 2015 UTC,"No problem, let me know if you need any help with the parameters."
PowerShell,3cjzsw,Swarfega,1 point,Thu Jul 9 07:04:20 2015 UTC,Updated 9/26/2013  ?
PowerShell,3cjzsw,JaapBrasser,1 point,Thu Jul 9 06:26:22 2015 UTC,"That is correct, I have not updated the script for a while. I do still actively answer questions for the script. If there is a bug in the script or an interesting feature request I would consider updating this script again."
PowerShell,3cjzsw,Swarfega,1 point,Thu Jul 9 07:03:47 2015 UTC,Ah sorry ignore me. I completely read you post wrong. I need my morning coffee.
PowerShell,3cjzsw,JaapBrasser,1 point,Thu Jul 9 07:20:39 2015 UTC,"No problem, I am just having mine as well c|_|"
PowerShell,3cjzsw,iexsist,1 point,Thu Jul 9 07:39:48 2015 UTC,"thanks, one for the library"
PowerShell,3cluk3,jfractal,1 point,Wed Jul 8 22:32:15 2015 UTC,"You kind of have to think of it like a function, if you want an object back from it, build that object and return it, don't write anything out to the screen, using Write-Host MIGHT be safe...your best bet is to not write anything at all and just do a return($object) at the end of the scriptblock. If you do that then set your Invoke-Command to a variable, for instance:  $test = Invoke-Command -Session $session -ScriptBlock{Get-Process} $test.GetType()   You should see it is the same type of object as if you just set a local instance of Get-Process to $test. Same if you return a string, etc. etc.  Hope that helps. I don't think I've tried doing it -AsJob and seeing what the results are, one would hope it would also keep the results but...you know...powershell...maybe it will and maybe it wont, depends on if they though of that. ;)"
PowerShell,3cluk3,alcaron,2,Thu Jul 9 15:17:42 2015 UTC,Huh - could it really he that simple?  I will try it out today and see what happens.
PowerShell,3cluk3,alcaron,1 point,Thu Jul 9 15:44:31 2015 UTC,could it really he that simple   Famous last words... ;)
PowerShell,3cluk3,alcaron,1 point,Thu Jul 9 15:51:17 2015 UTC,"Also, if you want to stay inside of powershell you can always replace...  $SERIALNUMBER = wmic BIOS get serialnumber $SERIALNUMBER = $SERIALNUMBER -Replace (""SerialNumber"","""")   ...with...  $SERIALNUMBER = (gwmi Win32_BIOS).SerialNumber"
PowerShell,3cl86z,Yellow_Odd_Fellow,6,Wed Jul 8 19:51:57 2015 UTC,"Try replacing this line  .\PsExec.exe \\$compname $msi   with two lines, like this  $cmd = "".\PsExec.exe \\$compname $msi"" Invoke-Expression $cmd"
PowerShell,3cl86z,schreckgestalt,1 point,Wed Jul 8 20:38:53 2015 UTC,"Okay. So I want to do something like this. It is almost the exact same code, but I'll emphasize the parts I'm stuck at. Any idea how I can pass the transform parameter through ? Mine seems to be running, from my side. When I look at the processes for the remote machine, however, it doesn't actually run. It also hangs indefinitely at the psexec section.   $msi=Get-Content c:\Remote_Installed_Apps\$compname-msi.txt  $mst=Get-Content c:\Remote_Installed_Apps\$compname-mst.txt  set-alias psexec ""c:\psexec.exe""  cd C:\scripts\PSexec  Invoke-Command -ComputerName $compname -ScriptBlock { & cmd /c ""psexec.exe \\$compname msiexec.exe /i $msi transform=$mst /qn+!""}"
PowerShell,3cl86z,im_cody,1 point,Thu Jul 9 13:56:30 2015 UTC,I'm surprised you're able to get PsExec to work at all within a PowerShell session. I've had constant problems getting it to work without wrapping it inside another cmd /c session.
PowerShell,3cl86z,alcaron,1 point,Thu Jul 9 02:22:14 2015 UTC,"I was able to get it to work, and posted the resolution up above. I had the $compname variable was defined previously, so defining it twice is what was breaking my script.  If you want to try it, since there is nothing that I can see that is domain dependent, it should be usable/testable. It's pretty quick as well."
PowerShell,3cl86z,SeanQuinlan,1 point,Thu Jul 9 13:58:39 2015 UTC,Really? What error are you getting? I use it to enable WinRM on machines all the time.
PowerShell,3cl86z,sgnewman,1 point,Thu Jul 9 17:53:00 2015 UTC,"Are you calling this ScriptBlock using Invoke-Command? If so, you need to use the -ArgumentList parameter to pass variables from outside the ScriptBlock ""into"" the ScriptBlock."
PowerShell,3cl86z,Daneth,0,Thu Jul 9 10:29:10 2015 UTC,"why not just use remoting?  You could just run this on the remote machine itself and skip over the psexec itself.  (I've not tested this, wrote it up directly in the comment box, so excuse any issues)  invoke-command -scriptblock{     param(         $cmd     )         & $cmd } -computername $computername -arguments ($command)"
PowerShell,3clw0i,danekan,1 point,Wed Jul 8 22:44:00 2015 UTC,"cleaning out some files... bit of an oldie but still useful to me. (and one of those things that I can say is directly saving us $)  Used in NetApp CIFS environment to have a large share that may in the back-end be multiple actual volumes of storage. I use it for a large company share where if folders haven't had anything modified in X years the folder gets moved to the cheaper SATA storage; this script is what enables the main share to be presented as one.  In the olden days we used to accomplish the same combination by simply using DFS to point to the different folders and it would take care of masking whether it was on $pub_SAS or $pub_SATA or what not, but our experience was that was terribly slow. On a Mac system it was unbearable, the Mac clients would seem to literally attemp to open each link. If you symlink them in the back-end, the server is doing all the work and from the client perspective it's just a typical single share.  We were a NetApp VFM (Brocade VFM) customer that configured DFS in this manner--this is what I've replaced that product w/... (the product itself they stopped supporting and didn't offer any replacement)"
PowerShell,3cluv0,LibraryAtNight,3,Wed Jul 8 22:34:51 2015 UTC,"Do you mean like all users who either like pizza, burgers or chicken?  You can just use -or in that case.  get-aduser -filter {(favoriteFood -eq ""pizza"") -or (favoriteFood -eq ""burgers"") -or (favoriteFood -eq ""chicken"")}"
PowerShell,3cluv0,sleeplessone,1 point,Wed Jul 8 23:55:29 2015 UTC,"Yes, exactly this! Thank you!"
PowerShell,3cluv0,ioFAILURE42,2,Thu Jul 9 01:17:12 2015 UTC,"Something like this should work (untested, will likely need tweaking)-  get-aduser -filter {favoriteFood -like ""*""}  | select name,favoriteFood | sort -property favoritefood   Alternatively maybe something like      get-aduser -filter {favoriteFood -like ""pizza"" -or favoriteFood -like ""burgers"" or favoriteFood -like ""chicken""}  I'm at home now and don't have a DC available to test.  Let me know what you find."
PowerShell,3cluv0,ioFAILURE42,1 point,Thu Jul 9 00:02:31 2015 UTC,"Thanks for the reply, that's actually the sort of info I was finding in my Googling, and it's useful, but Sleeplessone got exactly what I meant."
PowerShell,3cluv0,RampageUT,2,Thu Jul 9 06:10:10 2015 UTC,Glad you found a solution. I guess I was over thinking the request.
PowerShell,3cluv0,ioFAILURE42,1 point,Thu Jul 9 06:23:41 2015 UTC,"i think this is incorrect. It should be     get-aduser -filter * -properties favoritefood | Select Name, Favoritefood | Sort -property favoritefood"
PowerShell,3cluv0,RampageUT,1 point,Fri Jul 10 18:30:29 2015 UTC,Wouldn't that return several unnecessary users? IE users that do not have a value for their favoritefood attribute?
PowerShell,3cluv0,ioFAILURE42,1 point,Fri Jul 10 18:35:13 2015 UTC,"I'll verify at work, but I feel if you wanted to filter users with favorite foods you would have to do isnot null statement."
PowerShell,3clubq,ki01s,3,Wed Jul 8 22:30:27 2015 UTC,"Try defining the properties you want before format-table.  Get-adcomputer computername -properties company | select name,company | format-table  I'm on my phone so forgive errors. Company is not a default value when you call get-adcomputer or QAD either. Add the company attribute via the properties switch to include it as a returned attribute."
PowerShell,3clubq,Viashivan,1 point,Thu Jul 9 00:14:49 2015 UTC,"Awesome, That worked great!!   Thank you very much!"
PowerShell,3ckucu,ExEvolution,5,Wed Jul 8 18:17:52 2015 UTC,"Use the Switch statement: http://ss64.com/ps/switch.html  switch ($cleanup){      ""I"" {""Performing Interacrtive Cleanup""; break}      ""S"" {""Performing Silent Cleanup (No prompt)""; break}      default {""Unrecognized Input""; $cleanup = """"; break} }"
PowerShell,3ckucu,Gojs2015,1 point,Wed Jul 8 18:46:35 2015 UTC,"Thanks, I'll give it a shot."
PowerShell,3ckucu,occamsrzor,1 point,Wed Jul 8 19:26:36 2015 UTC,"Switch case is usually the solution if multiple if/else statements are needed. There is a specific case (no pun intended) when it won't work, but 99% it will."
PowerShell,3ckucu,orcbjork101,2,Fri Jul 10 01:45:51 2015 UTC,you might look at setting this up as a function and add parameters. You can also use verbose tagging to add verbose statements. Sorry I am on mobile and could provide more help later this evening when I get back to my office.
PowerShell,3ckucu,Betterthangoku,1 point,Wed Jul 8 19:47:30 2015 UTC,"Howdy! Is the intention to have the script loop through something multiple times?  Or is this a one and done script (i.e. - User chooses I or S, and script is done once based upon said selection).  And what do you want the script to do after it is complete?"
PowerShell,3ckucu,Betterthangoku,1 point,Wed Jul 8 18:32:03 2015 UTC,"I want them to choose I or S, if they press the wrong letter, I want it to loop that section until they choose a recognized option, after that, it should continue on through the rest of the script which includes functions I have written to calculate free space, display it to the user, and store it to a log file.  More functions will be added as I figure out how to convert them from my old batch script to powershell."
PowerShell,3ckucu,itsonlyabottle,1 point,Wed Jul 8 18:47:37 2015 UTC,"As Gojs2015 mentioned on here, I would lean towards a Switch statement instead.  I normally use a Do... While... if I need the construct to keep repeating.  I would combine the switch statement into an advanced function that uses parameter validation.  With parameter validation you can guarantee that the uses is putting in only the choices you need.    Here is a link to get you started with advanced functions if they are a bit new to you: https://technet.microsoft.com/en-us/magazine/hh360993.aspx"
PowerShell,3ckucu,dogfish182,1 point,Wed Jul 8 18:54:16 2015 UTC,"Here is my full script  # This PowerShell script is designed to do regular maintainance on PennyMac virtual machines # If you encounter any errors, please contact do { Clear-Host ""This PowerShell script is designed to do regular maintainance on PennyMac virtual machines"" ""If you encounter any errors, please contact""  # Set the domain for future reference $domain = ""PNMAC\""  # Prompt for input, loop if answer is not Y ""You will be prompted to enter Administrator credentials"" $localadmin = [System.Security.Principal.WindowsIdentity]::GetCurrent().Name $admincreds = Get-Credential -Credential ""$localadmin""  do { # Store admin username and password $adminuser = $admincreds.UserName $adminpassword = $admincreds.Password $adminpassword  # Collect computer info $computername = Read-Host -Prompt ""Enter the computer name"" $computerinfo = Resolve-DnsName -Name $computername $computerip = $computerinfo.IPAddress  ""`n"" # New Line For Readability ""Computer Name: $computername"" ""IP Address: $computerip"" ""Admin Username: $adminuser""  ""`n"" # New Line For Readability $verifyinfo = Read-Host ""Is this correct? (Y/N)"" } while ($verifyinfo -ne ""Y"")  # Collect info from computer, get active user ""Collecting information from $computername, please wait..."" $domainuser = Get-WmiObject Win32_ComputerSystem -Computer $computername | Select-Object -ExpandProperty Username $shortuser = $domainuser.Trim($domain)  ""Active user on $computername is $shortuser""  # Get the active profile, store local path as administrative share in variable $activeprofile = Get-WmiObject -Class Win32_UserProfile -Computer $computername | Where-Object {$_.Loaded -eq 1 -and $_.Special -eq 0} $profilepath = $activeprofile.LocalPath $profileshare = $profilepath -replace ':', '$'  ""Administrative share of active user is $profileshare""  ""`n"" # New Line For Readability ""Checking Free Space on $computername""  # Report Free Space For Selected computer Before Cleanup And Append The Results To File Get-WmiObject Win32_LogicalDisk -computername $computername | Where-Object { $_.DeviceID -eq 'D:' } | Select-Object @{ Name=""Computer Name""; Expression={ $_.SystemName } }, @{ Name=""Drive""; Expression={ $_.Caption } }, @{ Name=""Free Space (GB)(Before)""; Expression={ [math]::round( $_.FreeSpace / 1GB,2 ) } } | Format-Table -AutoSize | Tee-Object -Append -File .\bottleneckreport.txt  do { $cleanup = Read-Host ""Perform (I)nteractive or (S)ilent cleanup on $computername""  If ($cleanup -eq ""I"")     {         ""Performing Interacrtive Cleanup""         Remove-Item ""$profileshare\AppData\Local\Temp\*""         Remove-Item ""$profileshare\AppData\Local\Microsoft\Windows\Temporary Internet Files\*""      } ElseIf ($cleanup -eq ""S"")     {         ""Performing Silent Cleanup (No prompt)""         Remove-Item ""$profileshare\AppData\Local\Temp\*"" -Recurse         Remove-Item ""$profileshare\AppData\Local\Microsoft\Windows\Temporary Internet Files\*"" -Recurse     } Else     {         ""Unrecognized Input""         $cleanup = """"     } } While ($cleanup -eq """")  # Report Free Space For Selected Computer After Cleanup And Append The Results To File Get-WmiObject Win32_LogicalDisk -computername $computername | Where-Object { $_.DeviceID -eq 'D:' } | Select-Object @{Name=""Computer Name""; Expression={ $_.SystemName } }, @{Name=""Drive""; Expression={ $_.Caption } }, @{Name=""Free Space (GB)(After)""; Expression={ [math]::round($_.FreeSpace / 1GB,2) } } | Format-Table -AutoSize | Tee-Object -Append -File .\bottleneckreport.txt  $rerun = Read-Host ""Run again on a different computer? (Y/N)"" } while ($rerun -eq ""Y"")"
PowerShell,3ckucu,itsonlyabottle,1 point,Wed Jul 8 18:50:33 2015 UTC,"I haven't read your whole script.. but judging from the number of if/ifelse/else statements, I would suggest you use a Switch statement, Just like /r/Gosj2015 recommended.  Here is my interactive friendly script, I wrapped it into a function: BTW, this script will only work on the Powershell.exe shell and not on the ISE console.  I'm a noob, please feel free to correct me.  function set-mode {     write-host """"     write-host ""*****************************************""     write-host """"     write-host "" *Please Make A Selection Below*""     write-host """"     write-host "" Press [i] for Intereractive Cleanup""     write-host "" Press [s] for Silent Cleanup""     write-host """"     write-host ""*****************************************""      $x = $host.ui.RawUI.ReadKey(""NoEcho,IncludeKeydown"")  Switch ($x.character) {     i { write-host ""Selection i: Performing Interactive Cleanup"" }     s { write-host ""Selection s: Performing Silent Cleanup"" }     default { write-host ""Unrecognized Input"" }     } }  set-mode   EDIT: format and typos"
PowerShell,3clm2w,cris9288,2,Wed Jul 8 21:28:20 2015 UTC,"You're missing the Begin{} block.    ### This only gets run one time no matter how many pipeline objects you have Begin {     $cred=Get-Credential -Message ""Password for ""Domain\User"" -UserName user@domain }  ### This gets run for each pipeline object Process {     ### The rest of your processing...     ### i.e. the foreach part }  ### This gets run once after all of the pipeline objects have been handled End {     ### Do cleanup tasks here }"
PowerShell,3clm2w,ryanbrown,1 point,Wed Jul 8 22:03:37 2015 UTC,Thank you! That was exactly what I was missing.
PowerShell,3clm2w,alcaron,1 point,Thu Jul 9 18:46:42 2015 UTC,"You can also speed this up dramatically by adding -AsJob  Then you can do something like:  $running = $false while($running -eq $true){ Get-Job | %{ if($_.State -eq ""Running""){ $running = $true } } Get-Job | Receive-Job   It will run the task asynchronously instead of one at a time and wait for the jobs to finish then spit out the results."
PowerShell,3ckrxm,Shadoroth,2,Wed Jul 8 18:01:30 2015 UTC,"well I'm no expert, but instead of using net use, I would write it something like this:   If (Test-Path C:\pscp.exe){   Write-Output ""PSCP has been found on this system."" } Else {   $cred = Get-Credential   Write-Output ""PSCP is not on this system, copying...""   Copy-Item -Path ""\\192.168.0.6\Software Packages\pscp.exe"" -Destination $Env:HOMEDRIVE -Credential $cred   Write-Output ""Copy Complete!""   Start-Sleep -s 3 }   Also, if you want to pass something to null pipe it to Out-Null like this: get-process | out-null"
PowerShell,3ckrxm,SomnambulicSojourner,1 point,Wed Jul 8 20:29:37 2015 UTC,"I Finally got it working like this:    ###Check to see if the system needs pscp###  If (Test-Path C:\pscp.exe){   Write-Host ""PSCP has been found on this system.""   Sleep 3 }Else{  #Open the connection to the fileshare     Write-Host ""Please enter credentials for Coruscant...""     $cred = get-credential     sleep 1     New-PSDrive -Name CopyRoot -PSProvider Filesystem -Root ""\\192.168.0.6\Software Packages"" -Credential $cred  #Start copying item     Write-Host ""Copying...""     copy-item -Path CopyRoot:\pscp.exe -Destination C:\     Write-Host ""Copy Complete!""     sleep 1  #remove the fileshare     Remove-PSDrive -Name CopyRoot -Force     Sleep 2 }"
PowerShell,3cl60x,joerod,1 point,Wed Jul 8 19:37:17 2015 UTC,"Can you specify what you are looking for. Do you mean like your font, color scheme, etc?  Here are the first 5 lines of my $profile  New-Alias -Name np -Value C:\Windows\notepad.exe $ui = Get-Host $ui.UI.RawUI.BackgroundColor = ""black"" Set-Location C:\ clear   That $ui bit is the important part from a color standpoint, there are a bunch of members.  $ui.UI.RawUI | gm   C:\Windows\System32\WindowsPowerShell\v1.0\Microsoft.PowerShell_profile.ps1  Anything you put in there will be part of the system profile (no matter what user runs powershell) and:  C:\Users<username>\Documents\WindowsPowerShell\Microsoft.PowerShell_profile.ps1  Anything in there (also $profile resolves to that path) will just load when that user launches powershell.  Hope that helps, not sure what aspects ""layout"" covers.  edit: I need some sleep, I am pretty sure you mean under properties, the layout tab, you want to copy that.  Lets say you want to set a standard window size:  $ui = Get-Host $window = $ui.UI.RawUI.WindowSize $window.Height = 60 $ui.UI.RawUI.WindowSize = $window   You can set the buffer the same way, pretty much everything can be set that way."
PowerShell,3cl60x,alcaron,1 point,Thu Jul 9 18:12:18 2015 UTC,also fwiw if you are like me and have your taskbar at the top of the screen and get tired of powershell opening under it a bit I found this post a while ago that is awesome!  https://richardspowershellblog.wordpress.com/2011/07/23/moving-windows/
PowerShell,3cjymg,crapspakkle,4,Wed Jul 8 14:29:47 2015 UTC,Get-Content C:\servers.txt | % { Get-WindowsFeature -ComputerName $_ | Where Installed }
PowerShell,3cjymg,topherrr,1 point,Wed Jul 8 14:52:45 2015 UTC,"This worked perfectly, thanks."
PowerShell,3chk9u,boeprox,2,Tue Jul 7 23:30:38 2015 UTC,"Oh boy...not sure how I feel about that...needs an option to filter for only official...I have a reasonable amount of faith that MS approved stuff is safe, but anything I download that doesn't come from someone affiliated with MS is going to have to be code reviewed before I let it on the network..."
PowerShell,3chk9u,alcaron,7,Wed Jul 8 00:31:58 2015 UTC,"anything I download that doesn't come from someone affiliated with MS is going to have to be code reviewed before I let it on the network...   We wrote Save-Module explicitly for this scenario, and we highly recommend you use it within a sandbox before installing anything in a production environment."
PowerShell,3chk9u,joeyaiello,1 point,Wed Jul 8 01:08:51 2015 UTC,Saving this post for later.
PowerShell,3chk9u,alcaron,4,Wed Jul 8 15:46:25 2015 UTC,"Great stuff!  Trond mentioned this on twitter, would love to see a hook into GitHub to simplify deployments for modules hosted there. Would need to handle cases like 'module at the root of the repo, named after the repo,' 'module in a subfolder of the repository,' and other scenarios.  Looks like it would be reasonably straightforward to encrypt your API key in AppVeyor and deploy to PowerShell Gallery with some logic, but, native integration would be nice : )  Lastly, recall using PSScriptAnalyzer as a gateway was mentioned - have you considered publishing these results for each project, regardless of whether they are used as a gateway?  Cheers!"
PowerShell,3chk9u,ramblingcookiemonste,1 point,Wed Jul 8 01:29:01 2015 UTC,would love to see a hook into GitHub   But...but...TFS...  :)
PowerShell,3chk9u,alcaron,2,Wed Jul 8 15:47:18 2015 UTC,OT: v5 release date soon given Windows 10 is just around the corner?
PowerShell,3chk9u,Swarfega,2,Wed Jul 8 11:07:54 2015 UTC,I would put money on it shipping in the next server release but it's not guaranteed
PowerShell,3chk9u,Already__Taken,2,Wed Jul 8 11:57:03 2015 UTC,"Hehe, hopefully with the client OS.  Presumably they wouldn't ship preview bits of an integral component of the OS.  Unless you mean bits to install on down-level systems. In that case, not sure, you might be right. Hopefully sooner though!"
PowerShell,3chk9u,ramblingcookiemonste,1 point,Wed Jul 8 12:44:28 2015 UTC,"Yeah I mean 5.0 being in the Win10 preview, in my mind, means it's coming out at least for Win10 on July 29th...you'd think if it's ready to go there, then at most a month afterwards for downlevels, at the very least 8.1.  I kind of feel it's more WMF5 waiting for Win10 than it the other way around..."
PowerShell,3chk9u,alcaron,1 point,Wed Jul 8 15:50:16 2015 UTC,Well MS are gearing up to not have to make these distinctions any more. It's been a long time coming now.
PowerShell,3chk9u,Already__Taken,2,Wed Jul 8 17:03:44 2015 UTC,"Yeah I'm very pleased overall with the direction of Win10.  When 8 came out I LOVED the OS, but the pushing of metro on it and Server 2012 were the single biggest ""out of touch"" things I've seen them do, but with 10, while not perfect, I gotta think there are more engineers in charge this time around. I like it.  I've gone through...I guess three Fast ring updates and each one gets noticeably better, and the process is smooth. No complaints here. And the task switcher and vDesktops and multi-monitor awareness...loving it...  I just wonder if WMF5 will ever show up on Server 2008 R2...stupid XenApp means we HAVE to use it but DSC is killing me in very small ways and most of them get a lot better in 5. Will be a sad panda if it doesn't make it to that OS."
PowerShell,3chk9u,alcaron,1 point,Wed Jul 8 17:17:20 2015 UTC,8r2 is still well in active support I should think it will get 5. Ending maintenance support it wouldn't  Big 8 fan all along here too
PowerShell,3chk9u,Already__Taken,2,Wed Jul 8 17:39:42 2015 UTC,I'll just keep using github for my stuff.
PowerShell,3ci7vg,7Script,1 point,Wed Jul 8 02:46:01 2015 UTC,"Oops! I had to post an update to add leading zeros to prevent small numbers from being recognized as all 1's. For example, 255.255.255.7 would be converted to 11111111 11111111 11111111 111 and then return true instead of 11111111 11111111 11111111 00000111, which returns false."
PowerShell,3ci7vg,KevMar,1 point,Wed Jul 8 03:14:54 2015 UTC,"Can you post an example of using the wildcard mask?   It looks like there is a lot of repeated code between the two of them. Can you just have the wildcard validate call the other function after it preps the address?  This looks like it would be puzzle/learning question that could generate a lot of interesting results. Here is one way I would approach this one:  function Validate-SubnetMask     {        param (                [cmdletbinding()]                [string]$Mask        )     $validAddress = $null    if ([System.Net.IPAddress]::TryParse($Mask, [ref]$validAddress))    {          # take 0011111111 and left shift it 8 times         $postfix = 1..8 | %{(255 -shl $_) % 256} | % tostring          $patterns = ""{0}.0.0.0"", ""255.{0}.0.0"",""255.255.{0}.0"",""255.255.255.{0}""         $ValidSubnet = @()          foreach($NetworkClass in $patterns)         {            $ValidSubnet += $postfix | %{ $NetworkClass -f $_}         }          if($ValidSubnet -eq $Mask)         {            Write-Output $true         }               } }   Instead of validating all the bits in the address, this one generates a list of valid subnets. Then checks to see if the mask is in it. For a C# program, you could even consider generating this list once and hard coding into into your source."
PowerShell,3ci484,ShwnStrmn,2,Wed Jul 8 02:15:23 2015 UTC,"If there is content that is dynamically generated, then you need to be pulling the files from the source. Can you get access via FTP?  A better solution is to work on a better process. I have a feeling that devs are pushing updates directly to production. Introducing source control would be a good addition. Changes get checked in with a note about what changed and you have version history built in. Then only update the servers from source.  It may even be fine to add a build process that pushes the content. Then the devs can update production."
PowerShell,3ci484,KevMar,1 point,Wed Jul 8 06:30:13 2015 UTC,The actual issue is an aspx page that always changes the name of a CSS file every time you load the page to prevent it from being cached.   Thank you for your help though.
PowerShell,3ci484,alcaron,2,Wed Jul 8 18:17:52 2015 UTC,"Assuming you don't have any control over these sites or how they create them and you don't have direct access then your best best would be filtering the page through a regex that can strip the CSS chunk out reliably.  Without knowing the page content I couldn't really start to make suggestions on what the regex should look like, but...I mean if you don't care about the CSS changing and the CSS causes a problem in the test you do care about...excising it from the equation seems like the answer..."
PowerShell,3ci484,alcaron,1 point,Wed Jul 8 15:44:07 2015 UTC,"Completely right with the first part. I don't have a choice in any of it.   We are trying to confirm that the website is not going to a malicious website by, if the site changes, emailing the site administrator to confirm the changes. I am downloading the webpage from the address instead of comparing the source files in the event that the DNS record or something changed to a malicious site.  Regex could work, but I have never used it to compare files and I can't really find a place where it would work with the solution I posted.  Thank you for your help."
PowerShell,3ch7e9,IDA_noob,8,Tue Jul 7 21:54:21 2015 UTC,"Use the modulus, u/IDA_noob!"
PowerShell,3ch7e9,Darth_Vaporizer,5,Tue Jul 7 22:18:07 2015 UTC,%  Damn. Thanks.
PowerShell,3ch7e9,Darth_Vaporizer,2,Tue Jul 7 22:35:23 2015 UTC,We were all noobs once!
PowerShell,3ch7e9,GoodShitLollypop,2,Tue Jul 7 22:52:11 2015 UTC,"Ok, now integrate it into a revision :)"
PowerShell,3ch7e9,tehjimmeh,2,Wed Jul 8 03:04:17 2015 UTC,Done.  https://github.com/tylerapplebaum/FizzBuzz/blob/master/FizzBuzz.ps1  :D
PowerShell,3ch7e9,tuvok302,6,Wed Jul 8 14:53:10 2015 UTC,"Wow, of all the fizzbuzz solutions I've seen, this has got to be the most interesting...  Like, it's a horrible, roundabout, and downright weird method of checking for divisibility, but without knowing about using modulus, the fact that you came up with that way of doing it is remarkable. Hat's off."
PowerShell,3ch7e9,alcaron,3,Wed Jul 8 06:46:50 2015 UTC,"Definitely a different way of solving, don't think I've ever heard of anyone checking for a decimal."
PowerShell,3ch7e9,alcaron,2,Wed Jul 8 01:02:25 2015 UTC,"Here is my variant...don't feel like it's anything special, nothing clever I could think of to shorten it more...though I feel like I'm missing an obvious trick.  1..100 | %{ if($_%15 -eq 0){ ""FizzBuzz: $_""}elseif($_%3 -eq 0){ ""Fizz: $_""}elseif($_%5 -eq 0){ ""Buzz: $_"" } }"
PowerShell,3ch7e9,alcaron,0,Wed Jul 8 15:13:13 2015 UTC,"btw if memory serves you can shorten that first % comparison to a single one no matter what the combination of numbers is, you just need to take the smallest number that they are both divisible by and make it that. For instance the smallest number that is divisible by both 3 and 5 is 15, you may be tempted to say ""oh multiply the numbers"" but that wont work across the board.  For instance with 6 and 8 you need 24, 4 and 6 you need 12. I'm not big enough into math to know but you may be able to set it up so where if the two numbers divided by two is a whole number that is your smallest number...  Well, it's ten minutes later...ran a few permutations and as it turns out if one number is odd then the common factor is a*b if they are both even then it is a times b divided by 2 so if you wanted to be able to pump just about any two numbers into there...  function FizzBuzz ([int32]$first,[int32]$second,[int32]$top){     if($first%2 -eq 1 -or $second%2 -eq 1) {         if($first -gt $second){ if($first%$second -eq 0){ $factor = $first }else{ if($second%$first -eq 0){ $factor = $second } } }     }else{         if($first -gt $second){ if($first%$second -eq 0){ $factor = $first }else{ if($second%$first -eq 0){ $factor = $second } } }     }     1..$top | %{ if($_%$factor -eq 0){ ""FizzBuzz: $_""}elseif($_%$first -eq 0){ ""Fizz: $_""}elseif($_%$second -eq 0){ ""Buzz: $_"" } } }  FizzBuzz 90 30 600   ...anyone else bored? lol"
PowerShell,3ch7e9,FlippityFlip,1 point,Wed Jul 8 19:23:03 2015 UTC,"function FizzBuzz ([int32]$first,[int32]$second,[int32]$top){     if($first%2 -eq 1 -or $second%2 -eq 1) {         if($first -gt $second){ if($first%$second -eq 0){ $factor = $first }else{ if($second%$first -eq 0){ $factor = $second } } }     }else{         if($first -gt $second) {             if($first%$second -eq 0){ $factor = $first }else{ $factor = $first*$second/2 }         }else{             if($second%$first -eq 0){ $factor = $second }else{ $factor = $first*$second/2 }         }     }     1..$top | %{ if($_%$factor -eq 0){ ""FizzBuzz: $_""}elseif($_%$first -eq 0){ ""Fizz: $_""}elseif($_%$second -eq 0){ ""Buzz: $_"" } } }  FizzBuzz 12 6 200"
PowerShell,3ch7e9,FlippityFlip,2,Wed Jul 8 19:36:09 2015 UTC,What I came up with:   1..100 | ForEach-Object {     switch ($_)     {         {(($_/3) -is [int]) -and (($_/5) -is [int])}         {             'FizzBuzz'             break         }         {($_/3) -is [int]}         {             'Fizz'             break         }         {($_/5) -is [int]}         {             'Buzz'             break         }         Default         {             $_             break         }     } }   EDIT: Switch had conditions in the wrong order and needed some break action
PowerShell,3ch7e9,zenmaster24,1 point,Wed Jul 8 19:33:42 2015 UTC,Nice!   EDIT: Doesn't work. Your conditions are in the wrong order.
PowerShell,3ch7e9,alcaron,1 point,Wed Jul 8 19:56:11 2015 UTC,I noticed that just now and came back to edit!
PowerShell,3ch7e9,zenmaster24,1 point,Thu Jul 9 13:55:59 2015 UTC,Good save :)
PowerShell,3ch7e9,alcaron,1 point,Fri Jul 10 00:20:50 2015 UTC,"curious if people use if/elseif,switch,foreach, do/while? who prefers something like  $i = 0 do{     $i++;         if($i%15 -eq 0){""fizzbuzz""}         elseif($i%5 -eq 0){""buzz""}         elseif($i%3 -eq 0){""fizz""}         else {$i} } while ($i -lt 100)   over something like   1..100|foreach {switch ($_){{$_%15 -eq 0}{""fizzbuzz""};{$_%5 -eq 0}{""buzz""};{$_%3 -eq 0}{""fizz""};default {$_}}}   personally i think the first one is more readable, but some people got for code length rather than clarity."
PowerShell,3cfdt8,bobdle,4,Tue Jul 7 14:08:56 2015 UTC,"The ""drawing board"" just got a bit larger. Awesome share."
PowerShell,3cfdt8,itsteve,3,Tue Jul 7 14:21:49 2015 UTC,"Thanks for sharing!  There are so many interesting tools out there, can be quite hard to keep up with the best of these, let alone the concepts underneath them (messaging, in this case). My favorite part of the job though, love to learn and play with new stuff : )  Cheers!"
PowerShell,3cgh6f,IANALAMA,1 point,Tue Jul 7 18:50:30 2015 UTC,"I don't have any recommendations beyond f5 devcentral, but I can tell you that it is pretty well documented once you're there and there are forums with lots of Q&A and activity.   Enabling/Disabling nodes, pools, pool members etc.. are all pretty straightforward once you're connected."
PowerShell,3cgh6f,kittH,1 point,Tue Jul 7 20:32:20 2015 UTC,"Excellent news, hopefully i get logged in soon so i can get started! looking forward to lightening my workload of the approx 16 hours it takes to patch all of these servers every month"
PowerShell,3cf2ix,DrHardNuts,3,Tue Jul 7 12:22:57 2015 UTC,"I used it to migrate a bunch of dns zones over to 2012r2 servers in seconds vs several days it would have taken before to do it by hand.  Making an ad global catalog server is much faster now too,   testing the results by using power shell with get-ad* helped a ton in automation.    In v5 there are so many new features I'm not even sure what it is missing yet.  Deploying hyper v is simple,  setting up dns servers and file servers are simple.  If something missing, I guessa robocopy replacement for faster file migrations."
PowerShell,3cf2ix,lostmojo,3,Tue Jul 7 13:52:44 2015 UTC,"As /u/lostmojo has stated, DNS is now a dream. I migrated (copied) zones and records from a remote 2003 server (hundreds of the damn things) to a 2012 server and put in conditional forwarders on the old server within minutes.   Last I checked, DHCP migration is still more reliable with netsh (even then, exports have to be local - which is a pain) - might check to see if its better now.   You can now move the FSMO roles with powershell as well I believe - although I've not done that.  For file transferral, we've recently been implementing BITS policies to take advantage of start-bitstransfer and not flood our WAN links - which is always a good thing.   And the good ole favourite of DSC."
PowerShell,3cf2ix,allywilson,1 point,Tue Jul 7 17:30:38 2015 UTC,"I found this particular article which seems like it would work great for decommissioning the old dhcp server. http://jackstromberg.com/2013/10/migrate-dhcp-role-from-server-2008-r2-to-server-2012-r2/  I have reviewed some of the DSC abilities, it might just be me but I am having a hard time getting my head around it."
PowerShell,3cf2ix,allywilson,2,Tue Jul 7 21:21:25 2015 UTC,"Good find, I'll give that a go (my situation in the last couple of months has been from 2003R2 to 2008R2+ so not had a chance for the DHCP stuff).  I had a hard time with DSC as well. I decided to approach it role by role. Focussed on my domain controllers, then my file and print servers, then web servers, then SQL, etc.   So I approached it with the idea of 1 configuration file that ensures the bare-minimum to run a domain controller. And I used a pull server scenario, just so I could change it in the future (my test app was telnet-client install/removal).   Then I kinda moved on to the 3 party apps requirements I have, and as long as they are MSI, or EXE's that take arguments, for installation, then it was a bit of a breeze.   Have a look here."
PowerShell,3cf2ix,lostmojo,2,Tue Jul 7 22:11:32 2015 UTC,"With regards to DSC I am in the same boat, but from what I understand with it so far it could potentially be very helpful.  I am curious about it on clients as well, it seems like in a fairly locked down environment that dsc on win 10 would be very useful."
PowerShell,3cf2ix,Caseycrowe,2,Thu Jul 9 05:38:09 2015 UTC,*premesis. :)
PowerShell,3cf2ix,Waxmaker,3,Tue Jul 7 14:19:46 2015 UTC,"That particular battle is long lost, I'm afraid."
PowerShell,3cgecl,evetsleep,1 point,Tue Jul 7 18:31:00 2015 UTC,If it's a multi-valued property why are you turning it into a string?  When I leave it as an array it works just fine.  $groupOne = Get-ADGroup -Identity groupOne -Properties multiProp Set-ADgroup -Identity groupTwo -Replace @{multiProp=$groupOne.multiProp}
PowerShell,3cf8pl,zonfired,2,Tue Jul 7 13:24:04 2015 UTC,"fwiw in powershell it would have been this:  foreach($file in (gci ""C:\scripts\test"")) {     $from = $file.BaseName     $to = $file.BaseName.Substring($file.BaseName.Length-3)     Move-Item -Path $file.FullName -Destination ($file.FullName.Replace($from, $to)) }"
PowerShell,3cf8pl,alcaron,1 point,Tue Jul 7 14:33:12 2015 UTC,Thank you
PowerShell,3cfyma,anmghstnet,2,Tue Jul 7 16:43:30 2015 UTC,"Get-DistributionGroup | Select Name,DisplayName,GroupType,PrimarySmtpAddress,{$_.ManagedBy}"
PowerShell,3cfyma,RickSaysMeh,1 point,Tue Jul 7 16:54:25 2015 UTC,"Get-DistributionGroup | Select Name,DisplayName,GroupType,PrimarySmtpAddress,{$_.ManagedBy}   Hey Rick, Thanks for replying, I appreciate it. If I make the change you suggested it actually outputs ALL the distribution lists on the server, not just the ones owned by the specified user. Any suggestions?"
PowerShell,3cfyma,RickSaysMeh,1 point,Tue Jul 7 17:13:22 2015 UTC,"$Users = Get-Content c:\temp\dlowner.txt  ForEach($User in $Users) { Get-DistributionGroup -ManagedBy $User | Select Name,DisplayName,GroupType,PrimarySmtpAddress,{$_.ManagedBy} }    It won't display the user name from the input file, but it displays all managers, so I figure that's probably fine. Plus, you should be able to output to a CSV easily if desired.  If you REALLY want the user name from the input file to show up in the results as a field, just add this to the beginning of the select statement:  {$User},"
PowerShell,3cfv3w,small_horse,1 point,Tue Jul 7 16:19:16 2015 UTC,"If you attempt to read a directory you don't have permission to, you're going to throw an UnauthorizedAccessException. So TRY this:  Get-ChildItem -Directory -Recurse | ` ForEach-Object {try {Get-Acl} catch {}} | ` Where-Object {$_.Access.IsInherited -eq $false} | ` Select-Object -Property Path -ExpandProperty Access | ` Export-Csv C:\temp\inherit.csv   You're just catching the exception and doing nothing in those cases.  edit: formatting"
PowerShell,3cfv3w,zaboobity,1 point,Tue Jul 7 21:13:40 2015 UTC,"I'm nigh positive that try/catch isn't doing anything because the error isn't terminating.  That's kind of the problems with it in the pipeline/working with cmdlets, in your own loop you can just continue, but if you do something like gci and one out of twenty fails and you want to handle that error you are kind of screwed, only choice really is to roll it up into -ErrorVariable and deal with the aggregate.  Also the simple solution here is just -ErrorAction SilentlyContinue, if you know you don't care about the errors...just suppress them...  Haven't been able to look at it long enough but while this runs all day in the ISE (doesn't give a super useful path though) it creates a blank file when running the same code in a script...very strange..."
PowerShell,3cfv3w,alcaron,1 point,Wed Jul 8 15:58:30 2015 UTC,"But the error is terminating in OPs original code (at least it does when I run it).  The -ErrorAction cmdlet param only works for non-terminating errors, so using that param won't continue after the terminating  UnauthorizedAccessException I get with the original one-liner.  Anyway, this was a simple attempt to solve OPs question using their current code, and changing it in as minimal a way as possible. But I didn't test with the -Recurse param last night. And it doesn't even appear to work in my test folder now... Hmm. Not sure what I was doing last night.  Anyways, the code below seems to do the trick, and includes a better path, and doesn't terminate but still shows errors (use -ErrorAction as noted earlier to suppress).  Get-ChildItem -Directory -Recurse | ` ForEach-Object { $path = $_.Fullname; Get-Acl -Path $_.Fullname | ` ForEach-Object { $_.Access | Where-Object { $_.IsInherited -eq $false } | ` Add-Member -MemberType NoteProperty -Name ""Path"" -Value $path -Passthru }} | ` Export-Csv -NoTypeInformation -Path inherited.csv   So it appears that using Get-Acl with no params throws a terminating exception, but providing Get-Acl a -Path throws non-terminating exceptions. Hmm...  Yeah - just tested this small modification to the original code, and this doesn't terminate:  dir -Directory -recurse | % {Get-ACL $_} | Where{$_.Access.IsInherited -eq $false} | Select-Object path -ExpandProperty Access | Export-Csv inherit.csv   BTW, I'm only using Console, so not sure of any behavior diffs between the ISE."
PowerShell,3cfv3w,zaboobity,2,Wed Jul 8 21:03:47 2015 UTC,"not sure of any behavior diffs between the ISE.   The fact that there are any is a constant source of consternation for me... :(   The -ErrorAction cmdlet param only works for non-terminating errors, so using that param won't continue after the terminating UnauthorizedAccessException I get with the original one-liner.   The entire point of -ErrorAction is to control what happens with an error, unless you flat out break powershell then -ErrorAction will turn a terminating error into non terminating (in the case of Ignore, Continue, SilentlyContinue) or from non terminating to terminating. It will suppress anything but fatal errors.  The problem with the main example is he just pipes gci to Get-Acl when it really needs to be something like  gci ""C:\"" -ErrorActin SilentlyContinue |%{ Get-Acl -ErrorAction SilentlyContinue}   So in the OP's code it's passing the entirety of the directory listing to Get-Acl which just breaks it, bad, so even continuing on isn't really an option, especially given that what is next doesn't work either.  Though it is always possible in the infinite consistency that is powershell the specific type of error when get-acl tries to perform an unauthorized action you cannot suppress it, that has the whiff of ""security"" about it.  So I guess -ErrorAction supresses when it does, but not when it doesn't...lol...eiter way in the instance where it works as intended it shoud absolutely control terminating vs. non-terminating response to errors."
PowerShell,3ccdts,RickSaysMeh,5,Mon Jul 6 20:33:16 2015 UTC,"Can you try it to: Get-Mailbox | Get-MailboxPermission | Where { $.IsInherited -eq $False } | Select Identity,User,{$.AccessRights},Deny | Export-Csv C:\export.csv From here it advises so since it is an array: https://social.technet.microsoft.com/Forums/exchange/en-US/c788c2fb-5180-47e9-86c5-7ec131d48b5a/export-mailbox-permissions-to-csv?forum=exchange2010"
PowerShell,3ccdts,Frequentsy,2,Mon Jul 6 20:42:27 2015 UTC,That worked! Thanks.
PowerShell,3caksw,ramblingcookiemonste,4,Mon Jul 6 12:03:19 2015 UTC,That's a busy month for you!  What have I been doing. This last Month I have:   Been continuing my Learn PowerShell series on YouTube/Blog http://flynnbundy.com/. Made a way to watch TV via PowerShell https://github.com/bundyfx/PowerShell/blob/master/BountyBox Participated in the One Liner Contest (HappySysadm) Write up on the July PowerShell.org first puzzle. Implemented DSC (pull) in a production environment. learnt tons from some of the best in the business.   Its been a busy one!
PowerShell,3caksw,bundyfx,1 point,Mon Jul 6 12:28:53 2015 UTC,btw @ramblingcookiemonste looking forward to your presentation on version control. if only my boss would watch it!
PowerShell,3caksw,bundyfx,4,Mon Jul 6 21:51:55 2015 UTC,"Currently, we have applications written like 5 years ago in Python and C++, not documented, and kind of treated as black boxes that just do what we need. Well, they broke. And I'm not a programmer, so I decided to convert all of these tasks to PowerShell since ... why wouldn't they be in PowerShell, they handle Windows- and AD-specific tasks. They:   Pull lists of new hires Add needed AD info (OU, groups, shares, etc) Generate a random, complex initial password Create the accounts Generate a new file detailing the new account info Scan for accounts older than X days, disable it, move it to a staging OU Then delete after Y more days   We can then schedule these items to work each day in the wee hours of the morning, so when new hires show up or quit (we have a ton of staff turnover), it handles it and records it.   It's nothing crazy, but it was a fun little assignment."
PowerShell,3caksw,Starscream918,3,Mon Jul 6 17:00:06 2015 UTC,Just wrote a script to grab a lot of server information across our environment and hardware. It puts it all into a CSV for all servers and sets up a scheduled task to run at 04:xx with the minute it runs being a random time so that our server information is always up to date.  Eventually this information will be going to a database but this is stage 1.  I'll be putting it onto github in the next few days if anyone is interested.
PowerShell,3caksw,Theratchetnclank,1 point,Mon Jul 6 16:57:06 2015 UTC,Why the random minute? I don't understand.
PowerShell,3caksw,thatfatpolishdude,1 point,Mon Jul 6 20:24:58 2015 UTC,"One to stop file locking on the CSV from all kicking off at the same time, and two to not cause any CPU spikes on the hypervisor hosts when 300 machines start doing it all at once, I don't expect it to but its easy to mitigate just in case."
PowerShell,3caksw,Theratchetnclank,2,Mon Jul 6 20:37:41 2015 UTC,"So if I'm reading it right, you have 300 machines writing to the same file? Seems like it would be better to run whatever command it is with -ComputerName from a central location, if it's supported.  If that's not an option, then I would have all machines write to a file, such as $serverName.csv. Then combine those into one larger file."
PowerShell,3caksw,aaron416,1 point,Tue Jul 7 01:12:59 2015 UTC,Correct. The computername parameter isnt supported on many of things I'm doing unfortunately. I might end up changing to your method though I'll see how it goes. The script auto updates itself anyway so easy enough to push changes to the machines.
PowerShell,3caksw,Theratchetnclank,1 point,Tue Jul 7 06:16:33 2015 UTC,"I have done this but for 600+ servers and i'm having each go thru it's events looking for certain ones and then export them to a CSv locally then the central server gathers then all locally to itself, reads in each and builds a master CSV for it then emails it out.  nothing is left behind file wise.  It does this nightly, and using runspaces only takes about 20 mins to complete on 17+ years old servers."
PowerShell,3caksw,wigrif,3,Tue Jul 7 23:38:20 2015 UTC,"This one : https://www.reddit.com/r/PowerShell/comments/3c0vbe/powershell_reveal_windows_memory_credentials/  Also, I worked on a Active Directory auditing script."
PowerShell,3caksw,BelgiumSysAdmin,3,Mon Jul 6 17:10:09 2015 UTC,"Made a function with POSH-SSH to fetch the mac of a device connected to a specific port on a Cisco switch.   With this I made a GUI with Powershell Studio that decreased prestage times of new computers significantly.  The process now when you setup a new computer is:   Unbox it. Tag the computer. Plug it in. Scan Tag. (Barcode) Scan S/N. (Barcode) Fetches the mac automatically and prestages it in SpecOps.   And then plug it in on the other bench and push F12.  It ads it to inventory automatically and does other things that we had to do manually before.  The summer-intern pre staged and installed 70PC's in no time with this tool so now I can take my 3 weeks of without feeling stressed out over that he may not handle it :)  Smaller stuff I did:   Standardized the folder structure of our scripts. Realized that WMI is more powerful then i thought... I also created some easy tripwire-scripts all over the network that monitors AD-groups etc. Bugfixes in our big toolbox-gui (Powershell Studio)   Also I documented everything, as always :)  Edit: Formatting."
PowerShell,3caksw,VapingSwede,2,Mon Jul 6 18:28:51 2015 UTC,"Using the Running Config and Flogi DB (via SNMP) from our SAN Switches, I created a step by step script that will generate zoning configurations between any host and target storage (including VSAN/Fabric info)"
PowerShell,3caksw,Vortex100,2,Mon Jul 6 16:46:53 2015 UTC,"I wrote a script to migrate a given ESX cluster off the Cisco 1000v virtual switch and onto the VMware Distributed Switch (functionally equivalent, but superior). This was all thanks to PowerCLI support on top of PowerShell.  Even better, I found a way to make it have zero impact on virtual machines, so it's much easier for me to schedule when this is going to happen.  Perhaps the best part of this whole thing is it taught me how to use commands to be far more efficient than I intended originally. For example, use the MigrateVM_Task() method rather than get-vm -location $sourceHost | move-vm $destinationHost. When it comes to reconfiguring the VMs, group them by network interface and reconfigure them all at the same time, rather than one by one.  Overall time saved on the NIC reconfiguration alone was something crazy like 90%."
PowerShell,3caksw,aaron416,2,Tue Jul 7 01:27:04 2015 UTC,"I have just begun dabbling in power shell. I am trying to find ways to not only improve my work (help desk) but also as a way to fill downtime.  I haven't done anything as intense as I see on this sub, but I did make a few scripts this month all by myself!    AD Account Lookup - This allows me look up user accounts from AD and view all the information that is important to me (last set password, account enabled, etc) This has made my life so much easier. I love using this script instead of finding accounts in the AD snap in. AD Asset Lookup - A simple little script that takes in a machines asset number (This is also the last half of the host name)and pulls up the machine account in AD.  Restart Computer - This was actually the first script I wrote. I work at a state college and have to restart the computers in the open lab each morning. Writing a script to remotely restart these machines has cut 15 minutes from my morning, and made me fall in love with powershell!    I can't wait to see what else you guys have done. Although I don't have an opportunity to implement some of the more advanced scripts that I see around here, I really enjoy seeing some of the creativity."
PowerShell,3caksw,parad0xy,2,Mon Jul 6 16:05:40 2015 UTC,I would like to know what your AD account lookup script looks like.
PowerShell,3caksw,DanielG2112,1 point,Mon Jul 6 22:06:17 2015 UTC,I will toss it up tomorrow when I get to work.
PowerShell,3caksw,parad0xy,1 point,Mon Jul 6 22:07:34 2015 UTC,"I imagine it's something like this?  param(       $username,       $password ) get-aduser $username -properties passwordlastset,enabled,lockedout,lockouttime,lastbadpasswordattempt   Wrap it in a function if you like so you can add it into a module."
PowerShell,3caksw,Theratchetnclank,1 point,Tue Jul 7 11:58:42 2015 UTC,"$user = Read-Host 'Enter Account' Get-ADUser -Identity $user -Properties CN,Created,Displayname,Employeetype,Employeeid,extensionattribute2,lastlogon,memberof,mail,passwordlastset,whenchanged,whencreated  pause"
PowerShell,3caksw,parad0xy,2,Tue Jul 7 14:07:38 2015 UTC,"AD Account Lookup - This allows me look up user accounts from AD and view all the information that is important to me (last set password, account enabled, etc) This has made my life so much easier. I love using this script instead of finding accounts in the AD snap in.   I'm in a similar position and made a function like that as well (though not this month).  I use that function all day long.  This function was also my introduction to using the [adsiSearcher] type accelerator because the server admins shut down Active Directory Web Services."
PowerShell,3caksw,dorath,1 point,Tue Jul 7 01:56:34 2015 UTC,"They know this is kinda required for loads of things now? PowerShell, Exchange, ADAC? Etc"
PowerShell,3caksw,graemejevans,1 point,Sun Jul 12 11:02:31 2015 UTC,"Not done yet, but I'm making a script to email all of our ~2000 Office 365 users(split into roughly 70 Office 365 accounts)when their password is within 7 days of expiring.  Still working out how I want to store credentials for all these accounts."
PowerShell,3caksw,blckpythn,1 point,Mon Jul 6 15:31:57 2015 UTC,"Put my first official production script running (basic file cleanup and email report).  Other than that, I haven't had time to touch as much PowerShell since I've been tasked with picking apart my undocumented environment."
PowerShell,3caksw,c0mpyg33k,1 point,Mon Jul 6 15:46:28 2015 UTC,Still in testing / proof of concept phase but:  I wrote a script that pulls in a list of servers and critical services for each out of an ini file and the systematically restarts them. Once the server is back up the script checks to see if those critical services are back up and running within a specific timeline. If they do not start I get an email detailing which server failed and what services.   We are a smaller shop ~20 servers so this is intended to work with our WSUS server in keeping our systems patched automatically.
PowerShell,3caksw,S133P3R13,1 point,Mon Jul 6 15:56:01 2015 UTC,"So for my second script ever... I made a program that recreates a USER share folder structure from one server to another using makedir.  The script then places a DOCUMENTS folder in the newly created folder.  Next the script uses CACLS to automatically set the correct permissions on the newly created folder.   The folders are named after the AD username so this is what gets passed to CACLS.  In the end, each user has modify permissions on their documents folder.    The script then uses robocopy to copy the files from the source directory to newly created DOCUMENTS destination directory.  Not all users started with a source DOCUMENTS folder so there is some logic there.  After the robocopy completes the script goes out to ADUC and sets the user HOMEDIRECTORY to  the new path.  Each division has a different share so more logic.  Finally, I baked in a front end for my help desk staff to use.  At present, the user registry keys will point at the old server and share.  The PowerShell front end I gave to my staff allows them to query the remote registry keys for 10 specific values and automatically change the keys to the correct values.    I used remote REG.exe /add commands through invoke-command for the registry side of things.  The only trick is to grab the user SID and passing that to the remote registry... because the keys I need are in HKU.  You can change registry values for one single user or pull an OU from AD and do an entire division.  Along with the ten different keys and values I'm passing the computer name, SID, new server name and division to the invoke-command.  The only caveat is the user must be logged onto the machine.  Instead of my staff having to navigate to and then carefully type the correct path for each entry inside of regedit they can run this portion of the script and be done with it.  It's gone from what should be a 15 minutes fix to a 1 minute fix.  In fact, talking with the users is what's taking the most time.  With Powershell I am saving my staff a ton of headache and saving the company a lot of man hours.   I've also added into this script the ability to get the current logged on user or reboot one or more machines based off of OU structure.  Staff can also pull serial numbers if wanted and I'm looking to add some more features.  Right now the program is a while loop that my staff can just leave running until the choose to exit.  They can navigate menu structures, etc...  With the menus and what not I'm at about 1100 lines of code.  I think I can probably shorten it some if I could get the hang of objects.  I would love to make my division menu structure an object to just be called whenever.    I made this script to assist me with the migration of several TB worth of user files with a user base of approximately 700 users.  I am upgrading our file server from 2003 to 2012 with a cut over date of Monday, 7/13/15.  I'm going to make it.  Tanks Powershell!!!"
PowerShell,3caksw,s3xynanigoat,1 point,Mon Jul 6 17:35:21 2015 UTC,You should really look at using dfs namespaces for your shares. It will make migration a lot easier in the future.
PowerShell,3caksw,Theratchetnclank,1 point,Tue Jul 7 06:30:34 2015 UTC,"Wrote a script to create a report of Critical and Warning level VMware datastore utilizations for a VDI infrastructure (there are different thresholds for different types of datastores). Nothing fancy, it's just the company won't buy a proper SCOM management pack for VSphere and VCOps (managed by someone else) does not display this data in an way that would help operators to easily log incidents for these threshold breaches."
PowerShell,3caksw,marcabru,2,Mon Jul 6 18:07:13 2015 UTC,Take a look at vCheck - does loads of these actions and more! :)
PowerShell,3caksw,graemejevans,1 point,Sun Jul 12 11:04:21 2015 UTC,"I'll check it out, thanks."
PowerShell,3caksw,marcabru,1 point,Mon Jul 13 15:34:47 2015 UTC,Do you have anything that compares the VMWare datastore LUN size vs vmdk (and white size inside the vmdk) ?
PowerShell,3caksw,dangermouze,1 point,Mon Jul 6 23:06:05 2015 UTC,"Not really. It was nothing more than a report with utlization percentages (free space / datastore size), something that should come out of the monitoring (designed and implemented by someone else) but it does not. I use powershell because it produces easily formattable results as opposed to some graphical (Web/Flash/Silverlight based) tools we are instructed to use by clueless managers and higher tier engineers who don't give a fuck."
PowerShell,3caksw,marcabru,1 point,Tue Jul 7 18:06:12 2015 UTC,Still working on changing the source location for each driver in our SCCM environment.
PowerShell,3caksw,RParkerMU,1 point,Mon Jul 6 18:14:13 2015 UTC,Wrote a script to automatically mount & connect new iSCSI volumes on our Dell EqualLogic to all our Hyper-V hosts.  Still need to finish it to create the CSVs and rename it so it fits our naming schemes.
PowerShell,3caksw,FrenchFry77400,1 point,Mon Jul 6 18:32:40 2015 UTC,-Done three o365 cutover migrations with three lines of code. -Created first dsc pull server -Continue to learn powershell
PowerShell,3caksw,Rostropovitch,1 point,Mon Jul 6 19:01:06 2015 UTC,"Working (and finishing up) on a Scheduled Task creation script for Event ID monitors.  There are no really good ways using the built-in cmdlets to do this.  The alternatives are either to use schtasks.exe or a .Net implementation, which I opted for the latter.  Essentially, you give it a series of parameters:   Computer name(s) Log name to check Source Event ID/InstanceID Command Command Arguments   The script is intended to provide a quick way of setting up a task that is triggered on an event ID and execute a program of your choosing against a list of servers.  I'll share it here in the group when finished."
PowerShell,3caksw,maximillianx,1 point,Mon Jul 6 22:12:07 2015 UTC,I put everything into source control with Team Foundation Server and tested out Visual Studio 2015.  Also made a ton of syntactical and readability adjustments based on what I read in Code Complete 2nd Edition.
PowerShell,3caksw,labmansteve,1 point,Mon Jul 6 22:49:20 2015 UTC,I wrote an advanced function (Invoke-Shutdown) that utilizes the Win32ShutdownTracker method of the Win32_OperatingSystem WMI class to initiate a shutdown request on a remote host.  I made a big effort to add comment-based help and to add some error handling to my function.  Invoke-Shutdown
PowerShell,3caksw,ryanbrown,1 point,Tue Jul 7 20:37:12 2015 UTC,"Over the last few weeks I've laid the ground work internally, with management buy-in, to be more productive and scientific regarding how PowerShell projects are getting approved, implemented, measured, and maintained.   Our first project, with our new controls in place, is a full internal workflow, w/ dept. responsibilities, to keep our RMM in sync with every client AD environment (Are we accounting all production devices? What old devices can we purge from AD and the RMM?). The script itself does a diff between environments (RMM and AD) , and the output kicks off an internal process, where Operations generates tickets for Helpdesk, who review the device in question and either onboard (missing device) or purge (old device). We're measuring ticket hours worked and elapsed open time.  The best part about all this? For the first time we're making PowerShell a priority. This gives me time to focus on this stuff, without getting pulled into 100 directions. It's clear what our projects are. Its clear what work I have on my plate. And, we're releasing scripts that have measurable business value with management visibility.   More to come!"
PowerShell,3cc80y,mycall,3,Mon Jul 6 19:54:08 2015 UTC,"I can't find any way of doing it with .NET that doesn't involve P/Invoke - you probably don't want to go down that route in PowerShell.  However, this is one of those rare occasions where the classic FileSystemObject from Windows Script Host can help you out - it has a ShortPath property of the object emitted from GetFolder() which is what you're looking for.  $fso = New-Object -comobject ""scripting.filesystemobject"" $shortpaths = @(); foreach ($path in $env:Path.Split("";"")) {     $shortpaths += $fso.GetFolder($path).ShortPath; } $shortpaths -join "";"";"
PowerShell,3cc80y,alinroc,1 point,Mon Jul 6 20:44:33 2015 UTC,Thank you.  This shrunk my path from 4895 to 2057 in length.
PowerShell,3cc80y,KevMar,1 point,Mon Jul 6 21:25:32 2015 UTC,"You will also need to make sure 8.3 names are enabled on the system hosting the file. I don't know when they started disabling that by default, but I know Server 2012/Windows 8 disabled it.  And if you have to enable it after the fact, you will need to generate them on the filesystem.  Edit: are you sure you need the 8.3 names?"
PowerShell,3cc80y,Deathonus,1 point,Mon Jul 6 20:55:38 2015 UTC,I do as my path occasionally disappears since it is so long.  I guess I'm a power user with my 50+ applications installed.
PowerShell,3cbipl,campfire,4,Mon Jul 6 16:56:53 2015 UTC,"Seems to me like you have two primary things to deal with.  The first being permissions, you don't want to copy everyones data out to the network with any old person who knows the path able to see it.  The second being user mapping.  So lets assume the data is all under c:\users, that is simple enough. And you may luck out and if this is a domain environement, try running something like the following on a couple machines:  robocopy <C:\users\blah\foo\wherever> \server\backupshare /MIR /SEC  Assuming the permissions all copy over just fine then you should be able to do something along the lines of:  $folderlist = @(""Favorites"",""Links"",""Downloads"")  foreach($profile in (Get-ChildItem -Path C:\Users -Exclude @(""ADMI*"",""Public""))) {     $user = ($user = ($profile.FullName).Split(""\""))[$user.Count-1]     foreach($folder in $folderlist) {         $command = (""& robocopy C:\Users\{0}\{1}     \\server\backupshare\{0}\{1} /MIR /SEC"" -f $user,$folder)         $test = [scriptblock]::Create($command)         #Invoke-Command -ScriptBlock $test         $test.ToString()     } }   Hope that gets you started..."
PowerShell,3cbipl,alcaron,2,Mon Jul 6 18:37:37 2015 UTC,"Thanks the info and script, I appreciate it."
PowerShell,3cbipl,Swarfega,3,Tue Jul 7 12:26:20 2015 UTC,Can't you enable roaming profiles or better folder redirection instead?
PowerShell,3cbipl,alcaron,3,Mon Jul 6 17:05:22 2015 UTC,"If they are only doing this for a subset of machines that could be a problem, depending on what they want backed up that could be a problem (not everything is going to go under their profile), depending on what software they use that could be a problem.  Folder redirection is likely going to be a bigger project than just migrating the user data."
PowerShell,3cbipl,alcaron,1 point,Mon Jul 6 18:39:19 2015 UTC,Folder redirection is a good moving forward solution.  I build fresh GPOs for every OS release and that is a good time to add a feature like this without that feature creating a lot of extra work.
PowerShell,3cbipl,shitty_admin,1 point,Tue Jul 7 13:36:54 2015 UTC,Without knowing their environment I could not say if I agree with that or not.
PowerShell,3c934q,DevilDriving,12,Mon Jul 6 01:17:05 2015 UTC,"I work in a large (2 million) user organisation, we build roughly 200 (virtual) servers per day for various business units and so on. I have used PowerShell (and orchestrator) to tie in a complete build of  server OS all based on a few key pieces of information pulled directly from SharePoint. The process encapsulates SCCM also for the deployment of the OS but each step along the way is mostly all underpinned and held together with PowerShell. Currently I am working on the process for the complete end to end automation of SQL servers and their configuration with all information being taken from SharePoint. This sort of process allows for the specific area to just fill in their basic information (Server name/instance/DB name/OS choice/SQL flavour) then the rest is handled by PowerShell/SCCM/Orchestrator."
PowerShell,3c934q,bundyfx,2,Mon Jul 6 02:14:31 2015 UTC,"That sounds incredible, I'm in a 300 user environment myself."
PowerShell,3c934q,SemiSecure,6,Mon Jul 6 02:22:12 2015 UTC,As I sit here with my 50 local and 100 remote users.  I feel so insignificant.
PowerShell,3c934q,VelociraptorLlama,12,Mon Jul 6 06:15:27 2015 UTC,you are probably more significant to the users than this guy with 2M users :)
PowerShell,3c934q,WeDoTheWeirdStuff,1 point,Mon Jul 6 08:48:24 2015 UTC,Can you share any of that?
PowerShell,3c934q,bundyfx,3,Mon Jul 6 02:49:49 2015 UTC,"Sorry, Not any details of the content itself.  However my experience on working with a user base this large (10,000 Servers - 2 mil users) is that Automation is not simply a ""would be nice"" its essential to business. One of the things to know and constantly think about it reducing the amount of moving parts in your scripts. The more dynamic parts of a long script you have the more change for error there is. it's more about concatenating a lot of smaller scripts and actions to achieve well designed fault tolerable automation process."
PowerShell,3c934q,SteveMI,2,Mon Jul 6 03:03:25 2015 UTC,"Can you ballpark your salary, years of experience, certs?"
PowerShell,3c934q,alcaron,0,Mon Jul 6 12:30:30 2015 UTC,"fwiw I do something VERY similar and the fun thing about IT is...I technically never finished 4th grade, have zero certs and over a decade of experience (usually the most important part).  I was private school honor roll K-3 and then my genius parents thought they would homeschool me which turned out to mean ""go outside, take a book if you feel like it"", never even got a GED and...um, well, salary is...hmmm, I'll say 6 figures. Though honestly the place you are and the systems you work on can make that vary, get into something niche but vital and you wouldn't be shocked to find yourself making $250k, just be a really good engineer and you are probably going to be $100k or damned close for your starting.  Part of the country REALLY matters too, for availability AND salary range. $100k in Iowa -ne $100k in CA. :)"
PowerShell,3c934q,seanconnery84,2,Mon Jul 6 17:29:23 2015 UTC,100k in Iowa you live like a king!  100k in CA you live in a box?
PowerShell,3c934q,alcaron,0,Mon Jul 6 21:03:27 2015 UTC,And that box is probably a sublet run by a slum lord...
PowerShell,3c934q,Keninishna,0,Mon Jul 6 22:27:39 2015 UTC,lol at never passing 4th grade.
PowerShell,3c934q,alcaron,1 point,Fri Jul 17 18:42:58 2015 UTC,I bet I make more money than you jerkoff. :)
PowerShell,3c934q,Keninishna,1 point,Fri Jul 17 19:08:36 2015 UTC,"Haha probably, I too found that school isn't all that important in the IT field, skills are what matter the most. I'm still struggling to break 6 figures tho although I have no degree."
PowerShell,3c934q,upward_bound,12,Fri Jul 17 19:23:29 2015 UTC,If only they would give me the time to automate my job :P.  Every time I sit down to write a script I get interrupted.
PowerShell,3c934q,alinroc,6,Mon Jul 6 01:31:09 2015 UTC,"Sorry boss, got no time to sharpen the axe - too many trees to cut down!"
PowerShell,3c934q,ioFAILURE42,2,Mon Jul 6 12:54:05 2015 UTC,I feel your pain. I wish they would give me two weeks that I can dedicate to nothing but automation/scripting. We can only dream...
PowerShell,3c934q,ramblingcookiemonste,1 point,Mon Jul 6 05:37:15 2015 UTC,"It doesn't take that much of an investment. Here are some tips, you should use all three : )   Get a formal resource. A book ideally. Videos and trying by yourself are important, but on their own they will leave you in the dark about many things. Spend a few minutes a day using PowerShell. Not hours, unless you have them: minutes. You're not going to learn if you aren't using it on a regular basis. ""I don't have time,"" usually means ""I don't want to learn."" Hear it all the time from our click-next-admins. Join the community. It's a great way to learn and get more ideas on how you can use PowerShell.   My first job in IT-proper was deskside support in late 2010. First used PowerShell ~2012. Spent a few minutes a day using it. Soon I was saving enough time to spend more time learning it and using it. Now, most of my day involves PowerShell : )  Good luck!"
PowerShell,3c934q,upward_bound,2,Mon Jul 6 11:30:09 2015 UTC,"I already know how to write scripts!  I even studied PowerShell on my own time.  I said exactly what I meant!  Most times I sit down to write a script I get interrupted, so I just put it off until later.  The nature of my job (front side support) is that my job is to be interrupted.  The stuff I want to write scripts for are occasional tasks and some warning stuff to help with more root cause analysis.  Why is everyone assuming that I'm lazy :P."
PowerShell,3c934q,evetsleep,2,Mon Jul 6 13:00:03 2015 UTC,"I often find myself coding during slow times .. or even on my personal time.  That's certainly not a popular thing though...but I have a serious problem with automating things...in that I must automate as much as possible...which pays off in giving me time to do other things.  What's even better is that I've automated things so that others don't have to bother ME with things..again..freeing up more time.  I have a custom PowerShell framework I wrote that my company uses where ~200 IT admins use it daily....in this framework lots of things are scripted which means not only am I bothered less...but so are my peers.  So there are trade-offs but if your problem is constant context switching (interruptions), then you might want to consider picking up an off-hours hobby that starts with a P and ends with Shell.  If I were you I'd look for things that take up the most time and start with those first.  Those kinds of projects pay off big time which really open up the door for other things."
PowerShell,3c934q,runnystool,1 point,Mon Jul 6 20:14:38 2015 UTC,"Nobody is going to ""give you the time."" You just simply do it in a way that doesn't impact your existing deliverables.   Spend some small amount of time per day, say 30 minutes, working on automation. Time box it so that it doesn't eat into your deliverables (so nobody notices). At the end of your allotted time, go back to the manual way and brute force your way through the work. After a week, you'll have enough pieces automated that the script will buy you enough time that you can spend even more time on automation. It won't take too long before you're free!"
PowerShell,3c934q,matholio,0,Mon Jul 6 15:08:11 2015 UTC,"Invest your personal time, in your personal development.   I know that might sound trite but automating away repetitive tasks, will provide more time for new learning."
PowerShell,3c934q,upward_bound,2,Mon Jul 6 03:22:04 2015 UTC,"Oh I spend a significant amount of my personal time on personal development (certs, classes, etc).    I try not to spend personal time on work development though!"
PowerShell,3c934q,matholio,2,Mon Jul 6 10:52:15 2015 UTC,"Another approach is to identify the repetitive tasks, that are very simple one-liners.   Apply some self discipline, and forbid yourself to use the old way.    Looking up a users group membership  Rebooting a remote computer  Restarting a service"
PowerShell,3c934q,matholio,0,Mon Jul 6 13:43:07 2015 UTC,"It's been quite a few years since I was in your position, but I never minded giving my personal time for development work.  It's fun, and it helps form useful patterns of thinking.  Each to their own.  :)"
PowerShell,3c934q,upward_bound,2,Mon Jul 6 13:38:36 2015 UTC,"It's a mechanism I developed to stop myself from burning out.  I love playing around with computers, scripting, and digging in deep.  If I don't set boundaries then I'll spend hours at home doing the same thing.  Not really a big deal in the short term.  A few extra hours here and there are really a drop in the bucket.  Long term is where the problems come in.  Your workload becomes the new normal, they give you a few more assignments and wonder why your other tasks aren't going as well.  You start resenting that they don't notice your 'extra' work.  All of that is solved by having a stricter separation between my time and work time.  So I still play with computers and develop myself, but they are personal projects.  Sometimes those personal projects involve things that could be helpful at work, but they are never specifically work related (ie. I'm not writing an automation script at home, but I may investigate new technologies that weren't brought to me by the boss).  This works really well for me.  The only problems I have had are that a few bosses seem really put off that I push back when they try to stretch me.  I'm a very fast worker and I get things turned around quick which has helped me have a foundation from which to do the pushing.  At the end of the day though...you're right.  To each their own!"
PowerShell,3c934q,alcaron,1 point,Mon Jul 6 14:21:42 2015 UTC,"A few extra hours here and there are really a drop in the bucket.   Indeed, and a company that doesn't wrap its head around the idea of investing it's time in productivity reclamation isn't going to have any of their problems solved with any sane amount of your personal time invested in it. It needs to be ""the new normal"". People need to understand that when things change they never do so overnight, and while you wait for that paradigm to shift you may not see great rewards."
PowerShell,3c934q,alcaron,1 point,Mon Jul 6 17:35:13 2015 UTC,"What did the joker say again? If you're good at something, never do it for free. Good advice if you ask me. :)  Business is business, if it is valuable to them they should pay for it. Too many people give their time with far less consideration than the average company considers their expenditure of money, especially with regards to labor costs."
PowerShell,3c934q,evetsleep,1 point,Mon Jul 6 17:32:49 2015 UTC,"That's one way of looking at it.  Another way is that if it's a new venture (breaking new ground that you're unfamiliar with) then you benefit just as much (if not more) that your employer by working on an automation project in you own time (plus you set your own schedule here.....as in no deadlines).  I've been in IT for over 20 years now (working with PowerShell since it was in beta) and I have co-works who are 9-5 people and that's perfectly ok, but you want to take a guess how much further I've climbed in the IT world than they have because I've invested in self-improvement in this area?  In some cases I know for a fact I'm making double what they are.  It's giving it away for free if you know how to solve a problem and don't need to learn how (there we agree).  But there is value in investing personal time if you benefit in the end.  I know I have."
PowerShell,3c934q,alcaron,1 point,Mon Jul 6 20:22:58 2015 UTC,"If it is brand new to you then sure, I've done that. If we put those modifiers on there then absolutely. If it's something you don't already know how to do, want to learn it, and it will benefit you to know it. Absolutely.  But I consider that pretty different from just ""giving personal time to development work"".  I don't disagree at ALL with the idea of personal development, I don't think that development in any way shape or form NEEDS to overlap with what would come in handy at your job though.  I don't really know of anyone who has progressed, myself included, very far in IT without spending a lot of their off time learning.  But again, first and foremost it needs to be beneficial to you, you need to have a plan of what you want to do and what you want to learn, and if you find places where that overlaps with what your job needs, absolutely, go for it. But I would never let what my work could benefit from dictate what I pursued in my off hours."
PowerShell,3c934q,matholio,1 point,Mon Jul 6 20:57:21 2015 UTC,That depends on ones motivations.  Some people crave new knowledge and skills above money.
PowerShell,3c934q,alcaron,1 point,Tue Jul 7 08:15:47 2015 UTC,"Absolutely, and as long as what works for your employer also interests you, I would never suggest NOT doing something because your employer might gain for ""free"". I just would never suggest, as a rule, that people let their employers needs dictate what they learn is all."
PowerShell,3c934q,BelgiumSysAdmin,6,Tue Jul 7 14:36:29 2015 UTC,Think about all the tasks that you repeat several times.  Then automates them.
PowerShell,3c934q,DrTrunks,1 point,Mon Jul 6 01:20:31 2015 UTC,"Just looking for some personal examples, I always like hearing them."
PowerShell,3c934q,ramblingcookiemonste,1 point,Mon Jul 6 01:31:34 2015 UTC,"If a certain service fails with a certain Event Viewer ID, just restart it automatically..."
PowerShell,3c934q,evetsleep,4,Mon Jul 6 08:15:32 2015 UTC,"Ed, 'The Scripting Guy,' recently wrote about newcomer's perception of PowerShell. Don't start thinking automation. Start thinking 'save time', 'improve consistency and reliability', 'delegate tasks', and some of the other benefits that come from scripting itself.  Also, consider tooling, before you consider automation; it's a bit of a pre-requisite. Many folks mix up tooling and automation. Start building re-usable tools. Invoke-Ping is an example I often give. You can compare it a bit to legos. You might start with a single brick or premade piece, work directly from instructions, but eventually you can build your own solutions out of these blocks. I started with Test-Connect, paired it up with Invoke-Parallel, glued on Test-Server, and now I can quickly check connectivity (ICMP, Remote Registry, RPC, etc.).  When you first start, don't try to bite off too much, it can get overwhelming. Be sure to borrow from others, no shame in that. But do try to learn from them. Don't just use their functions or modules, take a peak under the hood and see how things work, try adding a feature you need or fixing a bug.  Hopefully you see some actual answers here. The monthly 'What have you done with PowerShell' posts usually have some interesting ideas. Some examples on my side:   Module to populate a home grown alert dashboard Module and scheduled tasks to populate a home grown systems inventory DB (servers, SQL instances, scheduled tasks, disks, etc.) Home grown module of functions targetted towards our environment Home grown server deployment system (ASP.NET/C#, PowerShell, MDT, vCenter). Delegated, constrained solution to allow help desk access to re-migrate passwords using ADMT, without the requisite privileges A variety of tools published on GitHub and TechNet gallery   Good luck!"
PowerShell,3c934q,kanehbosm,5,Mon Jul 6 11:56:32 2015 UTC,"So I just did a quick look in my library and I've determined that I'm a sick...sick engineer.  I've had 3-4 laptops since I started writing PowerShell stuff..so not all of my stuff has survived data ports, but over the past 10 years I've written 2,120 scripts and modules (so about 256 a year on average) that I still hold on to.  What have I automated?  I guess for me the question is what haven't I automated (well attempted to)?  Really I'm a toolmaker above all else (see the post by /u/ramblingcookiemonste that explains the difference).  In retrospect I'm starting to feel like a real-world Geppetto.  I'd say 80% of my projects are tools.  Anything that really makes it into the automation realm for me are larger projects since I work for a really big company.  For example, I recently completed code on an automation process which deals with inactive accounts in Active Directory.  Now you'll see all kinds of ways of doing this and in small\medium environments will show this as being pretty straight forward.  Unfortunately for me I don't work in one of those shops and this took 6 months of solid development time to do everything the business required (get those requirements up front folks...seriously).  Another example would be a simple process that looks for users that changed their password in the last hour.  When found I send them an SMS message informing them that their password was changed and to update it on their mobile phones, tablets, etc..  This actually saved our bacon once when one of our upstream systems that integrates with Active Directory started changing all of the user passwords due to a bug in someones script.  It was doing in in alphabetical order so it got to the D's before we got it stopped.  Without my notification process (which lit up the the phone lines at our help desk) it probably would have gotten to the Z's before anyone noticed and it would have been a really bad nightmare for all involved.  As for tools, I recently posted a sanitized version of a script I wrote a long time ago to return group memberships...even if paging is required (AD will only return a certain amount and stop unless you ask nicely).  When I started working with Monad (i.e. PowerShell) I was an Exchange guy in the Exchange 2007 beta.  It was more or less love at first sight for me.  I've turned it into a nice gig to where it's pretty much all I do these days (all internal projects though..one day I might entertain being a hired gun again).  Each new version of PowerShell has introduced new ways to write tools and to automate things.  When I learned I did it the hard way...there were no fancy books out there at the time and the help files...try as they may..were not as nice as the ones we have now.  I mentioned it earlier in another post, but if you're really looking for areas of improvement\automation\tool-making I'd recommend logging things you do on a regular basis...maybe a pseudo-journal.  After a few weeks review it and see if there is anything in there that takes up a lot of your time that you think might be something that PowerShell can help with..and then start whacking away at it.  I'm kind of a lurker here, but there are a LOT of really great people here who go above and beyond to help people.  If you get stuck or need ideas drop the subreddit a line...I bet you'll get something useful."
PowerShell,3c934q,evetsleep,2,Tue Jul 7 01:09:30 2015 UTC,"Damn another amazing post with very impressive work. I hope to get this good someday. So far all I've done is automatically reboot a few servers, and I export Exchange distro groups to a spreadsheet haha. Time to hit the books!"
PowerShell,3c934q,kanehbosm,1 point,Tue Jul 7 01:20:25 2015 UTC,Awesome ideas! Do you have any pointers for creating the script to SMS users who have just changed their password?
PowerShell,3c934q,AaronKClark,1 point,Tue Jul 21 14:10:13 2015 UTC,Well in my case we have an internal SMS system where I can send an e-mail message to it and it'll convert that into an SMS and send it along (it already knows the recipients mobile number based off the e-mail address).  So you'd  need a way to send SMS messages via SMTP really to get started.
PowerShell,3c934q,Espio,1 point,Tue Jul 21 17:56:59 2015 UTC,"Easy to do via email from exchange to the cell carrier where I'm located.  10digit-phone-number@msg.telus.com.  I'd likely need to test pulling cell number from their AD account and adding everything after the @, but it'd be neat tool to create."
PowerShell,3c934q,ramblingcookiemonste,3,Tue Jul 21 18:11:19 2015 UTC,"Every month the system architect takes backups of the production databases for each client (CompanyA.bak, CompanyB.bak, CompanyC.bak) etc.  He restores them to the corresponding Databases on the beta server, and puts them in an FTP Directory for us to be able to download.  I made a PowerShell Script that uses the WinSCP.net dll to download the databases and then restore them to my local SQL Server so I didn't have to do it manually each month.   The hardest part was figuring out the TLS options with WinSCP like the following;  # Setup session options $sessionOptions = New-Object WinSCP.SessionOptions $sessionOptions.Protocol = [WinSCP.Protocol]::Ftp $sessionOptions.FtpMode = 'Passive' $sessionOptions.FtpSecure = 'ExplicitTls' $sessionOptions.PortNumber = '21' $sessionOptions.HostName = $TMFTPHost $sessionOptions.UserName = $TMFTPUser $sessionOptions.Password = $TMFTPPassword $sessionOptions.SslHostCertificateFingerprint = $TMFingerprint"
PowerShell,3c934q,dogfish182,3,Mon Jul 6 02:57:55 2015 UTC,"Can DSC be used in a Workstation Scenario, for settings and features ETC"
PowerShell,3c934q,Espio,2,Mon Jul 6 03:24:13 2015 UTC,"Yes. But it runs in the local system context, not as the user.  I've tested it through a Citrix NetScaler, allowing configuration beyond our network boundary.  Quite cool. But... running as local system leaves it a bit limited for end user config, and most resources out there are designed for the server side.  Cheers!"
PowerShell,3c934q,alcaron,-2,Mon Jul 6 10:26:59 2015 UTC,"sadly no, however, i'm not 100% sure about win10 or what the strategy is there. DSC is still very new."
PowerShell,3c934q,dogfish182,1 point,Mon Jul 6 09:14:43 2015 UTC,"I read the first line from a dsc 3 part spesh a while back, and I was all like ermhagawd"
PowerShell,3c934q,alcaron,0,Mon Jul 6 09:26:45 2015 UTC,"I don't agree with this at all, it wont work if what you want to do is modify things in HKCU, their profile, etc, but that doesn't mean DSC isn't useful for workstations, not by a long shot.  Like everything it depends on how well you know DSC and don't try to use it to do things it isn't well suited to do.  You may be using SCCM and think why bother with DSC, well, a DSC config is a lot easier to manage ""at a glance"" than SCCM because there is no easy way of looking at SCCM and saying ""this is what happens to a machine"", you have to follow the breadcrumbs a fair amount. For light, system level changes, DSC is a VERY good options with a LOT less bulk."
PowerShell,3c934q,t0xie,1 point,Mon Jul 6 17:50:55 2015 UTC,"huh, I must have got bad info from somewhere. I thought DSC wasn't useable on 7/8.1 at all. my bad! I'm only looking at it on the server side at the moment."
PowerShell,3c934q,ioFAILURE42,0,Tue Jul 7 16:16:08 2015 UTC,"I believe it is available to any system with WMF4, I know I used it on 8/8.1 can't really say if I used it on 7, I think I have a 7 VM with WMF4 on it, lemme check...  Shit it's 3.0...4.5.1 is installed though so one second...  Yup cmdlets are there and working in Win 7 SP1 x86."
PowerShell,3c934q,seanconnery84,2,Tue Jul 7 16:52:48 2015 UTC,"I've automated lots of things, but the one that has had the biggest impact has been automating our snapshot handling in vCenter. Every day at 6am a snapshot cleanup script runs and any snap more than 3 days old is deleted. This has been a lifesaver. We had snaps over a year old when I started.  Having this automation in place allowed us to avoid disk space outages and let more people take their own snapshots. We're finally implementing hypervisor based backups, so this automation will probably be retired this year, but it's had a good run."
PowerShell,3c934q,ioFAILURE42,2,Mon Jul 6 03:56:47 2015 UTC,"Onboarding and offboarding of users. Tickets are generated by HR, which are collected by a report in our ticketing system twice a day. It spits out a CSV with the pertinent details (manager name, title, department, email address, username, etc), and 5 minutes later another automated task scans the output and performs the tasks in AD."
PowerShell,3c934q,dogfish182,1 point,Mon Jul 6 05:35:32 2015 UTC,I'm really close to having this setup for myself.  Any gotchas you come across that could be handy to know?
PowerShell,3c934q,theb1g,1 point,Mon Jul 6 21:08:34 2015 UTC,"The trickiest part is probably figuring out how to write to multi valued strings. If you have specific questions,  fire away. Or make a post on it. I'm sure there are others here who could come up with other creative ways to accomplish this."
PowerShell,3c934q,dogfish182,2,Thu Jul 9 06:25:54 2015 UTC,"since you mentioned that you are a newbie, start by banning yourself from the GUI. 'automate' password changes etc by doing it all via the shell. It won't actually save you any time (in fact in the start it will take longer) but repetition of commands and there structure will take a lot of time.   for example, I 'learned' how to filter AD, but it took quite a while before I could bang out the syntax   get-aduser | where {$_.name -like 'bob*'}   out of my head without having to look at red text. Powershells a lot like that, you can learn, but then it really has to go click.  I had learned it theoretically before I really understood it. This is probably a horrible description.   as for examples new starter procedure. probably the HR people have software right? that probably runs reports, capable of generating csv output most likely... Im currently looking at generating a 'all new starters in last 2 hours' report every 2 hours, running a scheduled powershell task that will do auto user creation (in a disabled state) and mail the helpdesk with an output of all groups (based of dept) that the new user is in. Helpdesk could then requested the required approvals, quality control the account as needed, then enable. saves a lot of time.   I'm going to attempt my first VMWare deployment using powercli to build a server in vmware this week   DSC, I'm going to make a strong push for a the the business. If I never have to install a ups agent manually ever again, it will be too soon."
PowerShell,3c934q,evetsleep,1 point,Mon Jul 6 09:12:08 2015 UTC,Get-aduser has a -filter option why would you pipe it into where?
PowerShell,3c934q,dogfish182,1 point,Mon Jul 6 11:52:27 2015 UTC,"because I didn't know that when I started, however the general | where   syntax was just an example I was trying to pick to show how something that's quite easy and logical requires repetition to get down (or at least did in my case).  but yes OP, use -filter instead of piping output to | where for get-aduser :D"
PowerShell,3c934q,alcaron,1 point,Mon Jul 6 16:43:42 2015 UTC,"This is a very common thing...people who use both the AD and the Exchange cmdlets commonly do this.  Yes it's bad form and not nice at all to your domain controllers, but it's such a common misunderstanding that I can forgive anyone who does it...once or twice :)"
PowerShell,3c934q,thebeersgoodnbelgium,1 point,Tue Jul 7 01:21:49 2015 UTC,"yeah, the AD cmdlets are... weird. I was first exposed to powershell via exchange migrations, so when the knowlege transfers flawlessly and 'works' well then.   was discussing with a colleague today actually.  I have to say the AD cmdlets are.... weird. you can really tell a diff team coded them. I'm actually running through the virtual academy stuff for AD powershell now and doing some dcpromo stuff tommorrow as well with powershell.  gotta say, start-transcript/stop-transcript is a GODSEND if you live in the misery of a SOX controlled company :)"
PowerShell,3c934q,bobdle,1 point,Tue Jul 7 16:14:10 2015 UTC,Not that it was in his example but wildcard searching on DistinguishedName comes to mind.
PowerShell,3c934q,sgnewman,2,Mon Jul 6 17:55:07 2015 UTC,"Migrating Databases between SQL Server instances Migrating Logins between SQL Server instances Actually, just a whole lot of migrations Recover sysadmin passwords on SQL Calculate SQL max memory and set it Count duplicates in a CSV file Import a CSV file to wherever Export vCenter structure to an RDG xml for remote admin Ported one of my favorite Unix commands (locate) to Windows   You can also look through Microsoft Script Center for PowerShell scripts to see what things have been done in PowerShell. One of my favorite authors is Boe Prox."
PowerShell,3c934q,bobdle,2,Mon Jul 6 10:53:36 2015 UTC,"Can you share some bits on your ""calc sql max memory and set it"" ? I was recently looking on how to accomplish this but came up empty handed. I could not find a way to set that option."
PowerShell,3c934q,sgnewman,3,Mon Jul 6 17:24:35 2015 UTC,"Knocked this up right quick.  Wish it was just as easy as setting it directly via the properties...but hey, what do i know.  ;)  Import-Module SqlPS -DisableNameChecking cls  try{  $srv = New-Object Microsoft.SqlServer.Management.Smo.Server 'YourSqlServerName' $srv.Configuration.MaxServerMemory.ConfigValue = 2000 $srv.Alter();  } catch{     $_ | fl -Force }"
PowerShell,3c934q,thebeersgoodnbelgium,2,Tue Jul 7 01:12:36 2015 UTC,Will play with that tomorrow. Thanks!   What formula/standard did you use to set max memory? Just take all memory and minus 2GB for Windows OS ?
PowerShell,3c934q,bobdle,3,Tue Jul 7 02:56:57 2015 UTC,"I didn't use a formula, I just threw a number in there.  It's really going to depend on your environment and how much memory the box has.  If it's a small vm with 4 GB memory, I just leave it at it's max and let windows and sql server fight it out.  If it's a massive server, I usually leave 5-8 GB.  If it's a cluster, you have to leave 5-8GB free for windows, then divide the ram in half so if both sql servers are running on the same node they won't contend for ram....etc....etc....  You see how much this can vary from environment to environment."
PowerShell,3c934q,thebeersgoodnbelgium,2,Tue Jul 7 21:20:42 2015 UTC,"I actually wrote a formal script for this and released it on Script Center. You can find it here: SqlMaxMemory.psm1  It uses Jonathan Kehayias's formula for determining default max memory. Get-SqlMaxMemory displays a SQL Server's:  total memory, currently configured SQL max memory, and the calculated SQL max memory recommendation.  Set-SqlMaxMemory sets SQL Server max memory then displays information relating to SQL Server Max Memory configuration settings.  You can run it against one or many servers.  sgnewman I also used Configuration.MaxServerMemory.ConfigValue :) I just put a bunch of stuff around it, but that's the meat."
PowerShell,3c934q,Blu3f1r3,1 point,Tue Jul 7 08:44:24 2015 UTC,Fantastic. Thanks for the detailed response!
PowerShell,3c934q,Vortex100,2,Tue Jul 7 12:25:33 2015 UTC,Happy to help!
PowerShell,3c934q,alcaron,1 point,Tue Jul 7 17:56:14 2015 UTC,"My company hosts applications for businesses across numerous virtual servers and normally we use Royal TS or VMWare to check them. However, this can be time consuming when I need to check 10+ servers for a particular user. To help, I have been developing functions and scripts to automate the most common cleanup tasks encountered. These include deleting corrupt folders, restarting services, and my favorite, searching for and removing stuck file handles."
PowerShell,3c934q,dogfish182,1 point,Mon Jul 6 03:37:45 2015 UTC,"Sometimes it's not just about the automation of tasks, it's the automation of routines you yourself do every day. I have a module called 'Grep' where I created regexable searches:   Find-InAD  Find-InDNS Find-IPMan (our IP management) Find-InAssetTracking (...) Find-InScheduler (Enterprise task scheduler) Find-InDFS   Some of these (like the AD one) I use on a daily basis, and they save me a huge amount of time.   NB. 'Find' was used as it's an approved verb - I actually alias them to be 'Grep-AD' and use those..."
PowerShell,3c934q,alcaron,0,Mon Jul 6 11:50:22 2015 UTC,"Automated the provisioned server image build process, use DSC to configure as many servers as we can, just the other week when the flash bug was discovered we updated it with powershell on the 150 legacy servers.  Basically wrote a script that would start the uninstall of the old and install of the new as background jobs, wait for them to complete, then spit out the results to a log file.  For perspective the last time we did that the other admin used a batch file with psexec and it took him about 3 hours to run it all asynchronously, and it took less than 4 minutes for my script to report every single server had successfully uninstalled and reinstalled.  I actually wrote a script to handle tasks against the common server clusters, it reads an XML so you pass it the name of a group of servers, say for instance ""legacy"" and a scriptblock and it will Invoke-Command -ComputerName -Credential $creds -Authentication Credssp -ScriptBlock $code -AsJob | Receiver-Job -Keep  And then monitor for the jobs to show completed, then spit out the results from each one. Has options to use remoting to enable CredSSP or bypass CredSSP if the server doesn't support it, will let you pipe in a string or a codeblock, a few other things, nothing super complicated but it goes to the core of your question. Running those jobs isn't hard, but even the automation can be automated to some extent, when you know what the variables are.  So whether it be the 8 staging or 150 legacy servers running a command on all of them is a very simple task.  ExecBlock -Target legacy -CodeBlock ""Get-Process outlook | Stop-Process""  Boom, bobs your uncle.  Almost everyone I know who tries to get into powershell has the same problem. ""It's easier and faster to just do it the way I know how.""  Which it totally true at first. At first it WILL NOT save you time for the majority of stuff you do. But a) this is where things are going, in ten years I don't know how much of a place there will be for engineers in MS environments that don't know PowerShell with some proficiency and b) when it starts being the kind of thing you can just DO...look out. It wont even just be a matter of speed, it will be a matter of power, what you can do, what you can extrapolate from your machines gets VERY interesting.  I have a beta version of a script that watches the Citrix servers for key signs of problems and tries to predict which ones will fail. i.e. when x+y+z occur this server is likely in a bad way, I try to compare that to the help desk tickets (when they actually bother to log which server the user was on) and see, at that time, what did the script think the odds were that this server was having a problem.  If/when I get it good enough it will start being proactive, forcing the server full and then when it empties, reboot it and re-enable it (the joys of provisioned servers).  Sorry for the wall of text..."
PowerShell,3c934q,GoodShitLollypop,1 point,Mon Jul 6 17:23:38 2015 UTC,would you care to share that citrix script? we're looking to revamp our servers in a big way with 7.6 now and that stuff sounds ideal..
PowerShell,3caehp,biggestluxplayseu,1 point,Mon Jul 6 10:40:15 2015 UTC,Boe Prox (/u/boeprox) wrote a function to get local users here. You could use that and just pipe in a list of computers.
PowerShell,3caehp,SeanQuinlan,1 point,Mon Jul 6 12:29:33 2015 UTC,"If all you're after is local users then you could do something like what I have shown below. However, it does require PSRemoting to be enabled on the workstation you want to query. It can of course be rewritten so as not to require PSRemoting, however, the downside is that it could take significantly longer as you'd probably be moving from a parallel process to a serial process.  If you're looking for local group membership including domain users, you'll need something slightly different for that.  Anyway, enjoy and let me know if you have any questions!  $ComputerName = (get-adcomputer -filter *).Name  Invoke-Command -ComputerName $ComputerName -ScriptBlock{   Add-Type -AssemblyName System.DirectoryServices.AccountManagement   $PrincipalContext = New-Object -TypeName System.DirectoryServices.AccountManagement.PrincipalContext -ArgumentList ([System.DirectoryServices.AccountManagement.ContextType]::Machine, $env:COMPUTERNAME)   $UserPrincipal = New-Object -TypeName System.DirectoryServices.AccountManagement.UserPrincipal -ArgumentList ($PrincipalContext)   $Searcher = New-Object -TypeName System.DirectoryServices.AccountManagement.PrincipalSearcher   $Searcher.QueryFilter = $UserPrincipal   $Searcher.FindAll() |    Select-Object -Property Name, @{     n = 'Username'     e = {       $_.samaccountname     }   }, Enabled, Description, LastPasswordSet, PasswordNeverExpires, PasswordNotRequired } | Select-Object -Property * -ExcludeProperty RunspaceID   EDIT: Modified to query AD for computernames."
PowerShell,3caehp,adrianrodriguez,1 point,Mon Jul 6 12:33:51 2015 UTC,"It's dirty but I wrote it in like 3 minutes so...I'm ok with that.  $computerlist = @(""comp1"",""comp2"") [scriptblock]$block = { foreach($profile in (Get-ChildItem -Path C:\Users -Exclude @(""ADMI*"",""Public""))){ Write-Host ($user = ($profile.FullName).Split(""\""))[$user.Count-1] } } foreach($computer in $computerlist){ Invoke-Command -ScriptBlock $block -ComputerName $computer -AsJob | Receive-Job -Keep }  $running = $true while($running -eq $true) {     $running = $false     Get-Job | %{ if($_.State -eq ""Running""){ $running = $true } } }  Get-Job | Receive-Job"
PowerShell,3caehp,alcaron,1 point,Mon Jul 6 19:07:33 2015 UTC,"are you looking to get all users who have ever logged on to the computer, all users on the computer with active AD user accounts, or all locally created user accounts that exist locally on the computers that are in AD?"
PowerShell,3caehp,Frequentsy,1 point,Tue Jul 7 05:28:02 2015 UTC,local users on each PC. Accounts that don't exist in AD.
PowerShell,3ca2db,AdventL,3,Mon Jul 6 07:36:21 2015 UTC,Scheduled task? Startup Folder (Start - Run - shell:startup)? Run key in registry (HKLM\software\microsoft\windows\currentversion\run)?
PowerShell,3ca2db,SeanQuinlan,1 point,Mon Jul 6 07:58:11 2015 UTC,Thanks! Found it under scheduled tasks :)
PowerShell,3ca2db,Reset_Assured,1 point,Mon Jul 6 09:53:25 2015 UTC,You can delete the script...
PowerShell,3c7o1o,gblansandrock,4,Sun Jul 5 17:42:14 2015 UTC,"Get-ADGroup ""Domain Users"" -Properties member | Select-Object -ExpandProperty member | Get-ADUser   This will also get past the limit, though I'm unsure how it compares from an efficiency standpoint."
PowerShell,3c7o1o,markekraus,2,Sun Jul 5 18:47:48 2015 UTC,That's interesting. I wonder how this gets past the limit?
PowerShell,3c7o1o,evetsleep,3,Sun Jul 5 18:56:01 2015 UTC,"My guess is in how the querying is done.   I believe the 5000 limit is an LDAP limitation. So what Get-ADGroupMember might do is query for all user objects that have the group membership as an attribute, which would be limited by the number of records LDAP can return.   The code /u/gblansandrock posted does this the other way around. It queries for the group object and then expands the member property it as objects.  Since only 1 record is returned by LDAP (the group object) it's not hitting the LDAP limitation."
PowerShell,3c7o1o,ATreePuncher,2,Sun Jul 5 19:21:18 2015 UTC,"I realize it's not a popular thing as the Quest cmdlets, but I've never liked either them nor the AD cmdlets for how I work (so not a knock on who develops them).  A long time ago I wrote my own cmdlet which pulls groups memberships which returns just the DN's because that's all I really need.  It's really not that hard once you learn how Active Directory stores memberships and how it responds once you hit its configured limits to where you need to page them out.  But there is something to be said about re-inventing the wheel where it's not necessary.  So I think it's great of the AD tools or the Quest tools solves a problem for someone to where they don't waste time writing their own."
PowerShell,3c7o1o,evetsleep,1 point,Sun Jul 5 23:35:18 2015 UTC,Cool
PowerShell,3c6pha,agent-squirrel,1 point,Sun Jul 5 10:33:27 2015 UTC,"Yup, the 32-64 bit trap.  Just wait til you need to check for the existence of registry values...  Hint: Test-path can only do keys."
PowerShell,3c600r,Llamathrust,7,Sun Jul 5 03:48:11 2015 UTC,"Yes, you're on your way!   We use Get-ChildItem to gather the contents of folders and files mostly. so that's the first place to start as you would of guessed. There is a switch parameter on Get-Childitem called -File this is basically a filter for the cmdlet that will only select Files rather then gather folders in its collection. Also we specify the -Recurse switch parameter which means essentially translates to (go through all of the below structure folders)  That explains:  Get-ChildItem -recurse -file   After that we use Foreach-Object or its alias % which takes a scriptblock {}  Inside that script block we telling the Foreach-object cmdlet what we want it to do. In this case we want to move all of the files that were gathered by the Get-ChildItem cmdlet and move them up to the root folder (or current working directory).  To do this we will use Move-Item and specify the -Path (from) to be the Fullname ($_.FullName) of each one of the items and -Destination (to) path to move to items to is going to be a single dot . which indicates the current working directory. You could have your destination as your desired path to copy the items to. the . used here is assuming that you are running this code from the directory you wish to copy the contents to.  Get-ChildItem -recurse -file | Foreach-Object {Move-Item -Path $_.FullName -Destination .}   When we say $.FullName we are referring to the Property Fullname of the current item coming across the pipeline. $ meaning the current item and the '.' (dot) meaning we want to select a single property from that item.  If you were wondering what properties were available for a certain cmdlet you can always pipe them to Get-Member (gm) like so:  get-childitem | gm   from here you can see what you can select from.  Hope this helped."
PowerShell,3c600r,bundyfx,3,Sun Jul 5 05:20:32 2015 UTC,"Upvote for you for a fantastic explanation and not just writing the code for him, and upvote for OP for actually trying to get a script going before coming here for help. Gotta love the /r/powershell community!"
PowerShell,3c600r,bandgeekndb,1 point,Sun Jul 5 20:24:14 2015 UTC,This explanation helped me greatly. Thank you for taking the time to write it.
PowerShell,3c600r,crosshairlol,1 point,Sun Jul 5 12:04:41 2015 UTC,"Awesome reply, exactly what I was looking for and you did a great job explaining the steps. Thanks!"
PowerShell,3c600r,samAccountName,3,Mon Jul 6 03:48:39 2015 UTC,Get-ChildItem -recurse -file |%{Move-Item -Path $_.FullName -Destination .}
PowerShell,3c600r,Reset_Assured,5,Sun Jul 5 04:47:06 2015 UTC,% is foreach-object BTW. Took me forever to learn that when I was first starting.
PowerShell,3c600r,whyjfrye,-1,Sun Jul 5 13:12:04 2015 UTC,"Try this:  $folder = Get-ChildItem  ForEach($Item in $folder) { Copy-Item -Path ""$($Item.name)\*"" -Destination "".\"" }"
PowerShell,3c3q5e,boeprox,6,Sat Jul 4 13:56:36 2015 UTC,"Remember:   To participate, add your solution to a public Gist (http://gist.github.com; you’ll need a free GitHub account, which all PowerShellers should have anyway). After creating your public Gist, just copy the URL from your browser window and paste it, by itself, as a comment on the PowerShell.org post, not this Reddit post please.   The Puzzle  Write a one-liner that produces the following output (note that property values will be different from computer to computer; that’s fine).   PSComputerName ServicePackMajorVersion Version· BIOSSerial · · · · · · · · · · · · · · · ·-------------- ----------------------- -------· ---------- · · · · · · · · · · · · · · · ·win81· · · · · · · · · · · · · · · · 0 6.3.9600 VMware-56 4d 09 1 71 dd a9 d0 e6 46 9f   By definition, a one-liner is a single, long command or pipeline that you type, hitting Enter only at the very end. If it wraps to more than one physical line as you’re typing, that’s OK. But, in order to really test your skill with the parser, try to make your one-liner as short as technically possible while still running correctly.  Challenges:  •Try to use no more than one semicolon total in the entire one-liner  •Try not to use ForEach-Object or one of its aliases  •Write the command so that it could target multiple computers (no error handling needed) if desired  •Want to go obscure? Feel free to use aliases and whatever other shortcuts you want to produce a teeny-tiny one-liner.  Good luck everyone!"
PowerShell,3c3q5e,WindosBK,2,Sat Jul 4 14:05:20 2015 UTC,"The sample output is displaying weirdly on powershell.org (and copying it here didn't fix it). I've pasted it here with the line breaks in place, hopefully it comes through properly:  PSComputerName ServicePackMajorVersion Version  BIOSSerial -------------- ----------------------- -------  ---------- win81          0                       6.3.9600 VMware-56 4d 09 1 71 dd a9 d0 e6 46 9f"
PowerShell,3c3q5e,ramblingcookiemonste,2,Sat Jul 4 22:06:56 2015 UTC,"Is the code behind formatting specific to reddit, or a subreddit?  I'm struggling to consider a redeeming factor behind any code block that wraps text. It should really be fixed..."
PowerShell,3c3q5e,WindosBK,1 point,Sun Jul 5 01:01:22 2015 UTC,"I'm not sure, code blocks wrap on /r/usefulscripts too. Also, agreed, to the point where I nearly edited the length of the serial number just so that it wouldn't wrap."
PowerShell,3c3q5e,1RedOne,1 point,Sun Jul 5 01:21:26 2015 UTC,"The source from the puzzle website itself was also really wonkily formatted too, even with the native powershell.org syntax highlighter."
PowerShell,3c3q5e,Vortex100,1 point,Sun Jul 5 01:56:44 2015 UTC,"Heh, not to tough to start with then :)   Gwmi -Cn <PC1>,<PC2>  Win32OperatingSystem | Select P*ME,S*J*N,V*, @{N='BiosSerial';E={(Gwmi -computername $.CSName win32_bios).SerialNumber}}  Edit (a few actually) - Got it down to 131 Characters excluding the Computernames (leaving -cn + spaces though)."
PowerShell,3c3q5e,1RedOne,1 point,Sat Jul 4 20:01:29 2015 UTC,I think my mobile client can't handle the syntax in the second bit.   Would you mind explaining what you're doing in your select statement / calculated property?
PowerShell,3c3q5e,Vortex100,1 point,Sun Jul 5 01:55:18 2015 UTC,Since you mentioned 'calculated property' I'll assume you know what they are - I'm pulling down the bios serial number of the computer using a 'Get-WMIObject' statement + computer name from the previous 'Get-WMIObject' statement
PowerShell,3c3q5e,1RedOne,1 point,Mon Jul 6 09:12:09 2015 UTC,"I think your asterisks in the first bit of the select statement are throwing off Reddit's code highlighting (notice how the rest of your code from there is in italics?), it looked REALLY weird from my phone :)  Thanks for typing it out, here on my desktop, it looks much more like normal PowerShell code."
PowerShell,3c3q5e,1RedOne,2,Mon Jul 6 13:16:58 2015 UTC,"Ohh I like this one. The fun thing is that it's querying multiple WMI classes too. This is really fun!   Alright, I have my solution!   The fun part here was handling two different queries in one pipeline and allowing for multiple computers too. I think my method was pretty elegant!   https://gist.github.com/1RedOne/e2a89f1a2ec5413d2c37"
PowerShell,3c3q5e,bundyfx,1 point,Sat Jul 4 14:55:50 2015 UTC,Good one Stephen. I didn't think of the read-host idea!
PowerShell,3c3q5e,bundyfx,1 point,Sun Jul 5 05:23:12 2015 UTC,I've decided to do a blog post on each of the monthly puzzles and how I went about solving them. Welcome for all to come and discuss. Hopefully some beginners can get something out of my answer to this first puzzle.  http://flynnbundy.com/
PowerShell,3c0vbe,BelgiumSysAdmin,4,Fri Jul 3 19:10:10 2015 UTC,Awesome work. Very impressive.
PowerShell,3c0vbe,GLiMPSEiNATOR,2,Fri Jul 3 19:35:46 2015 UTC,Thanks man :-)
PowerShell,3c0vbe,LunacyNow,2,Fri Jul 3 20:21:09 2015 UTC,Crazy shit... Kudos
PowerShell,3c0vbe,bundyfx,2,Sat Jul 4 01:05:43 2015 UTC,Great work!
PowerShell,3c0vbe,P1nkY-and-Th3Br4in,2,Sat Jul 4 01:32:54 2015 UTC,Good job buddy !
PowerShell,3c0vbe,Stoffel_1982,2,Sat Jul 4 17:08:43 2015 UTC,"Impressive stuff :-)  But we wouldn't expect less, coming from you!"
PowerShell,3c0vbe,work-work-work-work,1 point,Sat Jul 4 19:31:05 2015 UTC,^
PowerShell,3c0vbe,work-work-work-work,2,Sat Jul 4 22:49:07 2015 UTC,"Write-Host -object ((""10½11½13½10½11½11½13½11½1½12½13½11½11½11½19½110½111½111½110½112½11½113½114½115½11½112½114½116½113½115½11½117½118½119½119½116½113½11½120½121½122½10½11½11½01½15½11½17½11½11½11½11½11½11½11½123½118½127½124½118½115½125½115½126½18½128½129½118½116½111½16½130½110½129½10½16½15½11½18½11½17½16½11½10""-split ""½"")-split """"|%{if($-match ""(\d+)*(\d+)""){""$([char][int](""10T32T47T92T95T40T46T41T64T70T111T108T119T116T104T101T105T82T97T98T58T45T41T112T114T107T110T98T103T109T99""-split ""T"")[$matches[2]])""*$matches[1]}})-separator """"   ... woah."
PowerShell,3c0vbe,oddie121,1 point,Sun Jul 5 23:59:24 2015 UTC,The white rabbit :-p
PowerShell,3c0vbe,oddie121,1 point,Mon Jul 6 00:42:29 2015 UTC,"Yeah, that was awesome that's all."
PowerShell,3c0vbe,koltafrickenfer,1 point,Wed Jul 8 04:49:51 2015 UTC,"If modifying the C:\temp directory location in the script, is there any ramifications? Reason being is crypto-locker safe guards seem to be preventing this from runnning in my environment even running as administrator."
PowerShell,3c0vbe,koltafrickenfer,2,Mon Jul 6 14:08:52 2015 UTC,You can change this folder without any problem.
PowerShell,3c0vbe,swiftimundo,1 point,Mon Jul 6 14:16:56 2015 UTC,"Awesome, thank you!"
PowerShell,3c0vbe,Kamsiinov,1 point,Mon Jul 6 14:27:28 2015 UTC,"The fact that so much of this is done in powershell is crazy to me, I hope I can write code like this one day. unfortunately I think I'm going to spend a lot more time studying more complicated languages then powershell to understand this. Awesome work."
PowerShell,3c2h9i,workaloo,3,Sat Jul 4 03:41:27 2015 UTC,"It feels like you could skip a lot of the global variables if you built this in a way that let you pipe into your subfunctions. Also, just nitpicking, but you don't need to query all properties on get-aduser to pipe into set-aduser for those properties. 'get-aduser ""horseguy"" | set-aduser -managedby ""horseguy2"" ' ought to work fine even though managedby isn't a default property."
PowerShell,3c2h9i,SaladProblems,1 point,Sat Jul 4 06:13:09 2015 UTC,thanks. i'll read into piping variables into subfunctions.
PowerShell,3c2h9i,bundyfx,3,Sat Jul 4 16:25:40 2015 UTC,"Going to agree with SaladProblems on the global variables and some of the syntax surround AD queries. however you've done a great job considering you're new to PS!   One thing you will want to get used to doing is using Write-Verbose and Write-Warning in your scripts as opposed to Write-Host where needed. If this is for someone else to pick up and use you may want to think about creating a PowerShell GUI for simplicity sake as opposed to using the Console as a semi-GUI-thing to operate the script.  none the less, keep it up!"
PowerShell,3c2h9i,bundyfx,1 point,Sat Jul 4 12:40:48 2015 UTC,"there seems to be a big push not to use write-host, but i don't fully understand the difference.  i'll read up on the benefit of write-verbose vs write-host. thanks for the suggestions"
PowerShell,3bzyd2,ffmpeguser,5,Fri Jul 3 14:54:28 2015 UTC,"RoboCopy, rather then PowerShell might be the best tool for this. The /MON and /MOT options on RoboCopy might be of interest.  ""/MON:n :: MONitor source; run again when more than n changes seen. /MOT:m :: MOnitor source; run again in m minutes Time, if changed."""
PowerShell,3bzyd2,CrystalnikSpacebro,3,Fri Jul 3 15:11:14 2015 UTC,"Ahh, totally forgot about the monitor function in powershell, that would definitely do it, that with a /mov might be exactly what he needs."
PowerShell,3bzyd2,admin_all_the_things,2,Fri Jul 3 15:21:33 2015 UTC,"So would this be a case of it detecting the presence of a file in the folder being monitored and copying it to the remote drive and then monitoring the folder and detecting that the file has changed (growing as the export progress continues) and copying the changes?  If that is the case it'd probably be the most efficient way to do this process because the time between initiating an export and the file arriving at the remote destination would be minimised but actually I could achieve that even more simply by simply choosing the output directory for the video editing software to export to as the remote drive itself, I can't do this though because the people who administrate the network have specifically requested we do not do this because it would 'saturate the link'.   I don't really understand why that's the case as no one else will be  needing to send anything to that destination from my end except me and that's all I'd ever send and I wouldn't have thought trickling the data in with the bottlenecked speeds you'd get from the editing software processing the export but in any case there's probably more considerations I'm not aware of. I assume therefore that software that looks for changes to the file and sends over the changed bits would be essentially doing something basically equivalent to what I've been specifically asked not to do so I think I probably can't do that."
PowerShell,3bzyd2,colinmcleod,2,Sat Jul 4 05:57:41 2015 UTC,I wonder if I can get robocopy to monitor for changes and then initiate copying if there haven't been any changes for an extended period of time.
PowerShell,3bzyd2,KevMar,2,Sat Jul 4 06:00:05 2015 UTC,"That's kind of backwards, no need to monitor for lack of changes, if you want a copy to occur even if changes haven't been made just schedule the copy with task scheduler.  Best not to over complicate."
PowerShell,3bzyd2,Dilligaf23,1 point,Sun Jul 5 06:04:40 2015 UTC,"Yeah I have this same question posed elsewhere and the suggestion was the sync copy software and I planned to use that with the scheduler sometime after when I believe the export will be complete.  Since I still had the question going here though I'd thought I'd see what could be done with robocopy and see if there's a more elegant way of doing things. I figured if you can get the software to look for changes to files and use that as a trigger for copying the changed bits, then it mightn't be complicated to operate that same premise in reverse (though I don't know, not having used robocopy). If I could have robocopy trigger on condition of a lack of change to a file after a certain amount of time, that could be a fairly reliable proxy for detecting the completion of an export couldn't it?  The task scheduler would almost certainly be less complicated, but then if I had robocopy doing things the way I wanted I'd only need  to run it once. Then I could just sent exports to the folder robocopy is monitoring and then move them out of their later when they're done to be replaced with the next batch of files for sending. I guess there'd be further complication involved in preventing this triggering action from re-occurring multiple times after the export is finished though."
PowerShell,3bzyd2,admin_all_the_things,1 point,Mon Jul 6 09:54:24 2015 UTC,sleep -seconds (60*60)
PowerShell,3bzlcp,stgioia,4,Fri Jul 3 12:51:39 2015 UTC,"You are not doing anything wrong, Get-EventLog is the legacy cmdlet that is supported by older versions of Windows/PowerShell. Get-WinEvent is the cmdlet you want to be using.  If you are creating a script that will run on 2003 as well as newer versions you could have the script detect the Windows version and use the appropriate cmdlet based on that."
PowerShell,3bzlcp,JaapBrasser,2,Fri Jul 3 12:56:35 2015 UTC,Thanks for the reply.  Some servers in the network are accessible only using a slow link (1 Mbps) and i'm worried that Get-EventLog might cause some bandwith headaches.
PowerShell,3bzlcp,JaapBrasser,5,Fri Jul 3 13:01:53 2015 UTC,"The solution for that is to execute the command locally, write it to csv and then pickup the csv after the command has run. That will converse bandwidth and you can see the size of the csv before you pull it in over the network."
PowerShell,3byltw,dogfish182,5,Fri Jul 3 05:39:49 2015 UTC,"Try using schtasks.exe instead.  I know it's not ideal as it's not a cmdlet, however it will save you from using the dirty gui."
PowerShell,3byltw,Theratchetnclank,2,Fri Jul 3 08:19:28 2015 UTC,"indeed. but I'd love to use the cmdlets. what I want to do is arrange a shareable script for the IT departments so we can do our password rollovers. there's only about 10 tasks to change but you know, the principle etc etc :)"
PowerShell,3byltw,5MonkeyPunches,1 point,Fri Jul 3 11:42:42 2015 UTC,I would try running as admin 1st.
PowerShell,3byltw,Flyboy,1 point,Fri Jul 3 05:42:10 2015 UTC,"This is elevated permissions. I found a module named 'task scheduler' however, this contains   PS C:> get-command -Module taskscheduler  CommandType     Name                                               Version    Source                                                                                                                 -----------     ----                                               -------    ------                                                                                                                 Function        Add-TaskAction                                     1.0        taskscheduler                                                                                                           Function        Add-TaskTrigger                                    1.0        taskscheduler                                                                                                          Function        Connect-ToTaskScheduler                            1.0        taskscheduler                                                                                                          Function        Get-RunningTask                                    1.0        taskscheduler                                                                                                          Function        Get-ScheduledTask                                  1.0        taskscheduler                                                                                                          Function        New-Task                                           1.0        taskscheduler                                                                                                          Function        Register-ScheduledTask                             1.0        taskscheduler                                                                                                          Function        Remove-Task                                        1.0        taskscheduler                                                                                                          Function        Start-Task                                         1.0        taskscheduler                                                                                                          Function        Stop-Task                                          1.0        taskscheduler      which is not what I want. What I'm after is changing the password on a bunch of existing tasks."
PowerShell,3byltw,jfractal,1 point,Fri Jul 3 07:33:03 2015 UTC,"Not at work, so can't test. but can you do something like  $task = get-scheduledtask 'taskname' remove-task $task.name new-task $task.name -password 'newpassword'   Basically replace the existing task with a new one with the same attributes except provide a new password. Needs fleshing out."
PowerShell,3byltw,alinroc,1 point,Fri Jul 3 13:53:04 2015 UTC,Try reinstalling RSAT and Windows Management tools perhaps?
PowerShell,3bxjxa,sturmy81,2,Thu Jul 2 23:52:47 2015 UTC,You have to use the Persistent Chat SDK  https://msdn.microsoft.com/en-us/library/office/dn454982.aspx
PowerShell,3bxjxa,pertymoose,1 point,Fri Jul 3 11:11:00 2015 UTC,"thx, will take a look"
PowerShell,3bxjxa,midnightFreddie,1 point,Fri Jul 3 16:27:39 2015 UTC,"without Persistent Chat SDK, but only in combination with Desktop Client,  Lync 2013: Post messages to a persistent chat room that the user has joined"
PowerShell,3bwhtn,rwoeirj,4,Thu Jul 2 18:51:18 2015 UTC,"I don't think the group needs to represent the entire subreddit which is what seems to concern /u/derekhans and would be very difficult to manage.   Don's post suggests that there's no need for the virtual user group to pursue any activity other than the Scripting Games so the subreddit's primary focus of being a discussion forum for PowerShell would not, in my opinion, be lost by registering a group that just represents the subreddit subscribers that want to collaborate to solve the puzzles.  The group should be open to any /r/powershell subscriber that wants to participate, regardless of ability, and a link in the sidebar to a page describing the group's activity and encouraging participation would be useful.  This does, however, raise the question of numbers and how you best manage potentially dozens of people.  Do you split into separate teams and submit the best team's solution?  Do you pick a team at random each month and they get to work on the puzzle and represent the group that month?    While the group's primary focus would be the Scripting Games it could eventually arrange some usergroup-like activities but with a focus on the kind of things reddit usually does such as arranging AMAs and gift exchanges."
PowerShell,3bwhtn,pandiculator,2,Thu Jul 2 21:16:01 2015 UTC,"Well put.  At our core, we're a forum, just like Powershell.org's forums, TechNet, Stack Exchange, etc.except better :P.  There are a lot of people that come here for help, to learn and to share, and that should be the subreddit's core focus.  I put some thought into what /r/PowerShell would gain by doing the Scripting Games, and this is what I came up with.   Recognition of our community, and possibly new visitors. Assist new/old scripters with a team of people to learn from with real problems. Having fun and strengthening our community.   To me, the only one that is really important is number two.  Visitors and contributors will come in time.  Jeffery Snover posted here with no prompting from us just yesterday.  That's pretty cool.  Drawing our community tighter is good, but not at the cost of what the community is for.  No matter what happens, I fully intend to post every problem from the Scripting Games in the subreddit with a sticky, so people can post snippets, ask questions, give advice or share their solution.  If people want to form teams or submit something themselves, that's great, hopefully some folks learn something.    I understand Ed's reluctance to open up to other groups, the responses could be too much to handle.  I understand Don's desire to expand his brand or to make the user groups more attractive.  Personally, I don't think we need to be a formally recognized, registered Powershell.org user group chapter to do what we're here to do.  Who knows, maybe we'll just do our own Scripting Games.  We've tried in the past to get some sponsors to help with prizes, including Powershell.org, with limited success.  Maybe I'll just shell out for them myself, I don't know.  If it'll be a fun thing for the community, I'm willing to do it."
PowerShell,3bwhtn,gospelwut,2,Thu Jul 2 22:02:46 2015 UTC,"How about something like this:  We could simply have a post per ""game""/event (I'm still not 100% sure how this is going to work). We'd probably need the following (amongst other things):   Somebody, probably a mod, to post new challenges/sticky them. Emphasize that NO DOWNVOTES. State that people should only make ""top level"" replies with pastebin links to solutions--but can use child comments to discuss/praise/give input/etc.   It would really be no different than a BBS-esque (did I just date myself?) forum from posting a new topic per challenge. Though, I'd argue the threading makes it easier to sort out the solutions.  That way ""everybody participates"" (either submitting, commenting, and/or voting) but only the top answer(s) -- or an amalgamation thereof would be submitted to the official challenge(s)/games.  A running Google calendar of the game events would be pretty nice too.  Threads could later be shoved into a wiki or have their OP edited as an index of solutions. That way, people could look through interesting patterns and comments to a myriad of topics simply by going through old Posh Game threads. Could probably even write something to commit them to a github repo ranked by upvotes per folder (e.g.  game001\challenge2\000-derekhans.ps1"
PowerShell,3bwhtn,derekhans,1 point,Fri Jul 3 02:49:29 2015 UTC,"They have something like this already for Reddit, called Contest Mode.  We'll give it a try this next time they post and see how it goes."
PowerShell,3bwhtn,gospelwut,1 point,Fri Jul 3 03:06:44 2015 UTC,Huh. I've never seen that used anywhere I'm subbed. Fascinating.
PowerShell,3bwhtn,KevMar,1 point,Fri Jul 3 14:13:59 2015 UTC,You are right. We can do our own thing here. The only reason we need a group is so that we can submit one entry as a group to ED. I feel these challenges will be a good thing for our community anyway and many of us already try hard to welcome the new users. I know I try to give solid feedback and give them a little more insight any time I can.   I think we already have a community like Don Jones wants to grow. We just need to keep doing what we are doing.
PowerShell,3bwhtn,sid351,1 point,Fri Jul 3 04:22:08 2015 UTC,"How many people are actually serious I wonder?  If we do have a large number of people maybe we could split up into smaller groups (roughly geographical) and have 'team leaders' (or a better name) that run interactive sessions (webinars/hangout/group Skype) on a rolling rota?  It would show we all have things to learn, while hopefully handling any time zone differences fairly well.  I'd be happy to lead/chair some of the UK (time zone friendly) ones."
PowerShell,3bwhtn,gospelwut,2,Thu Jul 2 21:57:44 2015 UTC,"I'm interested. I'm curious, however, how the workflow of working on this together precisely works/would work/should work?"
PowerShell,3bwhtn,tjb627,1 point,Thu Jul 2 21:14:07 2015 UTC,Somebody already created a Powershell team on Slack which is pretty helpful. Powershell.slack.com
PowerShell,3bwhtn,derekhans,1 point,Thu Jul 2 21:58:53 2015 UTC,"How do you join it, though?  It looks like Slack requires the Team to invite you, or create an account for you."
PowerShell,3bwhtn,tjb627,2,Thu Jul 2 22:08:31 2015 UTC,Found it.   http://slack.poshcode.org
PowerShell,3bwhtn,tjb627,1 point,Fri Jul 3 00:51:08 2015 UTC,Seems like I requested an account to it but I don't remember how. It's free and they'll give an account to anybody. I'll see if I can remember.
PowerShell,3bvf0x,JeepDon,7,Thu Jul 2 13:50:24 2015 UTC,"Can Remoting v3 talk to Remoting v2?  ""Yes. There's this process where they talk to each other, like two dogs sniffing each others' butts, and figure out each other's capabilities."""
PowerShell,3bvf0x,b1llb3rt,5,Thu Jul 2 14:35:20 2015 UTC,"""PowerShell is such a great product because I'm a deeply-flawed human being."""
PowerShell,3bvf0x,bandman614,6,Thu Jul 2 14:54:46 2015 UTC,"I know Jeffrey. He's a great guy, for the record. And PS is still awesome."
PowerShell,3bvf0x,1RedOne,5,Thu Jul 2 18:41:47 2015 UTC,"'running a GUI on a server is like heroin, at first click it's great but the before you know it you're full of viruses dying in an alley'"
PowerShell,3bvf0x,JeepDon,4,Sat Jul 4 15:07:45 2015 UTC,"""Did you just lick my cookie?""  (at Ignite 2015 during session w/Don Jones)"
PowerShell,3bvf0x,JasonHelmick,2,Thu Jul 2 14:36:02 2015 UTC,This is my personal favorite - I almost spit-up at the conference
PowerShell,3bvf0x,737000,3,Fri Jul 3 15:11:37 2015 UTC,not exactly his quote.. but I love the story he tells where when he first tried to get powershell introduced he was told by one of the Microsoft executives 'What part of fucking windows don't you understand'
PowerShell,3bvf0x,halr9000,1 point,Thu Jul 2 23:51:32 2015 UTC,I would love to see where that guy is at now.
PowerShell,3bvf0x,halr9000,3,Fri Jul 3 01:29:11 2015 UTC,"He's doing well for himself. Charity work, malaria, clean water for the poor, etc. :)"
PowerShell,3bvf0x,PaulCunningham,1 point,Fri Jul 3 04:50:54 2015 UTC,"He might have told that one here: http://powershell.org/wp/2013/11/30/episode-249-powerscripting-podcast-distinguished-engineer-jeffrey-snover-for-the-powershell-v4-launch-party/  IIRC this was the show that I did in person in his office. That night he told us a story about Bill Gates that he asked us to pull. I'd have to go back and listen to be sure, and it's late. Either way, it's Jeffrey, so it is a good listen!"
PowerShell,3bvf0x,tomatwork,3,Fri Jul 3 04:59:01 2015 UTC,I have this saved as snover.jpg  http://imgur.com/bAnDBou
PowerShell,3bvf0x,MKmsftFan,3,Fri Jul 3 14:49:09 2015 UTC,"From a tweet a little while ago: Not updating from WS2003 is like the guy who jumps off a building on the way down says, ""so far, so good.""   From an Ignite talk with Don Jones regarding learning PowerShell, remote admin (https://channel9.msdn.com/events/Ignite/2015/BRK4451 around 1:09:00): (paraphrasing) Is that person worth 4 times the number of reboots and 10 times the number of security patches? The answer might be yes, or the answer might be, as Don points out, that these are IT professionals. Pro-fess-io-nals. That means you pay them money. Professionals that know how to do a job professionally. So in the IT profession, we learn new things. If you didn't want to learn new things, you should get into lumber. There has not been a new tree in quite a long time."
PowerShell,3bvf0x,bundyfx,2,Fri Jul 3 14:54:28 2015 UTC,From  Ask Me Anything (AMA) Featuring Jeffrey Snover part 1 with /u/JasonHelmick   The People that use our products should be heroes...if you use my products you should be rich
PowerShell,3bvf0x,halr9000,1 point,Fri Jul 3 20:02:20 2015 UTC,"""this is rock science, not rocket science"" one of the MVA videos with Jason Helmick. hilarious."
PowerShell,3bvf0x,ljawork,1 point,Thu Jul 2 23:12:12 2015 UTC,Microsoft is incapable of sustained error.
PowerShell,3bvf0x,jsnover,1 point,Fri Jul 3 04:51:43 2015 UTC,"During one of the Introduction MVA's he gave away possibly the best advice of all time:  ""When in doubt, run in circles, scream and shout"""
PowerShell,3bvf0x,JaapBrasser,5,Fri Jul 3 07:59:42 2015 UTC,"I believe it was:  When in trouble,fear, or doubt - run in circles, scream, and shout."
PowerShell,3bvf0x,ljawork,2,Fri Jul 3 14:38:55 2015 UTC,"And there you have it, Jeffrey Snover contributing to the ""Favorite Jeffrey Snover"" thread."
PowerShell,3bvf0x,Rostropovitch,1 point,Fri Jul 3 15:03:18 2015 UTC,"Yes, you are correct :)   EDIT: TFW Jeffrey Snover replies to my post to correct me and simultaneously I don't realise it's him ._.'"
PowerShell,3bvf0x,dorath,1 point,Mon Jul 6 06:43:10 2015 UTC,"""Why would you waste those precious neuron's there are so few""  after J. Helmick forgets to use IntelliSense at one of DSC MVA sessions."
PowerShell,3bvf0x,dscripter,1 point,Fri Jul 3 13:13:44 2015 UTC,"The ""Virtual Modules"" exchange with Jason Helmick in Advanced Tools & Scripting with PowerShell 3.0 Jump Start."
PowerShell,3bvf0x,halr9000,1 point,Fri Jul 3 14:54:54 2015 UTC,"""We've talked to customers. Some people adopt this policy of a gold image, where they put everything anyone would possibly want in a gold image and install it on all their servers. If you're doing that: stop it. You are asking for a cyber-punch to the face."""
PowerShell,3bvf0x,nakedpowershell,1 point,Fri Jul 3 17:14:33 2015 UTC,Here's another good one!   SSH has the risk profile of a 1980s San Francisco bathhouse  - way too much anonymous sharing   Source: http://i.imgur.com/SF88J5A.jpg ;)
PowerShell,3bvk3l,shalaschaska,4,Thu Jul 2 14:33:57 2015 UTC,You could also filter on the passwordlastset parameter and disable the offending accounts
PowerShell,3bvk3l,jbtechwood,4,Thu Jul 2 14:40:06 2015 UTC,"Don't over complicate this.  Assign the new passwords and set the ""Must reset password"" box.  On Monday night, disable every account that still has ""Must reset password"" flag set. Easy to test and easy to verify.  Get-ADUser -filter * -Properties ChangePasswordAtLogon | where ChangePasswordAtLogon   Save that list that you disabled and check those names in a week. Have HR review any that are still disabled.  You don't have to answer this if its a security breach type of issue, but I am curious about the events that prompted a AD wide password reset."
PowerShell,3bvk3l,KevMar,1 point,Fri Jul 3 01:46:02 2015 UTC,Oh dear bro. You are on to something there lol. Thanks!
PowerShell,3bvk3l,the_spad,1 point,Fri Jul 3 05:57:01 2015 UTC,"Sorry, did not respond to your second question. Eh. SOX audit. :)"
PowerShell,3bvk3l,Swarfega,6,Fri Jul 3 07:08:53 2015 UTC,Get-ADUser -filter * -properties PasswordExpired | ?{$_.PasswordExpired -eq $true} | Disable-ADAccount   You may of course wish to restrict this to specific OU trees with the -Searchbase parameter on Get-ADUser so as not to hose accounts by mistake.
PowerShell,3bvk3l,The_Smiling_Catfish,2,Thu Jul 2 14:38:26 2015 UTC,Looks like reddit stripped out your $ signs  Edit  Actually this appears to be a 'Sync for reddit' bug. Here I am on my desktop PC and all is well. Checking the Android app and again the $ symbols are missing.  /u/ljdawson can you see this bug?
PowerShell,3bvk3l,The_Smiling_Catfish,1 point,Thu Jul 2 15:59:16 2015 UTC,You are right. Awkward!
PowerShell,3bvk3l,Letmefixthatforyouyo,3,Thu Jul 2 20:11:06 2015 UTC,Waits to see all the service accounts lock ;)
PowerShell,3bvk3l,admin_all_the_things,3,Thu Jul 2 19:48:28 2015 UTC,Hahah ye might need to limit it to the user OU haha
PowerShell,3bvk3l,admin_all_the_things,1 point,Thu Jul 2 20:10:35 2015 UTC,I really would!! Also an audit is a good idea to make sure no 'experienced' admins have setup services or scheduled tasks to run as their own (or another) account.
PowerShell,3bvk3l,Ssoy,1 point,Thu Jul 2 20:13:44 2015 UTC,Dude our network is a mess. Every service account I will change will come with a suprise system that will go down because its linked hahaha!
PowerShell,3bvk3l,Frequentsy,1 point,Thu Jul 2 20:21:45 2015 UTC,"Well, thats one way to fix that mistake."
PowerShell,3bvk3l,geostude,2,Fri Jul 3 03:06:57 2015 UTC,"When you reset the password why not just check the ""Must reset password box"", since I imagine you're using a tool it should have the functionality, they will be required to change their password, no getting around it."
PowerShell,3bvk3l,geostude,2,Thu Jul 2 15:11:22 2015 UTC,"I have the reset password on next login, but as we sent out envelopes with passwords we want all passwords who are not set by users that day to be disabled, this is done to make sure those envelopes of users who have a day off will not be compromised. So anyone who did not change it that day because they have a day off or whatever need to have their accounts disabled Monday night and will contact help desk into re-enabling them when they return."
PowerShell,3bvk3l,work-work-work-work,1 point,Thu Jul 2 15:25:24 2015 UTC,"Ahh, that makes sense."
PowerShell,3bwo5k,JimboAinzley,7,Thu Jul 2 19:38:13 2015 UTC,"Possible, yes. Worth it, probably not.   If you're in an organization of any reasonable size, home brewing your enterprise monitoring tools isn't generally a good idea.   You'll have to train everyone how to interpret, be on the hook for when something happens and your tools didn't account for it or alert... Plus a host of other potential 'liability' related concerns.   Now, no ones calling the current suites available 'problem-less' but there are some efficiencies gained with having a standard suite in place for the rest of the IT staff."
PowerShell,3bwo5k,GLiMPSEiNATOR,1 point,Thu Jul 2 22:12:08 2015 UTC,"organization of any reasonable size, home brewing your enterprise monitoring tools isn't generally a good idea.   As someone in one of those enterprises I disagree.   On one hand it's great to go for proper tools. I overheard someone saying ""we can get a programmer to do a timesheet tool for a day"" from someone the other day. That is ridiculous given what is already out there to do the job properly.   However.   The problem that is missed in large enterprises is that once you have a few hundred servers the per-server licensing cost for almost any kind of monitoring is ASTRONOMICAL. I'm a DBA so we would be looking at close to a million dollars to get the tools we want.   My team has no hope in hell of getting that and so it's all home brew. That's just how it is.   With all of this said I don't think PowerShell is the right tool for the job. We automate a tonne on gathering statistics and building reports for each day and change control. But live screens would be too much - PS isn't built for the GUI and it isn't great at scaling past a dozen threads or so for going out and getting information."
PowerShell,3bwo5k,im_cody,3,Fri Jul 3 05:27:51 2015 UTC,Isn't nagios core free? While I agree powershell has its place and can be useful within small scale team based use cases I still hold firm that it's a better move to invest your time into tuning one of these frameworks and utilizing it as the base for your enterprise monitoring solutions rather then from scratch with powershell.
PowerShell,3bwo5k,GLiMPSEiNATOR,3,Fri Jul 3 14:35:13 2015 UTC,"I over engineered a solution like this once.   http://kevinmarquette.blogspot.com/2013/11/rrdtool-server-dashboards.html  I had a master list of performance counters (including target servers). I created a small datafile for each one. Then I spun up a job that ran get-counter to collect the performance counters and save to that file.  Then I processed those datafiles into some amazing kiosk displays. This turned out to be very resource intensive. The node doing all the data collection worked way too hard for what it was doing. Having a unique job for each one was not using resources efficiently and I am sure there are better ways. I was considering moving that part of it into C# to optimize it.  The datafiles I used were rrdtool round robin databases (a circular file that would automatically overwrite the oldest values.). A lot of open source tools use this under the hood. You end up having to learn a new language to generate the charts.   Someone recommended logstash, then to Elasticsearch, then search and visualize via Kibana. I think statsd and graphite can come into play here someplace. I would consider going that direction next time.  The roll your own approach is a fun experience and great as a home/side project that compliments your existing monitoring solution. While this is someone that many people can make, the time it eats up is often worth more than the cost of buying a professional solution."
PowerShell,3bwo5k,KevMar,0,Thu Jul 2 23:12:35 2015 UTC,Or Splunk
PowerShell,3bwo5k,halr9000,2,Fri Jul 3 05:01:50 2015 UTC,"/u/mcsparklenuts shared a script that does something similar.  https://www.reddit.com/r/PowerShell/comments/2ge1ql/powershell_network_device_monitor_v14_new_and/?  I have used it where i work, does the job nicely. Monitoring small amounts of devices is fine, however I dont know if it would work monitoring a large number of devices. It appears to check each devie in sequence, and waits for a response / timeout before testing the next.  I ended up modifying the timeout value, so that it cycled thru each device quicker. If anything on our network takes more than 500ms to respond has an issue."
PowerShell,3bwo5k,hellynx,1 point,Wed Jul 8 06:26:23 2015 UTC,"well the easy way would be to set it up in small segments with background jobs providing information to a central point, be it a html report or what have you.  For the past few days during my spare time I've been working with the ELK stack, maybe that's kind of what you are looking for as a central hub?  I think it might be extremely useful to drop the output from automated powershell scripts into 'logs', feed that into logstash, then to Elasticsearch, then search and visualize via Kibana."
PowerShell,3bwo5k,Honkykiller,1 point,Thu Jul 2 20:09:43 2015 UTC,"If you were to pursue this for purely academic purposes, you could probably pull it off. I would definitely not recommend this for production."
PowerShell,3bw6ze,zdmilot15,2,Thu Jul 2 17:31:30 2015 UTC,Found my problem used = instead of -eq
PowerShell,3bw6ze,mhurron,1 point,Thu Jul 2 18:17:07 2015 UTC,"That's a lot of repetition. Why not build your paths in three steps  First set the path if the department is IT, then test the region part, then prepend the department OU to the region."
PowerShell,3bw6ze,wtgreen,1 point,Thu Jul 2 18:18:07 2015 UTC,"You might be interested in this. Less duplication and easier to catch a typo.   $OUs = $DCs = @() switch -regex ( $Dept )  {     # Accounting and HR have OUs and DCs that are location-specific    ""Accounting|Human Resources"" {$OUs += ""Office Employees""                                  switch( $Local ) {                                     ""MA""  {$OUs += ""Boston""                                           $DCs += ""MainOffice""}                                    ""CA""  {$OUs += ""LA""                                           $DCs += ""CaliOffice""}                                  }                                 }     # IT's DC is always the same and no special OU     ""Information Technology""     {$DCs += ""MainOffice""}     # everone gets OU=Company and DC=company and DC=com    "".""                          {$OUs += ""Company""                                  $DCs += ""company"",""com""} }  $path  = ( $OUs | %{ ""OU=$_"" } ) -join ','  $path += ','  $path += ( $DCs | %{ ""DC=$_"" } ) -join ','"
PowerShell,3bw6ze,wtgreen,1 point,Fri Jul 3 16:04:13 2015 UTC,"That seems like a nice option but I am confused on how it works, for instance: what is the pipeline ""|"" symbol doing in a switch? Also could you do that with 3 different switches, and could you use {($_ -eq ""Project Manager"") -or ($_ -eq ""Project"") -or ($_ -eq ""PM"")} with is in order to create mutable error checks for user solicited input. Also how does a ""."" make it so that everyone would receive the OUs? This is very interesting syntax for someone who is beginner/intermediate, like myself."
PowerShell,3bvi65,Vortex100,2,Thu Jul 2 14:17:49 2015 UTC,"I'd do it the other way. Filter down to 'disabled users that are a member of more than 0 groups' and go from there  Get-ADUser -Filter {Enabled -eq $false} -properties MemberOf | Where-object -filterscript {($_.MemberOf | Measure).Count -gt 0}   Knocked the above up at home where I don't have ad, so forgive any mistakes"
PowerShell,3bvi65,the_spad,1 point,Thu Jul 2 18:02:20 2015 UTC,Hmm. That's a really interesting approach man. I might give that a shot.
PowerShell,3bvi65,SeanQuinlan,1 point,Thu Jul 2 18:28:32 2015 UTC,"Depends, what is your actual goal with this script? Are you simply trying to produce stats that show that 30% of the members of ""MySpecialFolderGroup"" are disabled or is there something specific you're trying to achieve?"
PowerShell,3bvi65,KevMar,1 point,Thu Jul 2 14:20:11 2015 UTC,"The idea behind the script is to try to find groups that may be inactive, unused or deprecated. To that end, the use case you've described is what I'm looking for, yes. With this goal in mind, I have a separate script that checks for nested groups to mitigate token bloat."
PowerShell,3bvi65,etepemllactnod,1 point,Thu Jul 2 14:23:58 2015 UTC,"Here is a function I wrote to search for a group or groups and recursively check group members, including whether they are disabled or not. It uses LDAP, so no need for the AD cmdlets.  If you use just ""*"" as the name it should search every group in the domain, although I've not tested it."
PowerShell,3bvnhl,danekan,3,Thu Jul 2 15:01:40 2015 UTC,"I believe there is an RSS feed, or at least there used to be.   EDIT: There is a RSS feed, in the Portal expand Service Health, click Service Health, at the top right there is a RSS symbol."
PowerShell,3bvnhl,lumberjack5500,1 point,Thu Jul 2 17:32:25 2015 UTC,oh gee IDK how I missed that RSS Button... but it looks like the feed is only a small summary and then to see the actual description it's linking to the actual portal?
PowerShell,3bvawu,zdmilot15,3,Thu Jul 2 13:11:23 2015 UTC,"Adding to the group is easy as you don't need the DN.  Add-ADGroupMember -Identity <Groupname> -Members <Username>   e.g.  Add-ADGroupMember -Identity ""Domain Users"" -Members ""contoso\jimbob""   As for moving the account, that's simple too:  Move-ADObject <UserDN> -Targetpath <OUDN>   e.g.  Move-ADObject ""CN=Glen John,OU=UserAccounts,DC=NORTHAMERICA,DC=FABRIKAM,DC=COM"" -Targetpath ""OU=MoreUserAccounts,DC=NORTHAMERICA,DC=FABRIKAM,DC=COM"""
PowerShell,3bvawu,the_spad,2,Thu Jul 2 13:19:47 2015 UTC,"Thank you for your response, but how would I go about creating a -Targetpath to an OU that is nested in another? For instance Contoso>NYC>Office Employees>Finance"
PowerShell,3bvawu,the_spad,2,Thu Jul 2 13:28:39 2015 UTC,"""OU=Finance,OU=Office Employees,OU=NYC,DC=Contoso,DC=com""  You can easily check this under the ""Attribute Editor"" tab in ADUC by copying the value of the DistinguishedName attribute."
PowerShell,3bvawu,SomnambulicSojourner,2,Thu Jul 2 13:41:41 2015 UTC,I just copy and paste that all the time for nested ous. I'm lazy
PowerShell,3bvawu,the_spad,2,Thu Jul 2 14:21:32 2015 UTC,Ditto.
PowerShell,3bvawu,the_spad,2,Thu Jul 2 14:30:27 2015 UTC,"Thank you very much, I have one question still though why did you state ""contoso\jimbob"" insted of just jimbob and what would one enter for the information before the ""\"" ?"
PowerShell,3bvawu,the_spad,2,Thu Jul 2 14:28:36 2015 UTC,"Just for clarity, if you've only got a single domain you can just use the samaccountname on its own and it'll work fine, otherwise the standard ""domain\username"" or ""upn@domain.com"" or even the full DN will all work."
PowerShell,3buukw,CasaDev,1 point,Thu Jul 2 09:49:43 2015 UTC,"You need to loop through your data, there are a lot of ways of doing this, my example uses ForEach-Object:  Import-Csv -Path YourFile.csv | ForEach-Object {     Get-ADUser -Properties staffid -Filter 'staffID -like ""*0123456""' |     Select-Object -Property samaccountname,staffid } | Export-Csv -Path YourNewFile.csv -NoTypeInformation   Let me know if you understand this code and if it works for you. If it doesn't work please show the header and the first line of your csv file."
PowerShell,3buukw,JaapBrasser,1 point,Thu Jul 2 09:59:40 2015 UTC,"$users = Import-csv ""C:\mycsv.csv""  foreach($user in $users){     get-aduser -Properties staffid -Filter 'staffID -like ""*$($user.staffid)""' | Select -Property staffID,name | export-csv c:\output.csv -NoTypeInformation -append }   This assumes your CSV ""columns"" are headed first,last,staffid.  Don't use ""-Properties *"" with Get-ADUser as it's massively inefficient. Only request the properties you need."
PowerShell,3buukw,the_spad,1 point,Thu Jul 2 10:01:43 2015 UTC,"Stupid question, potentially, but does ""staffid"" here - ($user.staffid) - refer to the column header out of interest?  Thanks for this, I'm trying it out now..."
PowerShell,3buukw,the_spad,1 point,Thu Jul 2 10:33:58 2015 UTC,"Yes, staffid is the column header from the CSV that corresponds with the staff ID value."
PowerShell,3bssgq,pTomic,2,Wed Jul 1 21:19:21 2015 UTC,"That's not supported, you need to do remoting. See Using Powershell with Exchange 2013 (Exchange Management Shell)"
PowerShell,3bssgq,JetzeMellema,2,Wed Jul 1 21:44:30 2015 UTC,"Just was working on this issue today myself to connect to Exchange 2013.  Used this how to and my block of code to give me an addon option for the connection in ISE, gives all auto complete information for the accompanying commands as well.  Made this block of PS code to autoselect one of my Exchange servers for me and connect, aborts to rest of the script it may be part of if a connection cannot be made to one of the servers. There is room for improvement but didn't bother yet.  ## Exchange Powershell Connection Block #List of Exchange Servers in prefered order. $ExConServers = ""EX13-SVR1"",""EX13-SVR2"",""EX13-ETC"" $ExConServer = $Null #Remove stale Exchange Powershell sessions Get-PSSession | Where-Object {$_.ConfigurationName -eq ""Microsoft.Exchange"" -and $_.Availability -eq ""None""} | Remove-PSSession  #Iterates through Exchange servers and attempts to connect to them. ForEach ($ExSRVObject in $ExConServers)     {         If (Test-Connection -ComputerName $ExSRVObject -BufferSize 16 -Count 1 -ErrorAction 0 -Quiet)             {                 $ExConServer = $ExSRVObject                 Break             }     } If ($ExConServer -eq $Null)     {         Throw ""Connection to Exchange Powershell could not be established. Something is very wrong...""     } Else     {         Write-Host ""Connection available to "" $ExConServer     }  #Calculated URI Connection to Exchange Powershell $ExURI = ""http://"" + $ExSRVObject + "".EXCHANGEDOMAIN.com/PowerShell/""  #Attempts to connect to determined Exchange Server's Powershell If (-not (Get-PSSession | Where-Object {$_.ConfigurationName -eq ""Microsoft.Exchange"" -and $_.Availability -eq ""Available""}))     {         $ExSession= New-PSSession -ConfigurationName Microsoft.Exchange -ConnectionUri $ExURI -Authentication Kerberos         Import-PSSession $ExSession         Write-Host ""Connected to Exchange Snapin.""     } Else     {         Write-Host ""Connected to Exchange Snapin.""     } ## End of Exchange Powershell Connection Block"
PowerShell,3bssgq,GammaLeo,1 point,Thu Jul 2 04:21:21 2015 UTC,"Well. Your script is working flawless. But for get-mailboxdatabasecopystatus I still need to go RDP. :( It can't be imported. :(  EDITED: I install exchange management tools locally, and solve this problem."
PowerShell,3bssgq,WindosBK,3,Thu Jul 2 05:56:19 2015 UTC,"You have to load them on the Exchange server, then you can import them into your current session.  $ExSession = New-PSSession -ConfigurationName Microsoft.Exchange -ConnectionUri http://exchange.example.com/powershell -Authentication Kerberos Import-PSSession -Session $ExSession   Importing them within your ISE sessions will allow you to work on it within your ISE (including Intellisense.)"
PowerShell,3bt1s9,RoninSpartan,2,Wed Jul 1 22:28:48 2015 UTC,"Hey mate.  Your first line is the issue. You have Write-Host rather than Read-Host.  Also you will probably want to save that to a variable to be used in the function. otherwise it will just display it on the console host and move on. On top of that, since you are only offering two choices for the read-host you could add in a validateset() to your param so that no one can come in and just put in 'bacon' rather than Computers or Users. for some good examples of advanced functions and validation sets jump into the ISE and press Ctrl + J to bring up the snipit's. hit advanced functional (complete) and take a look at the layout."
PowerShell,3bt1s9,bundyfx,1 point,Wed Jul 1 22:38:56 2015 UTC,"Wow, I feel kinda stupid after seeing that... Although I thought I had that there before.   Validateset() will replace the if statement I just set up to test it with.   Thank you very much for the tip in ISE too!"
PowerShell,3bt1s9,KevMar,1 point,Wed Jul 1 22:59:40 2015 UTC,A good way to troubleshot a script that closes too quickly is to start the script from a powershell window. You will see any output or errors and have time to read them.
PowerShell,3bqdbb,bundyfx,3,Wed Jul 1 08:22:53 2015 UTC,"Nice script I like the use of regular expressions and the error handling. I do think your Genre switch statement, line112-137, is not required, and could simply be replaced by:   $filter -match '\d{4}'   As you already do the validation on the parameter.  Aside from the coding perspective, I think legally posting scripts that utilize websites like piratebay might be a dark grey area, so I am not sure how the Mods will like this kind of content. But from an educational point-of-view, this is a nice script and thanks for sharing."
PowerShell,3bqdbb,JaapBrasser,2,Wed Jul 1 08:44:05 2015 UTC,"Thanks Jaap, appreciate it. You're right about the switch. Think I was planning something else there but forgot about it. The Script is for educational purposes only. I don't condone pirating."
PowerShell,3bqdbb,KTM_530_Durty,2,Wed Jul 1 08:59:09 2015 UTC,"Hi, probably a dumb question, but how do I run the script?  I downloaded it and changed the extension to .ps1  I also did set-executionpolicy unrestricted  Any tips are appreciated.  Thanks for the help."
PowerShell,3bqdbb,swimbikerunrun,1 point,Wed Jul 1 20:53:01 2015 UTC,Read the hints in the source code.
PowerShell,3bqdbb,snakai,1 point,Thu Jul 2 01:47:02 2015 UTC,Nice!  I will be looking over your script and learning from it.  I've been wanting to learn how to use Powershell to interact with webpages.
PowerShell,3bqdbb,Frequentsy,1 point,Wed Jul 1 15:38:00 2015 UTC,"I wonder if you could add something to leave a review on each message board of the movie that would have a signature of your script, to help spread it and advertise? Not sure if that'd be against any ToS."
PowerShell,3bqdbb,agnostracised,1 point,Wed Jul 1 16:34:46 2015 UTC,i like this a lot!
PowerShell,3bqdbb,swimbikerunrun,1 point,Wed Jul 1 18:51:43 2015 UTC,"get-movie -Genre Action Invoke-WebRequest : The operation has timed out. At C:\Users\Administrator\Desktop\get-movie.ps1:105 char:21 +         $GenreNav = Invoke-WebRequest ""http://www.imdb.com/search/title?genres=$ ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : InvalidOperation: (System.Net.HttpWebRequest:HttpWebRequest) [Invoke-WebRequest], WebException     + FullyQualifiedErrorId : WebCmdletWebResponseException,Microsoft.PowerShell.Commands.InvokeWebRequestCommand"
PowerShell,3bqdbb,swimbikerunrun,1 point,Thu Jul 2 01:47:49 2015 UTC,Help? :-/
PowerShell,3bqdbb,swimbikerunrun,1 point,Thu Jul 2 01:48:02 2015 UTC,Works fine for me. maybe internet/firewall issue with IMDB?
PowerShell,3bqdbb,HSChronic,1 point,Thu Jul 2 02:08:11 2015 UTC,"Nah, can go to url and manually replacing $name"
PowerShell,3bqdbb,E-werd,0,Thu Jul 2 03:01:41 2015 UTC,Cool script but most of this stuff is already in CouchPotato
PowerShell,3bqdbb,HSChronic,1 point,Wed Jul 1 17:44:45 2015 UTC,"Nice program, but that's a full blown program that get installed.  This is a script that does what it does and gets out of the way.  The use case is different.  This could be chained with other scripts as well, though I don't have an example off the top of my head."
PowerShell,3bqdbb,agnostracised,0,Wed Jul 1 17:51:36 2015 UTC,"Actually it is just python, sure you can get binaries but most people just run the python sources."
PowerShell,3bt8kk,shivering,5,Wed Jul 1 23:22:46 2015 UTC,"Hi!  Trap is a bit antiquated. Look into the Try/Catch or Try/Catch/Finally error handling options.  References:   A quick read on Try/Catch A small e-book on error handling Get-Help about_Try_Catch_Finally Shameless plug - on why it's quite important to consider what can go wrong (including error handling).   Common Try/Catch mistakes:   Don't forget that any error in the Try block must be a terminating error - Cmdlets and advanced functions should let you specify -ErrorAction Stop Don't use $Error[0]. In the catch block, $_ represents the current error.   Here's an example. I want the current server in any error message:  #Pretend we're doing something with $CurrentServer. We want it in the error message $CurrentServer = 'Blah!' Try {     Throw ""Some evil error!"" } Catch {     # Decide if you want to terminate here, clean up and continue, etc.     # Terminating: Throw     # Non-Terminating: Write-Error defaults     # etc...     Write-Error ""Failed to query $CurrentServer`:`n$_""  }   In your case, you could do a try/catch for each command, if you want separate error messages.  Also, please consider alternatives to write-host : )  Cheers!"
PowerShell,3bt8kk,ramblingcookiemonste,5,Wed Jul 1 23:53:14 2015 UTC,"Hey mate,  It may be worth investing in some logic to check for these scenario's rather than to handle the error that will no doubt occur.  For example: you could add an if statement in your foreach that does a (Test-connection -computername $_ -count 1 -quiet) to evaluate if the computer can be reached or not. That way it won't even attempt to put it into maintenance mode and no error will occur. You could have some Write-Warning output in your Else statement like ""$Server was unreachable"" if you wanted to know what was and was not contactable.  on the second error you could have an If (not) statement that checks if the machine is already in maintenance mode and if so it skips over and writes warning/verbose that its already set and doesn't need to be altered.  Otherwise paste your try/catch syntax and we can help with fixing that up."
PowerShell,3bt8kk,bundyfx,3,Wed Jul 1 23:56:12 2015 UTC,"This is the way I prefer to do it. I like to treat exceptions as something that is unexpected. If I expect something may fail, then I test for it and handle it appropriately when I can."
PowerShell,3bt8kk,KevMar,1 point,Thu Jul 2 04:07:14 2015 UTC,"test connection will always work because the servers exist. I'm running the script locally from the scom machine, we have 2 of them. some are in one and some are in the other. I want to be able to just paste a huge list into both and have them sort it out without giant verbose error messages.   edit: got it all working, thanks for the idea! how would the if statement work checking for it being in MM ?"
PowerShell,3bq5k2,JaapBrasser,2,Wed Jul 1 06:37:46 2015 UTC,"I have been writing a series of blog posts on my blog on Active Directory and how to interact with it using both the ActiveDirectory module as well as the DirectoryServices objects and [adsi]/[adsisearcher] type accelerators.  Recently I bundled my first 13 articles into an ebook format, the reason I posted it here is because I would like to have some feedback on which topics you would be interested in reading more about."
PowerShell,3bq5k2,Not2original,1 point,Wed Jul 1 06:40:20 2015 UTC,Thank you for this!  I greatly appreciate it as a quick reference =-)
PowerShell,3bo15j,KevMar,10,Tue Jun 30 19:27:10 2015 UTC,"While not very original, /r/Powershell would be a good team name. It shows pride in who we are and its a display of confidence in our ability. We are just as much of a community as any of the other user groups."
PowerShell,3bo15j,sid351,3,Tue Jun 30 22:07:44 2015 UTC,I'll second that. I don't think we need a gimmicky name; it could devalue the group.
PowerShell,3bo15j,thebeersgoodnbelgium,3,Wed Jul 1 05:11:21 2015 UTC,I love the idea of /r/PowerShell!
PowerShell,3bo15j,Rankath1,1 point,Wed Jul 1 10:36:28 2015 UTC,"When I tried to name our team /r/Powershell for the Scripting Games last year, it dropped the '/'.   Don´t know if they changed anything, but keep in mind that it might not work."
PowerShell,3bo15j,rwoeirj,7,Thu Jul 2 05:35:06 2015 UTC,I would love to use slack for this.  (if possible)  I would also hope that we could be all inclusive/mentor the new to powershell people.
PowerShell,3bo15j,dogfish182,5,Tue Jun 30 20:05:45 2015 UTC,slack with a git integration would be perfect for this?
PowerShell,3bo15j,pandiculator,3,Tue Jun 30 20:21:13 2015 UTC,"I would also hope that we could be all inclusive/mentor the new to powershell people.   I think this is the most important part of the games.  I learnt so much doing the 2013 scripting games, not just from the expert's comments but from the feedback and discussion with other PowerShell users and the practices that have evolved from that event.  My enthusiasm for PowerShell really stems from those games; I hope I can encourage those new to it to feel the same way."
PowerShell,3bo15j,bennington_woz_ere,2,Tue Jun 30 20:54:06 2015 UTC,Consider me in
PowerShell,3bo15j,JeepDon,1 point,Tue Jun 30 21:47:53 2015 UTC,"I LOVE the idea of mentoring newcomers. If you decide to make that part of how you participate in the Games, please LMK. Happy to help publicize. Of such generosity are PowerShell Heroes created!"
PowerShell,3bo15j,JeepDon,5,Thu Jul 2 03:19:52 2015 UTC,"So if I might jump in...  There's no rule against groups collaborating on monthly entries. So go for it!  The bit where groups submit a single entry to The Scripting Guy for a chance to be selected as his favorite is limited to formal user groups - simply because poor Ed doesn't have unlimited time to review entries.   However, nothing's stoppin you from forming a virtual user group. If you're ""meeting"" monthly, even if only to work on the Games, that's cool. Get a user group page up on PowerShell.org and go for it. And if that brings more people into your fold, so much the better.   The puzzles themselves WILL be varied. They'll start fairly simple, but we will be tossing more complex ones in every so often. We're recruiting lots of folks to write them, so it'll end up being a lot of perspectives. But he first few will be entry level friendly, mainly because a big part of the Games is serving newcomers. You experts ought to be authoring DSC resources people can use!! :)  Long term, it may be that we need to revisit the ""user group"" thing and create a place for ""study groups"" also. Totally open to it, so long as we can find a way to manage the volume. We're taking baby steps with this, knowing we can evolve as we go. But virtual user groups are totally legit, and you sure seem to be that here.   Hope that helps, and I hope you have fun.  DonJ"
PowerShell,3bo15j,pandiculator,2,Thu Jul 2 03:18:11 2015 UTC,"Hey Don,  Thanks for coming to check us out.  I'm hesitant to register as a virtual user group.  Scheduling events, lining up speakers or finding sponsors for contests is something that we're capable of doing, but is outside our focus.  We're a forum, just like Technet, Powershell.org or Stack Exchange.  Especially because we have over 11,000 subscribers all over the world, trying to do something that is available for everyone is very difficult.  Our format works for us, and while we would like for more people to come here to help and be helped, I don't think labeling or structuring ourselves as a user group is the way to do it."
PowerShell,3bo15j,LandOfTheLostPass,9,Thu Jul 2 16:48:22 2015 UTC,"I'd be interested in joining a Reddit team.  Git could be a useful a learning exercise for those of us who aren't using it but probably should be.  A private subreddit could be used for discussion.  Alternatively, I have largely unused web space I could throw some forum software on.  For the name, I suggest Team Snoover.  It's like Snover, but with Snoo :)"
PowerShell,3bo15j,bundyfx,3,Tue Jun 30 20:48:50 2015 UTC,"Assuming they are willing to accept a subreddit with (as of this post) ~11,000 memebrs.  I'm all for it."
PowerShell,3bo15j,upsideleft,3,Tue Jun 30 20:39:16 2015 UTC,"'Read-Host Reddit' gets my vote. As I suggested originally this is a great idea for not only the PS community but also for people who may be new to PowerShell to learn a truckload of stuff. can't wait.   As for platforms, i'm sure Git works for most people. +1"
PowerShell,3bo15j,sid351,2,Tue Jun 30 21:37:52 2015 UTC,I'm down too. Open to help any way I can (probably with my wallet - let's be honest).
PowerShell,3bo15j,jinoxide,2,Tue Jun 30 23:35:03 2015 UTC,"I'm down to script.  I've not used Git before, but I'm happy to learn. ...Maybe we could create a module to help people learn how to use it (even if they're is already one out there it couldn't hurt to write a new one).  We need to make sure our collaboration efforts aren't indexed and public before the submission deadline. Also some real time 'meetings' would be good, via something like a Skype group or Google Hangout once a week/fortnight at a set time (or two for international cousins - UK here)."
PowerShell,3bo15j,jinoxide,4,Wed Jul 1 05:17:27 2015 UTC,I think https://powershell.slack.com is still up and available for realtime chatter.
PowerShell,3bo15j,aytch,1 point,Wed Jul 1 11:12:28 2015 UTC,"Not anymore.  Should've just PMed it to me, so someone wouldn't take it.  :("
PowerShell,3bo15j,Not2original,2,Wed Jul 1 16:03:57 2015 UTC,"Oh, sorry. I meant ""There is currently a bunch of folk from /r/PowerShell (and the IRC linked channel) hanging out and chatting in Slack here"".  https://www.reddit.com/r/PowerShell/comments/2wrd9f/the_virtual_powershell_user_group_set_up_slack/  Could easily enough stick a new channel in there, I'd guess."
PowerShell,3bo15j,sid351,1 point,Wed Jul 1 16:05:43 2015 UTC,"https://github.com/dahlbyk/posh-git  And if you're working with any code, you should be learning git (or at least some VCS)."
PowerShell,3bo15j,JeepDon,2,Wed Jul 1 08:29:12 2015 UTC,Please don't let me get picked last.  I want to play too.  I need a project and someone to figure shit outwith.  Is there a limit to the scope of the project? or could we make several small projects that can be combined into 1 large project?
PowerShell,3bo15j,Not2original,2,Wed Jul 1 16:04:18 2015 UTC,"Reading the blog post from the Scripting (Guy's) Wife, it sounds like this year (and going forward) they're going to set monthly ""puzzles"".  Things aren't too detailed yet, but historically the games have evolved from ""create a one liner to do X"" to ""write a module that covers A, B, C, D and X"", so I'm expecting the puzzles to be pretty varied.  As far as us tackling them as a group, the logical way would be to ""chunk"" out the sections that make sense.  For example, if we have to find a bunch of files, then do something to the file names and then put them somewhere else, that would be 3 functions that would need to be written]...so 3 different ""smaller projects"".  Add in error handling and reviewing before submission, along with the fact we all have things going on in our lives, and you've got a need for a team to get something of decent quality turned around in a reasonable time frame."
PowerShell,3bo15j,sid351,3,Wed Jul 1 19:11:12 2015 UTC,"It's very much going to be a mixed bag. Very simple one liners for the first few (well, I think they're simple) and we will see how folks do. We will never push out newbies; they're the main audience for the Games. Promise."
PowerShell,3bo15j,shepismint,1 point,Thu Jul 2 03:22:16 2015 UTC,"Ok great! Thanks for the info I just really want more exposure to the language and syntax so I have something to sink my mind into.  I will do anything as I'm not very experienced with powersehll yet, But I have signed up for the MVA and watched all the jump starts with jason ans jeffery  plus some of the ones with Goetee."
PowerShell,3bo15j,ryanbrown,2,Wed Jul 1 19:18:27 2015 UTC,"Reply to edit: Let's do it. If you register the group I'll volunteer to do one of the first interactive sessions where we talk code.  I'm not sure if timescales are firm yet from the proper games, but I could talk about some former entries. Could dust off my 'Late to the party' blogs for the 2012 Games.  TL:DR; enough talk, lets make something happen :)"
PowerShell,3bo15j,bblades262,1 point,Thu Jul 2 22:04:47 2015 UTC,I'd love to get involved with this!
PowerShell,3bo15j,SomnambulicSojourner,2,Tue Jun 30 20:20:31 2015 UTC,"Don't you mean, you'd love to ""Git"" involved with this? ;)"
PowerShell,3bo15j,lostmojo,1 point,Tue Jun 30 20:46:00 2015 UTC,I'm absolutely willing to help. This communtiy has been great.
PowerShell,3bo15j,FantaFriday,1 point,Wed Jul 1 00:06:34 2015 UTC,"I suck, but I'd like to try"
PowerShell,3bo15j,madleprakahn,1 point,Wed Jul 1 00:34:56 2015 UTC,"Oooh, I'm in."
PowerShell,3bo15j,runliftdrink,1 point,Wed Jul 1 03:33:01 2015 UTC,"This sounds like a lot of fun, I'm down for it."
PowerShell,3bo15j,hematic,1 point,Wed Jul 1 05:09:16 2015 UTC,I'd be intereseted in joining a Powershell script team. As a student in IT and starter in Powershell which I mainly started just to create a bit more challenge for myself at school I would be very happy and interested to see what we can come up with and the possibilities of powershell.
PowerShell,3bo15j,Betterthangoku,1 point,Wed Jul 1 08:54:36 2015 UTC,I'd love to join a team!
PowerShell,3bo15j,EL337,1 point,Wed Jul 1 12:49:17 2015 UTC,I would love to join the team! Long time lurker. Just started getting my feet wet with PowerShell about a month ago. NIX convert
PowerShell,3bo15j,Rankath1,1 point,Wed Jul 1 13:13:06 2015 UTC,Id definitely love to join!
PowerShell,3bo15j,User_Yello,1 point,Wed Jul 1 13:16:19 2015 UTC,Sounds like a plan.  I also agree that our name shouldn't be too tongue-in-cheek though.  And I think git is the way to go (even more stuff for the un-initiated to pick up)  :-)
PowerShell,3bo15j,jeefke,1 point,Wed Jul 1 13:45:57 2015 UTC,I'm definitely in!
PowerShell,3bo15j,1RedOne,1 point,Thu Jul 2 00:56:15 2015 UTC,"I´m down! Where do I sign up?  Although \r\powershell only managed to finish one entry last year, the process of creating a script and discussing the various problems was so fun."
PowerShell,3bo15j,Waxmaker,1 point,Thu Jul 2 05:41:47 2015 UTC,"I'm in on this, I'd love to keep growing my skills with others in a group"
PowerShell,3bo15j,theseed,1 point,Thu Jul 2 08:46:17 2015 UTC,I'd love to join!
PowerShell,3bo15j,kusumuk,1 point,Thu Jul 2 19:30:50 2015 UTC,"This would be an awesome virtual users group. Most of the stuff I submit to my users group (AtlPug) I also share here anyway.   and while I do help out on PowerShell.org, I would consider myself an /r/powershell denizen first and foremost.   That being said, I must recuse myself from next month's puzzle... Because... Reasons."
PowerShell,3bnbww,Darkm27,10,Tue Jun 30 16:30:40 2015 UTC,This seems to be telling you that $PSCMdlet is null.  That would happen if you are using a function vs an Advanced Function   Try adding a [CmdletBinding()] directive.  Jeffrey Snover [MSFT]
PowerShell,3bnbww,jsnover,3,Tue Jun 30 17:53:17 2015 UTC,"I was just going to come here to say this, but by all means, take this guys' advice over mine any day. :)  Edit:  More specifically, if you're trying to execute $PSCmdlet.ThrowTerminatingError from the prompt or in an inline script, you're going to get this result since $PSCmdlet will be $null in those cases."
PowerShell,3bnbww,ryanbrown,2,Tue Jun 30 18:05:21 2015 UTC,"Note that you also need the Param() block (even if it's empty) for this to work.  Function Test-TTE {     [CmdletBinding()]     Param()      [System.Exception]$exception = ""Testing....""     [System.String]$errorID = 'FileIsEmpty'     [System.Management.Automation.ErrorCategory]$errorCategory =  [System.Management.Automation.ErrorCategory]::InvalidOperation     [System.Object]$target = 'C:\users'     $errorRecord = New-Object System.Management.Automation.ErrorRecord($exception, $errorID, $errorCategory, $target )     $PSCmdlet.ThrowTerminatingError($errorRecord) }  Test-TTE"
PowerShell,3bnbww,ryanbrown,3,Tue Jun 30 18:12:23 2015 UTC,"$target is referring to a directory, not a file"
PowerShell,3bnbww,occamsrzor,1 point,Tue Jun 30 16:58:41 2015 UTC,indeed
PowerShell,3bnbww,PostedFromWork,1 point,Tue Jun 30 17:06:31 2015 UTC,I have tried both pointing this at a file and setting it to $null both of which gave me the same error :/  I even get this error when directly copying script blocks from blogs that claim they work. It's almost like I'm missing an update constructor or something. I'm on powershell 4
PowerShell,3bnbww,occamsrzor,1 point,Tue Jun 30 17:09:08 2015 UTC,I suggest you learn how to use break points and debugging. It's an invaluable skill
PowerShell,3bnbww,KevMar,2,Tue Jun 30 17:12:11 2015 UTC,"You were close:  [System.Exception]$exception = ""Parameter ToPaths must contain 1 path or amount of paths equal to FromPaths"" [System.String]$errorId = 'FileIsEmpty' [Management.Automation.ErrorCategory]$errorCategory = [Management.Automation.ErrorCategory]::InvalidOperation [System.Object]$target = 'C:\users' $errorRecord = New-Object Management.Automation.ErrorRecord ($exception, $errorID,$errorCategory, $target) throw $errorRecord   Or if you don't need all those other details:  Throw ""Parameter ToPaths must contain 1 path or amount of paths equal to FromPaths"""
PowerShell,3bnbww,SenTedStevens,1 point,Tue Jun 30 18:00:25 2015 UTC,I ended up using throw write-error $errorRecord. Thank you for the suggestion
PowerShell,3bnwpb,ShiftNick,2,Tue Jun 30 18:56:35 2015 UTC,"Do you have a set username nomenclature? It'll be easier to take the first and last name for the user, then concatenate and increment until a viable username is found.   Ex: Someone is looking to create a user for John Smith   $i=1  Do{ $sAMAccountName = ($FirstName.substring(0,$i++).ToLower() + $LastName.ToLower())       Try   {$exists = Get-ADUser -LDAPFilter ""(sAMAccountName=$sAMAccountName)""}       Catch { }  }  Until ($exists -eq $null)   This will try jsmith, josmith, johsmith,johnsmith until an acceptable sAMAccountName is found"
PowerShell,3bnwpb,inaddrarpa,1 point,Tue Jun 30 19:21:11 2015 UTC,"I do have set nomenclature, it's first initial, lastname and my intent was to continue adding letters from the first name.  So,  this looks pretty good. One problem is I'm creating the $usam variable earlier in my function so I'm just not sure how I would make the incremental checks work.  Another question, why use the ldapfilter parameter as part of the verification?  Edit: Figured out where to put Do, Until.  Thanks."
PowerShell,3bnwpb,JaapBrasser,1 point,Tue Jun 30 19:34:53 2015 UTC,"Another question, why use the ldapfilter parameter as part of the verification?   Because you need to check if the account exists in Active Directory. Using a Filter or an LDAPFilter is required, unless you know the exact path of where the user would be stored then you could bind directly to the ADobject instead."
PowerShell,3bnwpb,JaapBrasser,1 point,Wed Jul 1 08:19:09 2015 UTC,"Gotcha. I don't generally use the LDAPFilter so, I thought maybe there was some other reason aside from the obvious  Thanks for the help folks!"
PowerShell,3bn0up,gingerbreaddave,3,Tue Jun 30 15:11:45 2015 UTC,"Taking a string, creating a file, and writing the string to the file for the sole purpose of reading the string back from the file immediately seems unnecessary, cut that part out.  There's also no reason to continue testing the length of the string, you can do it once and return $false if its wrong.  Here's how I would do it (http://pastebin.com/GYEa8GRh):  function Approve-ComputerName {     param(        [Parameter(Mandatory=$true)]        [ValidateNotNullOrEmpty()]         [string]$Name     )      if($Name.Length -ne 15){         return $false     }      if($Name[0] -notin ""D"",""F"",""S""){         return $false     }      return $true }"
PowerShell,3bn0up,PowerShellStunnah,1 point,Tue Jun 30 15:30:46 2015 UTC,Do strings have a length attribute in every version of Powershell? The function is going to be run on a few different machines and most of our environment isn't running Powershell 4.0  Something I read yesterday lead me to believe that I had to use Get-Content to measure strings. Obviously that's not true in 4.0
PowerShell,3bn0up,PowerShellStunnah,3,Tue Jun 30 15:41:18 2015 UTC,"Yes, the [string] class has had the Length property since version 1 of .NET  The -notin operator is introduced in PowerShell version 3.0, so you might want to change that if statement to:  if(@(""D"",""F"",""S"") -notcontains $Name[0])"
PowerShell,3bn0up,koltafrickenfer,1 point,Tue Jun 30 15:51:05 2015 UTC,I would imagine that the simplest way to do this would be with a   Get-Content $Path\temp.txt | foreach-object{ else statement here}   then out put that to another array/text file but Im not sure why you need to input the a file path but I would assume that was a pretty specific to your network / typology or something.. with that said I'm very confused on the way your populating your text file as it looks to me like your creating a blank one each time this function is ran then using the string input from your function to populate that text file.  In short I feel like it would have been easiest to just make sure you had all of your computers in one list which can very easily be managed as a array UNLESS your deployment is some how related to this part here  New-Item -ItemType File -Path $Path\temp.txt -Force $Name > $Path\temp.txt    I'm a long time lurker so if my post needs to be formatted or could look nicer I'm very sorry
PowerShell,3bn0up,PowerShellStunnah,2,Tue Jun 30 16:14:46 2015 UTC,Put 4 spaces in front of your code block to have it formatted nicely :)
PowerShell,3bnjgn,oddie121,2,Tue Jun 30 17:24:24 2015 UTC,"Cool stuff! You mentioned having a version that included SCCM patch stuff too, would you mind sharing that?"
PowerShell,3bnjgn,spoonstar,1 point,Wed Jul 8 16:35:35 2015 UTC,Sure! Give me a day to get it put in there and I'll get you the link
PowerShell,3bmlsc,Reset_Assured,2,Tue Jun 30 13:07:31 2015 UTC,"You may want to look into the FileWatcher Class.  It does pretty much exactly what you are looking for, no loop needed."
PowerShell,3bmlsc,LandOfTheLostPass,1 point,Tue Jun 30 14:41:38 2015 UTC,This is a little over my head and there isn't a powershell example. How would I implement this?
PowerShell,3bmlsc,real_parbold,2,Tue Jun 30 14:58:49 2015 UTC,Example of how to do a folder watcher in powershell  http://superuser.com/questions/226828/how-to-monitor-a-folder-and-trigger-a-command-line-action-when-a-file-is-created
PowerShell,3bmlsc,real_parbold,2,Tue Jun 30 15:21:19 2015 UTC,"My version of the linked code to watch the hosts file for modifications - it loops every 5 seconds until a file called 'C:\Scripts\FileWatcherStop.txt' is found  ### SET FOLDER TO WATCH + FILES TO WATCH + SUBFOLDERS YES/NO     $myWatcher = New-Object System.IO.FileSystemWatcher     $myWatcher.Path = ""C:\Windows\System32\Drivers\etc""     $myWatcher.Filter = ""hosts""     $myWatcher.IncludeSubdirectories = $false     $myWatcher.EnableRaisingEvents = $true  ### DEFINE ACTIONS AFTER A EVENT IS DETECTED     $myAction = {        if ( $myChangeType = ""Changed"" ) {         # We only care if the file was changed.         # Do something !       }     }  ### DECIDE WHICH EVENTS SHOULD BE WATCHED + SET CHECK FREQUENCY       $myCreated = Register-ObjectEvent $myWatcher ""Created"" -Action $myAction     $myChanged = Register-ObjectEvent $myWatcher ""Changed"" -Action $myAction     $myDeleted = Register-ObjectEvent $myWatcher ""Deleted"" -Action $myAction     $myRenamed = Register-ObjectEvent $myWatcher ""Renamed"" -Action $myAction      while ( -Not ( Test-Path ""C:\Scripts\FileWatcherStop.txt"" -PathType Leaf ) ) { Start-Sleep -Seconds 5}      Unregister-Event $myChanged.Id     Unregister-Event $myCreated.Id     Unregister-Event $myDeleted.Id     Unregister-Event $myRenamed.Id      Remove-Item ""C:\Scripts\FileWatcherStop.txt"""
PowerShell,3bmlsc,real_parbold,1 point,Tue Jun 30 15:25:35 2015 UTC,"I think my Xaml is throwing it off. It works without any gui, but with my xaml code in place it waits until after the window has been closed to notify the process... You can see my code here: https://gist.github.com/ResetAssured/d091c35c15e244ce7208#file-gistfile1-txt"
PowerShell,3bmlsc,footzilla,1 point,Tue Jun 30 18:27:27 2015 UTC,"My code is a pure ps1 script - yours exists within windows forms - I can do windows forms, but in this respect I am still an amateur...  I'm not entirely sure what you are trying to achieve - but when I need a responsive (and here I am assuming you are using a modal dialog box) - I have the form code, loop round calling [System.Windows.Forms.Application]::DoEvents() until a condition is met, before calling the exit/close routine.  This way, the windows forms events are processed and handled, and the form auto-closes after a predetermined time or event (close box still works)."
PowerShell,3bmlsc,occamsrzor,2,Wed Jul 1 08:47:46 2015 UTC,here's another example. I stumbled on this searching for how to unzip all files added to a certain directory. I haven't tried it yet.  http://blog.iisreset.me/2014/04/bigbrothershell-detect-and-suppress-those-files.html
PowerShell,3bmlsc,occamsrzor,1 point,Tue Jun 30 15:24:17 2015 UTC,"It should be noted that events and threading are still a little beyond the solid grasp of powershell.  I use it as a deciding factor on the language I use; if my app will require the use of eventing and/threading, I use C#"
PowerShell,3bn45y,takemeaway3135,2,Tue Jun 30 15:35:48 2015 UTC,"Try:    $csv = Import-CSV ""\\path\to\my\CSV\Termination Groups\$($reuser).csv"""
PowerShell,3bn45y,oddie121,1 point,Tue Jun 30 16:16:51 2015 UTC,That seemed to do it. Thank you for your help was pulling my hair out.
PowerShell,3bjzna,Stephanevg,4,Mon Jun 29 21:06:50 2015 UTC,Welcome to reddit /u/Stephanevg ! Great post!
PowerShell,3bjzna,lazywinadm,2,Mon Jun 29 22:14:42 2015 UTC,Thanks /U/LazyWinadm :)
PowerShell,3blxjs,xStimorolx,2,Tue Jun 30 07:51:29 2015 UTC,"Well, you can use a regex like ^+45(?:\s\d{2}){4}$ to identify any that are already in the format you want.  As for adding the spaces the simplest way I know is something like:  $number = ""+4512345678"" $number.insert(3,"" "").insert(6,"" "").insert(9,"" "").insert(12,"" "")"
PowerShell,3blxjs,the_spad,1 point,Tue Jun 30 08:03:19 2015 UTC,This is the solution. Using RegEx for something this simple is just silly.
PowerShell,3blxjs,cjluthy,1 point,Tue Jun 30 18:17:46 2015 UTC,It's also silly to take numbers that are already correct and perform a bunch of string manipulation tasks on them in order to make them the same as they were when you started.
PowerShell,3blxjs,the_spad,0,Tue Jun 30 19:39:42 2015 UTC,"I played with this :  ( ""+45 99 99 99 99"",""+4599999999"",""999999999"",""99 99 99 99"" ) | Foreach { if ( $_ -imatch [regex]'((\+45){0,1}(?<Tel>((\s*)(\d*)){8,20}))' ) {   Write-Host $( ( $matches['Tel'] -Replace ' ','' ).PadLeft(12,"" "").Insert(3,"" "").Insert(6,"" "").Insert(9,"" "").Insert(12,"" "").TrimEnd() )   } }   and I got ...       9 99 99 999      9 99 99 999     99 99 99 999      9 99 99 999   I just borrowed the inserts from /u/the_spad but I'm sure you could format them howerver you wanted.  The regex '((+45){0,1}(?<Tel>((\s)(\d)){8,20))' gets a match on 8-20 mixed numbers (with or without a +45 prefix) and spaces, removes all the spaces, pads the result to 12 (by adding spaces to the front) and then inserts spaces as per the_spad's comment."
PowerShell,3blxjs,real_parbold,0,Tue Jun 30 08:49:29 2015 UTC,"I would do something along these lines, regex to replace the spaces and to remove the +45 and insert to insert the spaces:  ""+45 xx xx xx xx"",""+45xxxxxxxx"",""xxxxxxxx"",""xx xx xx xx"" | ForEach-Object {     ($_ -replace '(\s)|(\+45)').Insert(2,' ').Insert(5,' ').Insert(8,' ') }"
PowerShell,3bmnmk,HalfVietGuy,1 point,Tue Jun 30 13:25:03 2015 UTC,"I'm a little confused; why do you need to write back to the CSV?  If you're pulling the constant paths from the CSV and then dynamically acquiring the others before running something against them, you can just add the dynamic paths to whichever variable you're holding the constant ones in.  Unless I'm missing something."
PowerShell,3bmnmk,the_spad,1 point,Tue Jun 30 13:33:29 2015 UTC,My idea was just that it would update the csv before loading it into the $varscsv variable. I think you're right that writing to the csv is unnecessary.   But I'm still confused on how I would add those dynamic paths and the 4th username to that variable after importing the others  from CSV.
PowerShell,3bk1tk,AzazelsAdvocate,2,Mon Jun 29 21:24:40 2015 UTC,"I can't tell you if there's other errors that might return that value or not. What I can tell you, is that I usually use $Error[0].Exception.GetType().FullName, not ...InnerException.ErrorCode. In fact, in both errors I just intentionally created, your command didn't return anything. One error was just entering a bunch of garbage letters and numbers and getting the ""not recognized as the name of a cmdlet, function...,"" and the other was running Get-ADUser against a non-existent user and getting the, ""Cannot find object with identity..."" Anyway, I just wanted to share that. In my experience, I code for the error I know of, and use a generic catch for any in which I'm unable to determine -- same as you've done."
PowerShell,3bk1tk,tommymaynard,2,Mon Jun 29 22:45:19 2015 UTC,"Woops, I actually did use $Error[0].Exception.GetType().FullName, but pasted the wrong command in my post (fixed now)"
PowerShell,3bjva9,agressiv,1 point,Mon Jun 29 20:34:49 2015 UTC,"When you're updating permissions on an object, you can choose ""Computers"" instead of, or in addition to, User objects. They're almost the same thing.  You're essentially giving LocalSystem of the remoting machine access to the target machine.  I haven't used it with powershell, tho."
PowerShell,3bjva9,mpaguilar,1 point,Tue Jun 30 14:53:20 2015 UTC,"I think that is an option that works with other management tools like SCCM, DSC or AD startup scripts or for any service running as system. i don't think you can as a user access resource that are open to the computer account.  But I would love to see how this is possible. (Other than using psexec).  To expand on the details above, sometimes you don't need that second hop like you think you do. For example, you want to remotely install something. Here are some options:   Use a URL to a download off a web server Pre copy it to the system using the $admin share (\server\c$) Invoke any built in updating systems (think SCCM or ninite)  Pull from a git repo If a VMWare VM,  use power CLI to push the file to the guest Use DSC to apply the changes Create a scheduled task then invoke it Use old school psexec.exe"
PowerShell,3bjuiu,RoninSpartan,3,Mon Jun 29 20:29:20 2015 UTC,would it work to prompt for credentials then they supply domain\username and password? $Credential = Get-Credential
PowerShell,3bjuiu,Frequentsy,1 point,Mon Jun 29 20:37:57 2015 UTC,Let me test that real quick
PowerShell,3bjuiu,Frequentsy,2,Mon Jun 29 21:43:37 2015 UTC,"Yeah I think it works when you use it, and then continue to use $Credential throughout the cmdlets in the script where credentials are required. So would append ""-Credential $Credential"" on the cmdlet"
PowerShell,3bjuiu,JaapBrasser,1 point,Mon Jun 29 21:54:09 2015 UTC,"Yes that does work with a little modification to the rest of the commands with:     -server $server -credential $credential  It seems I need to specify the server and credentials every time from a computer not on the domain  I also noticed another issue with my script, if the accounts have been disabled but not removed and the script is run again. It will pick up the disabled accounts again, given a ""technically correct"" count of the computers inactive but my be confusing when going through it.   I know it is possible to exclude the search/count for the already disabled computers. Just figuring out how :)  Edit: Pipe search-Adaccount | where {$_.enabled}"
PowerShell,3bjuiu,JaapBrasser,2,Mon Jun 29 22:26:36 2015 UTC,"It helps if you post a relevant portion of the script to highlight what your script does exactly. Otherwise you could prompt them for credentials in your script and use those credentials to start a new PowerShell session, for example using runas or a remote session using the credentials that were given by the end user."
PowerShell,3bjuiu,JaapBrasser,1 point,Mon Jun 29 20:44:05 2015 UTC,I've added the first portion of the script to the post
PowerShell,3bjuiu,JaapBrasser,2,Mon Jun 29 21:43:55 2015 UTC,"I see, so what you could do is to add in the -Credential parameter for all the relevant cmdlets that require the permissions. The Search-ADAccount and Set-ADComputer cmdlets are the ones that come to mind."
PowerShell,3bjuiu,JaapBrasser,1 point,Tue Jun 30 07:46:27 2015 UTC,It would be all that gather info from the domain or do something to the domain.  So pretty much every command and then specify the domain controller of the domain.  I got it working though
PowerShell,3bjuiu,pandiculator,1 point,Tue Jun 30 11:06:12 2015 UTC,"Great, a good idea could be to put the credentials and the domain controller in a hash table so you can splat it into each cmdlet instead of manually specifying it. This way, if you ever need to update the account or the dc it will be easier to implement. For example:  $Credential = Get-Credential $ADCredSplat = @{     Credential = $Credential     Server = 'YourFavoriteDC' } Get-ADComputer -Parameter1 Argument1 -Parameter2 Argument2 @ADCredSplat"
PowerShell,3bjkso,Sn0zzberries,2,Mon Jun 29 19:21:17 2015 UTC,"If memory serves... 1603 is the ""I have no clue what just happened"" error. Have you tied running the uninstall with logging? Just add /L*v c:\whatever.log to your command line."
PowerShell,3bjkso,the_gruffalo,1 point,Mon Jun 29 20:07:58 2015 UTC,"Here is the source of the fault from within Install Sheild:  Action start 13:20:22: ISStartup. 1: The InstallScript engine version currently installed on this machine is adequate.  MSI (s) (14!B0) [13:20:22:367]: PROPERTY CHANGE: Adding ISStartupEvent property. Its value is 'E2022351'. 1: Event 'E2022351' is created  1: GetInstallDriver, Can not find InstallDriver in ROT table, Return Code = 0x80004005  1: {3a3a86d2-041e-4c2a-a6fd-61e7d38ce4a7}  1: Extract supporting files  1: Failed to extract _IsUser.dll, Ignore it.  MSI (s) (14!B0) [13:20:23:334]: Note: 1: 2732 2: 0  MSI (s) (14!B0) [13:20:23:334]: Note: 1: 2732 2: 0  1: Failed to extract IGdi.dll, Ignore it.  1: Ev60958976  1: ISMsiServerStartup Failure, Failed to Open the shutdown event, Error = 0x36b7 1: MsiServerStartup failed. Abort installation.  CustomAction ISStartup returned actual error code 1603 (note this may not be 100% accurate if translation happened inside sandbox) Action ended 13:20:23: ISStartup. Return value 3. MSI (s) (14:3C) [13:20:23:381]: Doing action: ISCleanUpFatalExit CustomAction ISMsiServerStartup returned actual error code 1603 but will be translated to success due to continue marking MSI (s) (14:3C) [13:20:23:381]: Note: 1: 2235 2:  3: ExtendedType 4: SELECT `Action`,`Type`,`Source`,`Target`, NULL, `ExtendedType` FROM `CustomAction` WHERE `Action` = 'ISCleanUpFatalExit'  Action start 13:20:23: ISCleanUpFatalExit. MSI (s) (14:F4) [13:20:23:381]: Invoking remote custom action. DLL: C:\Windows\Installer\MSIBAEB.tmp, Entrypoint: CleanUp Action ended 13:20:23: ISMsiServerStartup. Return value 1603. 1: Shutting down the PRC server...  1: RPC runtime reported exception 0x6ba  Action ended 13:20:23: ISCleanUpFatalExit. Return value 1. Action ended 13:20:23: INSTALL. Return value 3.   Looks like the culprit?  1: ISMsiServerStartup Failure, Failed to Open the shutdown event, Error = 0x36b7"
PowerShell,3bjkso,the_gruffalo,2,Mon Jun 29 20:36:48 2015 UTC,Looks like a problem with your installshield install it can have issues if you are running remotely as described here https://community.flexerasoftware.com/showthread.php?149462-Unattended-installation-quot-Failed-to-Initialize-script-support-quot-problems/page2 I don't know if there if a fix as such as its a bug in ISS. On the bright side... it's not your code.
PowerShell,3bjkso,the_gruffalo,1 point,Mon Jun 29 20:49:48 2015 UTC,That looks very promising.  I will read it after this next meeting.  Cheers!
PowerShell,3bjkso,Eppmah,1 point,Mon Jun 29 20:52:38 2015 UTC,"Good find!  After reading through that stuff and doing some testing the issue was caused by the identity which the DCOM started as. (Probably a lingering issue from pre-UAC days).  For my version of the InstallSheild InstallDriver DCOM object the following solved the permissions issues:  Remove-ItemProperty ""HKLM:\SOFTWARE\Classes\AppID\{DEF67AFC-20D3-4ED3-8DE2-7A14E1C72E28}\"" -Name RunAs Start-Process ""msiexec.exe"" {...}"
PowerShell,3bjkso,I_Need_Cowbell,2,Wed Jul 1 15:48:52 2015 UTC,Nice one. Glad you got it sorted :)
PowerShell,3bjkso,shepismint,1 point,Wed Jul 1 15:56:31 2015 UTC,Are you running the script in an elevated prompt? I was recently working on a remote installation/uninstallation script and it wouldn't work unless I ran it from an administrative prompt.
PowerShell,3bjkso,shepismint,1 point,Mon Jun 29 19:28:20 2015 UTC,"Yep, the Start-Process cmdlet has the parameter for -Verb which allows runAs (aka Run As Administrator).  Edit: although I just pulled the verb table for an MSI and there is no runas verb. I tried the uninstall verb too, but recieved a seperate error."
PowerShell,3bi9bg,lazywinadm,1 point,Mon Jun 29 13:12:39 2015 UTC,"I'd be really curious to see the performance of this method vs. using EWS. I was tasked with building an out of office calendar that managers could use to schedule projects. It needed to show all out of office events for every employee within a certain time period.  I put one together using EWS that did what was needed, but it seemed like it took around 5 seconds per mailbox, which was fine in that organization of about 400 people, but would have scaled up badly.  I've moved onto another job where we have on-premise Exchange, so I have no way to test now."
PowerShell,3bi9bg,anklegrinder,1 point,Mon Jun 29 15:48:04 2015 UTC,"it would be probably faster. With the method I showed in my article, it took me 800ms to query the events for the next months, for one user.  I'm just getting started with O365 so I don't know yet If I can query multiple users calendars events efficiently (with one rest query)"
PowerShell,3bi9bg,anklegrinder,1 point,Mon Jun 29 22:27:49 2015 UTC,"That's definitely better. My script ran much faster if I reran it immediately, so I think it was relying on the content crawler to get its results. If the API doesn't go through that process, I bet it would blow my approach out of the water. Do you notice a difference if you query a mailbox that hasn't been queried recently?"
PowerShell,3bg51b,wormeyman,9,Sun Jun 28 22:47:52 2015 UTC,Is this in response to the new trapezoidal screen resolution standard?
PowerShell,3bg51b,HalalVeggieBacon,2,Sun Jun 28 23:10:11 2015 UTC,I'm not sure what you mean?
PowerShell,3bg51b,HalalVeggieBacon,5,Sun Jun 28 23:30:28 2015 UTC,I'm just being silly.
PowerShell,3bg51b,searlicus,2,Sun Jun 28 23:34:11 2015 UTC,oh you
PowerShell,3bg51b,HalalVeggieBacon,1 point,Mon Jun 29 10:32:52 2015 UTC,;)
PowerShell,3bg51b,ScientologistHunter,2,Sun Jun 28 23:37:43 2015 UTC,:-)
PowerShell,3bg51b,thebeersgoodnbelgium,1 point,Sun Jun 28 23:40:31 2015 UTC,:D
PowerShell,3bg51b,No1Asked4MyOpinion,1 point,Mon Jun 29 12:26:41 2015 UTC,"https://www.dropbox.com/s/8jnh20g1wh578cf/PowerShell-Icon-10130.zip?dl=1  I extracted this from Windows 10 build 10130, I quite like the new flat look. If this violates any trademarks or copyright please let me know."
PowerShell,3bhuam,tomerc10,3,Mon Jun 29 10:05:42 2015 UTC,New-aduser creates new accounts. You can use remove-adobject to delete them. These don't need you to interact with a psprovider.  The best way to delete the last one created is to not create it in the first place.
PowerShell,3bcy4u,EL337,6,Sun Jun 28 01:11:02 2015 UTC,"Write-Error and Write-Warning are both good alternatives if that is what you are trying to output in a different color.  I use them a lot with Write-Verbose in my scripts. In most cases, those are the optimal ways to display output within your scripts and functions.  I would recommend starting with those and see if they get the job done for you.  A lot of people shun the use of Write-Host because it tends to limit what you can do with powershell.  The command its self is not bad but it takes you in a scripting direction that builds bad habits. With that said, it is still a tool. If you have a controller script that must output in different colors, then you will have to use Write-Host."
PowerShell,3bcy4u,KevMar,3,Sun Jun 28 01:52:49 2015 UTC,"Yeah, isn't this the exact use case for write-host? For when you want to write text, possibly colored, to a live console?"
PowerShell,3bcy4u,chimney3,6,Sun Jun 28 19:41:55 2015 UTC,"Write-Output does not send objects or text to the screen, it ends them to the next command in the pipeline. If there is nothing at the end of the pipeline, it implicitly sends them to out-default. see: http://blogs.msdn.com/b/powershell/archive/2006/04/30/how-powershell-formatting-and-outputting-really-works.aspx  You could create a custom filter like this, though:  filter out-default { $_ | write-host -foregroundcolor red }"
PowerShell,3bcy4u,gsamuelhays,1 point,Sun Jun 28 04:52:18 2015 UTC,I had no idea what a filter was. I had to go look it up and learned something new.
PowerShell,3bcy4u,KevMar,1 point,Sun Jun 28 05:32:59 2015 UTC,great article!   That command is taking my object and piping it to write-host which I am trying to avoid because it destroys the object formatting.  I have a nice custom object with all of the data i want.  It prints perfectly with just write-output $obj
PowerShell,3baicl,bundyfx,5,Sat Jun 27 09:53:48 2015 UTC,oh btw. We should make a reddit/r/PowerShell team!
PowerShell,3baicl,sid351,2,Sat Jun 27 09:57:13 2015 UTC,"Count me in. How do we want to organise ourselves?  Obviously the sub is one way for us to contact each other, but it's not very good for real-time discussions.  We could organise regular Google Hangouts, group Skype chats or something similar.  I'm happy to help organise but my job can make me super busy all of a sudden, so can't commit to being the sole organizer."
PowerShell,3baicl,Sn0zzberries,2,Sat Jun 27 19:01:08 2015 UTC,I would be up for working on the team as well.  Could start with just having a sign up for the next couple weeks stickied on the sub.  Calling for advice:   /u/malice8691 /u/Davotronic5000 /u/derekhans
PowerShell,3baicl,invoke-coffee,3,Sat Jun 27 19:37:57 2015 UTC,I think having a Reddit PowerShell team is a great idea.  I'll put up a sticky post on Monday to start getting organized and see what kind of response we get.
PowerShell,3baicl,Waxmaker,1 point,Sun Jun 28 07:00:33 2015 UTC,Good Idea. Google hangouts sounds like a good idea also for real time discussion!
PowerShell,3baicl,ginolard,2,Sat Jun 27 22:26:03 2015 UTC,I would be up for that as well.  Github would probably be a decent platform to do most of the collaboration.
PowerShell,3ba3rr,catacombkid1,2,Sat Jun 27 06:01:50 2015 UTC,"Something like this should work:  Get the mailbox size for each user.  Add a NoteProperty for each user to the input object (the row in the CSV).  Add the updated object to a collection of objects.  Export the collection to a CSV.   I have made the output file UserList2.csv to avoid overwriting the original.   $staff = Import-Csv .\UserList.csv  $output = @()  foreach ($user in $staff) {      $mailboxSize = Get-Mailbox -Identity $user.alias | Get-Mailboxstatistics | Select-Object TotalItemSize      $obj = Add-Member -InputObject $user -MemberType NoteProperty -Name ""BoxSize"" -Value $mailboxSize -PassThru     $output += $obj  }  $output | Export-Csv .\UserList2.csv -NoTypeInformation"
PowerShell,3b86w6,nonades,8,Fri Jun 26 19:21:41 2015 UTC,"Ok, lets go over to MS connect and give them our feedback on this one: https://connect.microsoft.com/PowerShell/feedbackdetail/view/1477214/cmdlets-for-remote-windows-updates-over-pssession-or-over-winrm"
PowerShell,3b86w6,KevMar,6,Fri Jun 26 20:56:45 2015 UTC,"The problem lies at a deeper level than just PowerShell.  the Windows Update API continues to have a list of Interfaces which are not supported on remote connections.  Chief among them are IUpdateSession::CreateUpdateDownloader and IUpdateSession::CreateUpdateInstaller method.  So long as the WUAPI team keeps those locked down to the local machine only, we'll have to keep using hacks to get around that.  Granted, the PS team could probably take something like the task scheduler hack and wrap it in a cmdlet; but, I suspect they won't do that as it isn't a completely reliable way to do it."
PowerShell,3b86w6,LandOfTheLostPass,2,Fri Jun 26 19:36:03 2015 UTC,"I've poked through the module and have read a bunch of docs about this issue, I was just hoping the WUAPI team pulled their collective heads out of their collective asses.  It'd be rad if I could run updates on a dynamic schedule natively."
PowerShell,3b86w6,LandOfTheLostPass,1 point,Fri Jun 26 20:07:13 2015 UTC,"It would be nice to have that ability.  Best I have been able to come up with is using PSExec to launch a PowerShell script (basically what PoshPAIG does).  It's a crap workaround; but, sometimes you just do what you gotta do to get the job done."
PowerShell,3b86w6,da_chicken,2,Fri Jun 26 21:21:17 2015 UTC,I suspect they won't do it because the Microsoft Approved Solution™ to patch management is WSUS/SCCM.
PowerShell,3b86w6,boeprox,1 point,Fri Jun 26 22:52:22 2015 UTC,This is by far the biggest annoyance that I have with patching using PowerShell. I've spent far too much time testing workarounds only to have them fizzle out just when I think I am on to something. Still on my bucket list to lose the PSExec (or Scheduled Task) dependency.
PowerShell,3b86w6,oddie121,1 point,Sat Jun 27 02:41:08 2015 UTC,"To add to this, the searcher objects and install objects are still legacy com+ thay from my understanding weren't meant to be called remotely. I did find a way to get the results remotely from the com searcher object but to do the install command still requires a vbs script to be copied locally and executed locally (this is how posh peg does it). So you can do it within powershell, it's mostly a bunch of work arounds that you have to do. If you want more info on how to do it let me know."
PowerShell,3b86w6,Frequentsy,3,Sat Jun 27 10:25:53 2015 UTC,Not sure if you're interested in managing Windows Update outside of Powershell but BatchPatch is a useful tool for the job: https://batchpatch.com/ Not free for managing more than 5 comps and getting more features.
PowerShell,3b86w6,malice8691,2,Fri Jun 26 21:01:14 2015 UTC,This is on my list of things to try but my understanding is that boxstarter can do remote windows updates
PowerShell,3b86w6,iwifia,2,Fri Jun 26 22:03:13 2015 UTC,"I honestly can't remember if it was in the chocolatey repo on github or the powershell main repo but one of them has a goal to incorporate windows updates via ps.  I think using the repo in PS5 is the first step to making this happen, also from my understanding the new API in W10 should allow this to be much easier and more flexible.   In the end I am surprised that this was not with PS4 even."
PowerShell,3b86w6,cryolyte,1 point,Fri Jun 26 22:44:46 2015 UTC,"I'm not sure what the exact question is, but I've been using PoshPAIG to do this."
PowerShell,3b86w6,Frexspear,1 point,Fri Jun 26 19:42:55 2015 UTC,"That's not a cmdlet that can install windows updates, that's a GUI written in Powershell.  /u/LandOfTheLostPass basically nailed my frustration."
PowerShell,3b86w6,KevMar,1 point,Fri Jun 26 20:01:46 2015 UTC,https://poshpaig.codeplex.com/
PowerShell,3b8psd,UntrustedProcess,8,Fri Jun 26 21:46:34 2015 UTC,I'm using DSC to deploy systems off of a removable drive. (deployments without internet/network connections). I don't think many people are doing that.  I have just started making Let's Play Powershell videos on youtube where I mumble about things with a poor mic while I slowly write code. I am sure they are a little painful to watch but I hope to get better at it over time.
PowerShell,3b8psd,KevMar,1 point,Fri Jun 26 22:20:34 2015 UTC,"I'm curious about your offline DSC builds. At first I thought of client PCs, then I realized DSC doesn't work on them. So in what situation are you setting up offline servers? Are you pre-building them in anticipation of connectivity? Are you using djoin to put them on a domain offline? Whatever you're doing, it sounds cool."
PowerShell,3b8psd,midnightFreddie,2,Fri Jun 26 22:42:10 2015 UTC,"I need to be a little vague on some details but it boils down to having physical nodes in closed client networks that interact with special systems. In some cases we can get VPN connections but in others, someone has to physically be on site to interact with them.   The techs that work on them in the field and that perform the build outs know just enough to follow a check sheet and do minimal troubleshooting (Some are great but we have to account for the lowest common denominator). So I use removable media that on boot, deploys a wim to the hardware. When it comes up, it invokes the dsc config off the same media and does the rest of the set up.   In some cases, I replaced the check sheet with a boot to media guide. Others nodes need some additional manual steps but I am trying to eliminate as much as possible. The cool thing about this is the build out process at headquarters and live in the field is the same media and the same steps.   I am also pulling this process back into testing and development so their systems use the same DSC scripts (but pull from a share instead).  And you can use DSC on client OS's. The issue is the type of configuration you do on a client OS is a lot more complicated to account for users. I had to write a lot of DSC resources to account for user type scenarios."
PowerShell,3b8psd,KevMar,1 point,Fri Jun 26 23:14:30 2015 UTC,"Very cool, thanks.    And you can use DSC on client OS's. The issue is the type of configuration you do on a client OS is a lot more complicated to account for users. I had to write a lot of DSC resources to account for user type scenarios.   Errrr? I'd love to hear more about that. I tried DSCing Win10 preview and coudn't apply a config or find the LCM. Which clients have you DSCed?  Edit: I mentioned my client-DSC attempt here: http://www.reddit.com/r/PowerShell/comments/36l68k/oneget_and_chocolatey/"
PowerShell,3b8psd,midnightFreddie,1 point,Fri Jun 26 23:21:25 2015 UTC,"With the Management Framework 4.0 on Windows 7, you can use DSC. While DSC works, not all modules are compatible with Windows 7 (or Server 2008r2). For example the resource that adds windows features is server OS only. The DSC network resource uses 2012 powershell commands (or did at one time).  I took a quick look at your post and my only comment is that I have not really worked with powershell 5 or DSC on Windows 10.  I would say to test something dead simple on that windows 10 box first.  cd $env:temp configuration test {     node localhost {         file TestFile         {             DestinationPath = ""c:\temp2""             Type            = ""Directory""         }     } }   Test Start-DSCConfiguration .\test -wait -verbose   Verify you can get DSC working then move onto the other things."
PowerShell,3b8psd,KevMar,1 point,Sat Jun 27 00:18:10 2015 UTC,"no Ensure = ""Present"" ? ;)"
PowerShell,3b8psd,zenmaster24,1 point,Sat Jun 27 09:37:06 2015 UTC,That is what the default value is so you don't have to specify it.
PowerShell,3b8psd,KevMar,1 point,Sat Jun 27 14:45:45 2015 UTC,Can I have a link to your youtube channel?
PowerShell,3b8psd,davidlwdn,2,Mon Jun 29 19:59:08 2015 UTC,http://youtube.com/kevinmarquette
PowerShell,3b8psd,KevMar,1 point,Tue Jun 30 12:35:20 2015 UTC,Enjoying the modules video now! Thanks Kev!
PowerShell,3b8psd,davidlwdn,1 point,Tue Jun 30 20:29:26 2015 UTC,Any requests?
PowerShell,3b8psd,KevMar,6,Tue Jun 30 21:41:08 2015 UTC,"I'm a developer and use PowerShell to support development. For each project I am working on, I create a PowerShell module that contains functions for checking out the code, backup and restore databases, making builds with the correct set of dependencies and configuration, generate deployable artifacts, running unit tests,... In essence, my goal is that any task that must be done more than once, should become a function in that PowerShell module. This is very useful, because it allows new developers on the project to setup a development environment very fast, and it also ensures that fewer mistakes are made while creating releases, because as much as possible is automated.  Currently using PowerShell 4 on Windows 7, but looking forward to Windows 10 because it has much more PowerShell modules and functionality built in."
PowerShell,3b8psd,rvdginste,1 point,Sat Jun 27 09:48:05 2015 UTC,"Great idea, thanks for sharing this."
PowerShell,3b8psd,mikorun,5,Sat Jun 27 17:30:49 2015 UTC,"I wrote a massive module that performs a variety of esoteric email operations that we need for one reason or another. For example, it takes a user's Inbox and copies the entire contents to some folder as .msg files, complete with the original folder structure.  Another example: it can take a .PST file and copy the contents into a SQL database: sender, recipient, subject, body, attachments, etc... each is a field in the database where the respective data gets copied.  It can also perform all these operations in reverse, i.e. from SQL to .PST or account Inbox, etc.  The set of commands in the module makes full use of pipelining so that precisely the data needed is processed via the use of filters and stuff.  It's unusual because the time investment put into writing it versus its relative uselessness still astounds me sometimes.  EDIT: Bah. Since so many of you want to see this, then here it is: do with it what you will. Standard disclaimer here: I make no warranties and may not provide support, though I would be interested in thoughts in general on it. This will probably not even work for you unless it is heavily modified for your specific use-case scenario. As it is written, it expects administrative access to AD to read/write custom groups for permissions purposes. You may not want to go down this rabbit hole. You have been warned."
PowerShell,3b8psd,dragonmc,5,Sat Jun 27 05:26:10 2015 UTC,"Sharing would help to increase the use, thus help justifying the time you've spent writing it :-)"
PowerShell,3b8psd,Stoffel_1982,1 point,Sat Jun 27 05:40:31 2015 UTC,Yes! I'd love to see this code.
PowerShell,3b8psd,thebeersgoodnbelgium,3,Tue Jun 30 12:28:26 2015 UTC,"Are you using the Outlook Com object to manipulate the PST?  or is there a way to do it in pure Powershell?  I was looking at methods of merging pst files into a single file, but the Com method was the only way I could seem to manipulate them. (I know there are products that can do this)."
PowerShell,3b8psd,fooATfooDOTcom,2,Mon Jun 29 03:11:06 2015 UTC,"That is exactly what it uses. I looked into other (supposedly easier) ways such as Redemption and EWS but they all had their downsides, so I ate the steep learning curve of learning the  rather poorly documented OOM, but I'm actually quite glad I did."
PowerShell,3b8psd,dragonmc,2,Mon Jun 29 04:17:52 2015 UTC,That sounds like a fun project. I love looking at something and thinking there has to be a better way. Then coming up with a script or some other hack that makes it better. I find them to be the most rewarding.    along the way you now understand .pst and outlook in a whole different way. Good exposure to SQL if you had not had it before. And it is a good story to use at your next job interview.
PowerShell,3b8psd,KevMar,2,Sun Jun 28 01:58:52 2015 UTC,"PSTs must die. I'd love to have code to convert a PST to a folder-structure with msgs. Shitty, but searchable and usable way to access emails without psts."
PowerShell,3b8psd,gomibushi,3,Fri Jul 3 22:19:51 2015 UTC,"I'm using PS at a school district to query student attendance data in a SQL db, build HTML records of students with unexcused absences, and email nice looking email reports to teachers throughout the schools so they  can direct students to the school office."
PowerShell,3b8psd,mikorun,5,Sat Jun 27 08:41:42 2015 UTC,Created an powershell GUI application which uses Nikon and Canon SDKs to control said brand camera's for product capture and image post processing.
PowerShell,3b8psd,opicron,3,Sun Jun 28 16:23:10 2015 UTC,this is the most impressive of the bunch for me so far
PowerShell,3b8psd,chewb,2,Mon Jun 29 20:52:55 2015 UTC,"Thanks, you should see the LED table to automatically create the masks for transparent backgrounds ;)."
PowerShell,3b8psd,opicron,2,Mon Jun 29 22:07:16 2015 UTC,I made a custom powershell script that uses someone else's PS tellstick module that outputs XML for a PRTG monitoring sensor ... Of temperatures from my tellstick (433.92mhz) temp sensors in my chicken coop.
PowerShell,3b979k,sneezycheesy,2,Sat Jun 27 00:21:09 2015 UTC,Formatting should always be the very last thing that you do and the Format-Table is the cause of your problem.  Pretty much never assign a Format-* cmdlet to a variable; when you use that variable again you'll get unexpected results because what you have is an object that contains special formatting that is only understood by the Out-* cmdlets.  Try changing it to Select-Object so that you're building a hash table.
PowerShell,3b979k,pandiculator,1 point,Sun Jun 28 16:18:37 2015 UTC,"Ughhhh christ, I knew it was something obvious!  Thank you, so much. I've been so buried in powershell lately that I missed the obvious steps.  For those interested, this is the completed statement  $neededupdates = $wsus.GetSummariesPerUpdate($updatescope,$computerscope) | Select-Object @{L='UpdateTitle';E={($wsus.GetUpdate([guid]$_.UpdateId)).Title}}, @{L='NeededCount';E={($_.DownloadedCount + $_.NotInstalledCount)}}, UpdateID  $updates = $neededupdates | where {$_.NeededCount -gt 0} | Select UpdateID"
PowerShell,3b979k,pandiculator,1 point,Mon Jun 29 14:31:43 2015 UTC,"Well, I spoke to soon.   The new command gives me the following output  UpdateId -------- 014243df-26fe-4ca5-9c8e-096d1e49c35e aa0289a0-34fa-4b84-b307-7dd4a2806e5b 4031dac5-76ac-4b30-bd98-05f16a19587b cd2770fa-64c7-463b-a975-339fff108caf 00b4bac6-0c3d-4a27-8101-f31b539e4e7e ae914aa2-8737-46dd-ae8f-ea392b377687 6e05f6a1-4011-4dfb-acae-ce2e271b97b7 4a16d6dd-d3a2-46f2-9356-c4312134a81f 8ed5bbc6-ac2f-45b0-984b-a4d74f8b3471 7bf916bc-e83b-4020-bf85-a7c73e737eed   Great! Except, now if I run the foreach statment  ForEach ($Item in $updates) {        $Update = $wsus.GetUpdate($Item)     Write-Verbose ""Install $($Update.title) on $($TargetGroup.name)"" -Verbose      $Update.Approve(""Install"",$TargetGroup) }       I get the following error  Method invocation failed because [System.String] doesn't contain a method named 'Approve'. At line:4 char:5 +     $Update.Approve(""Install"",$TargetGroup) +     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : InvalidOperation: (:) [], RuntimeException     + FullyQualifiedErrorId : MethodNotFound  Cannot find an overload for ""GetUpdate"" and the argument count: ""1"". At line:2 char:5 +     $Update = $wsus.GetUpdate($Item) +     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : NotSpecified: (:) [], MethodException     + FullyQualifiedErrorId : MethodCountCouldNotFindBest   This is odd. We're giving it a GUID like we were before, but it looks like the search just isn't working in the foreach statement.   I've verified that each of the variables have data. They do.  I've even tried putting a out-string in here, but that isn't working for me.   I don't really want to search tens of thousands of updates and select the ones where the GUID matches the search. I can do that, and I'm pretty sure it'll work, but this one isn't making sense to me"
PowerShell,3b979k,boeprox,1 point,Mon Jun 29 15:29:08 2015 UTC,"I'm not familiar with the WSUS methods.  However, I found this article by /u/boeprox.  He's doing it like this $wsus.GetUpdate([guid]” fc08b450-6bdd-400e-9a1a-2f86e23ce462”).  So perhaps you need to cast $item?  $wsus.GetUpdate([guid]""$item"")"
PowerShell,3b979k,pandiculator,1 point,Mon Jun 29 18:37:14 2015 UTC,"Hmm, that came up with this. I'll keep digging, I appreciate your   efforts!   Cannot convert value ""@{UpdateId=7bf916bc-e83b-4020-bf85-a7c73e737eed}"" to type ""System.Guid"". Error: ""Guid should contain 32 digits with 4 dashes      (xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx).""     At line:3 char:5     +     $Update = $wsus.GetUpdate([guid]""$Item"")     +     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~         + CategoryInfo          : InvalidArgument: (:) [], RuntimeException         + FullyQualifiedErrorId : InvalidCastParseTargetInvocation"
PowerShell,3b979k,boeprox,2,Mon Jun 29 20:02:23 2015 UTC,Try specifying the updateid property of the object instead of the whole object.  $Update = $wsus.GetUpdate([guid]$Item.updateid)
PowerShell,3b85da,kylesaurus,5,Fri Jun 26 19:10:22 2015 UTC,"When you run a sql powershell command, it's automatically importing the sqlps module which includes loading the SQLSERVER: provider, but the module doesn't get auto-imported if you just try accessing the provider alone.  Type the following line before trying to access the provider and it should work:  Import-Module sqlps   This will also automatically flip you into the provider location; use the following to prevent potential inconvenience:  push-location Import-Module sqlps   Then you can use ""pop-location"" to get back to where you were before you imported the sqlps module."
PowerShell,3b85da,Waxmaker,2,Fri Jun 26 21:00:22 2015 UTC,"Thank you!  I ran it with your suggestion and it worked once.  Now it's not working at all again.  Closed PS and opened a new session, still nothing.  Can you see anything wrong with the script?  I tried to make it simple, for a single database.  DB backup Script:  $date = Get-Date -Format MM-dd-yyyy  $destination = ""C:\path_to\backup_location""  $db = ""SQLSERVER:\SQL\Server_Name\DEFAULT\Databases""  Push-Location  Import-Module sqlps  cd $db  Backup-SqlDatabase -Database DatabaseName -BackupFile ""$destination\Database_Name$date"""
PowerShell,3b85da,midnightFreddie,3,Fri Jun 26 21:41:30 2015 UTC,"http://www.midnightdba.com/Jen/2013/05/quick-tip-navigating-to-a-unc-within-sqlps/  Is your backup location on a UNC share? (I know it isn't in your example, but do I really believe you're backing up to C:?) Then maybe the problem and workaround in the link is releveant to you.  Or perhaps instead of using cd $db you could do something like this, where I use Pop-Location to get back out of SQLSERVER:  Push-Location Import-Module sqlps Pop-Location Backup-SqlDatabase -Database ""$db\DatabaseName"" -BackupFile ""$destination\Database_Name$date"""
PowerShell,3b85da,dstrait,3,Fri Jun 26 23:01:43 2015 UTC,"Are you running that command on the same computer where the SQL Server service is running or is the SQL Server service running on a server somewhere else? Does $destination path exist on the server or does it exist only on your workstation? IIRC, that path needs to be on the server because the SQL Server service needs to be able to access that path. Or you need to use a UNC path and the SQL Server service needs to run under an account with appropriate permissions to access that UNC."
PowerShell,3b85da,dstrait,1 point,Fri Jun 26 23:42:22 2015 UTC,"The script is being run from the server I am backup up.  The  backup location is also on the same server.  The server houses the script, database, backup location.  For now.  What do you mean by this?: "" IIRC, that path needs to be on the server because the SQL Server service needs to be able to access that path. """
PowerShell,3b85da,KevMar,2,Mon Jun 29 15:22:33 2015 UTC,"A common problem is not realizing that the path you provide for the backup must be an existing path that the server can get to. I've seen countless people provide a path that is only on the workstation they normally work from. You seem to have that worked out, so your problem is elsewhere."
PowerShell,3b85da,TheFirstRuKuS,2,Mon Jun 29 16:14:26 2015 UTC,"I am guessing the SQLServer drive is not mounting until the module is loaded. Powershell is dynamically loading the module when you issue a command. That is why it works after you run any command.  # verify it is not loaded Get-PSDrive -Name *SQL*  Import-Module SQLPS  # verify it is loaded Get-PSDrive -Name *SQL*   By running that import command (or adding it to your $profile), the sqlserver drive will show up."
PowerShell,3b879b,jfractal,1 point,Fri Jun 26 19:24:00 2015 UTC,"I did google search for openmanage powershell - turned up an old module (may work), reference to WMI module (you might be able to access OM stuff that way if it's still there) and a server health script (leverage that to see how it works and whether it covers what you're looking at.)  Also, the command you listed works with virtual disks.  I'm not sure they won't abstract away the physical health information you are looking for."
PowerShell,3b879b,xalorous,1 point,Fri Jun 26 21:45:47 2015 UTC,"Hello,  Yeah, I've googled pretty extensively on this, and it's not so much having the monitoring tools as it is figuring out PowerShell better.  I'm trying to get better at parsing text and turning that text into objects or hashtables."
PowerShell,3b879b,xalorous,1 point,Fri Jun 26 22:01:01 2015 UTC,PS is about managing objects where bash/perl are about parsing text.  But you could probably build a script that parses that output into PS object.  I suggest you research advanced functions and modules in powershell.  Build your functions into a module and share it when it is ready.
PowerShell,3b879b,KevMar,1 point,Fri Jun 26 22:25:40 2015 UTC,"If you are playing with Powershell 5, this looks like a good opportunity to play with ConferFrom-String http://blogs.msdn.com/b/powershell/archive/2014/10/31/convertfrom-string-example-based-text-parsing.aspx  Saddly, I have yet to work with it so I can't give you any more on that. But here is how I would parse that into an object.  # Read each line #   If line contains ""controller"" #     If $CurrentObject is not $null, write-output $CurrentObject #     Create new hashtable $CurrentObject #     add a DisplayName field that contains the current line #   If line contains "":"" #    Split line on "":"" #        Left becomes new property name in $CurrentObject #        Right becomes that properties value #   Ignore all other lines # End by Write-Output $CurrentObject if it is not null   That's the logic or pseudo code for it, now just fill in the commands for each step."
PowerShell,3b879b,Gojs2015,1 point,Fri Jun 26 22:00:29 2015 UTC,"Regular Expressions. Learn Them! Use them! Although you may find an easier solution for this I find that the better I understand RegEx the easier my life becomes. In this case I would probably match each line against something like ""(.+)\s+:\s(.+)"" (not sure if this is the exact format, I'm posting  this well past my bedtime...) to extract the text before the "":"" as $matches[1] and the text after as $matches[2] (Correct, $matches[0] matches everything the regex matches, or the whole line in this case assuming there is one or more whitespace characters followed by a colon then another whitespace character.) Then put the results into a hash table and you're done."
PowerShell,3b7qe3,IKeepMyNamePrivate,2,Fri Jun 26 17:22:38 2015 UTC,"howdy IKeepMyNamePrivate,      don't you need to use Invoke-Item instead of Invoke-Expression? the technet pages for those two say that the one you are using [Invoke-Expression] is for calling a powershell script.      lookee ... Using the Invoke-Item Cmdlet - https://technet.microsoft.com/en-us/library/ee176882.aspx      Using the Invoke-Expression Cmdlet - https://technet.microsoft.com/en-us/library/ee176880.aspx      take care, lee"
PowerShell,3b7qe3,Lee_Dailey,2,Fri Jun 26 17:58:55 2015 UTC,"Hi Lee,    Thanks for your answer!    No, the .exe file I am trying to run, must be ran from a command line. When using Invoke-Expression it will stay in the current PowerShell script and not get out. When using Invoke-Item it will open as a separate window. For example: If you run ; iex ""ping 127.1"" it will ping 127.0.0.1 When running ii ""ping 127.1"" it just does not work.  Thanks! IKeepMyNamePrivate"
PowerShell,3b7qe3,Lee_Dailey,1 point,Fri Jun 26 18:27:00 2015 UTC,"howdy IKeepMyNamePrivate,      you are quite welcome!      gah! i don't understand enuf of this to get past your problem. [sigh ...] i'll go back to lurking. [grin]        the post by KevMar on using Start-Process sure looks interesting ...      take care, lee"
PowerShell,3b7qe3,ryanbrown,2,Fri Jun 26 23:48:03 2015 UTC,"I think your problem is how PowerShell is interpreting your command.  PowerShell treats anything between single quotes as a literal string (i.e. EXACTLY as you typed it).  Try it like this instead:  Invoke-Expression -Command ""$DownloadsLocation\youtube-dl.exe -citwx --audio-format mp3 --audio-quality 0 $DownloadURL"""
PowerShell,3b7qe3,KevMar,1 point,Fri Jun 26 19:45:56 2015 UTC,"Thanks a lot, this helped me. Because $DownloadsLocation contains a space, and PowerShell does not want to listen to me... This works fine without problems:   Set-Location $DownloadsLocation    Invoke-Expression "".\youtube-dl.exe -citwx --audio-format mp3 --audio-quality 0 $DownloadURL""       But when I try this, it just does not work:     Invoke-Expression -Command ""`""$DownloadsLocation\youtube-dl.exe{escape-char}"" -citwx --audio-format mp3 --audio-quality 0 $DownloadURL""    This is the output then:   Invoke-Expression : At line:1 char:47 + ""D:\Downloads\Media Downloads\youtube-dl.exe"" -citwx --audio-format mp3 --audio- ... +                                               ~~~~~~ Unexpected token '-citwx' in expression or statement. At line:1 char:54 + ""D:\Downloads\Media Downloads\youtube-dl.exe"" -citwx --audio-format mp3 --audio- ... +                                                      ~~~~~~~~~~~~~~ Unexpected token '--audio-format' in expression or statement. At line:1 char:56 + ""D:\Downloads\Media Downloads\youtube-dl.exe"" -citwx --audio-format mp3 --audio- ... +                                                        ~ Missing expression after unary operator '--'. At line:1 char:56 + ""D:\Downloads\Media Downloads\youtube-dl.exe"" -citwx --audio-format mp3 --audio- ... +                                                        ~~~~~~~~~~~~ Unexpected token 'audio-format' in expression or statement. At C:\Users\XXXXXXXXX\Desktop\Media Downloader.ps1:48 char:5 +     Invoke-Expression -Command """"$DownloadsLocation\youtube-dl.exe"" -citwx --a ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : ParserError: (:) [Invoke-Expression], ParseException     + FullyQualifiedErrorId : UnexpectedToken,Microsoft.PowerShell.Commands.InvokeExpressionCommand     And I do not get why it does this..."
PowerShell,3b7fhk,tomerc10,5,Fri Jun 26 16:03:58 2015 UTC,"Hey, Scripting Guy! explains arrays better than I can.  $array.indexof($element)"
PowerShell,3b7fhk,xalorous,2,Fri Jun 26 16:25:55 2015 UTC,"$element means the name im looking for, right?"
PowerShell,3b7fhk,xalorous,3,Fri Jun 26 17:11:06 2015 UTC,"I meant that as an example, but yeah.  PS C:\> $array = 'A','B','C','D','E' PS C:\> $array(4)   E   PS C:\> $array.indexof('E')   4"
PowerShell,3b71m1,tradiuz,3,Fri Jun 26 14:18:01 2015 UTC,"If you use hex values, you need to set the hex parameter: https://technet.microsoft.com/en-us/library/dn282133.aspx  Here is a sample from one of my resources:  Registry DisableNICPowerManagement_0 {     Key       = ""HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Class\{4D36E972-E325-11CE- BFC1-08002bE10318}\0000""     ValueName = ""PnPCapabilities""     ValueData = ""00000038""     ValueType = ""DWord""     Hex       = $true }"
PowerShell,3b71m1,KevMar,1 point,Fri Jun 26 14:25:33 2015 UTC,"Let me give that a shot.  I really like IISCrypto, but I want a better way to specify what I want, and a pure PS way is perfect, and makes it easier to push out and verify it's set right."
PowerShell,3b75cw,Catatonic27,2,Fri Jun 26 14:47:58 2015 UTC,"There are a couple of ways to do this - some safe, some not  One quick, dirty unsafe way is this:  $alertSubject = Invoke-Expression ""$( """"$alertSubject"""" )""   As that forces re-expansion. Its very very bad to do this as anyone tampering with your text file could cause all sorts of havok.  Better is to replace your variables with markers;  <!--Marker:AlertHost-->   and then do a replacement such as  Function fn_Expand {   [ CmdletBinding( SupportsShouldProcess = $true, ConfirmImpact = ""Low"" ) ]   Param(     [string]$Text = ""Test Line""   )   While ( $Text -match [regex]'\<\!--Marker:(?<myMark>.*?)-->') {     $myVar = $matches['myMark']     Write-Verbose ""Found a marker for the variable '$myVar'""     try {       $myValue = ( Get-Variable $myVar ).Value       Write-Verbose ""Got a value for the variable '$myVar' as '$myValue'""     } catch {       $myValue = ""Undefined""       Write-Verbose ""The variable '$myVar' was not found""     }     $Text = $Text -Replace ""<!--Marker:$myVar-->"" , $myValue   }   return $Text }  $selHost = ""Test Server"" fn_Expand -Text ""<!--Marker:selHost--> is down"" -Verbose  $alertSubject = ""Hello - <!--Marker:ServerName--> is down"" $ServerName = ""The Server"" $alertSubject = fn_Expand -Text $alertSubject Write-Host ""`n`n`n`n"" Write-Host $alertSubject   Which gives  ~ C:\Users > .\test.ps1 VERBOSE: Found a marker for the variable 'selHost' VERBOSE: Got a value for the variable 'selHost' as 'Test Server' Test Server is down     Hello - The Server is down ~ C:\Users >   In this way, your subject line text file and body content text files will be templates and you can substitute in pretty much any variable you like!  Edit: Replaced IF with While to allow multiple replacements per line"
PowerShell,3b75cw,real_parbold,0,Fri Jun 26 15:30:24 2015 UTC,"Wat.  String formatting functions were literally made for this, you don't need to roll your own.  There's two ways to use them, either:  $str = [string]::format(""This is {0} speaking"", ""Bob"")  or  $str = ""my name is {0} and I do {1}"" -f ""Bob"", $job  You can even use the second way to template a wall of text:  $str = @"" Hello {0},  My name is {1}.  I like to eat candy and {2}.  Regards, {1}. ""@ -f ""Bob"", ""Steve"", ""apples""   You can even just store the template in a string (like above) and format it with what you want when you want it."
PowerShell,3b75cw,picklednull,1 point,Sat Jun 27 11:35:50 2015 UTC,"Yes they were.  Write-Host $( ""{0,-20}"" -f ""Hello"" )   But the OP was specifying the variable in the text, like a template.  Having a template with {0}, {1} etc throughout the body of a seemingly disparate text file, is not easy to revist at a later date.  My function is a little more user friendly."
PowerShell,3b75cw,real_parbold,1 point,Mon Jun 29 09:36:11 2015 UTC,Remove the quotes from around the variables in the script
PowerShell,3b75cw,ShiftNick,1 point,Fri Jun 26 15:10:19 2015 UTC,"I think you mean around the  send-mailmessage line.  I can't see the pastebin from here, so I don't know how the body is formed.  Pretty sure if you read it in from a text file with the variable name in the text file, it will be treated as text and not evaluated.  I'd recommend pulling out the first line.  Then do this:  $Body = <load boilerplate from text file> $alertBody = ""$selHost is offline! $Body""    # the quote is intentionally one line lower, used literal CRLF because I can never remember the escape code.  If you use the escape code, and it works, you can easily move this line up."
PowerShell,3b75cw,xalorous,1 point,Fri Jun 26 15:19:19 2015 UTC,"This would work if defining the $alertSubject and $alertBody in script, but if I read the OP correctly, the value of $alertSubject and $alertBody are being read from a text file.  Missed that you were wrapping the text read from file :O"
PowerShell,3b75cw,real_parbold,1 point,Fri Jun 26 15:48:59 2015 UTC,"Basically I wanted to have the variable portion of the message appended to the start of the message body.     $Body = <load boilerplate from text file>  $alertBody = ""$selHost is offline! `r$Body     # found the `r escape secquence   Actually, it could be simplified again.     $alertBody = ""$selHost is offline! `r$Body + <read in body file>"
PowerShell,3b75cw,xalorous,0,Fri Jun 26 16:15:23 2015 UTC,"Remove the quotes from around the variables in the script.  Also,  I don't think you want to use write-host in this case.  You should probably use write-output.  Jeffery Snover wrote a good article about it"
PowerShell,3b6rxk,shanedev,2,Fri Jun 26 12:49:47 2015 UTC,Seems like hotdocs has a command line parameter to save the file.  /of is the parameter  http://wiki.hotdocs.com/index.php?title=List_of_Command-line_Options  It's cleaner than a key press since you won't know when hotdocs has finished processing to then send the keypress otherwise.
PowerShell,3b6rxk,Theratchetnclank,2,Fri Jun 26 14:09:27 2015 UTC,Yeah I did that but it still forces you to click on the finish button :( and their /fia trigger doesn't seem to work either.
PowerShell,3b6rxk,catfoodsci,2,Fri Jun 26 14:16:00 2015 UTC,"I don't believe you can send keystrokes via powershell commandlets.   I'd investigate hotdocs options, maybe the program supports a switch like -quite, -silent, or -force. I'm not familiar with hotdocs but maybe your should contact their support group about what your are trying to do as it looks like their solutions have different components. Perhaps the desktop edition does not offer automation capabilities, but the server edition does?"
PowerShell,3b6rxk,catfoodsci,2,Fri Jun 26 14:11:59 2015 UTC,"You can send keystrokes but you have to actually be logged in, if the computer is locked the keystrokes generally get blocked :("
PowerShell,3b6rxk,Frequentsy,1 point,Fri Jun 26 14:16:32 2015 UTC,"Since I didn't know that you could send keystrokes via the powershell, can you please share how you do this?"
PowerShell,3b6rxk,KevMar,1 point,Fri Jun 26 14:24:44 2015 UTC,"Sure!   Here is an example:   add-type -AssemblyName System.Windows.Forms  [System.Windows.Forms.SendKeys]::SendWait(""Hello!"")  [System.Windows.Forms.SendKeys]::SendWait(""{ENTER}"")   Keystrokes: https://technet.microsoft.com/en-us/library/ff731008.aspx"
PowerShell,3b6n9h,danny6999,3,Fri Jun 26 12:01:33 2015 UTC,"For information : Powershelll - as with other languages 'Get-opts' parameter handling...  The parameters will match on 'first unique' part of the name  So, two parameters  [switch]$Printmeoutplease, [switch]$SilentAsAMous   Will work with -p and -s  However  [switch]$PrintAll [switch]$PrintOne   Would have to be distinguished as -printa -printo  Although you could still use -printall -printone or even -printal -printon"
PowerShell,3b6n9h,real_parbold,2,Fri Jun 26 15:39:21 2015 UTC,That switch is just a bool that is false unless defined.   if($printout){...}   Edit: Auto correct strikes again
PowerShell,3b6n9h,KevMar,1 point,Fri Jun 26 12:12:18 2015 UTC,Thank you!
PowerShell,3b6n9h,madleprakahn,2,Fri Jun 26 12:23:47 2015 UTC,"Use   if ($printout) {#Do the work with the printout here} else {#Do the work without the printout here}   Also, you're going to want to make the .csv before you pipe the output to Format-Table (ft). I would do in the first block  $comp = Get-ADComputer -Filter {Name -like ""$computername*""} -Properties lastlogondate,canonicalname $comp | Export-Csv -Path $Path $comp | ft name,lastlogondate,canonicalname -autosize   Leave what you've got in the Else block"
PowerShell,3b6n9h,xalorous,2,Fri Jun 26 12:17:10 2015 UTC,"$comp = Get-ADComputer -Filter {Name -like ""$computername*""} -Properties lastlogondate,canonicalname if($printout) {     $comp | Export-Csv -Path $Path } $comp | format-table name,lastlogondate,canonicalname -autosize   Combining what everyone else put, this should give the onscreen output every time, but only the csv if you as for it with -printout or -p."
PowerShell,3b6n9h,madleprakahn,1 point,Fri Jun 26 15:35:19 2015 UTC,Thanks for cleaning that up for me. I hadn't had my coffee this morning :-)
PowerShell,3b6s5j,speirus,1 point,Fri Jun 26 12:52:05 2015 UTC,"$Var = 'Bacon'  Get-Content -Path ""C:\Meaty$($Var)\food.txt"""
PowerShell,3b6s5j,bundyfx,2,Fri Jun 26 13:00:57 2015 UTC,"Many times you do not need the $($Var), and you can use $Var instead.  However, if you're accessing the members of the object, you do have to wrap it in $() to force it to evaluate the member before evaluating the expression in double quotes.  I think.  Bottom line, you can have:  $server = 'fileserver'   $share = 'fileshare'   $name = 'filename'   $ext = 'fileextension'   $path = ""\\$server\$share\$name.$ext""   $path     which should return: \\fileserver\fileshare\filename.fileextension  But if I want to access the properties of the variable and display them in the same line:  $example = ""foobar""   $example   $example.length   ""$example is $example.length characters""   ""$example is $($example.length) characters""     result is:  foobar 6 foobar is foobar.length characters foobar is 6 characters"
PowerShell,3b6s5j,xalorous,1 point,Fri Jun 26 16:39:01 2015 UTC,"I've learned to just do the following for all variables that I'm inserting into strings.  ""$($example) is $($example)""   Makes adding more things to the string easier.  ""$($example + 10) is 10 more than $($example)"""
PowerShell,3b6s5j,spyingwind,1 point,Fri Jun 26 16:51:14 2015 UTC,"the problem is that some of the parameters aka -rcvname it errors if I use the quotes, I have to use ' which then it will not process any variables"
PowerShell,3b5qrm,crapspakkle,3,Fri Jun 26 04:48:36 2015 UTC,"I'm waiting for PS5 to see what it brings to the DSC table.  I feel there's massive potential for DSC to take off but it's still a little immature.  Not being able to see the differences in a system and its Desired State with a single cmdlet is a big issue for our environment.  That's something PS5 will add so, yeah, fingers crossed!"
PowerShell,3b5qrm,ginolard,2,Fri Jun 26 07:48:08 2015 UTC,"Why are you waiting?  It's all available today... Even if you can't put it on your system(s) at work, get it installed at home, or spin up your chosen cloud platform and take it for a spin."
PowerShell,3b5qrm,jbtechwood,2,Fri Jun 26 10:41:26 2015 UTC,"Allow you to push changes to a group of servers by editing a single config file.  Prevent configuration drift - set your servers up to pull the DSC configs, and they'll check in and apply the MOF file on a regular basis.  That way you can keep everything configured exactly as per your documentation without worrying about anyone else changing anything."
PowerShell,3b5qrm,winter_mute,2,Fri Jun 26 07:19:56 2015 UTC,Number 2 has so much potential.  More so for a Remote Desktop/Citrix environment where servers need to have the same/similar configuration.  I'm yet to look into DSC properly.  When I get some free time in the evening I want to watch the starter DSC MVA video.  Might be worth a watch OP?
PowerShell,3b5qrm,Swarfega,2,Fri Jun 26 07:28:30 2015 UTC,How do you currently manage server configuration and configuration drift in your environment?
PowerShell,3b5qrm,jbtechwood,1 point,Fri Jun 26 15:38:48 2015 UTC,We do weekly reboots of the citrix farm and our vmware environment was rebuilt a couple months ago with a new UCS and SAN so drift has not been a problem yet.
PowerShell,3b5qrm,midnightFreddie,1 point,Fri Jun 26 16:08:02 2015 UTC,"I haven't used it in production yet, but I like its scalability, both up and down. It requires even less setup than Chef Zero to get started. It's already built-in...you can whip up a quick config and use a couple of cmdlets to apply it. Then you can scale up homebrew Powershell-fu or set up a pull-config system. You can have the LCM enforce compliance or just do one-time configuration-apply's. (As opposed to other configuration management systems where you have to invest and commit time and/or money before really getting going.)"
PowerShell,3b5fmn,TheSilenceOfWinter,1 point,Fri Jun 26 03:02:00 2015 UTC,"Try deleting this instead, otherwise run as admin:  Remove-Item -Recurse -Path $env:LOCALAPPDATA\Microsoft\Windows\Temporary Internet Files"
PowerShell,3b5fmn,JaapBrasser,1 point,Fri Jun 26 08:17:34 2015 UTC,"Just keep in mind that this will delete all the things.  If this is your daily machine that this is running on you may want to add some logic to track when the script started and delete any files created since then using Jaap's solution above, so as not to delete items you'd rather keep."
PowerShell,3b5fmn,jbtechwood,1 point,Fri Jun 26 10:48:15 2015 UTC,"That is correct, but it is temporary internet files so the risk of losing something you would like to keep should not be too high. Alternatively you could do a Get-ChildItem on the folder before you open IE and after and only delete the new files based on the output of Compare-Object."
PowerShell,3b4tid,bodysoda,3,Thu Jun 25 23:48:03 2015 UTC,"Never mind.. I worked it out..  $inputObject = (gc .*.txt ) |Select-Object -Index 0 $regex = ‘\b\d{1,3}.\d{1,3}.\d{1,3}.\d{1,3}\b’ select-string  -Pattern $regex -InputObject $inputdata -AllMatches | % { $.Matches } | % { $_.Value }|Group-Object |sort  -Property count -Unique -Descending|ft name,count  -AutoSize  Thanks"
PowerShell,3b4tid,jbtechwood,1 point,Fri Jun 26 01:18:30 2015 UTC,I assume $inputdata is the value of a get-content call
PowerShell,3b4iyt,Gabisonfire,2,Thu Jun 25 22:19:26 2015 UTC,"I don't think there's a way to query that.  You could take a look at all of the Exception classes in the [System] and [System.Management.Automation] namespaces, but I don't think there's anywhere that specifies what exceptions a specific cmdlet might throw.  You could put the following in your catch statement to print out the exception type:  catch {     $_.Exception.GetType() | Select-Object -Property BaseType }"
PowerShell,3b4iyt,ryanbrown,1 point,Thu Jun 25 22:57:24 2015 UTC,"Do you have a specific example? There would be tons of possible exceptions that could occur, have you tried using just $Error.exception with some smarts in it for a try/catch block?  even just do a $error | select * and check out all the available information you could use in a try/catch."
PowerShell,3b4iyt,bundyfx,2,Thu Jun 25 22:44:43 2015 UTC,I'm currently looking for possible exceptions for Get-EventLog
PowerShell,3b4iyt,KevMar,1 point,Fri Jun 26 17:40:57 2015 UTC,There is nothing in Powershell that presents or declares that information. Most of the errors and exceptions generated by powershell are really pretty good though.
PowerShell,3b3f9t,itguythrowway,3,Thu Jun 25 17:28:10 2015 UTC,Why not use group policy preferences. Printer doesn't need to be setup in group policy to remove it.
PowerShell,3b3f9t,captainironhulk,1 point,Thu Jun 25 17:58:58 2015 UTC,"Well, I have the new print server mapped with the group policy settings in print management so that they are enforced and users can't delete them. If I use group policy preferences to delete the old mappings they might take the ones I want to keep with them."
PowerShell,3b3f9t,Thats_a_lot_of_nuts,2,Thu Jun 25 18:04:56 2015 UTC,The printer mappings in Group Policy Preferences are applied sequentially. If the first item deletes all printers on the client and then you follow it with all your new mappings it should work quite nicely.  I've done numerous print server cleanups in this fashion.
PowerShell,3b3f9t,m4v1s,1 point,Fri Jun 26 02:35:28 2015 UTC,This. Run the delete actions before creating the new connections. Also works for file share mappings!
PowerShell,3b3f9t,captainironhulk,1 point,Fri Jun 26 03:22:29 2015 UTC,Is the old server and new server named the same?
PowerShell,3b3f9t,captainironhulk,1 point,Thu Jun 25 18:15:57 2015 UTC,"No, the server names are different. The printer names are the same though."
PowerShell,3b3f9t,colinmcleod,3,Thu Jun 25 18:28:40 2015 UTC,"Then preference shouldn't delete the new printers. It uses the full path. I would try a test and see, be a lot easier than trying to use powershell."
PowerShell,3b3f9t,catfoodsci,1 point,Thu Jun 25 18:46:12 2015 UTC,"Yeah, I'll try it by using the path. I couldn't find any scripts online for this purpose either."
PowerShell,3b3f9t,Luxtaposition,1 point,Thu Jun 25 18:50:11 2015 UTC,"I've used this in cases where the businesses didn't have a Windows domain and I had no idea what the printer names were -   $NetworkPrinters = ((Get-WmiObject -Class Win32_Printer) |     where {$_.network -eq $true})      Foreach ($Printer in $NetworkPrinters) {                              $PrinterListing = ($Printer.name)                             Invoke-Expression ""rundll32   printui.dll,PrintUIEntry /dn /q /n`""$PrinterListing`""""                                             }   Otherwise GPP is best."
PowerShell,3b3f9t,Luxtaposition,1 point,Sat Jun 27 10:57:19 2015 UTC,"I'm not sure if this will work for you, but there is a commandlet named: Remove-Printer   Applies To: Windows 8.1, Windows PowerShell 4.0, Windows Server 2012 R2  https://technet.microsoft.com/library/8a7a136f-d4dd-4e78-838a-01ce63347c48(v=wps.630).aspx"
PowerShell,3b3f9t,Luxtaposition,2,Thu Jun 25 17:51:26 2015 UTC,"Yeah, I found that cmdlet but it wouldn't work because i'm running a 2008 r2 print server and the clients are all Windows 7."
PowerShell,3b3f9t,Luxtaposition,1 point,Thu Jun 25 17:56:05 2015 UTC,I did the exact same thing in my previous environment. I had some users click a file share that I linked to the an email. others I dropped a file in the all users startup folder.
PowerShell,3b3f9t,ellisgeek,1 point,Thu Jun 25 22:24:50 2015 UTC,Do you have a sample of what it looked like?
PowerShell,3b3f9t,ellisgeek,1 point,Thu Jun 25 22:50:11 2015 UTC,I will have to dig it up. stay tuned
PowerShell,3b3f9t,ellisgeek,1 point,Fri Jun 26 01:24:58 2015 UTC,"I couldn't find a sample, but I gave you some hints. I can get you references after you reply.   @echo off    :: Delete Mapped Printer (Per User) **This can be run by the user. rundll32 printui.dll PrintUIEntry /dn /n\\SERVER\PRINTER  :: Delete Mapped Printer (Per Machine)  **This must be run by a local admin only. rundll32 printui.dll PrintUIEntry /dn /n\\SERVER\PRINTER  :: Add mapped printer (Per User) **This can be run by the user. rundll32 printui.dll PrintUIEntry /in /n\\SERVER\PRINTER  :: Add mapped printer (Per Machine) ** This must be run by a local admin only. rundll32 printui.dll PrintUIEntry /ga /n\\SERVER\PRINTER  Exit"
PowerShell,3b3f9t,ellisgeek,1 point,Sat Jun 27 06:49:23 2015 UTC,See my reply?
PowerShell,3b2tn4,2girls1netcup,3,Thu Jun 25 14:47:49 2015 UTC,Why on earth are you using PHP on IIS to call PowerShell?  Just use ASP.NET's native stuff for this!
PowerShell,3b2tn4,Get-ADUser,1 point,Thu Jun 25 18:28:05 2015 UTC,Because I don't know anything about .NET and php was easy?
PowerShell,3b2tn4,cjluthy,1 point,Thu Jun 25 23:36:55 2015 UTC,ASP.NET is NOT more difficult / complicated than PHP.
PowerShell,3b2tn4,alinroc,2,Fri Jun 26 00:15:33 2015 UTC,"My best guess for it being slow is that it has to start up a new session every time exec runs.   Put some logging in your PowerShell to record when it starts and ends, and I think you'll see that the AD query is pretty quick to run.  It's not just the time to start the PowerShell session, it's also the time to load the AD module.  You can use Measure-Command within your script to get even more detail about how long each step takes."
PowerShell,3b2tn4,snuxoll,2,Thu Jun 25 15:01:07 2015 UTC,"IIS is horrific at executing PHP in the first place, calling out to powershell on top is going to be bog slow.  Any reason you are using PowerShell to get AD information instead of just querying the LDAP directory through the native PHP extension?"
PowerShell,3b2tn4,snuxoll,1 point,Thu Jun 25 17:30:01 2015 UTC,"It was more of a proof-of-concept than anything, but the page also gives them the ability to add-adgroupmember."
PowerShell,3b2tn4,SeanQuinlan,2,Thu Jun 25 17:59:37 2015 UTC,"My advice, do it in .Net, the System.DirectoryServices namespace has everything you need."
PowerShell,3b2tn4,mikeybot_sfw,1 point,Thu Jun 25 19:03:34 2015 UTC,"Can you share the script?  I'm guessing there's a ""-Properties *"" somewhere in the query, pulling down all AD properties when you don't need them. This drastically increases the time take to retrieve information from AD."
PowerShell,3b2tn4,KevMar,1 point,Thu Jun 25 15:41:01 2015 UTC,"Also, filter as soon as possible. If you're using Get-ADUser, don't grab everyone and then do a Where-Object clause. Use    Get-ADUser -Filter ""Enabled -eq $true"""
PowerShell,3b2tn4,tangobravoyankee,1 point,Thu Jun 25 15:59:29 2015 UTC,"Are you using the -noprofile option on powershell.exe? Is there a more native way for php to query AD?  Can you pre-process this? Run the script on a schedule to export to a csv, then pull that csv into your page? Do you need real-time data or is daily\hourly accurate enough?  This is a good thing to experiment with and would question it more if it made it into production. I don't have any real php experience so this may be more common than i expect."
PowerShell,3b3nr2,spydertau,1 point,Thu Jun 25 18:26:47 2015 UTC,"What is the error?  Edit: I ask because unlike most languages, powershell errors are very useful.  Also run this to see how the command should look  get-help New-DfsnFolder -examples"
PowerShell,3b3nr2,KevMar,1 point,Thu Jun 25 18:29:39 2015 UTC,"New-DfsnFolder : A general error occurred that is not covered by a more specific error code. At line:1 char:1 + New-DfsnFolder -Path \domain.com\Mitchellville -TargetPath \server-01\sha ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : NotSpecified: (MSFT_DfsNamespaceFolder:Root\Microsoft...NamespaceFolder) [New-DfsnFolde    r], CimException     + FullyQualifiedErrorId : MI RESULT 80,New-DfsnFolder"
PowerShell,3b3nr2,ryanbrown,2,Thu Jun 25 18:45:04 2015 UTC,Your paths don't seem to start with a double backslash.  I'm not sure if that's just reddit messing with your post or not?
PowerShell,3b3nr2,KevMar,1 point,Thu Jun 25 18:59:57 2015 UTC,The underlying CIM or WMI class raised that error. I would try doing it manually to see if you have the same issue.   Check the system/evenlog for errors and diagnose your DFS to make sure it is healthy.
PowerShell,3b3bgu,SybariticLegerity,1 point,Thu Jun 25 16:59:47 2015 UTC,"If H: only gets mapped when you log in, is there a batch script that runs upon login? If so it would probably be pretty simple to spawn a browser process just using that, or use it to launch a PS script if that's the way you're determined to go."
PowerShell,3b3bgu,dokoun,1 point,Thu Jun 25 17:37:06 2015 UTC,"There is a script that runs on login, I wrote it myself. For some reason I completely forgot about it, hah. Is there an easy/reliable way to get a Powershell script to call another Powershell script?"
PowerShell,3b3bgu,dokoun,1 point,Thu Jun 25 17:44:47 2015 UTC,"Just write the path of the script: c:\whatever\script.ps1  or  & ""c:\documents and settings\script.ps1"" if the path contains spaces."
PowerShell,3b3bgu,dokoun,1 point,Thu Jun 25 17:49:08 2015 UTC,Thanks! What exactly does the ampersand do?
PowerShell,3b3bgu,dokoun,1 point,Thu Jun 25 17:53:23 2015 UTC,"It's an alias for Invoke-Expression. You do need quotes if the path contains spaces as well, I edited my comment."
PowerShell,3b2xuy,Dagoron,2,Thu Jun 25 15:19:14 2015 UTC,"With the line you have there it has the potential to create multiple exports for the same mailbox if it has more than 1 email address in the specified domain. If you know the user's from that tenancy all have the same domain for their primary SMTP address then this will do the job:  Get-Mailbox -resultsize unlimited | Where-Object {$_.PrimarySmtpAddress -like ""*domain1.com*""} | foreach { New-MailboxExportRequest -Mailbox $_.alias -FilePath ""\\<server FQDN>\<shared folder name>\$($_.Alias).pst"" }"
PowerShell,3b2xuy,justing1319,1 point,Thu Jun 25 18:20:27 2015 UTC,"Thank you sooooo much. This script worked perfectly for what I needed. If you don't mind, what exactly did I have that would cause redundant PSTs to be created for each account? Was I just missing the -Mailbox $_.alias bit?"
PowerShell,3b2xuy,gimp0,2,Thu Jun 25 19:49:52 2015 UTC,you were checking smtp address and not primary smtp address.  can only have 1 primary thus no duplication.
PowerShell,3b2xuy,justing1319,2,Fri Jun 26 03:59:32 2015 UTC,Glad I could help. The second piece of code in the original:  Select-Object displayname -expandproperty emailaddresses       Takes all the email addresses the user has and breaks them out into an array. If someone had john.smith@example.com and jsmith@example.com the export command would be run for each one.
PowerShell,3b2wju,ethanmc12,2,Thu Jun 25 15:09:51 2015 UTC,"proxy addresses attribute needs to be changed to SMTP:jsmith@companyb.com, (the uppercase denotes primary address), a secondary address can be denoted with smtp:jsmith@companya.com (the lowercase means secondary alias)  I think.. been a while since i toyed with this, but should get you on the right track."
PowerShell,3b2wju,blitzedkrieg217,1 point,Thu Jun 25 15:41:28 2015 UTC,"So you'll probably want to use exchange email adress policys to manage this. It is hell to do it manually.  Look in to the ""New-Emailadresspolicy"" and ""Set-Emailadresspolicy"" cmdlets.  If your AD is up to date it shouldn't be a problem to use the ""Company"" property, if that isn't possible use one of the custom properties as a filter.  Also, a fair warning, make sure you double and triple check everything before you apply the policy. Turns out people get a bit frustrated when they get the wrong email-adress. ;)"
PowerShell,3b2wju,xabbuj,1 point,Thu Jun 25 18:15:49 2015 UTC,"I ended up using a variation of this script  ""#alias,addnewemailaddress  import-csv .\source.csv | foreach { $user = Get-Mailbox $.alias $user.emailAddresses+= $.addnewemailaddress $user.primarysmtpaddress = $_.addnewemailaddress Set-Mailbox $user -emailAddresses $user.emailAddresses set-Mailbox $user -PrimarySmtpAddress $user.primarysmtpaddress }"
PowerShell,3b332o,Short_Walter,3,Thu Jun 25 15:58:59 2015 UTC,"I've never heard of SkyTap, but a quick google search reveals that they have a command line client:   http://help.skytap.com/#Command_Line_Interface.html#Installing_the_Skytap_CLI  It would probably be way easier to install that, and invoke it from your script than to try to directly interact with the REST API. If you are not familiar with a gem, it's a ruby package so you will need to have that installed fist.  If using PowerShell is not a strict requirement, it looks like there are some third party client libraries for node.js and python which may make things easier:  http://help.skytap.com/#APIDocumentation.html#Example_API_Scripts_and_Clients%3FTocPath%3DAPI%2520v1%2520Documentation%7CExample%2520API%2520Scripts%2520and%2520Clients%7C____0  If you must use pure PowerShell, then you'll have to learn the Invoke-WebRequest and Invoke-RestMethod cmdlets inside and out, because they will be doing all the dirty work for you in terms of interacting with the API.  https://technet.microsoft.com/en-us/library/hh849901.aspx  https://technet.microsoft.com/en-us/library/hh849971.aspx  Good luck.  edit  Another technet article on using the Invoke-RestMethod cmdlet  http://blogs.technet.com/b/heyscriptingguy/archive/2013/10/21/invokerestmethod-for-the-rest-of-us.aspx"
PowerShell,3b332o,le_Dandy_Boatswain,2,Thu Jun 25 23:01:32 2015 UTC,"Everybody starts somewhere, so I wouldn't worry about being ""new"" to PowerShell.  However, I'd suggest you start by reading this post from a few months ago:  http://www.reddit.com/r/PowerShell/comments/32lz9r/help_yourself_if_you_ask_for_help/  You're more likely to get helpful comments if you provide more detail and let us know what you've already tried (with examples) and what you're struggling with."
PowerShell,3b332o,ryanbrown,1 point,Thu Jun 25 16:27:09 2015 UTC,Thanks for the link! I've also updated the post so you could better see details.
PowerShell,3b332o,ryanbrown,1 point,Thu Jun 25 18:12:44 2015 UTC,"Working with APIs is not one of my fortes, but I suspect that the type of ""image"" Skytap is referring to is an OS-based image (i.e. a WIM, VHD, ISO, etc...) and not a graphic image (i.e. JPG, GIF, etc...).  I don't know enough about Skytap to really help you out, but it looks like the PowerShell snippets you've got are good, it's just not returning the results you're expecting (likely because $data doesn't contain the input the API is expecting)."
PowerShell,3b332o,kittH,1 point,Thu Jun 25 18:55:33 2015 UTC,You don't give any indication to your background or level of experience interacting with APIs. If you were honest about your experience level when they hired you I don't think they'll fire you for not knowing a particular language.   I don't know anything about skytap specifically but it looks like a standard rest api. You'll probably want to use some combination of Invoke-WebRequest and Invoke-RestMethod. There are plenty of examples online. For example: http://www.lavinski.me/calling-a-rest-json-api-with-powershell/
PowerShell,3b332o,betty_anne,1 point,Thu Jun 25 16:23:20 2015 UTC,"Thanks for the reply! I was pretty honest with them about not knowing powershell before I took the job, and they seemed to be understanding about my lack of previous experience. I'm just afraid that if I don't provide the needed results soon their understanding will quickly expire."
PowerShell,3b332o,blackdevl,1 point,Thu Jun 25 18:07:00 2015 UTC,"I'm not sure how helpful i'll be as I'm also new, but have only been working with invoke-restmethod.  When you run your script is there an error that is returned?   Does the -body section support a .jpeg per the API's documentation?  The way that i've done my rest commands uses the @params ""feature?""      function Invoke-CustomRestMethod     {          param([Parameter(Mandatory=$true)][String]$DESRelativeURL)              #Passes the base URL and the relative URL (mandatory param) into the API Request             $params = @{uri = ""$DESBaseURL""+""$DESRelativeURL"";             Method = 'Get';             Headers = @{Authorization = ''+ $Authorization;}             }              #Attempts to pass the paramaters of the API request               $ReturnObject = Invoke-RestMethod @params             $ReutrnObject             }   Once you set the param's up to your needs then you can use the function invoke-customrestmethod to help form your requests easier."
PowerShell,3b332o,blackdevl,1 point,Thu Jun 25 18:56:46 2015 UTC,"Do you actually know what they want you to do? Looking at the skytap api, it looks like there is backup a VM image to a ftp site, but the uri for that is different than what you are trying. Is that the full scope scope that they assigned to you, or just a summary? If it was a summary based on prior conversations you had with them, or you summarized what they assigned to you when you posted here, try to go back to what they said and figure out if that is what they want. If I am interpreting it correctly, and they want a ftp backup of a VM, seems straightforward according to their docs, and the doc has sample code for powershell that might be helpful"
PowerShell,3b3tqk,EthnicTwinkie,1 point,Thu Jun 25 19:11:00 2015 UTC,"$a = Get-ADUser -Filter {displayname -eq ""Lastname, Firstname""}    You need to grab the pwdlastset property  $a = Get-ADUser -Filter {displayname -eq ""Lastname, Firstname""} - properties pwdlastset  Try that and report back?"
PowerShell,3b3tqk,silentmage,1 point,Thu Jun 25 19:43:03 2015 UTC,Man....I feel really stupid.  Thanks!
PowerShell,3b3tqk,silentmage,1 point,Thu Jun 25 19:55:35 2015 UTC,Catches me sometimes too. It can be hard to remember what the default values are when using cmdlets. I pipe to gm all the time to see what I have to work with when scripting. You never know what you might find to make things easier.
PowerShell,3b3tqk,m4v1s,1 point,Thu Jun 25 20:13:38 2015 UTC,You can also just get the property PasswordLastSet and skip converting into a datetime.
PowerShell,3b3cj5,VapingSwede,1 point,Thu Jun 25 17:08:10 2015 UTC,"I have been looking for something like this, would you mind answering some questions?"
PowerShell,3b3cj5,scopesiide,1 point,Thu Jun 25 18:20:55 2015 UTC,"Sure, ask away :)"
PowerShell,3b3cj5,scopesiide,1 point,Thu Jun 25 18:22:46 2015 UTC,Do i need to specify the switch I am connected to or does it pick that up on its own? Do the credentials running the script need read access to the table or do can you use a separate account ex. service account for the switch vs user creds for local machine.
PowerShell,3b3cj5,scopesiide,1 point,Thu Jun 25 18:26:16 2015 UTC,You will need to specify the switch and port with -ComputerName and -Port.  So for example:  Get-MacFromPort -ComputerName switch10.sw.lan.contoso.com -Port Gi1/0/10 -Credentials <username of account on switch or TACACS+ etc>   The user logging in to the switch would need read-rights to the table i think for this to work. I'm not to good at Cisco and deal mainly with the basic stuff.
PowerShell,3b3cj5,scopesiide,1 point,Thu Jun 25 18:36:30 2015 UTC,"So that was my confusion, I thought this was a way for the end host to do a reverse lookup.   Computer takes MAC  Queries switches mac address list based on what switch its connected to  finds its MAC and reports back the port number the computer is connected to"
PowerShell,3azjp2,thisisnotmyssn,18,Wed Jun 24 19:35:26 2015 UTC,"Yes. That is Exactly what you would do.  # Read Registry Key  # Compare value of key  # Create file if true   This is a great first learning script is why I left out the code. You will use Get-ItemProperty, and if($value -eq ""test"") and finally Set-Content to create the file. Quick tip, $env:temp is a variable to the temp folder."
PowerShell,3azjp2,KevMar,11,Wed Jun 24 20:06:49 2015 UTC,"This made me unreasonably happy. This is a great way to respond to folks new to powershell (or anything really).  In that spirit, here's my tip for u/thisisnotmyssn: Get-Help Get-ItemProperty, will give you the built in description of the command, and some examples."
PowerShell,3azjp2,ibn4n,1 point,Wed Jun 24 23:52:19 2015 UTC,"Second this, built in help and get-command usually have the answers"
PowerShell,3azjp2,Fridge-Largemeat,3,Thu Jun 25 10:34:09 2015 UTC,"awesome! thank you for the ""quick tip"" as well. will be trying this out tomrrow."
PowerShell,3azjp2,chimney3,3,Wed Jun 24 20:50:13 2015 UTC,Welcome aboard!! I'm sure you've already got your head wrapped around this but you could look at this as three questions:  1) Can PowerShell read registry settings? (Absolutely!)  2) Can PowerShell create files? (Yes indeed!)  3) Can PowerShell do things depending on the condition of other things? (Sure! Using IF statements!)
PowerShell,3azjp2,paradizelost,4,Wed Jun 24 21:18:46 2015 UTC,Don't forget switch/case statements as well. On mobile so I can't remember which PS uses off hand.
PowerShell,3azjp2,sid351,3,Wed Jun 24 21:45:33 2015 UTC,It's switch. :)
PowerShell,3azjp2,drzorcon,1 point,Wed Jun 24 22:07:51 2015 UTC,"$RegQuery = Reg Query HKLM\Software\Cygwin\Setup | Out-String  If($RegQuery -Like ""RootDir""){New-Item C:\Working\TESTFILE.TXT}  Note that ""RootDir"" or whatever you're searching for should have wildcards around it (but inside the quotation marks) if you're using the Like operator. Reddit's formatting just interprets that as italics.  Works like a charm."
PowerShell,3azjp2,Icolan,1 point,Thu Jun 25 11:42:17 2015 UTC,"If you put 4 spaces in front of the code, reddit will format it as code:  $RegQuery = Reg Query HKLM\Software\Cygwin\Setup | Out-String  If($RegQuery -Like ""*RootDir*""){New-Item C:\Working\TESTFILE.TXT}"
PowerShell,3b0uva,vrsuresh,1 point,Thu Jun 25 01:48:43 2015 UTC,"Found this, thought might be useful for people confused due to firewall issues with WMI"
PowerShell,3azqtv,Nervwreck,1 point,Wed Jun 24 20:28:52 2015 UTC,"You're nearly there.   Get-ADOrganizationalUnit -filter 'Name -like ""*server*""' | Select DistinguishedName   Edit: changed servers to server."
PowerShell,3azqtv,pandiculator,1 point,Wed Jun 24 20:46:31 2015 UTC,"Wow thank you so much, you made my headache a little better!  I don't think Get-Orgunit has the ability to add a search base to specify a certain OU but ultimately I was going to need everything out of the domain anyways.  Thank you so much, I feel good that i was slightly close!  For future reference if I run into issues like this, is this the best place to post things like that or is this frowned upon?  thank you so much again!"
PowerShell,3azqtv,pandiculator,2,Wed Jun 24 21:13:27 2015 UTC,"No problem.  It does have a SearchBase parameter Get-Help Get-ADOrganizationalUnit.  You enter the DistinguishedName of the OU -SearchBase 'OU=Sales Computers,OU=Sales,OU=New York,DC=Contoso,DC=COM'.  This is a good place for any PowerShell queries.  It's a very helpful subreddit and there's some really knowledgeable people here including PowerShell MVPs and some top PowerShell bloggers too.  It's not just a good place to ask questions, you'll find links to really helpful PowerShell articles."
PowerShell,3azqtv,pandiculator,1 point,Wed Jun 24 21:29:39 2015 UTC,"The only other thing which I should be able to figure out is that the output is essentially backwards, so i got Servers\Something\Company\TLOU.  Also it was a bit crude but i used notepad to replace the FQDN stuff to make the path correct (despite being reversed) Again, Many thanks pandiculator!"
PowerShell,3az5y1,MaIakai,1 point,Wed Jun 24 17:53:57 2015 UTC,"Here is some code I used recently to do a similar thing, it might be helpful.    $a = gc .\dnslookups.txt $count = 0 $obj = @() foreach ($b in $a){     $count++     if ($b -match ""Name""){         $obj += new-object psobject -property @{             DNS = $b.split("":"")[1].trimstart("" "")             IP = $a[$count].split("":"")[1].trimstart("" "")         }     } } $obj   the input (from file) looked like this:  Name:    reddit.com Addresses:  198.41.208.140  and the script would put them both on one line.  I used a counter ($count) to grab a line and then line+1 effectively to merge them."
PowerShell,3az5y1,stanrc,2,Wed Jun 24 18:22:53 2015 UTC,"im going the counter route as well but the problem is the matching of the name. How can I tell line 2,3 to match line 1 and then lines 6,7,8 to match line 5 and so on. Each group can contain a different number of objects below it"
PowerShell,3az5y1,stanrc,1 point,Wed Jun 24 18:27:23 2015 UTC,"If you add them to an object then it will keep them together. As for the groups having different lengths, I think you'll just have to search for a common string in the first line such as ""server"" to use as the starting point. Similar to how I'm searching for ""name"" in my script."
PowerShell,3az5y1,stanrc,2,Wed Jun 24 18:33:59 2015 UTC,"Still working on this. getting closer   As of now I look for Server and create a new object with server type/servername/date(Having problems regexing the datetime and server name out of it but whatever)  Beyond that using an else statement I'm populating the Username,Fullname field  The problem I have is im just overwriting the same object over and over again instead of creating a new line."
PowerShell,3az5y1,mpaguilar,1 point,Wed Jun 24 21:59:22 2015 UTC,Are you doing obj += ?
PowerShell,3az5y1,KevMar,1 point,Wed Jun 24 22:23:05 2015 UTC,"$data = get-content .\data.txt  $typ = """" $name = """" $dte = """"  $data | foreach {     [String]$curline = $_      if( $curline -like ""*Server*"" )     {         $tmp = $curline.Split("" "")         $typ = $tmp[0] + "" "" + $tmp[1]         $name = $tmp[2]         $dte = $tmp[3]         return     }     write-host ""$typ, $name, $dte, $($curline.Replace(':', ','))"" }   EDIT: removed some overkill"
PowerShell,3az10m,fcewen00,1 point,Wed Jun 24 17:17:41 2015 UTC,"-TrustedSendersAndDomains   Isn't a valid parameter, you probably want something like:  Get-MailboxJunkEmailConfiguration <user> | ?{$_.TrustedSendersAndDomains -match ""pacmail.em.marketinghq.net""}"
PowerShell,3az10m,the_spad,1 point,Wed Jun 24 17:20:38 2015 UTC,That would be why I was having problems.  Lets see how this works. crosses his fingers Thanks for your help.  I've been chasing phishing attacks at the university I work at for nearly two weeks trying to be proactive.
PowerShell,3az10m,RampageUT,1 point,Wed Jun 24 17:25:51 2015 UTC,Any idea how I would make the addition of making it search just the active accounts instead of the 150k+ we have?
PowerShell,3az10m,the_spad,3,Wed Jun 24 17:30:33 2015 UTC,"Get-MsolUser -All | ?{$.islicensed -eq $true}| Foreach {Get-Mailbox $.userprincipalname |          Get-MailboxJunkEmailConfiguration | ?{$_.TrustedSendersAndDomains -match ""pacmail.em.marketinghq.net""}}  This will return all licensed users and search each mailbox."
PowerShell,3az10m,the_spad,1 point,Wed Jun 24 18:20:00 2015 UTC,"150k? Jesus.  Well it's tough as the mailboxes will still be enabled regardless. You'll need to do something like get a list of enabled accounts from AD and then pipe that into the Exchange cmdlets - unless you mean ""active"" in a different context."
PowerShell,3az10m,the_spad,1 point,Wed Jun 24 18:20:12 2015 UTC,"University.  We have a shitton of enabled accounts, not all are used at any give time."
PowerShell,3azfhv,Beowulf87,1 point,Wed Jun 24 19:02:55 2015 UTC,Which dialogue box?  Do you mean change what it says or change which users & groups can add to the domain?
PowerShell,3azfhv,the_spad,1 point,Wed Jun 24 19:29:46 2015 UTC,"Sorry about that I should have clarified myself, I want to change which users and groups can add that computer to the domain."
PowerShell,3azfhv,the_spad,1 point,Wed Jun 24 19:30:44 2015 UTC,You need to delegate the Create Computer Objects permission for the users you want on whatever your default join container is (Computers by default) in AD.
PowerShell,3azfhv,the_spad,1 point,Wed Jun 24 19:43:28 2015 UTC,"I think I understand what you are saying and I think we already have something like that.  We have a group called Techs that are allowed to add and remove computers from the Domain so when I create a computer using the New Object dialogue box I change the user or group from Default: Domain Admins to Techs, is it possible to do this with powershell?"
PowerShell,3az0b4,Kerackiswhack,1 point,Wed Jun 24 17:12:23 2015 UTC,"It sounds like there's something wrong with your machine; I know you said it works from the console but that doesn't change the fact that it should also work via ISE (though I've had massive issues with Exchange cmdlets via ISE in the past) and you really shouldn't have any issues with the [ADSI] provider in any context.  [ADSI] stuff is independent of the RSAT tools, they only provide the AD cmdlets (Get-ADUser, etc). The [ADSI] provider is built into vanilla Powershell."
PowerShell,3az0b4,the_spad,1 point,Wed Jun 24 17:18:05 2015 UTC,"That's what was totally throwing me off.  The ""default"" according to the help files for PS is -STA, but apparently running STA in the regular console and -MTA on the ISE is the trick.  The logic behind this is clearly beyond me, and it's frustrating as all hell."
PowerShell,3az0b4,the_spad,2,Wed Jun 24 17:21:26 2015 UTC,Since Powershell 3 both the console and ISE run in STA by default.  You can get the current operating state with  [System.Management.Automation.Runspaces.Runspace]::DefaultRunspace.ApartmentState   or  [threading.thread]::CurrentThread.GetApartmentState()
PowerShell,3aykew,MrYiff,4,Wed Jun 24 15:17:57 2015 UTC,"$Session = New-PSSession –ConfigurationName Microsoft.Exchange –ConnectionUri $exchangeServer -Authentication Kerberos   The dashes before ConnectionUri and Authentication are different. The latter is ASCII 22, minus; the latter Unicode em dash U+2013."
PowerShell,3aykew,BadSysadmin,3,Wed Jun 24 15:28:47 2015 UTC,"AHA!  Bravo to you /u/BadSysadmin   I figured it had to be something completely obvious staring me right in the face, it just never dawned on me that it it would be one of those pesky -'s!  Have my thanks and an upvote!"
PowerShell,3axj79,JaapBrasser,4,Wed Jun 24 08:20:19 2015 UTC,This implies I close my ConEmu terminal ;)
PowerShell,3axj79,gospelwut,2,Wed Jun 24 11:38:08 2015 UTC,Should check out: Cmder. http://gooseberrycreative.com/cmder
PowerShell,3axj79,bobdle,1 point,Thu Jun 25 14:39:04 2015 UTC,My blog post is about Cmder actually :)
PowerShell,3axj79,gospelwut,1 point,Thu Jun 25 14:50:25 2015 UTC,"Haha, then in your case Pin that one to the taskbar so you have easy access to it if you happen to be in another application :)"
PowerShell,3axj79,gospelwut,1 point,Wed Jun 24 11:50:20 2015 UTC,"Actually, ConEmu can be setup to pop up when you hit CTRL+` (once the process is running). Though, I do have it pinned.  CTRL+T = new tab CTRL+SHIFT+T = new admin tab  Come to the dark side - https://blog.runas.me/2014/08/28/powershell-console-conemu-psreadline/"
PowerShell,3axj79,SomnambulicSojourner,1 point,Wed Jun 24 20:04:13 2015 UTC,"I installed ConEmu a couple of weeks ago and it has changed my life. I love the quake terminal style, makes everything so much easier and smoother when I can just pop it up and down. I've barely scratched the surface of what it can do and I love it."
PowerShell,3axj79,bundyfx,1 point,Wed Jun 24 21:25:53 2015 UTC,"It is still on my to-do list, I heard good things about conemu!"
PowerShell,3axj79,feelingsofwhite,2,Wed Jun 24 21:44:13 2015 UTC,Good to know Jaap! nice little shortcuts.
PowerShell,3axj79,implicitly_bonsai,1 point,Wed Jun 24 10:44:18 2015 UTC,"No problem, here to help!"
PowerShell,3axj79,maancha,1 point,Wed Jun 24 11:50:36 2015 UTC,"Been doing this fire a few years now and it's awesome. And TIL about the shift and alt variants -- thanks!   I actually have a few standard pins for all my machines,  vms, etc. So for example my text editor of choice is always win+2. Web browser is win+3.   Makes for some quick navigation between apps"
PowerShell,3av3kn,lostmojo,5,Tue Jun 23 19:15:18 2015 UTC,"Because PowerShell tries to match the type on the right side of the comparison to the type on the left side of the comparison. Usually this works out quite great, in case of $true and $false it is initially confusing.  For example:  $true -eq 'true' True  $true -eq 'false' True  $false -eq 'false' False  $true -eq 1 True  $true -eq 0 False  $true -eq ' ' True  $true -eq '' False"
PowerShell,3av3kn,JaapBrasser,6,Tue Jun 23 19:30:39 2015 UTC,"You're comparing a Boolean to a string, I think this comparison would give you the result you are expecting. When you use -like its automatically doing to casting from Boolean to String.  [String]$result -eq 'LineError'"
PowerShell,3av3kn,HamQuestionMark,2,Tue Jun 23 19:28:19 2015 UTC,"So it must be casting the string to a bool for the comparison.  $true -eq [bool]""LineError""   Interesting."
PowerShell,3av3kn,KevMar,4,Tue Jun 23 19:33:12 2015 UTC,"Could it be that  $true -eq ""anythingthatisnotfalse""   Interesting question, I'm curious to see what others think."
PowerShell,3av3kn,Stoffel_1982,7,Tue Jun 23 19:21:59 2015 UTC,"$true -eq ""anythingthatisnotfalseORnull""   Minor point, but this is essentially correct.  $true is anything not $false (integer value of zero) or $null (no value).  Basically, any string will evaluate to a boolean value of ""true"".  -like is a conditional operator and only evaluates to $true if both sides of the equation are the same.  If you type  $true.ToString()   You'll notice you get the string ""True"", which is what the -like operator is using for its comparison.  As such, ""True"" -like ""LineError"" will return False."
PowerShell,3av3kn,ryanbrown,2,Tue Jun 23 19:27:53 2015 UTC,"I thought since the first operand was a boolean, that it was casting the string down to a boolean, and since it wasn't the empty string (which is $false), it evaluates as $true"
PowerShell,3av3kn,wonkifier,1 point,Tue Jun 23 22:48:06 2015 UTC,That's how I see it.
PowerShell,3av3kn,MShepard70,5,Wed Jun 24 03:05:08 2015 UTC,Really?  How have I not noticed this over the years?  Haha I can go crawl in to a corner and weep silently to myself now.   Thanks
PowerShell,3av3kn,mhurron,3,Tue Jun 23 19:24:35 2015 UTC,"Pretty much. The answer is the standard 'What is Truth' section of every programming manual.  The equality is asking, ""Is this true?"" The answer is yes because strings are True."
PowerShell,3av3kn,gregortroll,1 point,Tue Jun 23 19:31:11 2015 UTC,"Yeah, this is the consequence of allowing cross-type comparisons, with automatic casting.  $true  -eq  '0' is true $false -eq   0  is true but.. '0' -eq 0 is true   So, you just have to learn it, or code such that you can avoid thinking about it."
PowerShell,3av3kn,nduval,1 point,Tue Jun 23 21:25:15 2015 UTC,"It is worth mentioning, if you are ever not sure what your variable is, you can use $Result.getType() to show if it is an integer (int32) a string or boolean."
PowerShell,3av3kn,ShippingIsMagic,1 point,Tue Jun 23 22:04:38 2015 UTC,Truthy - not just for JavaScript anymore!
PowerShell,3avkbm,lostmojo,2,Tue Jun 23 21:12:12 2015 UTC,"[datetime]""10:00:00 Tue 06/23""   Done."
PowerShell,3avkbm,the_spad,1 point,Tue Jun 23 21:16:44 2015 UTC,Really?  This has not been my day for smarts yet... Maybe more coffee?  Thank you!
PowerShell,3avkbm,the_spad,1 point,Tue Jun 23 21:33:48 2015 UTC,PowerShell is surprisingly good at converting dates and times except when it randomly decides to treat everything as if it's in US date format.
PowerShell,3avta4,RoninSpartan,0,Tue Jun 23 22:19:11 2015 UTC,"Is what you have posted how your script is actually formatted?  Using proper intending sure would make your code a lot easier to follow.  This is particularly helpful when trying to figure out a program flow issue like this.  BTW do you really need your read-host stuff to be in a loop?  That seems over-kill for a script like this.  Anyway with proper indenting your code might look like this.  (I cut out the active commands to debug).  ""blah blah intro text"" Do {     $disabled = read-host ""Do you want to?""     If ($disabled -eq 'Y')     {         Write-host 'disabled'     }     ElseIf ($disabled -eq 'N')     {         break     }     {         'not disabled'     }     Else     {         'Only two options'     }  } While ($disabled -ne 'Y')   See how you have not one but two {} blocks after your ElseIf?  That is your problem.  Your ElseIf section probably should look like this, but I am not entirely sure what you are going for.      ElseIf ($disabled -eq 'N')     {         'not disabled'         break     }"
PowerShell,3avta4,zoredache,1 point,Tue Jun 23 23:20:16 2015 UTC,"ah that makes sense...  the formatting for the script into code didn't stick, sorry about that.   read-host probably isn't need for the IT side of things. I was going to modify it for user accounts as well so that it could be sent for some of our clients (as they don't allow for remote sessions, or just prefer not to give us a list in a timely fashion).   Thank you though for clearing it up. I'll clean up the code and mark it solved."
PowerShell,3av7c8,sysadm1n,1 point,Tue Jun 23 19:41:42 2015 UTC,"OK I'm special figured it out :)  Move     Import-DscResource -module xjea  outside the ""node"" block but keep it inside the ""configuration"" block. Apparently I need to keep reading about DSC to see WHY that is, but it is what it is. Time to move forward. :)"
PowerShell,3av6ey,ryanmcd90,2,Tue Jun 23 19:35:41 2015 UTC,"With persistent data we store a JSON text file in Azure blob storage, a simple function at the start of all the scripts needing to pull persistent data just makes one call to the Azure Blob and it auto converts into a PSObject that can be easily searched/manipulated (it holds expected config information). Its worked out pretty well so far. Obviously you might not have a ""blob"" storage system but you can get the same affect with a json document on a share also. I would take JSON over CSV/XML in 90% of the cases..."
PowerShell,3av6ey,ButterCupKhaos,1 point,Wed Jun 24 03:11:53 2015 UTC,"So, if I'm reading this correctly, for each branch there will be no less than four static variables, and possibly more depending on how many positions there are (you use the term 'approximately', so I assume it varies).  I'm not following why you need to edit multiple text files, though, so good chance I'm missing something. To me it sounds like you have the need for one file to map the groups to the positions, and one file to store the data that the script produces?  For small scale, that sounds to me like it could easily be saved in a CSV file, which PoSh can easily import and read the variables of based on the header. Assuming you are looking for the groups to be changeable, I'd personally just throw those in the top of the script as variables with instructions.  But, if that isn't working you could just have a second CSV that has two columns, one for the position and one for the group(s) it is associated with.   Personally I hate XML, so take what you will =) Either way, let me know how I misinterpreted and we'll go from there."
PowerShell,3auksf,RickSaysMeh,1 point,Tue Jun 23 17:05:02 2015 UTC,"$ is PowerShell's variable designator.  When you use double quotes, PowerShell tries to interpolate variables in a string.  It might be trying to translate the piece following the $ as a variable.  edit: Read the path wrong, but it might still be interpolation."
PowerShell,3auksf,ryanbrown,1 point,Tue Jun 23 17:11:09 2015 UTC,"I agree, shouldn't the path include the backtick (`) by the $ to escape that character?  ""\\server\users`$\user\My Documents\PowerShell Scripts\DeleteFiles.ps1"""
PowerShell,3auksf,ShiftNick,1 point,Tue Jun 23 17:23:43 2015 UTC,"Yes, either escape $ with a backtick or use single-quotes instead of double-quotes to avoid string expansion.   It seems that OP need to do this both in the expression he uses to invoke the script and inside the script itself"
PowerShell,3auksf,PowerShellStunnah,1 point,Tue Jun 23 18:25:07 2015 UTC,"This works perfectly fine (without the delimiter):  Get-Content ""\\server\users$\user\Desktop\DELETE.txt"" | Remove-Item   Why would it be any different within a variable... It also doesn't explain why it did work previously and now it doesn't..."
PowerShell,3auksf,ShiftNick,1 point,Tue Jun 23 18:41:30 2015 UTC,"Also, you said they did a system restore.  Did it restore to a previous version of Powershell?  Check $PSVersionTable"
PowerShell,3auksf,mikefrobbins,1 point,Tue Jun 23 17:25:13 2015 UTC,"You need to use the invocation operator since there's a space in the path:  & '\\server\users$\user\My Documents\PowerShell Scripts\DeleteFiles.ps1' -InputFile '\\server\users$\user\Desktop\DELETE.txt'   If you're not going to enter the -InputFile parameter with the command, drop the quotes all together when specifying it (I was able to reproduce the problem and workaround it with this solution):  & '\\server\users$\user\My Documents\PowerShell Scripts\DeleteFiles.ps1' Supply values for the following parameters: InputFile: \\server\users$\user\Desktop\DELETE.txt <<-- No Quotes   Also, stick to single quotes for literal values unless there's a variable or something you're trying to expand.  Mike F Robbins mikefrobbins.com @mikefrobbins"
PowerShell,3auksf,mikefrobbins,1 point,Tue Jun 23 18:36:10 2015 UTC,"The dot appears to work as well in this case... But I will have him try the ampersand.  My coworker has a shortcut on his desktop with this as the target:  C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe -File ""\\server\users$\user\My Documents\PowerShell Scripts\DeleteFiles.ps1""   And he just drags and drops the text file onto it. I only used the dot sourcing to keep the window open so I could see the error..."
PowerShell,3auksf,ryanbrown,1 point,Tue Jun 23 18:45:06 2015 UTC,"I was able to reproduce the exact problem. It appears if you wait until the mandatory parameter kicks in and ask for the InputFile, it complains if quotes are used and it only works when no quotes are specified:  InputFile: \\server\users$\user\Desktop\DELETE.txt <<-- No Quotes"
PowerShell,3auksf,ryanbrown,1 point,Tue Jun 23 18:52:56 2015 UTC,So the end-user likely has some non-sanitized input in the file he/she drags and drops onto the script.  Likely a blank line or a line with a space?
PowerShell,3auksf,catfoodsci,1 point,Tue Jun 23 19:03:55 2015 UTC,"I added this line to the script and I think it may be fixed:  $InputFile = $InputFile -Replace '""',''   I'm waiting to hear back from my coworker. It's still weird that it worked prior to the system restore. ShiftNick may have a point about the PowerShell version."
PowerShell,3auksf,catfoodsci,1 point,Tue Jun 23 19:19:38 2015 UTC,"You could also try wrapping the Get-Content line with a Try..Catch statement and write the exception message to a file.  That should help you trap any errors when your co-worker runs the script as opposed to trying to trace it manually.  Something like...  Try {     Get-Content $InputFile | Remove-Item } Catch {     Out-File -FilePath ""C:\temp\error.txt"" -Append -InputObject $_.Exception }"
PowerShell,3au8w5,superadmin1990,5,Tue Jun 23 15:36:10 2015 UTC,Just add each machine name as a separate line in a text file.  Then change to this:  $ListOfMachines = (Get-Content C:\ListOfMachines.txt)
PowerShell,3au8w5,SeanQuinlan,2,Tue Jun 23 15:54:15 2015 UTC,"Well, that was easy. Sorry, I'm still a newbie. Thanks a ton!"
PowerShell,3au8w5,InvisibleTextArea,3,Tue Jun 23 15:57:08 2015 UTC,"Use a CSV File?  $FilePath = ""C:\Listofcomputers.csv"" $MyCSV = Import-CSV $FilePath ForEach ($Computer in $MyCSV) { Write-Host $Name =$Computer.Name `n }"
PowerShell,3au8w5,mikefrobbins,1 point,Tue Jun 23 15:41:15 2015 UTC,"so my current script  $service = ""servicename"" $listOfMachines = @(""computer1"",""computer2"") $listOfMachines | ForEach-Object { Get-Service -ServiceName                  $service -ComputerName $listofmachines | Stop-Service   Would then look like  $filepath = ""c:\filepath\listofcomputers.csv $myCSV = import-CSV $filepath $service = ""servicename"" $listOfMachines = @($myCSV) $listOfMachines | ForEach-Object { Get-Service -ServiceName                  $service -ComputerName $listofmachines | Stop-Service   ?"
PowerShell,3au8w5,frisked,1 point,Tue Jun 23 15:48:11 2015 UTC,"As SeanQuinlan said, just save the computer names in a text file with one computer name per line. Also, you can use Get-Content in a one-liner by enclosing it in parentheses without having to store the machine names in a variable and there's no need to use ForEach-Object since the ComputerName parameter accepts an array of strings:  Get-Service -Name servicename -ComputerName (Get-Content -Path C:\ListOfMachines.txt) | Stop-Service   Mike F Robbins mikefrobbins.com @mikefrobbins"
PowerShell,3au8w5,Rage321,1 point,Tue Jun 23 16:03:08 2015 UTC,"Not really answering your question but could possibly help here, if you're in a domain you could run Get-ADComputer -filter * (or actually put a filter in if you need to limit)"
PowerShell,3au6qv,biggestluxplayseu,1 point,Tue Jun 23 15:19:52 2015 UTC,"Do you have any blank lines in the CSV file?  How many users are in the CSV file? Do you get this error for every user in the CSV file or just once?  How was the CSV file generated? Did you do that manually, or are you getting it from another application?  I suspect the problem is with the formatting of the OU. I would check there first. Since the OU contains spaces, unless it's quoted correctly in the CSV file, it may not be imported correctly.  I would echo out the value of $OU for each user to confirm it's correct."
PowerShell,3au6qv,SeanQuinlan,1 point,Tue Jun 23 15:35:46 2015 UTC,"OU looks like this OU=Franchise-Managers,OU=Group-Operations,OU=ACA Users,DC=***,DC=***,DC=com  there are  27 users in the CSV File and it happens for all of them, I generated the list manually,   Goes - Firstname | Lastname | OU  **Edited for security"
PowerShell,3au6qv,SeanQuinlan,2,Tue Jun 23 15:41:09 2015 UTC,"If you open the CSV file in a text editor (notepad is fine), does the OU field have double quotes around it?"
PowerShell,3au6qv,SeanQuinlan,1 point,Tue Jun 23 15:48:21 2015 UTC,"Yes, should it/Should it not?"
PowerShell,3au6qv,SeanQuinlan,2,Tue Jun 23 15:50:09 2015 UTC,"It should yes.  I have spotted the problem. Remove the quotes on this line:  $OU = ""$User.OU"""
PowerShell,3au6qv,SeanQuinlan,1 point,Tue Jun 23 15:51:19 2015 UTC,That worked :) Second pair of eyes always helps!  Wouldn't know a simple way to generate a random password for each user within the script would you?
PowerShell,3au6qv,ShiftNick,1 point,Tue Jun 23 15:55:41 2015 UTC,"This will generate a random password of 20 characters with a minimum of 5 special characters:  Add-Type -Assembly System.Web $Random_Password = [Web.Security.Membership]::GeneratePassword(20,5)   Randomly generating a password like this is fine if you never intend to log in with that user at all (eg. the local Administrator account). Otherwise you'll need a way to store the username and password so that you can tell the user what their password is."
PowerShell,3au6qv,ShiftNick,1 point,Tue Jun 23 19:36:25 2015 UTC,"ahh yeah, I'd need it to output the password that it generates for each username so I could give it to each user. . I'll just do it manually. .   Thanks for the code though."
PowerShell,3au6qv,SaladProblems,1 point,Tue Jun 23 19:40:23 2015 UTC,"Well you could add this after the New-ADUser line:  ""$SAM : $Password"" | Out-File ""c:\users\user\desktop\users_pw.txt"" -Append   Although personally I'd just set it to the same password and force the user to change it when they log in. No-one is ever going to remember a randomly generated password, better to let them choose it :)"
PowerShell,3atj7w,the_spad,1 point,Tue Jun 23 11:44:58 2015 UTC,"(get-adgroupmember ""Domain Users"").count   Works just fine for me. Returns <number of users in the domain -1> as I would expect.  Neither Get-ADGroup nor Get-ADGroupMember return objects with a Members property, which might explain your odd results."
PowerShell,3atj7w,the_spad,2,Tue Jun 23 12:04:09 2015 UTC,The quoted text writes 'size limit for the request was exceeded' to the console. Expected behavior. Any way to work around this limit?
PowerShell,3atj7w,blackcamo,4,Tue Jun 23 12:11:50 2015 UTC,"My DU is only ~3000 members so I didn't hit the issue. Looks like you can increase the limit on ADWS  You can't do the other workaround of  Get-ADGroup ""Domain Users"" -Properties member | Select-Object -ExpandProperty member   Because it'll return blank for Domain Users. This is because Domain Users is the primary group of most (if not all) of your users and thus they don't count as members of it in the same way as other groups (Domain Users won't appear in the user's memberof attribute either). Equally using ADSISearcher will have the same problem.  ([adsisearcher]""name=Domain Users"").FindOne() | % { $_.GetDirectoryEntry() | Select-Object –ExpandProperty member}"
PowerShell,3atj7w,JaapBrasser,2,Tue Jun 23 12:27:38 2015 UTC,"Yes, it is expected behavior so you don't shoot yourself in the foot (as fast). Check this out: https://social.technet.microsoft.com/Forums/windowsserver/en-US/dbb3777c-dd14-4e3a-8690-103d991e2b85/how-do-i-resolve-the-size-limit-exceeded-for-getadgroupmember-error-when-listing-a-group-with?forum=winserverpowershell"
PowerShell,3atj7w,JaapBrasser,2,Tue Jun 23 12:20:18 2015 UTC,"You could set the page size for your query, here is an example using the DirectorySearcher object:  New-Object DirectoryServices.DirectorySearcher -Property @{     Filter = '(&(objectCategory=person)(objectClass=user)(primarygroupid=513))'     PageSize = 100 } | ForEach-Object {     $_.FindAll() | Measure-Object }"
PowerShell,3atj7w,creamersrealm,1 point,Tue Jun 23 12:51:53 2015 UTC,"Sure, you can use the Get-ADGroupMember cmdlet instead. For example:  Get-ADGroupMember 'Domain Users' | Measure-Object"
PowerShell,3aseyl,THINNINGnotBald,6,Tue Jun 23 03:21:56 2015 UTC,What has helped me out in my workplace is to stop and think about some of the problems or inefficiencies there and how to solve them using Powershell.   My best learning experiences have been how to take real world problems and solve them no matter how big or small.  Start looking.
PowerShell,3aseyl,cyborgcommando0,3,Tue Jun 23 04:37:08 2015 UTC,This is how I started learning. Need to create 1 or 100 users and aren't pressed for time? Powershell learning! Need to set up a new server? Powershell learning! Need to set up a new vm host? Powershell learning! Need to create a new dns record? Powershell learning! Need to search for a specific file/s? Powershell learning! See a cmdlet you haven't seen before? Powershell learning!
PowerShell,3aseyl,silentmage,2,Tue Jun 23 10:21:58 2015 UTC,"Totally agree. I am blessed and super grateful to get this internship. I am excited that I actually get to run some basic PowerShell cmdlets and not just ""know of PowerShell and yea, its powerful"".  I just learned nested loops today and how to parse an XML file to get the 2nd, 3rd or 4th child element.  The challenge I am having is that, what if I am given an XML file so huge that looking through it is impossible? Say, I don't even have access to the file itself in any other means besides through PowerShell, and I need to figure out how many child-elements this XML file has.   I tried doing a Loop to go inside the Parent XML element, and spit out the first child element, using Write-Host, and it seems to spit out what ever data there was in the child element.  Kind of confused right now but I WILL  GET THIS! I am confident of that.  Thank you for your advice and if you recommend any book, video resource, and any other way of doing this, I am grateful."
PowerShell,3aseyl,Daslayah,6,Thu Jun 25 04:39:19 2015 UTC,Get a book - learn the book - write scripts to solve problems.  That is how I did it.
PowerShell,3aseyl,JaapBrasser,3,Tue Jun 23 07:30:48 2015 UTC,"This works great, especially when you have a decent book. You'll have the in-depth knowledge to tackle most problems you'll run into. There's some good books out there, give them a try."
PowerShell,3aseyl,JaapBrasser,1 point,Tue Jun 23 09:23:12 2015 UTC,"I would love to, any that you would recommend? I have the next 5 months at this internship and if I get lucky, possibility of a 3 month extension."
PowerShell,3aseyl,SaladProblems,1 point,Thu Jun 25 04:40:05 2015 UTC,"I would recommend PowerShell In Action, it is the most indepth book I have read so far. So if you want to go deep, it is a great book to dive into. Other great books are PowerShell Best Practices, PowerShell Deep Dives or PowerShell In Depth."
PowerShell,3aseyl,ioFAILURE42,3,Thu Jun 25 09:30:48 2015 UTC,"Just post more info about the data you need to get and there's almost always someone on here who will help you figure it out.  When it comes to VMware, you're probably going to be choosing between Get-VM and Get-View. You'll find that Get-VM is almost definitely going to give you all the of the info you need and is easy to use. However, Get-View, though harder to learn, will be way faster.  I'd personally recommend using Get-VM initially for your VM list, and then move on to Get-View once you've your head around manipulating data and you are more interested in speed.  Is editing XML files really going to be the easiest route for people to use? Editing them and then importing may complicate things, but you should be able to do it gracefully nonetheless. It just depends on what your input data and desired output are."
PowerShell,3aseyl,ioFAILURE42,2,Tue Jun 23 17:11:24 2015 UTC,"To solve the problem that the company has right now, editing the XML is what is desired by management, and I am following their lead since I have no idea how to solve it.  The problem is, from my limited understanding:  1) There are daily list of backup servers generated with server names and name of each VMs inside those servers  2) We have had issues where we found a VM that is in the backup, but was not found in Prod/Test/...and other environments (this part is not 100% clear to me so I am probably wrong here).  3) We want to take the daily generated list of backups, and compare it to the list of current VMs that we DO have, and do a unique comparison to find any missing ones, find discrepancies, etc. The tricky part is the VM names - they are horribly done. Some VM's are literally like ""Contact Jane Doe"" and THAT is the name of the VM....I am able to see this info when logging in through vSphere client."
PowerShell,3aseyl,JaapBrasser,2,Thu Jun 25 04:52:18 2015 UTC,"It sounds like you're on the right track already. Virtual academy is a great place to learn basic and advanced concepts, but there's no way someone can be expected to learn all the different cmdlet's/techniques available to them in PowerShell. It's just so diverse.  Google is your friend. For instance:  $a = get-content <file-path> $a = $a | select -uniq   With time, your natural library of known commands will grow. At least to the point where you might remember specific keywords to re-google at a later date.  Save ALL your scripts, and save copies of them as backups for you to play with. That way you can modify or cut/paste bits out of them to adapt them as time goes on. There is nothing worse than taking an existing script that is functional and butchering it trying to make it fit another need without having a backup available. Every time your script reaches a milestone, save it as a new backup, then continue scripting. This can get messy fast, so stay organized with it as well.  Biggest thing I can say to you is this-  If you're trying to do something in any scripting/programming language, odds are that someone else on the internet has already done it for you. You just have to find it. You are not the first person to come up with these concepts, y'know?  The tricky part is adapting what you can find online into usable scripts for your own organization/needs. Also improving script efficiency.  edit: formatting."
PowerShell,3aseyl,JaapBrasser,1 point,Tue Jun 23 06:21:01 2015 UTC,"Awesome! You are right! I am already getting messy because now I have a "".ps1"" file and a corresponding "".xml"" file to go with it. I am currently just zipping the older scripts along with its xml files.  Any good recommendations to keep this organized?   Should I make folders separated by date-stamps inside a backup folder?  Also, Google. I have struggled a lot when finding a simple solution and Google has saved the day many, many times. I have lots of ""UNKNOWN, UNKNOWNs"" where I don't even know what to search, and therefore cannot find the solution that I need. This is where the IT manager is really helpful. He just tells me 2 words and that sets me on the right track.  I will try the     $a = $a | select -uniq that you suggested. My goal for this week is to take a list of AD-Users.txt from my co-worker, and compare that for any Unique ones to a list generated by a script my co-worker made, and then spit that onto a separate csv or xml file - ALL using PowerShell. I want to avoid having to convert back and forth from file formats.  Currently it is available as a huge list in notepad, separated by a new line. (so a big column list of usernames).  Thanks for the advice, really loving this subreddit!"
PowerShell,3aseyl,GAThrawnMIA,1 point,Thu Jun 25 04:47:14 2015 UTC,"It sounds like you have an excellent resource in your manager. Those unknown unkowns are what I was talking about when I said that your natural library of previously used commands will grow in time. There's no easy way to learn them other than to ask others and do some googling.  As for keeping things cleaned up, your guess is as good as mine. I personally have a base ""prod"" folder for each script I write, and inside of it I keep a ""test"" folder for different versions that I'm working on. Do what feels best for you.  As for your specific tasks here, writing to output has always been a pain for me. I found it easier to modify the system $ofs variable to make arrays be separated by specific terms.   For instance, $ofs by default equals "" "", so elements inside an array will be separated by spaces. If you set   $ofs = ""`r`n""   then your elements will be stored in the array separated by a return character      (`r)   and a new line      (`n).   You could do the same thing to make output to csv's easier.      $ofs = "",""  Let me know if you learn any handy tricks for export-csv or similar commands.   Good luck and happy scripting!"
PowerShell,3aseyl,sfw247,1 point,Mon Jun 29 04:24:47 2015 UTC,"Alright, MVA is great Youtube a good option as well. The best thing is when you are able to apply your knowledge to a problem, by actually attempting to script something. For me personally working on a script will allow me to learn much faster as I can directly put new tricks to use.  As for practicing with vCenter, you can install ESX in VMware Workstation so you could play around with a lab environment before practicing with your production environment.  Following the forums to see how others are using PowerShell is a great way to do this as well. I personally follow PowerShell.com, PowerShell.org, TechNet Scripting Guy/PowerShell and of course these boards. It can be interesting see what other people use PowerShell for and learn from their experiences.  I wrote a blog post with a number of learning resources, feel free to have a look at it here: [How to Learn PowerShell](www.jaapbrasser.com/how-to-learn-powershell/)"
PowerShell,3aseyl,mikefrobbins,1 point,Tue Jun 23 08:38:52 2015 UTC,Thank for the detailed blog post! It is getting late for me now but I will be reading this during lunch time at work!
PowerShell,3aseyl,afoggy,1 point,Thu Jun 25 04:53:42 2015 UTC,"No problem, let me know if you have any questions in regards to the post or if you feel that there is any information missing in the post! I love feedback :)"
PowerShell,3apofd,ramblingcookiemonste,3,Mon Jun 22 14:17:48 2015 UTC,"Hi all!  This is nothing new, but I've always been a bit intimidated by things like format.ps1xml files.  Turns out they aren't too bad, and they can help make your PowerShell functions more usable.  Cheers!"
PowerShell,3apofd,1RedOne,3,Mon Jun 22 14:19:46 2015 UTC,"Nice work, Warren.  I've also been afraid of ps1xml files myself.  Since you're bravely forging ahead, could you write a modern example of making modules and how I should be doing it?    Currently, I just put a bunch of function declarations in a text file and save it as .psm1."
PowerShell,3apofd,itsteve,2,Mon Jun 22 15:44:35 2015 UTC,also guilty
PowerShell,3apofd,1RedOne,2,Mon Jun 22 19:53:04 2015 UTC,"Hi Stephen!  I do that as well, nothing wrong with it : )  That does sound like a fun quick hit though, might take you up on the suggestion!  On a side note, there's an interesting project on GitHub to help simplify creating modules; most module authoring steps apply to pretty much any module you write, with a few substitutions.  Cheers!"
PowerShell,3apofd,KevMar,1 point,Mon Jun 22 21:46:10 2015 UTC,"Also, I must say that your site loads lightning fast now. Good work!"
PowerShell,3apofd,boeprox,1 point,Mon Jun 22 23:04:39 2015 UTC,I create a functions folder and have the .psm1 file load every .ps1 file in it. I have a single file for each function. This makes it easy to manage pester tests and works well with source control.  I did a quick writeup: http://kevinmarquette.blogspot.com/2015/06/quick-and-dirty-powershell-modules.html
PowerShell,3apofd,KevMar,2,Tue Jun 23 02:01:27 2015 UTC,"This is exactly what I do now. I used to have everything in a single .psm1 file, but after working with PoshWSUS, I separated everything out into its own .ps1 file. I find it much easier to manage now doing it this way."
PowerShell,3apofd,bundyfx,1 point,Tue Jun 23 02:05:26 2015 UTC,I think I picked this up looking at Dave Wyatte's pester code.
PowerShell,3apofd,boeprox,1 point,Tue Jun 23 02:16:00 2015 UTC,Great read! very insightful.
PowerShell,3aqm9u,stormnet,2,Mon Jun 22 18:39:44 2015 UTC,"This is what I used recently.  You will have to download and install the Access database engine 2010 for your particular flavor.  Hope it helps.  After installing the Access database engine you should be able to run  (New-Object system.data.oledb.oledbenumerator).GetElements() | Where-Object { $_.SOURCES_NAME -like '*ACE.OLEDB*'}   at the PS prompt to verify it is accessible.  You should see something like this:  SOURCES_NAME        : Microsoft.ACE.OLEDB.12.0 SOURCES_PARSENAME   : {3BE786A0-0366-4F5C-9434-25CF162E475E} SOURCES_DESCRIPTION : Microsoft Office 12.0 Access Database Engine OLE DB Provider SOURCES_TYPE        : 1 SOURCES_ISPARENT    : False SOURCES_CLSID       : {3BE786A0-0366-4F5C-9434-25CF162E475E}   PS Insert Function:  Function Update-DB {     param ([pscustomobject] $info, [string] $dbase)     Write-Debug -Message '***** Function Update-DB *****'     $conn=New-Object System.Data.OleDb.OleDbConnection(""Provider=Microsoft.ACE.OLEDB.12.0; Data Source=$dbase"")     $conn.Open()     $query = ""INSERT INTO Table (Field1, Field2, Field3) VALUES ('$($info.F1)','$($info.F2)','$($info.F3)')""     $cmd = $conn.CreateCommand()     $cmd.CommandText = $query     $result = $cmd.ExecuteNonQuery()     $conn.Close()     Write-Output $result }  $info = [pscustomobject] @{     F1 = 'sometext'     F2 = 'sometext'     F3 = 'sometext' }  $dbase = '\\path\to\some.mdb'  Update-DB $info $dbase"
PowerShell,3aqm9u,smarsha,1 point,Mon Jun 22 19:10:24 2015 UTC,"You can use the inbuilt ole provider, but you need to use 32 bit powershell. My account creation script does it. See my addtoicreatedb function here: https://github.com/nonprofittechy/psnewaccount/blob/master/provisioning/provision.ps1 and more details here: http://nonprofittechy.blogspot.com/2015/05/user-account-creation-script.html?m=1"
PowerShell,3aqre2,SaladProblems,3,Mon Jun 22 19:17:57 2015 UTC,The Get-Help for Invoke-WebRequest has an example for logging in with web-based forms.    User /u/1RedOne has a blog post on Invoke-WebRequest and web forms which you might find helpful.
PowerShell,3aqre2,pandiculator,2,Mon Jun 22 21:21:22 2015 UTC,Thanks for the shout!   Yep I'd be happy to help!
PowerShell,3aqpr7,sysadm1n,1 point,Mon Jun 22 19:05:45 2015 UTC,"LOG may help  PS C:\Users\sysadm1n\Desktop> C:\Users\sysadm1n\Desktop\Scripts\IIS-Install.ps1  Directory: C:\Users\sysadm1n\Desktop\ContosoWebsiteAndSetupJEA   Mode                LastWriteTime         Length Name                                                                                    -a----        6/22/2015  11:56 AM           2826 localhost.mof -a----        6/22/2015  11:56 AM           2410 DSC-CLIENT.corp.contoso.com.mof VERBOSE: Perform operation 'Invoke CimMethod' with following parameters, ''methodName' = SendConfigurationApply,'className' = MSFT_DSC LocalConfigurationManager,'namespaceName' = root/Microsoft/Windows/DesiredStateConfiguration'. VERBOSE: Perform operation 'Invoke CimMethod' with following parameters, ''methodName' = SendConfigurationApply,'className' = MSFT_DSC LocalConfigurationManager,'namespaceName' = root/Microsoft/Windows/DesiredStateConfiguration'. VERBOSE: An LCM method call arrived from computer DSC-PULL-SERVER with user sid S-1-5-21-4072296432-3645720219-549885891-13484. VERBOSE: An LCM method call arrived from computer DSC-PULL-SERVER with user sid S-1-5-21-4072296432-3645720219-549885891-13484. VERBOSE: [DSC-PULL-SERVER]: LCM:  [ Start  Set      ] VERBOSE: [DSC-PULL-SERVER]: LCM:  [ Start  Resource ]  [[xJeaToolKit]Process] VERBOSE: [DSC-PULL-SERVER]: LCM:  [ Start  Test     ]  [[xJeaToolKit]Process] VERBOSE: An LCM method call arrived from computer DSC-PULL-SERVER with user sid S-1-5-21-4072296432-3645720219-549885891-13484. VERBOSE: [DSC-PULL-SERVER]:                            [[xJeaToolKit]Process] 11:56:44 Start Test [JeaToolkit]Process VERBOSE: [DSC-PULL-SERVER]:                            [[xJeaToolKit]Process]      [JeaToolkit]Process Present VERBOSE: [DSC-PULL-SERVER]:                            [[xJeaToolKit]Process] 11:56:45 Done  Test [JeaToolkit]Process VERBOSE: An LCM method call arrived from computer DSC-PULL-SERVER with user sid S-1-5-21-4072296432-3645720219-549885891-13484. VERBOSE: [DSC-PULL-SERVER]: LCM:  [ End    Test     ]  [[xJeaToolKit]Process]  in 0.1560 seconds. VERBOSE: [DSC-PULL-SERVER]: LCM:  [ Skip   Set      ]  [[xJeaToolKit]Process] VERBOSE: [DSC-PULL-SERVER]: LCM:  [ End    Resource ]  [[xJeaToolKit]Process] VERBOSE: [DSC-PULL-SERVER]: LCM:  [ Start  Resource ]  [[xJeaEndPoint]Demo1EP] VERBOSE: [DSC-PULL-SERVER]: LCM:  [ Start  Test     ]  [[xJeaEndPoint]Demo1EP] VERBOSE: [DSC-PULL-SERVER]:                            [[xJeaEndPoint]Demo1EP] 11:56:45 Start Test [EndPoint]Demo1EP VERBOSE: [DSC-CLIENT]: LCM:  [ Start  Set      ] VERBOSE: [DSC-PULL-SERVER]:                            [[xJeaEndPoint]Demo1EP] Test   [JeaEndPoint]      Demo1EP VERBOSE: [DSC-PULL-SERVER]:                            [[xJeaEndPoint]Demo1EP]        [JeaEndPoint]      Demo1EP Present VERBOSE: [DSC-CLIENT]: LCM:  [ Start  Resource ]  [[WindowsFeature]IIS] VERBOSE: [DSC-CLIENT]: LCM:  [ Start  Test     ]  [[WindowsFeature]IIS] VERBOSE: [DSC-PULL-SERVER]:                            [[xJeaEndPoint]Demo1EP] TEST   SecurityDescriptorSddl VERBOSE: [DSC-PULL-SERVER]:                            [[xJeaEndPoint]Demo1EP]        TODO: Check for Toolkits, StartupScript and User Account VERBOSE: [DSC-PULL-SERVER]:                            [[xJeaEndPoint]Demo1EP] 11:56:45 Done  Test [EndPoint]Demo1EP VERBOSE: [DSC-PULL-SERVER]: LCM:  [ End    Test     ]  [[xJeaEndPoint]Demo1EP]  in 0.7040 seconds. VERBOSE: [DSC-PULL-SERVER]: LCM:  [ Skip   Set      ]  [[xJeaEndPoint]Demo1EP] VERBOSE: [DSC-PULL-SERVER]: LCM:  [ End    Resource ]  [[xJeaEndPoint]Demo1EP] VERBOSE: [DSC-PULL-SERVER]: LCM:  [ End    Set      ]    in  6.1950 seconds. VERBOSE: Operation 'Invoke CimMethod' complete. VERBOSE: [DSC-CLIENT]:                            [[WindowsFeature]IIS] The operation 'Get-WindowsFeature' started: Web-Server VERBOSE: [DSC-CLIENT]:                            [[WindowsFeature]IIS] The operation 'Get-WindowsFeature' succeeded: Web-Server VERBOSE: [DSC-CLIENT]: LCM:  [ End    Test     ]  [[WindowsFeature]IIS]  in 0.9840 seconds. VERBOSE: [DSC-CLIENT]: LCM:  [ Start  Set      ]  [[WindowsFeature]IIS] VERBOSE: [DSC-CLIENT]:                            [[WindowsFeature]IIS] Installation started... VERBOSE: [DSC-CLIENT]:                            [[WindowsFeature]IIS] Continue with installation? VERBOSE: [DSC-CLIENT]:                            [[WindowsFeature]IIS] Prerequisite processing started... VERBOSE: [DSC-CLIENT]:                            [[WindowsFeature]IIS] Prerequisite processing succeeded. WARNING: [DSC-CLIENT]:                            [[WindowsFeature]IIS] You must restart this server to finish the installation proces s. VERBOSE: [DSC-CLIENT]:                            [[WindowsFeature]IIS] Installation succeeded. VERBOSE: [DSC-CLIENT]:                            [[WindowsFeature]IIS] successfully installed the feature Web-Server VERBOSE: [DSC-CLIENT]:                            [[WindowsFeature]IIS] The Target machine needs to be restarted. VERBOSE: [DSC-CLIENT]: LCM:  [ End    Set      ]  [[WindowsFeature]IIS]  in 21.6120 seconds. VERBOSE: [DSC-CLIENT]: LCM:  [ End    Resource ]  [[WindowsFeature]IIS] VERBOSE: [DSC-CLIENT]:                            [] A reboot is required to progress further. Please reboot the system. VERBOSE: [DSC-CLIENT]: LCM:  [ End    Set      ]    in  23.2990 seconds. VERBOSE: Operation 'Invoke CimMethod' complete. VERBOSE: Time taken for configuration job to complete is 28.992 seconds"
PowerShell,3aqm70,futuresysad,2,Mon Jun 22 18:39:15 2015 UTC,"That script looks like it checks the size of everything in the folder, and if that total size is less than 100 MB, it then goes through and deletes every file... Here is one that will check every file in every subfolder and only delete the files smaller than 100 MB:  $Dir = ""F:\stuff"" $SizeMin = 100 #MB  Get-ChildItem -Path $Dir -Recurse | Where { $_.Length / 1MB -lt $SizeMin } | Remove-Item -Force"
PowerShell,3aqm70,RickSaysMeh,1 point,Mon Jun 22 19:50:16 2015 UTC,"I'm getting an error with this one but the window is closing too fast to read it. I'll try running it with -noexit  So the directory path is causing the error.  ""F:\TV : The term 'F:\TV' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again."""
PowerShell,3aqm70,RickSaysMeh,1 point,Mon Jun 22 21:00:58 2015 UTC,"Do you have a typo anywhere? That script works for me, although I did just find an issue with it (it deletes folders even if they still have larger files in them)... This should fix that, but may leave you with empty subfolders:  Get-ChildItem -Path $Dir -Recurse | Where { $_.Attributes -ne ""Directory"" -and $_.Length / 1MB -lt $SizeMin } | Remove-Item -Force"
PowerShell,3aqm70,RickSaysMeh,1 point,Mon Jun 22 21:42:48 2015 UTC,"I can't see an error anywhere in the path name and it works with other scripts.  edit  hold that thought, think it may be working now. I'll report back.  edit 2  That's working great! Thanks so much for the help. Now, is there a way to display the status in the powershell console? As it's deleting the files it shows the file name and say something like ""successfully deleted."" Then when all files matching the criteria are deleted maybe a ""All matching files deleted."" then wait for me to confirm with pressing enter? lol"
PowerShell,3aqm70,RickSaysMeh,1 point,Mon Jun 22 21:59:10 2015 UTC,"It looks like your PowerShell is trying to execute that path... Do you have a period before it in the script? I copied and pasted exactly what I typed here and just changed ""F:\stuff"" to a valid path on my machine and it worked as expected..."
PowerShell,3aqrv7,powershellnewb,1 point,Mon Jun 22 19:21:21 2015 UTC,"Have a look at the -raw parameter for Get-Content.  This forces Get-Content to read the file as a single string rather than as multiple strings.  If each text file is formatted exactly as $config in your example, it will work fine.  However if the text files contain multiple certificates then you'll have to reformat the regular expression.  My file, file2.txt is just a text file that contains the text in $config.  $readIn = Get-Content F:\__Temp\file2.txt -raw $regex = [regex] '(?sm)certificate self-signed 01\s+([0-9A-F\s]+?)\s+quit$' $result = $readIn | Select-String -Pattern $regex  $cert = $result.Matches $censored = $readin -replace $cert, '<REMOVED>' Write-Output $censored"
PowerShell,3aqu7f,scopesiide,1 point,Mon Jun 22 19:39:13 2015 UTC,Do you want the cmdlet name and arguments? If so that should be available from PSCmdlet.MyInvocation and its various properties
PowerShell,3aqu7f,ficuswhisperer,1 point,Mon Jun 22 22:39:01 2015 UTC,"I think maybe you misunderstand.  The admin GUIs that show what is done in PowerShell are keeping track of what you are doing in the GUI.  The GUI is actually either performing the script if you press OK or showing you the script if you ask it to.  WPF doesn't have ""translate these actions to PowerShell"" functionality."
PowerShell,3aqu7f,MShepard70,1 point,Tue Jun 23 03:12:46 2015 UTC,"I want the users of my GUI to see that when they click query, my gui is running Get-QADuser $searchname  in powershell to return the properties."
PowerShell,3aqu7f,thebeersgoodnbelgium,1 point,Tue Jun 23 16:17:00 2015 UTC,"I setup a label and put text on that. So $labelname.Text = ""Contacting $servername"" which would say ""Contacting AD.local"" or whatever."
PowerShell,3aqf9w,Nerdible,2,Mon Jun 22 17:47:32 2015 UTC,"What you're after is -confirm:$false on your Remove-Items  There's also the ConfirmPreference setting which you can use to achieve the same thing for an entire script, but needs to be handled carefully as it can be confusing if you're not expecting it."
PowerShell,3aqf9w,the_spad,1 point,Mon Jun 22 17:54:52 2015 UTC,ok cool. so should I ditch the -force and replace that with the confirm false? or does it hurt to leave it?
PowerShell,3aqf9w,the_spad,2,Mon Jun 22 18:30:44 2015 UTC,"They do different things, so you probably need both of them in this case."
PowerShell,3apvp0,Hallelujah10,1 point,Mon Jun 22 15:19:33 2015 UTC,"I would use some existing tools : )  Makes it a bit more readable down the road, IMHO, and you can use these in other scenarios.  Download and dot source Invoke-SqlCmd2, import PSExcel module  # Load up dependencies Import-Module PSExcel . ""\\Path\To\Invoke-SqlCmd2.ps1""  # Get data $Data = Invoke-Sqlcmd2 -ServerInstance ServerName -Database DatabaseName -query ""     SELECT DISTINCT SourceServer, DestinationServer FROM TableA""  # Export it $Data |     Select -Property SourceServer,                      DestinationServer,                      ""Destination SQL Version"", #I'm assuming you fill these in later, otherwise, use calculated props                       ""Source SQL Version"" |     Export-XLSX -Path ""D:\MyFolder\ServerValidation_New.xls"" -WorksheetName ServerValidation   Copy and paste that into the ISE, apparently reddit wraps code now? Yuck.  Side benefit: you can do this from any system, regardless of whether it has Excel installed : )  Cheers!"
PowerShell,3apvp0,ramblingcookiemonste,1 point,Mon Jun 22 16:37:01 2015 UTC,Going with other options is fine. I just want to understand what's wrong with what I've written. So that I can learn something from it. :)
PowerShell,3apvp0,midnightFreddie,2,Mon Jun 22 16:59:21 2015 UTC,"Agree with using existing tools. In fact when moving data from a MS database to MS Excel I see no reason to involve Powershell myself. When I do use Powershell for tabular data--and I do, a lot--I output to csv files and convert to Excel later if needed. The Excel COM object is just too clunky to use for my tastes.  That said, troubleshooting your script I would first comment out the loop and see if the error happens while creating the header cells. If it fails there, then perhaps you don't have the right worksheet selected, maybe it's a protected spreadsheet, or maybe it's open read-only. In fact, one of the things I don't like about the COM object is that it often leaves processes running without any visible window. If your script crashed while the workbook is open there may be an invisible Excel process holding a lock on your workbook. Log out, log in and try it again. Maybe set .Visible = $true or handle errors to close the file if that's the problem."
PowerShell,3apvp0,ramblingcookiemonste,2,Mon Jun 22 21:14:09 2015 UTC,"Sounds good!  Long story short, it looks like you are trying to insert a PowerShell object into an Excel cell, rather than a string.  Longer story:  If you run the code up to the loop, have you played around with things to verify the data is in the expected state?  One of the benefits to PowerShell is that it's both a shell and scripting language... so you can just run through the first section, and then type in $DServers[2] at the prompt.  Does that give you a source server name alone? Or does it give you an object with a SourceServer property?  I could be off, but it looks like the latter. Try substituting this out:  #Existing line. This gives you an object with a SourceServer property Select-Object SourceServer  #Replace with this. Select-Object -ExpandProperty SourceServer   This will result in $DServers being an array of SourceServer strings, not an array of objects with a SourceServer property.  Alternatively, if you plan to use both SourceServer and DestinationServer, you could change things as follows:  #Don't strip out Destination server... $DServers = $DataSet.Tables[0] | Select-Object SourceServer, DestinationServer  #Reference the right prop when inserting into Excel: $Sheet1.Cells.Item($m,3) =$DServers[$m].SourceServer $Sheet1.Cells.Item($m,1) =$DServers[$m].DestinationServer   There are many ways to skin a cat; experiment and test things out at the shell.  Cheers!"
PowerShell,3aps09,TacticalSniper,1 point,Mon Jun 22 14:48:21 2015 UTC,"Something like this would be more elegant:  $Folders = @{     Archives              = "".zip"","".rar"","".7z"","".7zip"" # Archives     Certs                 = "".cer"","".crt"","".pfx"","".p7b"" # Certificates     Documents             = "".doc"","".docx"","".xls"","".xlsx"","".pdf"","".mht"","".html"","".csv"" # Documents     ""Logs & Texts""        = "".log"","".txt"","".evt"","".evtx"","".xml"" #Logs & Texts     Programs              = "".exe"","".msi"","".msu"","".dll"" # Programs     Licenses              = "".lic"","".slf"" # Licenses     Images                = "".jpg"","".gif"","".png"" # Images     Linux                 = "".tgz"","".tar"","".rpm"" # Linux     Scripts               = "".ps1"","".bat"","".cmd"","".job"" # Scripts     ""Performance reports"" = "".iokit"" # Performance reports, such as IOKit and PerfMon     Video                 = "".m4v"" # Videos     ""Disk images""         = "".iso"","".ova"" # Disk images }  foreach($folder in $folders.keys) {     if($folders.$folder -eq $file.Extension)     {         Move-Item -Path $File.FullName -Destination $DestinationRootFolder\($folders.$folder) -Force         Continue       } }    I used a hashtable to hold the data and drive the logic. Anytime you have copy and paste code, consider different options. That usually indicates the need for a function but this trick works too."
PowerShell,3aps09,KevMar,0,Mon Jun 22 15:39:32 2015 UTC,"foreach($folder in $folders.keys)   Inefficient, you're adding an entirely unnecessary extra level of loop   if($folders.$folder -eq $file.Extension)   Won't work, $folders.$folder is an array and will never match a string  $DestinationRootFolder\($folders.$folder)   Won't string concatenate as written. Also $folders.$folder is an array of strings, not the folder name"
PowerShell,3aps09,BadSysadmin,1 point,Mon Jun 22 15:54:06 2015 UTC,"foreach($folder in $folders.keys)    Inefficient, you're adding an entirely unnecessary extra level of loop   I didn't see a better quick solution in the 30 sec I looked at the problem. I am sure there are lots of optimizations.  if($folders.$folder -eq $file.Extension)    Won't work, $folders.$folder is an array and will never match a string   Yes, that does work. again, probably a better way.   $test = ""a"",""b"",""c"" if($test -eq ""a"") {$true}   and this  $DestinationRootFolder\($folders.$folder)   was a mistake from typing too fast. This should work.  $DestinationRootFolder\$folder   Thanks for catching those items and pointing out where things can be improved."
PowerShell,3aps09,KevMar,1 point,Mon Jun 22 16:02:37 2015 UTC,"A slightly shorter and quicker version  $ht =  @{     "".zip""=""archive""     "".rar""=""archive""     "".cer""=""certs"" } gci -recurse $directories | % ` {     mv $_ (join-path (split-path $_.fullname) $ht.($_.extension)) }   You shouldn't really hardcode in your dictionary either but I'll leave fixing that as an exercise for the reader."
PowerShell,3apscl,Ropiak,1 point,Mon Jun 22 14:51:11 2015 UTC,"By the way, the script works fine. I just don't understand why I'm getting this output."
PowerShell,3apscl,tomkandy,1 point,Mon Jun 22 14:58:50 2015 UTC,"You're overwriting $info each time that loops, although that doesn't explain the output you're getting.  Might be easier to understand if you fix the formatting of your post."
PowerShell,3apscl,midnightFreddie,1 point,Mon Jun 22 15:28:04 2015 UTC,"I could add to it each time, I'm just used to doing it this way.   It's actually importing it this way, for whatever reason."
PowerShell,3apscl,midnightFreddie,1 point,Mon Jun 22 16:21:14 2015 UTC,"I'm going to stop trying to figure out what's going on there. That just ain't right. The @{} indicates an object. Try something like this:  $info = Import-Csv C:\users\user\downloads\computers.csv |     Select-Object -ExpandProperty Computers |     Get-ADComputer |     Select-Object -ExpandProperty DistinguishedName     #Select-Object Name, DistinguishedName   As-is it will give you an array or list of DNs. Uncomment the last line and comment the line before it and you'll get a table including the name and DN.  Two things to note: No need to put the CSV data in a temp variable; just pipe it to the loop. However, this cmdlet--like many others--accepts a list of names to act upon, so instead of looping I'm using Select-Object -Expandproperty which passes a simple list of computer names down the pipeline.  Your csv should look like this. Based on the results I think something may be funny in your csv, and that plus the multi-computer capability of Get-ADcomputer is making the odd output.  Computers device25435 device26256"
PowerShell,3ar8a7,sneezycheesy,2,Mon Jun 22 21:22:47 2015 UTC,"I always do something like:  $continue = $true while ($continue -eq $true) {     Try      {         # Based on the previous comment...         # you might want to check the var $servername here...         get-adcomputer $servername -erroraction stop         $continue = $false     }     Catch     {         # do something when there is an error.  sleep..whatever     } }   I can't actually test it right now, but I think the concept makes sense.   If you use this format, you can do different things for different errors, force it to quit after X tries, etc."
PowerShell,3ar8a7,drh713,1 point,Mon Jun 22 22:41:23 2015 UTC,This worked! Thank you!
PowerShell,3ar8a7,kittH,1 point,Tue Jun 23 13:35:35 2015 UTC,"Try something like this:  While(-Not(Get-ADComputer -Identity $servername)) { Start-Sleep -Seconds 60 }   If anything returns it will evaluate the statement true, if null returns it will evaluate it false. In your example you are trying to look at the ""name"" property which throws an error if nothing is returned."
PowerShell,3ar8a7,kittH,1 point,Mon Jun 22 21:50:02 2015 UTC,"Thanks for this  I've just thrown this into ISE to test, but it seems to just throw back out the same error  PS C:\Windows\system32> While(-Not(Get-ADComputer -Identity $servername)) { Start-Sleep -Seconds 60 } Get-ADComputer : Cannot validate argument on parameter 'Identity'. The argument is null or an element of the argument collection contains a null value. At line:1 char:37 + While(-Not(Get-ADComputer -Identity $servername)) { Start-Sleep -Seconds 60 } +                                     ~~~~~~~~~~~~     + CategoryInfo          : InvalidData: (:) [Get-ADComputer], ParameterBindingValidationException     + FullyQualifiedErrorId : ParameterArgumentValidationError,Microsoft.ActiveDirectory.Management.Commands.GetADComputer"
PowerShell,3ar8a7,kittH,1 point,Mon Jun 22 21:58:30 2015 UTC,"I was assuming that $servername contained a string with the name of the server you were waiting for, but based on that error it sounds like $servername is null.   Either make sure that $servername is populated with a string before running, or just try evaluating directly against the computername. IE replace $servername with 'Name of Server'."
PowerShell,3aoo1e,mpaguilar,1 point,Mon Jun 22 06:25:00 2015 UTC,"I'd had an excuse to work at combining a C# front-end with PowerShell scripts   Did you do this at work? Did you get them to clear any ownership of it?  edit: of course I get down-voted asking a question about a post that has no license listed and created for his employer's purposes, so they probably own the copyright on it. Have fun using this in your applications."
PowerShell,3aoo1e,MrUnknown,2,Mon Jun 22 14:35:04 2015 UTC,"The initial iteration was a work project, but it had some bad ideas.  This was written from scratch, and I have the logs to prove it. And has different bad ideas :)"
PowerShell,3aoo1e,MrUnknown,1 point,Mon Jun 22 19:23:06 2015 UTC,Thank you for the info.  You should put a license on it so people know how they are allowed to use it.
PowerShell,3aoo1e,MrUnknown,2,Mon Jun 22 22:30:32 2015 UTC,"I haven't really decided on a license, or how I'll use it. I may just leave it as a reference for myself and others."
PowerShell,3aor99,Pissfunny,2,Mon Jun 22 07:10:11 2015 UTC,"The reason your code didn't work was because you didn't include the additional -notlike statements. You did -notlike -and -and -and..., it should be -notlike -and -notlike -and -notlike...  I have also taken the liberty to wrap your statement in the Where-Object scriptblock in individual brackets. Try this code:  $then = (Get-Date).AddDays(-45) Get-ADUser -Filter * |  Where-Object {(($_.lastLogonDate -le $then) -and (($_.DistinguishedName -notlike ""*OU=Users,OU=Inactive Objects,DC=company,DC=local"") -and ($_.DistinguishedName -notlike ""*OU=Services,OU=MDP,DC=company,DC=local"") -and ($_.DistinguishedName -notlike ""*CN=Monitoring Mailboxes,CN=Microsoft Exchange System Objects,DC=company,DC=local"")))} | ft DistinguishedName"
PowerShell,3aor99,JaapBrasser,2,Mon Jun 22 07:16:30 2015 UTC,Wouldn't you want to put  most of the where object into the filter of get-aduser for performance reasons?
PowerShell,3aor99,jbtechwood,1 point,Mon Jun 22 10:18:04 2015 UTC,Yes indeed this.  I actually made the same mistake a week ago...  http://www.reddit.com/r/PowerShell/comments/39kjkk/removing_aged_ad_user_accounts/
PowerShell,3aor99,Swarfega,1 point,Mon Jun 22 12:03:03 2015 UTC,Thanks for that. I had the first of all but it didn't seem to do anything different. I've just run your block again and it still seem to list back all the users in the domain. Any ideas?
PowerShell,3aor99,JaapBrasser,1 point,Mon Jun 22 07:21:05 2015 UTC,"It should work, check if there is no spelling errors in your filters that could cause the notlike operator not to match the OUs correctly.  Also you could consider using a searchroot parameter to limit results from a single OU, either recursively or not depending on what you are trying to do."
PowerShell,3aor99,the_spad,1 point,Mon Jun 22 09:34:33 2015 UTC,"Why not just use Search-ADAccount?  Also, -notmatch is probably a better option than -notlike here.  Search-ADAccount -AccountInactive -TimeSpan ""45"" -UsersOnly | ?{($_.distinguishedname -notmatch ""OU=Users,OU=Inactive Objects"") -and ($_.distinguishedname -notmatch ""OU=Services,OU=MDP"") -and ($_.distinguishedname -notmatch ""CN=Microsoft Exchange System Objects"")} | Select DistinguishedName"
PowerShell,3aor99,sean_blake,1 point,Mon Jun 22 07:40:54 2015 UTC,"Have you considered storing a list of OUs in a variable, then using a ForEach loop to reference them for your 'Searchbase' parameter when using Get-ADUser?"
PowerShell,3aor99,sean_blake,1 point,Mon Jun 22 11:03:24 2015 UTC,"I would probably use -LDAPFilter ""(&(!OU=Incactive)(!OU=Services)(!OU=Monitoging Mailboxes))"", or something like that."
PowerShell,3aniow,biffon,2,Sun Jun 21 23:26:27 2015 UTC,Ok I've got it working with the below but it only does it for my machine how would i go about writing it so it targets a specfic OU and does it for all the machines in that OU. Would i need to use the For-EachObject?   Script -   $descr = (Get-ADComputer 6cphj12 -Properties IPv4Address).ipv4Address | Out-String $Username = (Get-WmiObject win32_computersystem -ComputerName 6cphj12 | select username) Set-ADComputer 6cphj12 -Description ($descr + $Username)
PowerShell,3aniow,SSessess,2,Mon Jun 22 01:38:16 2015 UTC,"something like:  $computers = get-adcomputer -filter ""*"" -searchbase <OU CN> -properties IPv4Address   foreach ($computer in $computers) { $username = (Get-WmiObject win32_computersystem -ComputerName $computer.name | select username) $descr = $computer.ipv4Address + $username  Set-ADComputer $computer.name -Description $descr }"
PowerShell,3aniow,scriptmonkey420,1 point,Mon Jun 22 06:03:14 2015 UTC,Thanks!
PowerShell,3aniow,kcbwya77,1 point,Mon Jun 22 06:45:58 2015 UTC,$descr = $computer.ipv4Address + $username  wouldn't that just make it one long string with no spaces?
PowerShell,3aniow,SSessess,1 point,Mon Jun 22 11:38:57 2015 UTC,"yes; you can also do something like this     $descr = $computer.ipv4Address + "";"" + $username"
PowerShell,3aniow,kcbwya77,1 point,Mon Jun 22 16:14:56 2015 UTC,"Yep, feel free to get creative with your delimiters"
PowerShell,3aniow,replicaJunction,1 point,Mon Jun 22 21:13:45 2015 UTC,"This won't show you users that are logged in remotely though, only users at the console"
PowerShell,3aniow,PoundKeyboardNow,2,Mon Jun 22 17:18:13 2015 UTC,"Instead of running this script on your machine and ""pushing"" the changes to all computers in an OU, why not assign it as a startup / logon script in Group Policy?  That way, you'll have client computers updating their description on each boot."
PowerShell,3aniow,replicaJunction,1 point,Mon Jun 22 14:38:18 2015 UTC,Can a machine read from and write to AD without having the AD powershell modules installed?  I have it writing service tag and model to the description now during shutdown but I use vbscript. Haven't found a way to stop it from pausing and waiting for a timeout when you rename the machine though.
PowerShell,3aniow,PoundKeyboardNow,2,Mon Jun 22 16:02:53 2015 UTC,"Sure. In PowerShell, you can use the [ADSI] type accelerator, which references the DirectoryEntry class.  Here's a snippet from my logon script:  $domain = [System.DirectoryServices.ActiveDirectory.Domain]::GetCurrentDomain() $root = $domain.GetDirectoryEntry() $searcher = [System.DirectoryServices.DirectorySearcher] $root  Write-Log ""Attempting to find AD computer object"" $searcher.Filter = ""(sAMAccountName=$env:ComputerName`$)"" $searcher.PropertiesToLoad.Add(""distinguishedName"") > $Null  $results = $searcher.FindAll() ForEach ($computer In $results) {     $dn = $computer.properties.Item(""distinguishedName"")     $Computer = [ADSI]""LDAP://$dn""     $Computer.description = $finalDescription     $Computer.SetInfo() }   Edit: formating"
PowerShell,3aniow,KevMar,1 point,Mon Jun 22 18:43:13 2015 UTC,That's awesome. Thank you very much.
PowerShell,3aniow,MortoftheHillPeople,1 point,Mon Jun 22 21:44:01 2015 UTC,I don't think I can update AD via the machines because they dont have the Active Directory powershell module? Correct me if im wrong!   May have to use VB?
PowerShell,3ao9mq,supermamon,1 point,Mon Jun 22 03:43:05 2015 UTC,"Quick fix, but which will get rid of the headers altogether would be to add ""Format-Table -HideTableHeaders"" like this:  ver 2  Get-ChildItem $exe ` | ForEach-Object { $_.VersionInfo } ` | Select-Object FileName,FileVersion ` | ForEach-Object {     $Obj | Out-SomePSObject-Message -Message  ($_ | Format-Table -HideTableHeaders | Out-String) }   Slightly more complex, but will print the headers.  Change your Out- function to take objects, not just strings, have $Message be the pipeline object, and do the Out-String in there:  Function Out-SomePSObject-Message{     [CmdletBinding()]     param(         [Parameter(Mandatory=$True)]         $App,         [Parameter(Mandatory = $true), ValueFromPipeline=$True)]         $Message     )      begin{         $firstElement = $true     }      process{         if($firstElement)         {             $firstElement = $false             $messageStr = $Message | Out-String         }         else         {             $messageStr = $Message | Format-Table -HideTableHeaders | Out-String         }          [void]$App.ShowMessage($messageStr)     }      end { } }  Get-ChildItem $exe ` | ForEach-Object { $_.VersionInfo } ` | Select-Object FileName,FileVersion ` | Out-SomePSObject-Message -App $Obj"
PowerShell,3ao9mq,tehjimmeh,1 point,Mon Jun 22 05:25:09 2015 UTC,"Thank you! I adapted the ""slightly more complex"" route. But I couldn't change Out- function since it's being used in several places. The -HideTableHeaders switch was a big help but it still has those ugly empty lines in between items. Anyway, did some quick string manipulations to kick those out. Here's the modified script:  Clear-Host; $Obj = New-Object -TypeName PSObject; $Obj | Add-Member -MemberType ScriptMethod `        -Name ShowMessage -Value {         param($Text)          # The original method is actually         # appends the output to a Winforms         # textbox.          Write-Host $Text     } Function Out-SomePSObject-Message{     [CmdletBinding()]     param(         [Parameter(Mandatory=$True,             ValueFromPipeline=$True)]         $App,         [Parameter(Mandatory = $true)]         [string] $Message     )      [void]$App.ShowMessage($Message)  } Function Show-Program-Version{     [CmdletBinding()]     param(         [Parameter(Mandatory = $true, ValueFromPipeline=$True)]         $Program     )        BEGIN {         $first = $true;     }     PROCESS {         $VersionInfo = $Program.VersionInfo | Select FileName,FileVersion,ProductVersion;         if ($first) {             $first = $false;             $VersionInfo | Out-String `             | % {                      $_ -Split ""`n"" `                     | Select -Skip 1 -First 3 `                     | % {                          $Obj | Out-SomePSObject-Message -Message $_                         }                 }         } else {             $messageStr = $VersionInfo | Format-Table -HideTableHeaders | Out-String `             | % { $_ -Split ""`n"" | Select -Skip 1 -First 1}             $Obj| Out-SomePSObject-Message -Message $messageStr         }      }  }  $exe = ""C:\Windows\System32\*.exe""  # ver 3 Get-ChildItem $exe | Show-Program-Version;"
PowerShell,3ao9mq,tehjimmeh,1 point,Mon Jun 22 07:05:59 2015 UTC,Try:  ... | Out-String | %{ $_.Trim() }   Should get rid of the newlines a little more nicely.
PowerShell,3ao9mq,real_parbold,1 point,Mon Jun 22 07:13:57 2015 UTC,TIL. I've always assumed Trim works only for spaces. Thanks again!
PowerShell,3ao9mq,real_parbold,1 point,Mon Jun 22 07:17:14 2015 UTC,"IMHO ; Your initial code should output objects that can be consumed later.  If the code that ingests the output from your initial script needs string objects then what I would do in the interim is;  Call-Proc1 | Out-String | Call-Proc2   In the end, you should never try to text-parse when you can hold so much more info in objects, and you can always convert the objects to text anyway :)  I am re-writing a lot of my early scripts to throw objects onto the pipeline, rather than to raw text output or ( even worse shudder set global variables ) :)"
PowerShell,3am0f0,stupidGits,5,Sun Jun 21 15:19:56 2015 UTC,"Learning Python The Hard Way which requires the reader to learn Powershell as well   It doesn't require you to learn Powershell, he's just getting you comfortable with using the CLI on your chosen host, in your case, Windows. It's not really important so I wouldn't get hung up on it.  Explanation: Ever been to a buffet? The have the plates on a spring loaded thing. You put stuff on the top, and take the most recent plate from the top. That is a stack.    You push a directory, this is like placing a plate on the stack. If you pop it, you get that one back, because it was the last one you put there. If you pushed another one, it would go on top of the first. if you pop now, you would now get the second directory."
PowerShell,3am0f0,mhurron,3,Sun Jun 21 15:49:10 2015 UTC,"Pushd and popd are pretty nifty if you have to run something from a UNC path in the old CMD days since CMD doesn't like UNC paths Unless they're mapped.  It allows you to quickly map a directory (starts from Z: and backwards ) do what you need you, and then unmap it.  So for example, if I wanted to run something from CMD and it was a UNC path and I didn't want to give it a letter after mapping, I'd do something like this;  Pushd \\server\share\folder && doesstuff.bat Popd    Pushd changes your current drive to the pushd drive, the two ampersand call the batch file within the folder since you are in the root of the folder, and the popd runs after the script is completed and removes the drive mapping from your mapped drives."
PowerShell,3am0f0,RC-7201,1 point,Sun Jun 21 17:58:55 2015 UTC,"Ah yes, pushd and popd are common commands in the UNIX/Linux would. It's a stack (first in, last out) to save directory locations.  A great example is, let's say you are in your main directory and you need to check and see what python libs you have on your system. You pushd your current directory, then navigate you where your python libs are. You jump around a bit as you look in various other dirs. When you're done exploring, type popd to return to your original directory.  That's a simple example. Keep in mind that it's a stack (FILO) so you can do a bunch of pushd's as you explore your filesystem, then popd back to your pushd'd locations.  EDIT: /u/mhurron did a good job explaining what a stack is. If you are still a bit confused, Google ""stacks and queues"""
PowerShell,3am0f0,jerfoo,1 point,Sun Jun 21 15:56:55 2015 UTC,"I don't use it much, but I can think of two usages.  You need to change directories but know you are coming back. This does not have to be just directories, it could be jumping between psdrives. Like registry, SQL, active directory....  The other is when dealing with batch files\programs that like to change the location on you or don't want to run from a unc path. Copy to temp dir, run it, then jump back.  Pusd and pops help in those situations. While you may not see it used much with people that started scripting with PowerShell, people that came from other shells will find it more natural to use."
PowerShell,3am0f0,KevMar,1 point,Sun Jun 21 16:01:16 2015 UTC,"Sorry, I know I'm coming to the party late, I'm just learning Powershell as well and came here looking for an explanation on pushd/popd, as an analogy, are they kind of like ""teleporters""? Basically a save location/teleport to location?"
PowerShell,3am0f0,chumly143,1 point,Thu Jul 2 03:14:58 2015 UTC,"Yeh, thats basically how it works. pushd saves a location and then you use popd to jump back to it.  pushd and popd in action: https://www.youtube.com/watch?v=rqYlloaVVEA"
PowerShell,3am0f0,KevMar,1 point,Thu Jul 2 03:56:57 2015 UTC,"It's probably best to start with knowing how stacks work, which you'll find in all kinds of programming languages.   Imagine you have a stack of pancakes.   When you push a pancake to the stack, you're placing it on top.   When you pop a pancake, you're taking it off the top.  The same applies with pushd and popd.   Pushd in CMD for example maps a unc path to the last available drive (usually z:) and automatically changes your working directory to that drive.  If you pushd several times and to several locations, it'll keep taking the last available drive (y:, x:, etc).   With popd, you're simply releasing those mappings in the opposite order they were added.   Popd is taking the topmost addition to the stack and ""popping"" it off (x:,y:,z:)"
PowerShell,3am0f0,ajeoae,1 point,Sun Jun 21 19:50:08 2015 UTC,"No one mentioned it, but there's Push-Location and a Pop-Location in PowerShell. Those cmdlets do the same thing as the old pushd and popd native command lines tools."
PowerShell,3am0f0,tommymaynard,1 point,Sun Jun 21 20:01:32 2015 UTC,pushd and popd are actually aliases to these cmdlets.
PowerShell,3am0f0,sean_blake,1 point,Sun Jun 21 20:14:42 2015 UTC,"Thanks, I wasn't aware of those two aliases (and I wasn't in front of a computer when I wrote that). Doh!"
PowerShell,3am0f0,tommymaynard,1 point,Mon Jun 22 15:16:50 2015 UTC,"pushd (Push-Location) is like clicking a link in your browser.  popd (Pop-Location) is like clicking back.  Except, it's for paths on the command line.  Personally, I have this in my $profile:  if(Test-Path alias:cd) {     Remove-Item alias:cd }  function cd ($path) { Push-Location $path } function back { Pop-Location }"
PowerShell,3am0f0,tehjimmeh,1 point,Sun Jun 21 21:47:17 2015 UTC,"This question has been well-answered already, yet I can't keep away from the reply box.  If you've ever done this:  $OriginalFolder = Get-Location cd $PathMyScriptNeeds  Do-Things  cd $OriginalFolder   You can instead do this:  Push-Location cd $PathMyScriptNeeds  Do-Things  Pop-Location"
PowerShell,3akhbr,andibnz,3,Sun Jun 21 02:14:10 2015 UTC,"Kind of dirty, but try using a switch. Have the OU and home directory stuff be set in a variable. Something like...  $csv = import-csv something.csv  foreach ($user in $csv){      switch $user.office          office1 { $ou = ou location                      $homedirectory = homedir location                      $secgroup = security group                   }         office2 { $ou = ou location                      $homedirectory = homedir location                      $secgroup = security group                   }     new-aduser -identity $user.samname -container $ou  }   And so on. Again, it's dirty and will require a lot of hand coding, but it should work."
PowerShell,3akhbr,silentmage,3,Sun Jun 21 02:28:48 2015 UTC,"Another way, if you want to stay dynamic, because this will NEVER stay static (my experience, your mileage may vary)  Have a Location CSV  read the user  based on office, look up the OU, HomeDir, and SecGroup in Location.CSV do the create Print exceptions (the ones that failed lookup for manual creation)"
PowerShell,3akhbr,jeffrey_f,2,Sun Jun 21 04:13:59 2015 UTC,"Expanding on this: this is exactly the method that I use in my environments, and dirty or not, it works fine.  Here's the sanitized version of my production scripts. I actually use two switches, one that just populates variables and another that actually does stuff.   This could be made to be much more compact and probably faster, but it's more or less a line-for-line re-implementation of a a VBScript that used to do the same job (which is why some of the variable names are just the AD attribute names instead of their more readable Powershell cmdlet arguments). As-is, this script completes updates on ~300 staff in 6-7 seconds, which is good enough for me to happily leave alone.   You could pare this down to just the parts you want/need and still keep basic user management.  source CSV requires: firstname, lastname, facility, number (payroll ID number)  source CSV options: mobile, extension  $staffinglist = Import-Csv -Path ""\\TEAMSHARE\\Human Resources\Staffing\hourly.csv""  foreach ($staff in $staffinglist)  { $givenname = $staff.firstname $sn = $staff.lastname $displayName = $givenname + "" "" + $sn $cn = $displayName $userPrincipalName = $givenname + ""."" + $sn + ""@COMPANYNAME.org"" $number = $staff.number $sAMAccountName = ""orgname.""+$number $mobile = $staff.mobile $extension = $staff.extension $company = ""COMPANYNAME"" $department = $staff.department $physicalDeliveryOfficeName = $staff.facility $title = $staff.title $description = $company + "" "" + $department + "" "" + $physicalDeliveryOfficeName + "" "" + $title  switch ($staff.facility){ ""Cleveland""     {     $path = ""OU=Building,OU=CLEVELAND,OU=OHIO,OU=COMPANYNAME Staff,DC=companyname,DC=org""     IF ($staff.extension -ne $null) #staffing spreadsheet has extension         {         $telephoneNumber = ""555-555-1234"" + "" x"" + $staff.extension         }     Else #staffing spreadsheet has no extension         {         $telephoneNumber = ""555-555-1111""          }     $facsimileTelephoneNumber = ""555-555-1112""      $streetAddress = ""12345 Streetname Street""     $postOfficeBox = ""USPS Box 12345""     $l = ""Cleveland""     $st = ""Ohio""     $postalCode = ""44111""     } ""Columbus""     {     $path = ""OU=Building,OU=COLUMBUS,OU=OHIO,OU=COMPANYNAME Staff,DC=companyname,DC=org""     IF ($staff.extension -ne $null) #staffing spreadsheet has extension         {         $telephoneNumber = ""555-555-1234"" + "" x"" + $staff.extension         }     Else #staffing spreadsheet has no extension         {         $telephoneNumber = ""555-555-1111""          }     $facsimileTelephoneNumber = ""555-555-1112""      $streetAddress = ""12345 Streetname Street""     $postOfficeBox = ""USPS Box 12345""     $l = ""Columbus""     $st = ""Ohio""     $postalCode = ""43210""     } default     {     $path = ""OU=Building,OU=Beverly Hills,OU=California,OU=COMPANYNAME Staff,DC=companyname,DC=org""     IF ($staff.extension -ne $null) #staffing spreadsheet has extension         {         $telephoneNumber = ""555-555-1234"" + "" x"" + $staff.extension         }     Else #staffing spreadsheet has no extension         {         $telephoneNumber = ""555-555-1111""          }     $facsimileTelephoneNumber = ""555-555-1112""      $streetAddress = ""12345 Streetname Street""     $postOfficeBox = ""USPS Box 12345""     $l = ""Beverly Hills""     $st = ""California""     $postalCode = ""90210""     } }  $user = Get-ADUser -Filter {((givenname -eq $givenname) -and (sn -eq $sn)) -or (employeeid -eq $number) -or (employeenumber -eq $number)}  switch ($staff.facility) { ""disabled""     {     IF ($user -ne $null) #existing account, facility set to disabled in CSV         {         $user | Disable-ADAccount         $user | Move-ADObject -targetpath ""OU=-DISABLED-,DC=COMPANYNAME,DC=org""         }     Else #nonexistant account, flagged disable in source         {         #don't do anything here         }      } default     {     IF ($user -ne $null) #matching account exists, update         {         $user | Rename-ADObject -NewName $cn         $user | Move-ADObject -targetpath $path             $user | Set-ADUser -GivenName $givenname -Surname $sn -DisplayName $displayname -EmployeeNumber $number -EmployeeID $number -MobilePhone $mobile -Company $company -Department $department -Title $title -Office $physicalDeliveryOfficeName -Description $description -OfficePhone $telephonenumber -Fax $facsimileTelephoneNumber -StreetAddress $streetAddress -POBox $postOfficeBox -City $l -State $st -PostalCode $postalcode -SamAccountName $sAMAccountName         $user | Enable-ADAccount          }     Else # no matching account exists, create         {         New-ADUser -Name $DisplayName -GivenName $givenname -Surname $sn -DisplayName $displayname -EmployeeNumber $number -EmployeeID $number -UserPrincipalName $userPrincipalName -SamAccountName $sAMAccountName -MobilePhone $mobile -Company $company -Department $department -Title $title -Office $physicalDeliveryOfficeName -Description $description -Path $path -OfficePhone $telephonenumber -Fax $facsimileTelephoneNumber -StreetAddress $streetAddress -POBox $postOfficeBox -City $l -State $st -PostalCode $postalcode -accountPassword (ConvertTo-SecureString -AsPlainText ""orientation"" -Force)         $user | Set-ADUser -ChangePasswordAtLogon:$true         $user | Enable-ADAccount         #Enable-Mailbox -identity $user.name                 }      } } }"
PowerShell,3akhbr,saeraphas,2,Sun Jun 21 06:37:32 2015 UTC,"This is how I would put this together. I used a hashtable to define the office related options. This will support multiple groups per office. If you only had one group to add them to for each office, then a csv would have worked just as well.  <# .SYNOPSIS Adds User to domain with office details .EXAMPLE import-csv something.csv | New-User -Verbose  .NOTES This is untested - Kevin Marquette #> function New-User {     [cmdletbinding()]     param(         # Dataset that contains the user details. Username, name, office, ect         [Parameter(             Mandatory         = $true,             Position          = 0,             ValueFromPipeline = $true,             ValueFromPipelineByPropertyName = $true         )]         $UserData,          $OURoot = ""DC=my,DC=local""     )      begin     {         $Template = @{             Office1 = @{                 OU = ""OU=Office1""                 Groups = ""O1_Group1"",""O1_Group1""                 HomeDirectory = ""\\Office1\Profile""             }             Office2 = @{                 OU = ""OU=test,OU=Office2""                 Groups = ""O1_Group2"",""O1_Group2""                 HomeDirectory = ""\\Office2\Profile""             }         }     }      process     {         foreach ($user in $UserData)         {             Write-Verbose ""User: $user""              $office = $user.office             Write-Verbose ""Office: $office""              $OU = ""{0},{1}"" -f $Template.$office.OU, $OURoot              Write-Verbose ""OU: $OU""                 $ADUserParams = @{                 SamAccountName = $user.Username                 DisplayName    = $user.Name                 Container      = $OU                 HomeDirectory  = (Join-Path $Template.$office.HomeDirectory, $user.username)             }             Write-Verbose (""HomeDirectory: "" + $ADUserParams.HomeDirectory)             Write-Verbose ""Creating new ADUser""             $ADUser = New-ADUser @ADUserParams              foreach($group in $Template.$office.Groups)             {                 Write-Verbose ""Adding user to ADGroup: $group""                 Add-ADGroupMember -Identity $group -Members $ADUser             }         }     } }  $UserDataset = import-csv something.csv $UserDataset | New-User -Verbose   Video with commentary: https://www.youtube.com/watch?v=sd_PiVx_GQs"
PowerShell,3akhbr,KevMar,1 point,Sun Jun 21 07:25:27 2015 UTC,This is similar to how i did mine as well.  Hashtables are your friend in these situations.
PowerShell,3akhbr,seanconnery84,-2,Mon Jun 22 19:05:37 2015 UTC,This is pretty straight forward.  IF you don't understand the code you're going to get into a mess... I can fully automate your AD and Email creation...  https://networksafely.wordpress.com/pricing/
PowerShell,3aiga4,-neNull,10,Sat Jun 20 14:27:15 2015 UTC,I'm not convinced that screenshots are really a great way to publish code.
PowerShell,3aiga4,the_spad,3,Sat Jun 20 14:47:43 2015 UTC,"Also, where are his results?"
PowerShell,3aiga4,bump909,1 point,Sat Jun 20 20:16:12 2015 UTC,Just print it out and run it through a scanner using an OCR program.  Way easier than copy/paste!
PowerShell,3aiga4,extremepcs,2,Sat Jun 20 15:50:52 2015 UTC,"I went ahead and wrote it all out, code is posted in comments below"
PowerShell,3aiga4,kcbwya77,2,Sat Jun 20 21:38:08 2015 UTC,Awesome!  What I'd really like to see is a reasonably simple and intuitive way to build Visio diagrams with Powershell.
PowerShell,3aiga4,HalalVeggieBacon,2,Sat Jun 20 15:48:42 2015 UTC,Oh god I'd love this
PowerShell,3aiga4,kcbwya77,1 point,Sat Jun 20 21:03:15 2015 UTC,"Me too. I have a lot of uses for it, but creating Visio objects is a convoluted process of providing static X/Y coordinates. A function to analyze a hierarchy of objects and build a diagram would be rad."
PowerShell,3aiga4,HalalVeggieBacon,2,Sat Jun 20 21:06:53 2015 UTC,I checked into this for you.  I don't see a COM object for VIZIO.  With that said it would be easy to output as an HTML you could  draw shapes with JS.  This is doable.  What do you use VIZO for?
PowerShell,3aiga4,HalalVeggieBacon,1 point,Sat Jun 20 22:44:11 2015 UTC,"I appreciate it. There is a Visio COM object, but you have to have the application installed. Hey, Scripting Guy! talks a little bit on how to use it.  The problem isn't that I understand how it's supposed to be used, but rather why it's so damn clunky.   I appreciate your looking into it for me!"
PowerShell,3aiga4,HalalVeggieBacon,1 point,Sat Jun 20 22:54:37 2015 UTC,COM objects are difficult but legit. If there is a COM object let me look into it some more this may be fun.
PowerShell,3aiga4,HalalVeggieBacon,1 point,Sat Jun 20 22:57:50 2015 UTC,"Word! I have some pretty complex diagrams I'd like to auto-draft, but working the math out to make it work would be pretty challenging.  Check out the link I posted, he goes into detail about how to manipulate Visio objects within a Visio COM object."
PowerShell,3aiga4,HalalVeggieBacon,2,Sat Jun 20 23:00:30 2015 UTC,dude check out my class that generates GUIs for you...  I can tell you will appreciate the math.
PowerShell,3aiga4,courvus,2,Sat Jun 20 23:07:48 2015 UTC,I especially appreciate math that someone else has already done the legwork for :-D  What's your site?
PowerShell,3aiga4,ramblingcookiemonste,2,Sat Jun 20 23:10:00 2015 UTC,"It's PowerShell 5.0 it's fun to work with but not practical in your operational environment, yet.  https://networksafely.wordpress.com/2015/05/06/on-the-fly-gui-generating-class-in-powershell/"
PowerShell,3aiga4,ramblingcookiemonste,2,Sat Jun 20 23:16:08 2015 UTC,Thanks man!
PowerShell,3aiga4,kcbwya77,1 point,Sat Jun 20 23:43:43 2015 UTC,Did you see this that someone below posted?  https://vimeo.com/94408016
PowerShell,3aiga4,kcbwya77,1 point,Sun Jun 21 00:21:04 2015 UTC,"Cool stuff!  If it helps, here are a few other methods I've used for charts in PowerShell:   Tutorial: PowerShell and Microsoft Chart Controls  (Google for more details on Chart Controls) HighCharts or DotNet.Highcharts – Google for a few examples of using PowerShell with HighCharts.  When you get it working, you can provide some fantastic charts.  Note:  I work for a non-profit – be sure to check the licensing! PSExcel - Simple way to export data to Excel and create pivot charts, among other things.  Thanks to Doug Finke for the idea! Visio and PowerShell - Not charts per se, but a handy way to work with visio for visuals.   Presumably you could send data out to d3.js as well, but high charts always fit my needs.  Cheers!"
PowerShell,3aiga4,LatexGolem,1 point,Sat Jun 20 15:56:06 2015 UTC,I like those...  I don't know if I'd use the applications though.  You can use the COM object of excel to create pivot tables....  yells PIVOT (like Ross when they were moving the couch)
PowerShell,3aiga4,kcbwya77,1 point,Sat Jun 20 22:42:59 2015 UTC,Hi!  I took screen shots to illustrate the outcome. PSExcel includes a small .NET library called EPPlus... You don't even need Excel on a system to use it : )  Cheers!
PowerShell,3aiga4,LatexGolem,1 point,Sun Jun 21 00:04:42 2015 UTC,"I went ahead and copied it from the pictures, i'm getting several errors. It does not seem to be working. I'll take a look at the errors later just wanted to post this for everyone  $i=0 $lw = @() while((((Get-Date).AddDays(-$i)).DayOfWeek -ne ""Monday"")){ $i++ } $daysSinceMonday = $i foreach ($facility in $facilities){ $lw += (Get-QADUser -OU $facility.OU -SizeLimit 0 -DontUseDefaultIncludedProperties -        includedproperties whenCreated |     where {$_.whenCreated -gt (Get-Date).AddDays($daysSinceMonday) }) } #### function buildPieChart($data, $name){ [Reflection.Assembly]::LoadWithPartialName(""System.Windows.Forms"") [Reflection.Assembly]::LoadWithPartialName(""System.Windows.Forms.DataVisualization"") #Chart deleration $Chart = New-Object System.Windows.Forms.DataVisualization.Charting.Chart $Chart.Width = 500 $Chart.Height = 400 $Chart.Left = 40 $Chart.Top = 30  #create a chartarea to draw on and add to chart $ChartArea = New-Object System.Windows.Forms.DataVisualization.Charting.ChartArea $Chart.ChartAreas.Add($ChartArea)  #add data to chart [void]$Chart.Series.Add(""Data"") $Chart.Series[""Data""].Points.DataBindXY($data.Keys, $data.Values) $Chart.Anchor = [System.Windows.Forms.AnchorStyles]::Bottom -bor     [System.Windows.Forms.AnchorStyles]::Right -bor                 [System.Windows.Forms.AnchorStyles]::Top -bor [System.Windows.Forms.AnchorStyles]::Left $Chart.Series[""Data""].ChartType = [System.Windows.Forms.DataVisualization.Charting.SeriesChartType]::Pie  $Chart.Series[""Data""][""PieLabelStyle""] = ""Outside"" $Chart.Series[""Data""][""PieLineColor""] = ""Black"" $Chart.Series[""Data""][""PieDrawingStyle""] = ""Concave"" ($Chart.Series[""Data""].Points.FindMaxByValue())[""Exploded""] = $true  [void]$Chart.Titles.Add(""$name"")  $Form = New-Object Windows.Forms.Form $Form.Text = $name $Form.Width = 600 $Form.Height = 500 $Form.bacground =  ""white"" $Form.controls.add($Chat) $Form.Add_Shown({$Form.Activate()}) $Form.ShowDialog() }"
PowerShell,3aiga4,kcbwya77,1 point,Sat Jun 20 21:28:06 2015 UTC,Post your error...  I'll help you. I got it to work.
PowerShell,3aiga4,kcbwya77,1 point,Sat Jun 20 21:44:22 2015 UTC,You need to create an array of strings... Each string being an ou.
PowerShell,3ak57m,swimbikerunrun,2,Sun Jun 21 00:06:36 2015 UTC,"You almost had it. If you specify a property, it will measure that:  get-queue | Select Identity,MessageCount | Measure MessageCount -Sum"
PowerShell,3ak57m,KevMar,3,Sun Jun 21 00:30:55 2015 UTC,"I love you, thank you!"
PowerShell,3aiexn,-neNull,1 point,Sat Jun 20 14:12:45 2015 UTC,Could I get a more detailed example of return? Looks pretty cool.
PowerShell,3aiexn,silentmage,1 point,Sat Jun 20 16:26:00 2015 UTC,Return is mostly used in functions to return a value to the calling scope.
PowerShell,3aiexn,scriptmonkey420,0,Sat Jun 20 18:37:42 2015 UTC,"Return is a common concept in many languages. You call a function and you can only get one single thing back from it. Return is the keyword that returns that single object. It also immediately exits the function when it is called.  The more common thing to use in powershell is Write-Object. But the difference is that it puts the object in the pipe and keeps processing. Good for streaming objects out of a function.  Return has not been used traditionally in most powershell scripts. This will become more important in powershell 5 with class based functions. This was done for developers that prefer using return in the traditional context.  I would recommend using Write-Object instead of return, but keep return in your tool belt for when you know you need it.    Edit: Not sure why, but I typed write-output instead of write-object. Fixed it inline."
PowerShell,3aiexn,KevMar,1 point,Sat Jun 20 19:20:38 2015 UTC,why write-output?  I'm not familiar with it.  edit: is it when you are returning multiple objects? https://www.sapien.com/blog/2009/06/02/powershell-functions-return-vs-write/
PowerShell,3aiexn,KevMar,2,Sat Jun 20 22:30:17 2015 UTC,That's just bad memory while typing on my phone. Totally should have been write-object. I agree with the views of that blog post but also recognize that it s a personal preference more than anything.
PowerShell,3aiexn,SeanQuinlan,1 point,Sat Jun 20 23:53:05 2015 UTC,"Continue will only work on a foreach loop, not Foreach-Object (or it's alias ""%""). So in your example, continue will exit the whole block and not continue to the next item in the ""loop""."
PowerShell,3ahy9b,MrAyThree,2,Sat Jun 20 10:11:28 2015 UTC,Why does he have to change the settings?
PowerShell,3ahy9b,drh713,1 point,Sat Jun 20 13:07:39 2015 UTC,Some ISP's only allow you to use their SMTP servers from their network for example.
PowerShell,3ahy9b,picklednull,1 point,Sat Jun 20 13:31:27 2015 UTC,Are the SMTP settings stored on disk somewhere? What is the format? Can you share a sample?
PowerShell,3ahy9b,itsteve,1 point,Sat Jun 20 12:26:33 2015 UTC,Maybe there is a free SMTP service (with authentication) that he could use. I've used Google's stuff for this in the past.   Apologies for not answering the question you asked.
PowerShell,3ahy9b,EthiopianHarrar,1 point,Sat Jun 20 14:12:42 2015 UTC,"The first thing you need to do is figure out where that setting is saved at in the system (besides the application GUI). Is it in a file or in the registry? Once you track that down, do it by hand a few times. You need to do this homework first, then we can help show you how to turn those manual steps into a powershell script."
PowerShell,3ahy9b,KevMar,1 point,Sat Jun 20 16:58:30 2015 UTC,Can't you migrate him to GMail and configure GMail to poll his POP3 mailbox?    The only thing I can think of is to check the registry for the SMTP settings. If its in there you could edit the registry with PowerShell.
PowerShell,3ahy9b,Swarfega,1 point,Sat Jun 20 18:29:39 2015 UTC,Most ISPs and free mail providers offer alternative SMTP options for sending such as SSL/TLS on port 465/587 which should work fine on your 3G connection. Call them up or check their KBs to see if they offer this.
PowerShell,3agysp,jrDevOverthinker,2,Sat Jun 20 02:15:28 2015 UTC,Check out the taglib library. You can use it to check and filter via id3 tags.
PowerShell,3agysp,spoonstar,1 point,Sat Jun 20 02:31:57 2015 UTC,"I may do that, I am just looking for something simple and /u/bundyfx may have what I need."
PowerShell,3agysp,-neNull,2,Sat Jun 20 22:32:43 2015 UTC,I love how geeky this makes me feel...   meh....  oneliner to get only the unique into a new folder... meh...  get-childitem c:\Path -recursive | select namePropertyHere | sort-object | get-unique | % { move-object newPathHere -identity $_ }
PowerShell,3agysp,bundyfx,1 point,Sat Jun 20 22:52:53 2015 UTC,This! I love how some people just know how to look at problems differently. Rather than pull out all the ones that are not unique. Simply move the ones that are. Thank you!
PowerShell,3agysp,imsoindustrial,1 point,Sun Jun 21 01:58:18 2015 UTC,"Pretty simply. You just need to find a common identifier between the duplicates. ie. Do they have the same name in the file name? are they the exact same size (bytes). as a quick check you could even do something as simple as:  Get-ChildItem -Recurse -Filter *.mp3 | Group-Object length,name | sort count -Descending   This will give you a list of all MP3's on that volume. and group them so you will be able to tell if you have more than (1) copy of the file.  there are lots of other ways to to this but this might get you started."
PowerShell,3agysp,GLiMPSEiNATOR,2,Sat Jun 20 02:28:15 2015 UTC,I'd also make use of get-hash for empirical comparisons.
PowerShell,3afec7,kittH,1 point,Fri Jun 19 18:07:00 2015 UTC,Had you tried to accomplish this with logparser or logresolvemerge.pl?
PowerShell,3afec7,techmattr,1 point,Sat Jun 20 03:51:23 2015 UTC,"Nope, no familiarity with those tools and seemed like a good chance to stretch into .net a little bit.  Would those have provided a turnkey solution?"
PowerShell,3afec7,techmattr,1 point,Sat Jun 20 05:16:25 2015 UTC,logresolvemerge.pl is a script included with awstats written just for combining log files. LogParser makes it really easy as well.  This is a very simple LogParser command I had used at one point to combine IIS log files: https://gist.github.com/techmattr/7c3a6ec5612d7b853d45#file-iislogconsolidate This would require a script to copy the files into these directories prior to combining. A better way to do it would be to grab the correct files from the source server by date and combine them without copying them locally first.  I'm not sure if either of these tools will handle the stack traces well or not. I know LogParser can as it natively handles Event Viewer logs without issue but I'm not sure if the simple command I posted would handle them.
PowerShell,3afec7,moojitoo,1 point,Sat Jun 20 21:01:22 2015 UTC,"Very nice, thanks for sharing! You never know when something like this could come in handy."
PowerShell,3afec7,zinver,1 point,Sat Jun 20 10:34:08 2015 UTC,"You can speed up get-content, try this:  get-content -readcount 0  Instead of get-content looking at every line, it will dump all lines to a single array.  there are other speed up tricks with the @array in hand as well.   http://powershell.com/cs/blogs/tobias/archive/2010/11/30/speeding-up-your-scripts.aspx"
PowerShell,3afec7,zinver,1 point,Sun Jun 21 12:36:30 2015 UTC,"There are definitely some ways to speed up Get-Content, but I guess it was misleading to say get-content was too slow because the real issue was dealing with the data as a giant in-memory chunk. Doing the regexing and sorting and stuff.   I really wanted a way to parse the files simultaneously and move through line by line handling the reading/writing/sorting as I went."
PowerShell,3ag2t4,Tidusblue,1 point,Fri Jun 19 21:18:50 2015 UTC,You need to connect to the http://sitename-admin.sharepoint.com
PowerShell,3ag2t4,jcollinsco,1 point,Sat Jun 20 16:10:30 2015 UTC,"Yeah, I am doing that, and can connect from my office, but when at the clients office I can't and get the error that I posted"
PowerShell,3afn5q,statikp,1 point,Fri Jun 19 19:15:19 2015 UTC,"Try doing a ""show-command new-distributiongroup"" command and see if running it through that gives you the same error.  What OS are you running it from?"
PowerShell,3afn5q,mr_crank,1 point,Fri Jun 19 20:54:41 2015 UTC,It's been a while since I created one but I seem to remember reading somewhere that a room list is just a DL that only contains room mailboxes. Try just creating it without the switch and see what happens.  When you do Get-Help New-DistributionGroup does it list the RoomList switch in the parameters section?  EDIT: I just ran New-DistributionGroup TestRoomList -RoomList against our tenancy and it accepted it with no errors.
PowerShell,3afn5q,jsmcnair,1 point,Sat Jun 20 09:21:45 2015 UTC,type this: get-help new-DistributionGroup  -examples
PowerShell,3agpla,tehreet,1 point,Sat Jun 20 00:41:50 2015 UTC,"Here are some things that I would change. Some is style and syntax. Others use more advanced functions to get and validate input.   ####################################### # Script by: Josh Frantz # Date: 6/19/2015 # Synopsis: Connecting a disconnected user's mailbox to an ISS account # Edit suggestions by: Kevin Marquette #######################################   Import-Module ActiveDirectory  if (! (Get-PSSnapin Microsoft.Exchange.Management.PowerShell.E2010 -ErrorAction:SilentlyContinue) )     {     Add-PSSnapin Microsoft.Exchange.Management.PowerShell.E2010 -ErrorAction:Stop     }  if (!(Get-ADServerSettings).ViewEntireForest)     {     Set-ADServerSettings -ViewEntireForest $true -WarningAction SilentlyContinue     }  ############# # Functions # #############    <# .SYNOPSIS Refreshes all DB's in Exchange (We have 70 at my company, across 7 servers* .EXAMPLE Refresh-Databases  .EXAMPLE Refresh-Databases -Verbose .NOTES  #> function Refresh-Databases  {     [cmdletbinding()]     param()      Write-Vost ""Refreshing all Exchange Mailbox databases, please wait...""     Get-MailboxDatabase * | Clean-MailboxDatabase     Write-Verbose ""Finished refreshing all databases."" }  <# .SYNOPSIS This function finds the ISSAccount (this is an alias we use so that people don't just add terminated user's disconnected mailboxes .EXAMPLE Get-ISSAccount  -ISS abc123 -OldManager joe.goodwin .NOTES  #> function Get-ISSAccount  {     [cmdletbinding()]     param(         [Parameter(             Mandatory         = $true,             HelpMessage       = ""Please enter the ISS account you are using to connect mailboxes"",             Position          = 0,             ValueFromPipelineByPropertyName = $true         )]         [string]$ISS,          [Parameter(             Mandatory         = $true,             HelpMessage       = ""Please enter the user id of the person you're removing access from for this ISS account"",             Position          = 1,             ValueFromPipelineByPropertyName = $true         )]          [string]$OldManager      )      $ISSDB = Get-MailboxDatabase *      foreach ($database in $ISSDB)      {         Remove-MailboxPermission -identity $ISS -user $OldManager -access FullAccess         Disable-Mailbox $ISS -confirm:$false         Write-Verbose ""Removed full access permissions from $OldManager, disabled mailbox $ISS""      } }  <# .SYNOPSIS This finds the disconnected mailbox  .EXAMPLE Get-UserMailbox joe.goodwin .EXAMPLE ""Joe"",""Kevin"",""Sarah"" | Get-UserMailbox .NOTES extremely slow because it looks through all our DB's :( #> function Get-UserMailbox  {     [cmdletbinding()]     param(         [Parameter(             Mandatory         = $true,             HelpMessage       = ""Please enter the user's last name that you want to connect"",             Position          = 0,             ValueFromPipeline = $true,             ValueFromPipelineByPropertyName = $true             )]         [string[]]$UserName      )      begin     {         Write-Verbose ""Getting all mailbox databases""         $MailboxDB = Get-MailboxDatabase *         foreach($database in $MailboxDB)         {             Write-Verbose ""Getting stats for $database""             $MailboxStatistics += Get-MailboxStatistics -database $database | where {$_.DisconnectDate -ne $null}          }     }      process     {         foreach ($User in $UserName)         {             Write-Verbose ""Get User: $User""             $disconMB = $MailboxStatistics | ?{$_.DisplayName -like ""*$User*""}               Write-Verbose (""Found {0} Items"" -f $disconMB.count)              foreach($item in $disconMB)              {                 Write-Output ([pscustomobject]@{                     Displayname       = $item.Displayname                     LegacyDN          = $item.LegacyDN                     MailboxGUID       = $item.MailboxGUID                     Database          = $item.Database                     OriginatingServer = $item.OriginatingServer                 })             }         }     } }  <# .SYNOPSIS This attempts to connect the disconnected mailbox to the ISS account, and grants full permissions to the user requesting access .EXAMPLE Reset-MailboxPermission -MBGUID d8ef824c-cd8f-4e80-9757-6adf1bbbb280  .EXAMPLE  .NOTES  #> function Reset-MailboxPermission {     [cmdletbinding()]     param(         [Parameter(             Mandatory         = $true,             HelpMessage       = ""Please copy and paste the Mailbox GUI from the list above"",             Position          = 0,             ValueFromPipelineByPropertyName = $true         )]                 [string]$MBGUID,          [Parameter(             Mandatory         = $true,             HelpMessage       = ""Please enter the user getting full access permissions"",             Position          = 1,             ValueFromPipelineByPropertyName = $true         )]         [string]$Manager,          [Parameter(             Mandatory         = $true,             HelpMessage       = ""Please enter the ISS account you are connecting this to"",             Position          = 2,             ValueFromPipelineByPropertyName = $true         )]         [string]$ISSAccount,           [Parameter(             Mandatory         = $true,             HelpMessage       = ""Please enter the database from above"",             Position          = 3,             ValueFromPipelineByPropertyName = $true         )]         [string]$Database     )      Write-Verbose ""Connect to mailbox""     Connect-Mailbox -Identity $MBGUID -database $Database -User $ISSAccount      Write-Verbose ""Connecting user mailbox to $ISSAccount...""     Add-MailboxPermission -Identity $ISSAccount -user $Manager -access FullAccess -Automapping:$true      Write-Verbose ""Applying permissions...""     Clean-MailboxDatabase $Database }  ####################### # Use Functions Above # ####################### Reset-MailboxPermission Get-ISSAccount Get-UserMailbox Refresh-Databases"
PowerShell,3agpla,KevMar,1 point,Sat Jun 20 03:10:52 2015 UTC,"Awesome! thanks for the tip. The problem i seem to be having is this line here:  Write-Verbose ""Connect to mailbox"" Connect-Mailbox -Identity $MBGUID -database $Database -User $ISSAccount   It appears as though it is looking for the $ISSAccount in the same database as the $MBGUID account. They will not be in the same database. Anyway i can make it so it goes to the DB to get the disconnected account, and then searches all the databases for the alias it connects to?"
PowerShell,3agpla,whatcantyoudo,2,Sat Jun 20 03:20:15 2015 UTC,"It appears as though it is looking for the $ISSAccount in the same database as the $MBGUID account. They will not be in the same database.    Uh. What? $ISSAccount can't be in any database as it's just a user without a mailbox?  $MBGUID = disconnected mailbox, which already resides in a database  $database = the database the disconnected mailbox is in  $ISSAccount = AD User without a mailbox that should be connected to $MBGUID."
PowerShell,3agpla,whatcantyoudo,1 point,Sat Jun 20 14:47:19 2015 UTC,"For some reason, i get an error saying $ISSAccount cannot be found in DBXX"
PowerShell,3agpla,KevMar,1 point,Sat Jun 20 17:21:40 2015 UTC,Doesn't make sense unless those functions are being called out of order or variables are mixed up or something else silly. The -user switch for connect-mailbox isn't required; it's just the option to connect the disconnected mbx to a diff user account than the one matching the display name..Perhaps you should add some breakpoints and/or debug output. :)
PowerShell,3afen3,FireITGuy,2,Fri Jun 19 18:09:25 2015 UTC,"This is janky and awful.  You're supposed to (as part of your work duties - not just messing around) run a query against a production SQL database for the 30k employees in the company... and they won't give you access to the SQL database?  I'm sure there is some awful convoluted way that you can do this with web scraping and hating yourself, but why bother if you can avoid it?  ""I'm sorry $Boss, but I don't have the access to the tools needed to accomplish this task."""
PowerShell,3afen3,ebauman,2,Fri Jun 19 18:38:15 2015 UTC,"No argument that it's absolutely janky and awful, but I work for the government, so we specialize convoluted solutions!   The issue with access comes down to the fact that the system I need data from holds personnel records. I don't need (Or want to be involved in) the majority of information in the system. I just need 5 nonsensitive fields out of their database  With the recent OPM data breach ( https://krebsonsecurity.com/2015/06/catching-up-on-the-opm-breach/ ) there is no way that they're going to be handing out direct access to a personnel database to staff that aren't absolutely required to have it.  I can do the task manually via the web interface, It's just slow. Because of this my boss isn't going to push hard for something that he knows would be a losing battle anyway. Because of this it would be better for me to have an ugly solution that works, than no solution at all."
PowerShell,3afen3,ElMalakai,3,Fri Jun 19 19:01:30 2015 UTC,"You don't need direct access to the underlying data.   There's a chance by altering the Querystring or a form param, you can have SSRS spit out the data as XML, CSV, or some other more easily parsable format.  Also, anytime you have an exposed SSRS report, more than likely you can reach the SOAP API for that report as well.   You'll need to describe how your accessing the report. Is this an emedded report viewer in a vanilla website, or are you hitting the ReportServer virtual directory directly?  You should check out SSRS URL Access and see if you can't use the RS:Format query param to render the report as XML, and then do what you got to do."
PowerShell,3afen3,ShippingIsMagic,2,Fri Jun 19 19:08:39 2015 UTC,"That was a very good read. I'd never considered URL parameters for accessing the data.  I believe the access is through the embedded report viewer. It looks just like this Google Image  The server will take the url with &rs:Format=CSV, but it doesn't change anything. It still just goes to the report viewer.  Strangely enough I found that I actually can download the report from the report viewer, even though I get hit with rsAccessDenied when I try download it from the folder view in the report viewer.  The (Sterilized) URL I normally use to access the report is: https://SERVERNAME.DOMAIN.COM/Reports/Pages/Report.aspx?ItemPath=%2fORGAccountManagement%2fSYSTEMEmployees&ViewMode=Detail  The (Sterilized) URL I'm using and not having any luck with is: https://SERVERNAME.DOMAIN.COM/Reports/Pages/Report.aspx?ItemPath=%2fORGAccountManagement%2fSYSTEMEmployees&rs:Format=CSV (Or XML, PDF, etc)"
PowerShell,3afen3,ElMalakai,1 point,Fri Jun 19 20:02:51 2015 UTC,You'll most likely use one of the asmx endpoints to render the report instead (passing rs:Format)  An example:  http://blogs.technet.com/b/stefan_stranger/archive/2010/05/16/rendering-sql-reporting-reports-with-powershell.aspx
PowerShell,3afen3,ElMalakai,1 point,Fri Jun 19 20:42:43 2015 UTC,"Not at computer now, will explain later, but you are accessing the reports via the Native SSRS web portal/web interface. This is different than via an embedded viewer control on a third party website. Also this makes it easier to do what you need.  You may want to try accessing http://localhost/reportserver  If that displays anything like a file directory looking interface, you have web service access to your reports. Life just got easy."
PowerShell,3afhne,mb9023,1 point,Fri Jun 19 18:31:44 2015 UTC,What is it you're actually trying to accomplish?
PowerShell,3afhne,mr_crank,1 point,Fri Jun 19 19:18:54 2015 UTC,"Right now I have to remote into my server, open powershell for Azure (with the MSOnline module imported) and navigate to its directory to launch this .exe file. Because it syncs our AD with Azure through that module so it has to be run in powershell.  I want to double click on a file to automatically do this so I don't have to open powershell and type it in. I thought I made that pretty clear.."
PowerShell,3afhne,mr_crank,2,Fri Jun 19 19:34:44 2015 UTC,Not so sure you need to run anything via powershell.   https://msdn.microsoft.com/en-us/library/azure/jj151800.aspx  I'd take a look at this. You should be able to just run the tool and set it up.
PowerShell,3afhne,mr_crank,1 point,Fri Jun 19 19:52:33 2015 UTC,Yes the Sync tool sets up the initial sync and installs a Sync scheduler which runs every 3 hours. We have to run this .exe to force run the sync if we need a user or password update right away.
PowerShell,3afhne,silentmage,1 point,Fri Jun 19 20:23:30 2015 UTC,you can use a script to tell the task scheduler to run the task. Just call schtasks.exe in your script and make sure you run the script as a user that has the correct permissions.
PowerShell,3afhne,sudochmod,1 point,Fri Jun 19 21:01:27 2015 UTC,When I want to force a dirsync there is a powershell command for it.   Import module dirsync  Start-onlincoexistancesync   And that forces a sync. Are you up to date with dirsync?
PowerShell,3afhne,sudochmod,1 point,Sat Jun 20 13:26:32 2015 UTC,You set it as a scheduled task...  Is this for Office 365?
PowerShell,3afhne,sudochmod,1 point,Fri Jun 19 19:39:15 2015 UTC,"Yes, there is a Directory Sync Scheduler already which does so every three hours. This .exe is to force the sync manually."
PowerShell,3afhne,sudochmod,1 point,Fri Jun 19 20:24:30 2015 UTC,"Are you using dirsync or AADSync? You can just run the sync client from the local cmd line, you don't need to RPOSH to Exchange Online."
PowerShell,3afhne,-neNull,1 point,Sat Jun 20 15:46:11 2015 UTC,"AADSync. Our Microsoft rep who set it up is the one who told us to do it this way, so idk"
PowerShell,3afhne,JatKaffee,1 point,Sat Jun 20 16:09:37 2015 UTC,When I get home later I'll post the directory. Pretty sure it's directorysync something under the Microsoft azure sync folder. You just run this and it should sync everything...
PowerShell,3agbuf,boboysdadda,2,Fri Jun 19 22:32:32 2015 UTC,"This will get the hash assuming you're on v3 :  $FilePath = ""C:\foo.txt"" $md5 = New-Object -TypeName System.Security.Cryptography.MD5CryptoServiceProvider $filehash = [System.BitConverter]::ToString($md5.ComputeHash([System.IO.File]::ReadAllBytes($FilePath)))   I'm on mobile so it'd  take me a bit to write all of it out,  but this should get you started."
PowerShell,3agbuf,i_me_me,2,Sat Jun 20 00:11:40 2015 UTC,"$Computers = Get-Content -Path ""C:\computernames.txt""   foreach($node in $Computers)  {      $file = ""\\$node\c$\windows\calc.exe""      $hash = (Get-FileHash $file).hash       $result = [pscustomobject]@{          computer=$node          file = $file          hash = $hash      }      $result  }"
PowerShell,3agbuf,KevMar,1 point,Sat Jun 20 01:53:44 2015 UTC,Thanks for the help guys. I actually managed to solve it before i checked back here by adding  %hash = Get-Filehash -Algorithm sha1 $FilePath   and then calling the %hash back in the output.  but it still needs tweaking. because it was putting the $filepath after the hash in the results. So that $filepath may not be needed based on where I placed it in the script.  Thanks Again
PowerShell,3af17z,lovewhale,3,Fri Jun 19 16:27:56 2015 UTC,"Fair warning, I haven't tested this... It assumes the csv file is split in two columns labelled on the first row: Name, Email  $CSV = Import-Csv ""C:\users.csv"" $PDFFolder = ""\\SERVER\Share\Folder""  ForEach($User in $CSV) {     $PDFs = Get-ChildItem | Where-Object { $_.Extension -eq "".pdf"" -and $_.Name -like ""*$($User.Name)*"" }      $to = $User.Email     $from = ""fromaddress@domain.com""     $smtp = ""smtp.domain.com""     $body = ""Please see attachments.""     $attachments = @()      ForEach($PDF in $PDFs)     {         $attachments += $PDF.FullName     }      $MessageParameters = @{         From = $from         To = $to         Subject = ""Here, have these $($PDFs.Length) PDF Files!""         Body = $body         SmtpServer = $smtp         Attachments = $attachments     }      Send-MailMessage @MessageParameters }"
PowerShell,3af17z,RickSaysMeh,2,Fri Jun 19 17:41:14 2015 UTC,"I won't be able to test this until Monday, but thankyou, you beautiful internet stranger.   I'll let you know how it goes."
PowerShell,3af17z,veggie124,1 point,Fri Jun 19 19:15:39 2015 UTC,"I would suggest an automated archiving function as well, to keep the scanned folder manageable size."
PowerShell,3af17z,RickSaysMeh,1 point,Fri Jun 19 19:21:19 2015 UTC,"If the PDFs are no longer needed after emailing, then this could be added after the Send-MailMessage:  $PDFs | Move-Item "".\ArchiveFolder""   If there is a chance that multiple people would receive the same PDFs (had more than one name in the filename), then you'd have to keep track...  Before the loop:  $PDFsToArchive = @()   In the loop, after the Send-MailMessage:  $PDFsToArchive += $PDFs   After the loop:  $PDFsToArchive | Move-Item "".\ArchiveFolder""   It'll throw up some errors when trying to move PDFs it already moved, but should work..."
PowerShell,3af17z,imsoindustrial,1 point,Fri Jun 19 19:54:15 2015 UTC,Might also consider wrapping in a try catch (email on error) and quit on $errorCount -ge 5
PowerShell,3af17z,RickSaysMeh,1 point,Sat Jun 20 04:20:56 2015 UTC,"Thanks, should be OK but will try implementing the above as well.  Also, for extra-mega-brownie points here's another conundrum I just thought of:  We have a send/receive limit of 10MB, so when the script runs it seems to send to all users whose items total <10MB, but fails for those whose total >10MB. Is there any way we can get it working so it'll either send across multiple messages if it exceeds or perhaps send a warning or log to one of our end users so they can manually send across mult. messages?  EDIT: I've come up with solution where if a message fails to send it'll notify one of the users with the name of the person it failed to send to. If you have any better ideas though please let me know!"
PowerShell,3af17z,RickSaysMeh,1 point,Mon Jun 22 11:59:06 2015 UTC,"Using nested while loops you could get it to send batches of the PDF files provided each PDF is below 10 MB, and use a try/catch to send an email with the FullPath of any that are too large. I don't have the time to workup the logic at the moment, but it would just check the length of each file in $attachments, and while those added together are less than 10MB, it would send them, otherwise, it would stop before the total size is 10MB, send the email and start over with the remaining files in $attachments. If a single file is too big, its FullPath and size/length could be added to the body of the message so the user knows there is another file that is too big to send."
PowerShell,3af17z,RickSaysMeh,1 point,Mon Jun 22 13:38:31 2015 UTC,"Yeah that's what I'm looking into now- the notification I have set up is using a try/catch so I'm sure it'll get there.  Thanks for the help though, much appreciated!"
PowerShell,3aeqyu,swimbikerunrun,7,Fri Jun 19 15:06:11 2015 UTC,Get-Help Send-MailMessage
PowerShell,3aeqyu,itsteve,5,Fri Jun 19 15:21:53 2015 UTC,If($object.count -lt 20)|Send-Mailmessage -to $toEmail -from $fromEmail -Subject ($object.count) -body $body -smtpserver $server
PowerShell,3aez97,xsymbianx,1 point,Fri Jun 19 16:12:14 2015 UTC,"So the problem is with PermUser and Access, right?  Try PermUser=($MailPerm | select -expand User) -join ';'   Something similar should work for Access, but I don't have an exchange in front of me to test it with."
PowerShell,3aez97,michaelshepard,1 point,Fri Jun 19 16:24:55 2015 UTC,Well since I am filtering for FullAccess I guess its redundant to put it in the CSV. Trying your suggestions
PowerShell,3aez97,catfoodsci,1 point,Fri Jun 19 17:07:31 2015 UTC,"Correct me if i'm wrong, but i beleive that the variable $mailperm may result in a collection which would cause problems for  PermUser = $MailPerm.User Access = $MailPerm.AccessRights   As they may need to be referenced like an array depending upon how many results you get back.  PermUser = $MailPerm[0].User Access = $MailPerm[0].AccessRights   I may be off base, but in my basic testing my test mailbox had 2 accounts with Full Access and therefore simply outputting ""$MailPerm.User"" didn't display the results."
PowerShell,3afg15,BloominFunyun,1 point,Fri Jun 19 18:19:46 2015 UTC,You can use a where if you can isolate the property you need.  Get-AdGroupMember $oldGroup|select -expand name | ? {(get-adgroupmember $newGroup|select -expand name) -notcontains $_}|add-adgroupmember -members $_   Code should compare the group members and then add the ones not already present to the group.  There might be a shorter way though:  Get-ADGroupMember -Identity ExsistingGroup | Add-ADPrincipalGroupMembership -MemberOf NewGroup -erroraction silentlycontinue
PowerShell,3afg15,mr_crank,1 point,Fri Jun 19 18:53:05 2015 UTC,"That second one looks promising. I thought it would be the erroraction parameter but couldn't figure out the context.  I went ahead and found another PS script on google that worked for me, although it's about 10 lines long and requires an existing csv file for comparison. I'll try yours next time I have a chance."
PowerShell,3afg15,mr_crank,1 point,Fri Jun 19 19:23:23 2015 UTC,Either one should work. I tested the first line to make sure it outputs the correct subsection. Let me know how it turns out for you.
PowerShell,3afg15,the_spad,1 point,Fri Jun 19 19:49:51 2015 UTC,Can't you just do  Get-ADGroupMember -Identity ExsistingGroup | Add-ADGroupMember -Identity NewGroup   You can always do an -ea silentlycontinue if you don't want to see errors written to the console for users who are already members of the destination group.  Remember that Add-ADPrincipalGroupMembership is for adding a single user to multiple groups while Add-ADGroupMember is for adding multiple users to a single group.
PowerShell,3advgc,Aviio,4,Fri Jun 19 09:05:06 2015 UTC,"Take a read through the PowerShell DSC eBook at PowerShell.org too.  I don't remember if they had a ""best practices"" section."
PowerShell,3advgc,jbtechwood,1 point,Fri Jun 19 10:22:33 2015 UTC,It doesnt have a best practices section but theres a lot of information in there on getting started! Thanks.
PowerShell,3advgc,bundyfx,3,Fri Jun 19 11:13:08 2015 UTC,Head over to PowerShell.org and check out the DSC resources section. lots of the guys over there have tons of experience with DSC in a Production environment. I saw Don Jones tweeting about a new MVA to be released shortly in regards to DSC in production. should be a good one!
PowerShell,3advgc,bundyfx,1 point,Fri Jun 19 10:21:43 2015 UTC,"Wow, so many resources that I havent read yet! Fantastic!   Quick question though - Any ideas as to why the majority are favouring a pull server configuration instead of a push one?"
PowerShell,3advgc,KevMar,2,Fri Jun 19 11:12:32 2015 UTC,"for a production environment you would want a HTTPS Pull Server setup. There are a few reasons for this, namely the fact that nodes will pull the information from the pull servers website and automatically change their configuration to apply with their designated .mof. its more of a hands off approach to DSC.  At first though you will do your testing by pushing your changes (.mof) to the nodes and testing your configuration that way, once you have your config set and you're happy with it you will want that machine to pull for its configuration as its a more practical approach. As first steps you will want to setup and understand the need for both these methods. I would highly recommend the PowerShell DSC MVA (google) with Jeffrey Snover and Jason Helmick."
PowerShell,3advgc,m-o-n-t-a-n-a,1 point,Fri Jun 19 12:13:25 2015 UTC,"Ive been wondering for a while if its possible to have the best of both worlds, as our infrastructure team wants more control over what DSC is doing to the environments.  What I was hoping for was the pull server would serve up any resources required by the configurations and monitor any changes using a compliance server and notify our infrastructure team of any changes that need to be pushed out to those machines, those changes can be pushed out manually by the team using DSC, giving us more control over our infrastructure.  Are you aware of this being done in any way? or am I going to be forced into making a choice between the two?"
PowerShell,3advgc,joeyaiello,3,Fri Jun 19 12:23:58 2015 UTC,"I think the best approach here would be to use a pull server, but then issue a command to the server to invoke the pull.  It's the same effect as the push but it makes sure all changes make it into the pull server and all nodes keep using it. You can then build tour change control around the pull server.  If you have a pull server, then you push to it, it is now a push server until you make it a pull server again."
PowerShell,3advgc,QuistyTreppe,2,Fri Jun 19 13:05:37 2015 UTC,"Blogger Ben Gelens has some pretty good article about setting up a secure DSC environment, IMHO a must read when setting up a production environment: http://www.hyper-v.nu/archives/category/ben-gelens/"
PowerShell,3advgc,bundyfx,2,Fri Jun 19 13:35:40 2015 UTC,"For writing DSC resources, we've published this blog post, but it only applies to MOF-based resources.  We definitely recognize the need for official best practices across both PowerShell and DSC. I'm working on it..."
PowerShell,3aeah6,Swarfega,2,Fri Jun 19 12:34:39 2015 UTC,"From http://powershell.org/wp/2015/04/28/why-is-remoting-enabled-by-default-on-windows-server/ in which Don Jones explains why (in his view) MS has enabled it by default now (emphasis mine).   Now, in defense of this “on by default” approach, I’ll point out that unlike nearly every preceding remote management protocol introduced by Microsoft, Remoting is incredibly controllable. It uses WS-Management (WS-MAN), which is HTTP-based. It runs on just one incoming port, which is easy to lock down through physical, soft, and virtual firewalls. You can certainly have an environment that’s pre-engineered to protect that port. But if you buy into Microsoft’s “headless” approach – and whether you do or not, Microsoft certainly buys in – then they had to enable something so you could configure the server, at least initially.   How to set up WinRM with HTTPS  /u/ramblingcookiemonste offered up a couple links last year on the subject in this sub  Definitely explore JEA"
PowerShell,3aeah6,alinroc,1 point,Fri Jun 19 13:05:27 2015 UTC,Thanks. Im surprised though there isn't some sort of whitepaper or anything official from Microsoft.  I would hope that the fact Microsoft are enabling this by default would be enough to tell them this is safe.
PowerShell,3aeah6,ramblingcookiemonste,1 point,Fri Jun 19 14:22:41 2015 UTC,"Hi!  What /u/alinroc said.  Also, some other links here, including a read from SANS that mentions even HTTP traffic is encrypted via kerberos.  Long story short, it's secure; far more so than legacy protocols like DCOM, RPC, or Remote Registry. If you have folks using RDP today, you are using CredSSP, which sends their creds over to the remote box where someone could use mimikatz to steal the creds.  Good luck. Given that it's 2015 and you're getting pushback on this, there's a chance you'll have a tough fight. It's worth it though : )  Cheers!"
PowerShell,3aen7t,kaluce,3,Fri Jun 19 14:34:44 2015 UTC,Can you not simply use Group Policy restricted groups to achieve the same result?  Otherwise you've got a few options; simplest is probably to use Run As to run the script as a domain user.   You could go with the PSRemoting option but it's probably a little overkill for what you're trying to achieve. You should be able to configure WinRM to only listen to connections from localhost if required.
PowerShell,3aen7t,the_spad,1 point,Fri Jun 19 14:45:31 2015 UTC,"Why not just use net.exe from your PowerShell script?  As long as the machine is domain joined, the names should resolve even if you're logged in with a local account.  Net localgroup administrators /add domain\username"
PowerShell,3aen7t,fatshady,1 point,Fri Jun 19 15:16:57 2015 UTC,"I've tried that. I got a ""trust relationship failure"" while running as a local admin account. It does however work if you have a domain account running the command since it needs to access the domain."
PowerShell,3aen7t,-neNull,0,Fri Jun 19 15:25:16 2015 UTC,this has bad intentions written all over it...
PowerShell,3aehgm,swimbikerunrun,1 point,Fri Jun 19 13:44:36 2015 UTC,Something using Get-MailboxStatistics I should imagine (ItemCount).  You could store the mailbox stats in a file and parse it every x minutes to make sure the integer is greater than. Sadly I don't have access to Exchange so can't look right now.
PowerShell,3aehgm,Swarfega,1 point,Fri Jun 19 15:18:36 2015 UTC,"I have tested this in pieces, but not as a whole. It should accomplish what you want if you save it as a script and then setup a job in Task Scheduler on your Exchange server. It requires Exchange 2010 SP1 or higher. If your PowerShell is under version 3, you will probably need to import the Exchange module in the script.  $NumberOfMinutes = 30 $SearchDateTime = (Get-Date).AddMinutes(-1 * $NumberOfMinutes)  $Mailboxes = @(""user1"",""user2"",""user3"")  $Outputs = $Mailboxes | Search-Mailbox -SearchQuery Received:>""$($SearchDateTime)"" -LogLevel Suppress -TargetMailbox yourmb -TargetFolder SearchResults  ForEach($Output in $Outputs) {     If($Output.ResultItemsCount -lt 1)     {         Send-MailMessage -From search@domain.com -To youremail@domain.com -Subject ""$($Output.DisplayName) has not received an email in the last $($NumberOfMinutes) minutes"" -SmtpServer smtp.domain.com     } }   The TargetMailbox and TargetFolder are required but will not be used due to the -LogLevel Suppress."
PowerShell,3aehgm,RickSaysMeh,1 point,Fri Jun 19 18:27:31 2015 UTC,"Here is something that will work with one mailbox  $mailbox = ""userid"" $SleepSeconds  = 10 $CurrentInboxCount = (Get-MailboxFolderStatistics $mailbox | ?{$_.Name -eq ""Inbox""}).ItemsInFolderAndSubfolders do{     Start-Sleep $SleepSeconds     $NewInboxCount = (Get-MailboxFolderStatistics $mailbox | ?{$_.Name -eq ""Inbox""}).ItemsInFolderAndSubfolders     If ($CurrentInboxCount -lt $NewInboxCount)         {$CurrentInboxCount = $NewInboxCount}     Else         {Send-MailMessage -SmtpServer smtp.domain.com -To alerts@domain.com -From alerts@domain.com -Subject ""Alert"" -Body ""No new incoming mail""} }while(-1)"
PowerShell,3adcn5,XenuLovesTheCock,3,Fri Jun 19 04:54:43 2015 UTC,I'm sure you can shove the commands for plink in a txt file and call upon that. That should work.  I'm on my phone ATM so can't give an example.  I used something similar to execute a bunch of commands on ESX hosts pulled out of vCenter using PowerCLI.
PowerShell,3adcn5,Swarfega,1 point,Fri Jun 19 06:08:20 2015 UTC,"Yeah, Plink can call a file to execute the command as such:  Plink -v -ssh USER@ADDRESS [command]  to use the text of a file for a command  Plink -v -ssh USER@ADDRESS -m [PATH]  So I broke out the command part of the script (everything after the password) and put that into a text file then added the -m switch and path; tried both with and without the single quotes. It logs in but still gives the syntax error."
PowerShell,3adcn5,treatmewrong,1 point,Fri Jun 19 06:32:28 2015 UTC,"With the command in a text file, add a semi-colon to the end of the command, and make sure to put an extra newline at the end of the file. Make this with Notepad (or Notepad++).   Also make sure your login shell is specified on the Mac (no reason it shouldn't be).  I use Plink in Powershell a lot, since I can use Powershell to access my inventory DB and loop over the Linux hosts. I've never had a problem like this."
PowerShell,3adcn5,real_parbold,1 point,Fri Jun 19 06:45:38 2015 UTC,"Could it be something quite simple - like the line breaks in the text file you are throwing at the mac?  \r is carriage return, and \n is line feed.  Windows \r\n Linux \n Mac OSX \r Mac Classic \n   I know you get some strange behaviour on Linux when script files had windows file line endings (hence dos2unix and unix2dos commands to convert files.)  If using notepad++, try set the files line-endings to mac and try again :)  Edit: Formatting and clarity"
PowerShell,3adcn5,sid351,1 point,Fri Jun 19 11:05:28 2015 UTC,"This is actually the answer that worked for me and I tried everything on this page as of now.  The bat and the text file that contained the command were in the same folder. when I used the -m switch, I put in the entire path to the command file. This would not work.   It only works when I use the -m switch and put only the file name in quotes afterward. Such as:  osascript -m ""command.txt""  Thank you (and everyone) for helping get this sorted!!"
PowerShell,3adcn5,sid351,2,Fri Jun 19 20:42:19 2015 UTC,"I've not used plink before, but when you run the commands manually you run then sequentially yes? As in you connect (line 1) then run your notification command (line 2).  Have you tried making your batch file be two separate lines?  If I get a chance I'll have a look at this on my laptop later today."
PowerShell,3adcn5,ajeoae,1 point,Fri Jun 19 05:43:38 2015 UTC,"This is a great suggestion! I thought that this was going to do it, but I gave it a shot and it didn't work.  It logs onto the mac and brings up the terminal, but I never see the second line get executed and it just hangs at the ssh terminal.I also tried adding in a 10 second delay between the lines and the behavior was the same.  I've also double checked the documentation for plink to make sure I'm invoking the command correctly & I'm also pretty sure that I'm using osascript 'display notification' correctly, which makes sense since it does work when I manually execute these commands through the shell.   Maybe I don't know how to make a bat file? Just literally ""notifymac.bat"" and the files text is just:  Plink -v -ssh [USERNAME]@[IPADDRESS] -pw [PASSWORD] osascript -e 'display notification ""NOTIFICATION"" with title ""TITLE"" sound name ""SOUNDNAME""'"
PowerShell,3adcn5,divbo,1 point,Fri Jun 19 06:20:28 2015 UTC,"Reading up on Plink and you're right it all should be on a single line.  Your approach to the Batch script is right.  What happens when you run the single line in your batch script manually?  I'm guessing it's the same problem (as it should be really).  Just thinking ""out loud"" it may be that Plink is expecting commands to be space delimited.  Let me have a play and come back to you."
PowerShell,3adcn5,Theratchetnclank,2,Fri Jun 19 07:13:26 2015 UTC,"What happens if you escape the single quotes being passed to osascript?  Plink -v -ssh [USERNAME]@[IPADDRESS] -pw [PASSWORD] osascript -e \'display notification ""NOTIFICATION"" with title ""TITLE"" sound name ""SOUNDNAME""\'"
PowerShell,3adcn5,Acaila,1 point,Fri Jun 19 05:51:27 2015 UTC,This was one of the permutations that I've tried. I get this error when I take those single quotes.
PowerShell,3adcn5,Freon424,2,Fri Jun 19 06:08:23 2015 UTC,"Try this: .\Plink.exe --% -v -ssh [USERNAME]@[IPADDRESS] -pw [PASSWORD] osascript -e 'display notification ""NOTIFICATION"" with title ""TITLE"" sound name ""SOUNDNAME""'  Powershell won't try and parse anything after the --% so you can throw anything at it. This is with PS v4"
PowerShell,3adcn5,cizzit,2,Fri Jun 19 06:51:50 2015 UTC,Does it have to use plink?  I use the SSH-Sessions Module with powershell and it works great http://www.powershelladmin.com/wiki/SSH_from_PowerShell_using_the_SSH.NET_library.  I use it to quickly check the free disk space on our Linux boxes every morning. It allows me to send long and complex commands to a session or drop into the session interactively too.
PowerShell,3adcn5,sid351,2,Fri Jun 19 07:56:26 2015 UTC,Build an args array to give to plink (split on whitespace) and be sure to escape the single quotes (')
PowerShell,3adcn5,marzme,1 point,Fri Jun 19 06:02:11 2015 UTC,Upvote for this. I don't trust passing arguments to external programs any other way.
PowerShell,3adcn5,JewStyleKungfu,1 point,Fri Jun 19 10:37:14 2015 UTC,"Have you tried running other commands than your 'osascript' command?  Also, looking up the error you're receiving, it seems related to the osascript command you want. What happens if you enclose the command in double quotes like so:  Plink -v -ssh [USERNAME]@[IPADDRESS] -pw [PASSWORD] ""osascript -e 'display notification \""NOTIFICATION\"" with title \""TITLE\"" sound name \""SOUNDNAME\""'""   ?"
PowerShell,3adcn5,tehjimmeh,1 point,Fri Jun 19 06:42:19 2015 UTC,"Came back to say pretty much this.  I think it's because Plink expects different commands to be space delimited.  If I'm right Plink is interpreting your original command of  Plink -v -ssh [USERNAME]@[IPADDRESS] -pw [PASSWORD] osascript -e 'display notification ""NOTIFICATION"" with title ""TITLE"" sound name ""SOUNDNAME""'   As:  Run osascript  Run -e  Run 'display notification ""NOTIFICATION"" with title ""TITLE"" sound name ""SOUNDNAME""'   So give the idea from the comment above a go and let us know how you get on."
PowerShell,3adtis,FreshlyBakedMan,1 point,Fri Jun 19 08:36:03 2015 UTC,"Install ""MS Word/Excel Viewer"" en use any of the free available pdf printers."
PowerShell,3adtis,prutseratwork,1 point,Fri Jun 19 10:15:57 2015 UTC,"I may have found a solution: http://www.verydoc.com/doc-to-any.html  This software has the ability to convert office docs to PDF.  Thanks for all the input, it gave me some more ideas to keep searching.  It does cost 79$.  This way I don't need to install office on a server."
PowerShell,3adtis,bundyfx,1 point,Fri Jun 19 13:08:28 2015 UTC,"Hi mate, take a look at itextsharp. hopefully helps you with your task.  https://github.com/itext/itextsharp"
PowerShell,3adtis,supermamon,3,Fri Jun 19 08:45:58 2015 UTC,take caution. it’s sourceforge.net.
PowerShell,3adtis,bundyfx,2,Fri Jun 19 09:41:50 2015 UTC,changed my link to github.. my b!
PowerShell,3aajox,-neNull,3,Thu Jun 18 15:12:31 2015 UTC,"-like doesn't require a wildcard.  ""Something"" -like ""Something""  True"
PowerShell,3aajox,spikeyfreak,2,Thu Jun 18 17:07:14 2015 UTC,would that be better suited with an -eq check?
PowerShell,3aajox,spikeyfreak,2,Thu Jun 18 17:27:34 2015 UTC,"Not necessarily.  Think of a situation where you're asking for input to find something.  Just as an example:  [PS] C:\> $some = ""Somethin*"" [PS] C:\> ""Something"" -like $some True [PS] C:\> $some = ""Somethink"" [PS] C:\> ""Something"" -like $some False"
PowerShell,3aajox,PsTakuu,2,Thu Jun 18 17:43:26 2015 UTC,"Aye you need you update your blog post.  It absolutely is not a requirement.  It does support wildcards though.   edit: also if you are going to discuss -contains, you should discuss -in, those two are more like comparing apples to apples instead of -like and -contains, which is more like apples and oranges."
PowerShell,3aajox,PsTakuu,1 point,Thu Jun 18 20:08:06 2015 UTC,I thought that article was about when you use apples vs oranges...  when would you use -in?
PowerShell,3aajox,PsTakuu,2,Thu Jun 18 20:18:12 2015 UTC,"When you want to find whether or not a test is in a list of values:   ""def"" -in ""abc"", ""def""  True   ""Shell"" -in ""Windows"", ""PowerShell""  False   # Does the list of computers in $domainServers  # include $thisComputer?  # -------------------------------------------  PS C:\> $thisComputer -in  $domainServers  True   Whereas -contains is the other side, when you want to find out if a list of values contains a test:   ""abc"", ""def"" -Contains ""def""  True    # Does the list of computers in $domainServers   # include $thisComputer?   # -------------------------------------------   PS C:\> $domainServers -Contains $thisComputer   True"
PowerShell,3aajox,chade1979,2,Thu Jun 18 21:15:15 2015 UTC,Yea idk anymore man! You do a good job of clarifying the differences between the two. I must have interpreted it wrong.  Keep blogging tho! I need to get back on the horse.
PowerShell,3aajox,chade1979,2,Thu Jun 18 21:23:27 2015 UTC,The only time I use -eq is when I want to compare an integer. Or maybe if you wanted to compare something that could have a wildcard character in it and you didn't want to treat it as a wildcard.
PowerShell,3aajox,PsTakuu,2,Thu Jun 18 20:16:33 2015 UTC,it's a dynamically typed language.... why would you declare something to be an int?   edit: or for that matter typecast a variable.
PowerShell,3aajox,chimney3,2,Thu Jun 18 20:22:15 2015 UTC,"Who said anything about declaring or strong casting ?  I mean, these two statements return the same result:  4/2 -eq 2 4/2 -like 2   But to me, the second just makes more sense. Also, anyone who has written more than a few scripts/functions knows that casting things is extremely important and useful. Letting PowerShell dynamically choose your type can cause things to not work."
PowerShell,3abtfe,pandiculator,3,Thu Jun 18 20:47:01 2015 UTC,You could create a custom object for each pair:  $user = Import-Csv .\team.csv  $count = $user.count  $reviewer = $user | Get-Random -count $count $reviewee = $user | Get-Random -count $count  for ($i = 0; $i -lt $count; $i++) {      $pair = [PSCustomObject]@{          Reviewer = $Reviewer[$i] | Select-object -ExpandProperty Name;         Reviewee = $Reviewee[$i] | Select-Object -ExpandProperty Name      } #end create pair object      Write-Output $pair  } #end for loop
PowerShell,3abtfe,RickSaysMeh,1 point,Thu Jun 18 21:12:47 2015 UTC,"In my 2+ hour googling to try to figure this out, I actually got pretty close to this but couldn't make it work.  Thanks!"
PowerShell,3abtfe,RickSaysMeh,2,Thu Jun 18 23:00:26 2015 UTC,"This one will makes sure no one is ever matched up with themselves or more than one other person. I used Get-Content which just takes in a text file with one user name per line.  $Reviewers = Get-Content ""C:\userlist.txt"" [System.Collections.ArrayList]$Users = $Reviewers  $Pairs = @()  ForEach($Reviewer in $Reviewers) {     $Users.Remove($Reviewer)      $Pair = """" | Select Reviewer,Reviewee     $Reviewee = $Users | Get-Random      $Pair.Reviewer = $Reviewer     $Pair.Reviewee = $Reviewee      $Users.Remove($Reviewee)     $Users.Add($Reviewer)      $Pairs += $Pair }  $Pairs"
PowerShell,3abtfe,RickSaysMeh,1 point,Thu Jun 18 21:35:55 2015 UTC,"This looks like what I will use, thank you very much.  Simpler than how I was trying to go about it."
PowerShell,3abtfe,RickSaysMeh,1 point,Thu Jun 18 23:01:02 2015 UTC,"When outputting the $Pairs variable, it's spitting out numbers before the actual hash table.  Can you help me understand what it's doing?  I'm running this on PS4.0."
PowerShell,3abtfe,chreestopher2,1 point,Thu Jun 18 23:13:24 2015 UTC,What does the output look like? My test worked with a small text file for input with one username per line.
PowerShell,3abtfe,sid351,1 point,Fri Jun 19 00:15:32 2015 UTC,Here is a screenshot:  http://i.imgur.com/md868uw.jpg
PowerShell,3ace35,GoonerGuru,1 point,Thu Jun 18 23:30:06 2015 UTC,"If you run on a Server 2012R2 server, you will have access to the new AD cmdlets.  I haven't tried to do what you are trying, but I expect if you refer to this reference, you'll find that you can get the existing users with one command and then add them to the target domain with a different command - you could probably use the pipeline to do it in a single line, but I am not good enough with Powershell to show you how.  The key, I think, is going to be to export the users with all of the properties you need (using Get-ADUser with the -Properties option to get all of the properties you need, then use the New-ADUser command to create them in the target domain.  You will need to do the same, of course, for groups and group memberships, OUs, group policy, and so on.  You should be able to do all of it with Powershell, just work on one piece at a time until you have it all working.  I think you're getting the error because you're trying to essentially do a restore, and the GUIDs do not match the domain GUID of the target domain."
PowerShell,3ace35,ilovetpb,1 point,Thu Jun 18 23:44:03 2015 UTC,"Thanks very much for your reply. Unfortunately, all servers in this particular domain are 2008 R2 and I am unable to upgrade .net, wmf, powershell, etc. and therefore am limited to PS v2.   I appreciate your post though because you mentioning doing one piece at a time made me think about doing an ldifde export one object class at a time (ou, user, etc.), instead of doing one bulk update like I have been doing. That will help me narrow down exactly what is wrong.  Thanks again for your post."
PowerShell,3ace35,ilovetpb,1 point,Fri Jun 19 00:22:13 2015 UTC,"You just need a Windows 8 or Windows 2012 box to run it on.  So if you have either, you have what you need. I'm happy to help, pm me if you need anything."
PowerShell,3ace35,JewStyleKungfu,1 point,Fri Jun 19 02:54:42 2015 UTC,"Get-ADUser and New-ADUser are part of the ActiveDirectory module which should be installed by default on any 2008 R2 DC.  I could be wrong, but I'm pretty sure I ran v2 with the AD module on my workstation for a year or so before I started upgrading Powershell."
PowerShell,3aaa79,the_spad,1 point,Thu Jun 18 13:54:31 2015 UTC,$results.count or $results.length dont work?
PowerShell,3aaa79,zenmaster24,1 point,Thu Jun 18 14:11:15 2015 UTC,"If I get zero results, count and length return 0  If I get 2 or more results, count and length return 2 or more  If I get 1 result, count and length don't return anything.  Can't even do a .count -eq $null check because the properly just doesn't exist when a single result is returned so the check doesn't return true or false."
PowerShell,3aaa79,cjsommer,2,Thu Jun 18 14:13:18 2015 UTC,"Try strongly typing the variable you are using for your results as an array. This is why I strongly type my arrays, so I'll always have the count property.  [array]$Results = Get-ADUser 'Joe*'"
PowerShell,3aaa79,JaapBrasser,1 point,Thu Jun 18 14:22:52 2015 UTC,"Thank you, I knew I was missing something obvious."
PowerShell,3aaa79,cjsommer,2,Thu Jun 18 14:27:30 2015 UTC,"What is your intention exactly, you could use the ForEach-Object cmdlet as well, the begin block is always triggered, the process block is only trigged if there is something is passed down the pipeline and the end block can determine if there was more than 1 object."
PowerShell,3aaa79,cjsommer,1 point,Thu Jun 18 14:30:33 2015 UTC,The point was not to handle different numbers of returned objects differently but to only process unique results.
PowerShell,3aaa79,-neNull,1 point,Thu Jun 18 20:24:20 2015 UTC,"You're welcome.   If you want to see why, run it the old way you were doing it and pipe the results to Get-Member. Betting you will see the type as 'TypeName: System.String' for a single result, and you won't find a count property."
PowerShell,3aaa79,KevMar,1 point,Thu Jun 18 14:28:20 2015 UTC,"Like I said in my first post, the returned type is always Microsoft.ActiveDirectory.Management.ADUser regardless of the number of results, which is what threw me.  If I'd been getting back the typical types it probably would have clicked that I should just type the variable to make sure it's always an array."
PowerShell,3abins,vomitfreesince83,2,Thu Jun 18 19:28:33 2015 UTC,Sorry to not answer the question but I thought I'd mention that there is a module for Terminal Services available on CodePlex: Terminal Services Module  You might find it easier to use this rather than mess with qwinsta.
PowerShell,3abins,pandiculator,1 point,Thu Jun 18 21:23:01 2015 UTC,Wow - this will probably be much easier.  Gonna poke around with it more tomorrow.  Thanks!
PowerShell,3abins,Vortex100,1 point,Thu Jun 18 21:52:09 2015 UTC,"qwinsta has set lengths for each column so....  $ComputerName = read-host ""enter cn""   if($ComputerName -eq $null) {     $c = qwinsta 2>&1 | where {$_.gettype().equals([string]) } } else {     $c = psexec ""\\$ComputerName"" -s qwinsta 2>&1 | where {$_.gettype().equals([string]) } } $starters = New-Object psobject -Property @{""SessionName"" = 0; ""Username"" = 0; ""ID"" = 0; ""State"" = 0; ""Type"" = 0; ""Device"" = 0;};  foreach($line in $c) {      try {          if($line.trim().substring(0, $line.trim().indexof("" "")) -eq ""SESSIONNAME"") {             $starters.Username = $line.indexof(""USERNAME"");             $starters.ID = $line.indexof(""ID"");             $starters.State = $line.indexof(""STATE"");             $starters.Type = $line.indexof(""TYPE"");             $starters.Device = $line.indexof(""DEVICE"");             continue;         }          New-Object psobject -Property @{             ""SessionNAme"" = $line.trim().substring(0, $line.trim().indexof("" "")).trim("">"")             ;""Username"" = $line.Substring($starters.Username, $line.IndexOf("" "", $starters.Username) - $starters.Username)             ;""ID"" = $line.Substring($line.IndexOf("" "", $starters.Username), $starters.ID - $line.IndexOf("" "", $starters.Username) + 2).trim()             ;""State"" = $line.Substring($starters.State, $line.IndexOf("" "", $starters.State)-$starters.State).trim()             ;""Type"" = $line.Substring($starters.Type, $starters.Device - $starters.Type).trim()             ;""Device"" = $line.Substring($starters.Device).trim()         }     } catch {         throw $_;         #$e = $_;         #Write-Error -Exception $e.Exception -Message $e.PSMessageDetails;     } }   Source"
PowerShell,3abins,JewStyleKungfu,1 point,Thu Jun 18 20:40:53 2015 UTC,"Oh man, I like this one but I don't have time for it today.  I can probably help out tomorrow if you still need it."
PowerShell,3aal3t,KarmaElite,1 point,Thu Jun 18 15:23:35 2015 UTC,"If you can copy the batch file to the machines or store it on a network share that all of the machines can access, you should just be able to do something like:  Invoke-Command -ComputerName $computer -ScriptBlock { cmd /c c:\path\to\batch.cmd }"
PowerShell,3aal3t,ryanbrown,1 point,Thu Jun 18 15:34:42 2015 UTC,Have a discussion with your team about getting those patches put into your base .wim file that machines are built with in SCCM. keep this updated every few months and its easy sailing.
PowerShell,3aal3t,bundyfx,1 point,Thu Jun 18 21:38:26 2015 UTC,"Don't take this the wrong way. (I have been in your shoes, just playing devil's advocate).   Why are you even doing this? As a company resource, you are doing work that another team is doing. Someone decided that it is acceptable to be vulnerable for weeks at a time. You are doing work that is not benefiting the company. Why isn't your manager pushing the SCCM team to solve this issue?   Sorry, those questions had to be asked. But this isn't a bad approach and a good learning project. I would still make the request for a group policy to point your systems at WSUS. That will start that conversation. If nothing else, you can offer to be the early release patch group. You get them sooner and they have a good test group.  Invoke-command or remote registry would both work."
PowerShell,3aal3t,KevMar,1 point,Fri Jun 19 01:53:36 2015 UTC,"I have my orders, so I don't really have a choice."
PowerShell,3aal3t,wickedang3l,0,Sat Jun 20 18:37:49 2015 UTC,My advice would be to talk to the SCCM team because I'd do my best to get you fired if I found out you were circumventing processes and procedures to manage functionality you're not responsible for managing (While simultaneously creating problems for the team that actually is responsible).
PowerShell,3a75dd,diggydoge,7,Wed Jun 17 19:25:24 2015 UTC,"This is how you would start the process with the priority set to ""High"" and running on cpu 0, 1, and 2. When using Start-Process, you can exclude the -ArgumentList part if you don't need to pass any arguments to your exe. Just added it as an example  # Start the exe $app = Start-Process -FilePath ""C:\App.exe"" -ArgumentList ""-Log 'C:\Logs\App.log'"" -PassThru  # Set the priority and affinity $app.ProcessorAffinity = 7 $app.PriorityClass = ""High"""
PowerShell,3a75dd,ab0mbs,2,Wed Jun 17 20:31:14 2015 UTC,$proc = $app | Get-Process   What's the point of this?  $app is the process object.  $app and $proc will be identical.
PowerShell,3a75dd,tehjimmeh,1 point,Thu Jun 18 07:32:04 2015 UTC,I guess I missed that somehow. I used some old code that I haven't looked at in a while and just went off that. I've fixed the script's to not use $proc
PowerShell,3a75dd,ab0mbs,1 point,Thu Jun 18 16:13:14 2015 UTC,"You are truly the best, Sir! Thank you.  Do you have any solution in that certain case when I try this method on a ""launcher"" that opens an another exe? Is there any way to fork this object property to a child? Is the only option to workaround with a delayed Get-Process? I am sorry for my foolishness, I just started learning POSH"
PowerShell,3a75dd,ab0mbs,1 point,Wed Jun 17 22:37:25 2015 UTC,"Wasn't sure if this was possible but did some googling and found a function that someone wrote to locate child processes.  The function is from this website http://powershell.com/cs/media/p/16455.aspx  Here's the updated code with that function that should do what you're looking for  function Find-ChildProcess {    param($ID=$PID)       $CustomColumnID = @{          Name = 'Id'          Expression = { [Int[]]$_.ProcessID }      }       $result = Get-WmiObject -Class Win32_Process -Filter ""ParentProcessID=$ID"" |        Select-Object -Property ProcessName, $CustomColumnID, CommandLine       $result      $result |           Where-Object { $_.ID -ne $null } |           ForEach-Object {          Find-ChildProcess -id $_.Id      }  }  # Start the exe $app = Start-Process -FilePath ""C:\App.exe"" -ArgumentList ""-Log 'C:\Logs\App.log'"" -PassThru  # Set the priority and affinity $app.ProcessorAffinity = 7 $app.PriorityClass = ""High""  # Get child processes $children = Find-ChildProcess -ID $app.Id  # Get Children process objects $childrenProc = Get-Process -Id $children.Id  # Set priority and afinity for children $childrenProc | ForEach-Object {     $_.ProcessorAffinity = 7     $_.PriorityClass = ""High"" }   You may need to add a couple other things to make this work as expected. First, if the launcher launches the other applications then closes itself, add the following after starting the launcher. This will wait for it to finish running before it looks for the children  $app | Wait-Process   If the launcher needs to stay running but doesn't launch the children instantly, you may need to tell powershell to ""sleep"" for a little bit. If this is needed, add this after setting the priority and affinity on the parent process.  Start-Sleep -Seconds 60"
PowerShell,3a7bgh,tyhuffman99,3,Wed Jun 17 20:08:55 2015 UTC,"I did a similar thing recently, but found it easier to just use icacls and define the icacls options strings..  So I went $OICI = ""(OI)(CI)"" $rxw = ""(RX,M)""  ...then  $shr = ""\server\root_of_share"" $usr = gci -Directory ""path to a bunch of folder names with .stuff trimmed""  foreach ($i in $usr) {         & icacls ""$shr\$i.stuff"" /grant ""$i"":${OICI}${rxw} /inheritance:r }          ...don't know if that helps.  TL;DR icacls was easier than Get-ACL | Set-ACL for this type of thing, at least in my case. edit: sorry I don't know how to format the thing with the right breaks and stuff..."
PowerShell,3a7bgh,funky_fart_smeller,2,Wed Jun 17 23:28:14 2015 UTC,I will have to give this a try tomorrow and i'll let you know.
PowerShell,3a7bgh,BrewN1nja,2,Wed Jun 17 23:53:23 2015 UTC,"This is the answer.  I spent a lot of time trying to do it strictly with powershell only to find it really isnt possible (yet at least).  You need to use icacls.    For the folders, I would just strip the end: $folder.Substring(0,$folder.Length-6)"
PowerShell,3a7bgh,funky_fart_smeller,2,Thu Jun 18 03:07:53 2015 UTC,"Yes. Powershell has a hard time [for now] breaking the NTFS permissions inheritance, which appears to be our problem.   They should just make icacls into a cmdlet with all kinds of awesome parameters in PS 6.   FWIW, I use cmd all the time in scripts because you'll find there are some things PS just doesn't do without 20 lines of craziness - but then you'll find that there's a 15 year old simple command for that thing that lives in every single %windir%."
PowerShell,3a7bgh,the_spad,2,Thu Jun 18 05:39:22 2015 UTC,"$acl.SetAccessRuleProtection($true,$true)   First argument enables ($false) or disables ($true) inheritence, the second argument removes ($false) or keeps ($true) existing inherited permissions. The second argument is obviously ignored if the first is set to $false."
PowerShell,3a7bgh,Cutoffjeanshortz37,2,Thu Jun 18 07:56:53 2015 UTC,"I wouldn't rename the directories FYI, you probably have a .v2 after their name and that's windows roaming profiles which was as change when moving away from XP. If you rename them windows will recreate a profile folder for them.  Just an FYI.  Best of luck with the script though"
PowerShell,3a7bgh,jbtechwood,2,Wed Jun 17 22:22:17 2015 UTC,"I wasn't actually going to be renaming the folders.  I figured the easiest way to get the username that the folder belongs to is by piping the name of it.  The way I have it now is with:  $FullFolder = gci * -Directory  $Folders = $FullFolders -rename "".stuff"",""""   That way I can use the $Folders variable to get just the username without the .stuff behind it."
PowerShell,3a7bgh,Kio_,2,Wed Jun 17 22:36:02 2015 UTC,For ntfs you should look at PowerShellAccessControl module from Rohn Edwards.  Help us still a bit thin but he's got enough on the website to make the module functional.  And it has DSC support.
PowerShell,3a7bgh,halbaradkenafin,1 point,Thu Jun 18 10:11:46 2015 UTC,"Doing this from my phone so excuse any mistakes, I didn't test the script but this should do what you are asking for.  $folders = Get-childitem -directory  $currentLocation = (Get-Location).fullname Foreach($subfolder in $folders)  {      $newFolderName = ""$(($subfolder).name.replace('.stuff',''))""      if(-not(Test-Path $newFolderName))     {          Rename-item $subfolder -newName $newFolderName          try          {              Get-Aduser $newFolderName -ErrorAction Stop | out-null              If($?)              {                  Set-location ""$($currentLocation)\$($newFolderName)""                  Takeown /R /F . /U ""$($newFolderName)""                  Set-location $currentLocation              }          }          catch          {              write-host ""Username not found in AD""          }      }      else      {          write-host ""The folder already exists. Failed to change name.""          Break      }  }   Edit: Oh god, the formatting that I put on my phone did not go through on the post. Fixed it."
PowerShell,3a7bgh,majkinetor,1 point,Thu Jun 18 06:17:13 2015 UTC,"NTFS Security Module is pretty awesome for dealing with this stuff, I've used it for similar things in the past and it's much easier than dealing with icacls or even the built in ACL and ACE cmdlets."
PowerShell,3a7r3a,sysadm1n,2,Wed Jun 17 22:00:34 2015 UTC,Slightly shorter version  diff ((get-aduser alice -prop memberof).memberof) ((get-aduser bob -prop memberof).memberof)
PowerShell,3a7r3a,BadSysadmin,1 point,Thu Jun 18 12:11:09 2015 UTC,Thanks for that. Did not know about compare-object (diff). That is awesome! Learned something super helpful today!!
PowerShell,3a7r3a,Shagni,1 point,Thu Jun 18 13:38:14 2015 UTC,compare-object    Compare-object is great when dealing a small number of items BUT watch out for the sync windows issue.   Read up on the following.  https://dmitrysotnikov.wordpress.com/2008/06/06/compare-object-gotcha/
PowerShell,3a7r3a,SaladProblems,1 point,Thu Jun 18 15:42:29 2015 UTC,"Good to know! Maybe M$ will fix it at some point? Doesn't seem to difficult.  Looks like they did fix it. At least in version 4. I went up to 125 and worked like a boss. Didn't care about adding more to the arrays after that.  PS C:\Windows\System32\WindowsPowerShell\v1.0> $set1 = @(125, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 1) $set2 = @(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,     116, 117, 118, 119, 120, 121, 122, 123, 124, 125) Compare-Object $set1 $set2  PS C:\Windows\System32\WindowsPowerShell\v1.0>"
PowerShell,3a7be0,tgiles,2,Wed Jun 17 20:08:31 2015 UTC,"the thing is, you can have more than one volume per disk. here's a script that outputs it all anyway:  get-disk | %{ $firmware = $_.firmwareversion; Get-Partition $_.number | ?{$_.driveletter} | select driveletter,@{N=""firmware"";E={$firmware}} }   This loops through each disk, gets the firmware and then goes through and selects all the partitions with a drive letter as well.  A better approach would be to just use the drive ID with the firmware:   get-disk | select number,firmwareversion"
PowerShell,3a7be0,m0po,1 point,Wed Jun 17 23:24:38 2015 UTC,"Hey,  Thanks for the reply! That was perfect. your response helped me end up with the following script:  get-disk | ForEach-Object{     $myname = $_.friendlyname     $myfirm = (%{ $firmware = $_.firmwareversion; Get-Partition $_.number | ?{$_.driveletter} | select driveletter,@{N=""firmware"";E={$firmware}} }).firmware     $myletter = (%{ $firmware = $_.firmwareversion; Get-Partition $_.number | ?{$_.driveletter} | select driveletter,@{N=""firmware"";E={$firmware}} }).driveletter      ""$myletter -> $myname -> $myfirm"" }   It outputs something along like this:  I -> ASMT 2105 USB Device -> 0 C -> Intel Raid 1 Volume -> 1.0. G -> SanDisk Ultra Fit USB Device -> 1.00 H -> ASMT 2105 USB Device -> 0 D -> LSI MR9361-8i SCSI Disk Device -> 4.26   While the friendlyname bit wasn't in the original question, I think I'll capture it as well to make sure the guy who gets this report knows exactly what is being viewed.  Thanks again, appreciate the help!"
PowerShell,3a7be0,m0po,1 point,Thu Jun 18 14:22:54 2015 UTC,Glad to help.
PowerShell,3a7be0,tommymaynard,1 point,Thu Jun 18 21:57:27 2015 UTC,"I saw this thread and so I decided to update a function I wrote awhile ago. This function will return the drive letter and (as of now) the firmware revision. Here's an example usage:  PS C:\> Get-TMDriveToLetter -ShowMore | select DriveLetter,Firmware  DriveLetter                                                 Firmware -----------                                                 -------- C:                                                          DEM6 S:                                                          1.0 Y:                                                          1010 Z:                                                          1010   You can download it here: https://gallery.technet.microsoft.com/Map-Drive-to-Drive-Letter-1fff91ad. If it's helpful for you, please rank it! Thanks.  Edit: Just so it's noted, this solution uses WMI and will work on systems that don't have, or can't support, the Storage module and it's cmdlets: Get-Disk, Get-Partition, etc."
PowerShell,3a7be0,brkdncr,0,Fri Jun 19 17:39:50 2015 UTC,why is volume letter important?  You can have disks that don't have letters assigned.
PowerShell,3a6xj3,blastmaster44,3,Wed Jun 17 18:31:21 2015 UTC,"$object_array = ($object1, $object2);  # $object_array | <insert cmdlet name here>; # OR # $cmdlet_output = $object_array | <insert cmdlet name here>; # OR # $object_array | <insert cmdlet name here> -InputObject $_; #"
PowerShell,3a6xj3,cjluthy,2,Wed Jun 17 21:00:56 2015 UTC,"Get-ClientAccessServer | ?{$_.autodiscoversitescope -eq ""ADsite1""}   Should do it for you."
PowerShell,3a6xj3,the_spad,1 point,Wed Jun 17 18:34:59 2015 UTC,"Yea that's what I've been doing for Get-ClientAccessServer I'm just using it as an example.  Another would be setting Outlook Anywhere settings or reconfiguring virtual directories or moving database copies.  Those are all examples of cmdlets that finish quicker if you can scope them to run only on the servers in the same AD Site.  Really though I'd like to know how this is done.  I tried converting the string value of ""server1, server2"" to an array and used .split("", "") hoping each object in the array would be treated separately.  That did not work and now I'm just Googling and posting here with you fine folks.  I'm obviously new to this and would appreciate any guidance you can give me."
PowerShell,3a6xj3,dindenver,1 point,Wed Jun 17 19:17:46 2015 UTC,"So, the trick is, in EMS, it runs against your local CAS by default. This works well for you as the vast majority of information is retrieved locally. Certain cmdlets have to be run against a DC/GC and it uses the DC in in your AD site. Again, this is ideal. The only settings that do not seem to run in the local AD site are Virtual directory related settings (get-webvirtualdirectory, etc.) and mailbox specific cmdlets (get-mailboxfolderstatistics). In those cases, it runs against the server you specify, regardless of AD site. In these cases, there is no better server to access as there is only one choice.  When setting, instead of retrieving, it is not always best to use a local CAS. The efficiency of that depends largely on the speed of AD replication.  If you are getting random CAS when you do exchange cmdlets, you should make sure that the IP of the server/workstation you are running them from corresponds to a AD Site that has a CAS in it. you might need to tweak AD Sites and Services if that is not working right."
PowerShell,3a6xj3,cjluthy,1 point,Wed Jun 17 22:04:17 2015 UTC,cjluthy I swear I tried what you're saying and it failed.  I'll give it another go.
PowerShell,3a6d32,Jinkce,5,Wed Jun 17 16:07:05 2015 UTC,"on your psexec line do this:  cmd /c ""psexec \10.9.100.$a ipconfig /all""  This makes cmd run the string.  Since we are using a string we can pass our PowerShell variables."
PowerShell,3a6d32,TheZolen,3,Wed Jun 17 16:57:16 2015 UTC,"Import-Module ActiveDirectory $computers = Get-ADComputer   ForEach-Object ($computers){     if(Test-Path ""\\$($_)\admin$\win.ini""){         Invoke-Command -ScriptBlock {Get-NetIPConfiguration -All} -ComputerName $_     } } | Out-File mytext.txt"
PowerShell,3a6d32,spyingwind,2,Wed Jun 17 18:32:25 2015 UTC,"On a site note, if your not remoted into a server, you'll need the RSAT tools to use the AD module.  Which you probably should get, it is amazing."
PowerShell,3a6d32,Deathonus,1 point,Wed Jun 17 19:09:43 2015 UTC,Added that bit to my post above.
PowerShell,3a6d32,spyingwind,2,Wed Jun 17 20:22:20 2015 UTC,"Probably could add a catch or two in the event an error occurs.  Maybe use something like Test-Connection to make sure it is online before running the Invoke-Command script.    OP if Powershell is an option, then just go that route.  PSExec might be ok for older systems but it should probably be restricted in use as it can be leveraged by unauthorized users."
PowerShell,3a6d32,TheDewser,1 point,Thu Jun 18 00:24:15 2015 UTC,"Changed original comment.  Test-Path ""\\$($_)\admin$\win.ini""   I've found this to be a bit more reliable in telling me if the machine is a windows machine. I've had trouble with Test-Connection before."
PowerShell,3a6d32,spyingwind,2,Thu Jun 18 00:52:19 2015 UTC,"ok so I tried narrowing the get-adcomputer scope a bit because I'm trying to only look at servers specifically. getting an error reading ""Parameter set cannot be resolved using the specified named parameters""  Import-Module ActiveDirectory $computers = Get-ADComputer -Filter 'OperatingSystem -like ""Windows Server*""'  -Properties ipv4address | FT Name,DNSHostName,IPV4Address,OperatingSystem -Wrap -A  ForEach-Object ($computers){ if(Test-Path ""\\$($_)\admin$\win.ini""){     Invoke-Command -ScriptBlock {Get-NetIPConfiguration -All} -ComputerName $_ } } | Out-File c:\scripts\mytext.txt"
PowerShell,3a6d32,spyingwind,1 point,Thu Jun 18 19:48:56 2015 UTC,"Try something like this:  $computer = (Get-ADComputer -Filter {OperatingSystem -like ""Windows Server*""} -SearchBase ""ou=Servers,$Domain"" -Properties cn).cn  $computers = (Get-ADComputer -Filter {OperatingSystem -like ""Windows Server*""} -Properties cn).cn  $computers = Get-ADComputer -Filter {OperatingSystem -like ""Windows Server*""}   Any one of them should work. The first is if you want to specify the OU that the servers are in. You can do with out the ""-Properties cn).cn"". I use that to dump to test files or to just only output the name of the server. I like to reduce the amount of data going into variables."
PowerShell,3a6d32,kyleathompson,2,Thu Jun 18 20:37:55 2015 UTC,Any reason why you aren't using powershell remoting?  If you've got v2+ all you need is a gpo and you're golden.
PowerShell,3a6d32,justdiver,1 point,Wed Jun 17 18:58:00 2015 UTC,I've run into that issue quite a bit as well. Passing variables from PowerShell to PsExec seems to be a no-go. Not sure what to make of it.
PowerShell,3a6d32,nsto,1 point,Wed Jun 17 16:19:35 2015 UTC,"i suppose we can just run a \target1,target2,etc.... type script.. just frustrating haha"
PowerShell,3a6d32,bundyfx,1 point,Wed Jun 17 16:40:50 2015 UTC,"Awesome, I'm currently running it. Just takes a wicked long time to timeout on empty IP addresses but hopefully once it's finished it will pipe out properly.   Thanks all!"
PowerShell,3a6d32,chreestopher2,2,Wed Jun 17 18:08:29 2015 UTC,What method did you end up using?   And did it work the way you had hoped?
PowerShell,3a62hx,Headend,3,Wed Jun 17 14:49:16 2015 UTC,"How big is your environment? I'm not a fan of the ""random 3 digits"" idea unless you're looking at a very large number of users.  Who has set the naming convention? Is it not up for debate? Personally, I prefer doing it this way:  User 1: John Smith - JSmith User 2: John Smith - JoSmith User 3: Janet Smith - JaSmith User 4: Jane Smith - JanSmith   And so on. Its as easy as incrementing a number on the end, but instead you increment in the substring.  $i=1 $UserName = $firstname.substring(0,$i)+$lastname while (get-aduser $UserName){     $i++     $UserName = $firstname.substring(0,$i)+$lastname }"
PowerShell,3a62hx,neogohan,1 point,Wed Jun 17 18:38:23 2015 UTC,"35,000 users.  30,000 of those accounts are deleted, and recreated each summer/fall (public school system), and the current convention is firstname.lastname which is fine for staff, but creates problems when recreating the student accounts."
PowerShell,3a62hx,neogohan,2,Wed Jun 17 19:27:22 2015 UTC,"Ouch, yeah. 30k is a decent number.   Does HR provide any additional identifying information? Middle name, grade/year, or something else known to the end user?"
PowerShell,3a62hx,BabyBack_Dragon_Ribs,1 point,Wed Jun 17 19:46:05 2015 UTC,There's bound to be a key value in their database.  Hopefully they aren't dumb enough to make it their social security number.
PowerShell,3a62hx,neogohan,1 point,Wed Jun 17 20:40:49 2015 UTC,"Haha, true. I just think it's nice when it's something the end user knows so they understand why the numbers are on the end of the username and such. It also makes it easier for them to remember, so fewer support incidents from people who thought they were mary.sue4362 but are actually mary.sue4263."
PowerShell,3a62hx,ternarybit,1 point,Wed Jun 17 20:45:59 2015 UTC,"Use the SIS ID number and be done with it, are you insane? :)"
PowerShell,3a62hx,administraptor,1 point,Wed Jun 17 19:43:54 2015 UTC,Using the raw SIS ID as their AD username would create a security issue due to the way it is already being used elsewhere.  How about pulling part of the SIS ID?  firstname (3 chars) + lastname (3 chars) + partial SIS ID?
PowerShell,3a62hx,clevertwain,2,Wed Jun 17 20:24:41 2015 UTC,"We currently use first two of first name, first two of last name and last four of SIS ID. No duplicate problems whatsoever."
PowerShell,3a62hx,ternarybit,1 point,Thu Jun 18 03:57:54 2015 UTC,"What about using Get-Random, and use the SIS ID as the seed?"
PowerShell,3a62hx,-neNull,1 point,Wed Jun 17 20:44:34 2015 UTC,would create a security issue due to the way it is already being used elsewhere   ಠ_ಠ
PowerShell,3a62hx,JewStyleKungfu,1 point,Thu Jun 18 22:37:04 2015 UTC,you could throw in an if branch to add a number to the end of the last name... if there isn't any more letters in the name to work with... so that it would be johnsmith1..3..3000.  You know combine the two.
PowerShell,3a62hx,JewStyleKungfu,2,Wed Jun 17 20:12:35 2015 UTC,"I got really lazy when it came to the account creation line, because there's so much that depends on your environment.  This should do it, though.  Worked pretty well on my machine.    EDIT:  I forgot to mention, it does throw a bunch of red text at you when it doesn't find the AD account.  It looks scary, but it works fine.  There's definitely a better way to do it, I just went for the quickest thing I could get to work.  $HRExportFilePath = ""C:\tmp\HRExport""  #This variable is used to fill the username in case a name is less than 3 characters $nameFillerCharacter = ""-""  #Assuming one name per line, format ""FirstName LastName"" $users = get-content $HRExportFilePath foreach ($user in $users) {      $names = ($user.ToLower()).Split(' ')     [string]$firstNameTrunc = """"     [string]$lastNameTrunc = """"     for ($i = 0; $i -lt 3; $i++)     {         if (($names[0])[$i]) {$firstNameTrunc += $names[0][$i]}         else {$firstNameTrunc += $nameFillerCharacter}         if (($names[1])[$i]) {$lastNameTrunc += $names[1][$i]}         else {$lastNameTrunc += $nameFillerCharacter}     }      [string]$uniqueSuffix = get-random -Minimum 100 -Maximum 999     $NewUsername = $firstNameTrunc + $lastNameTrunc + $uniqueSuffix     while (get-aduser $NewUsername)     {         [string]$uniqueSuffix = get-random -Minimum 100 -Maximum 999         $NewUsername = $firstNameTrunc + $lastNameTrunc + $uniqueSuffix     }      ""Unique username found for $user : $NewUsername""     #new-aduser -Name $user -AccountPassword ""password"" -SamAccountName $NewUsername -GivenName $names[0] -    Surname $names[1] blah blah }"
PowerShell,3a62hx,t0xie,1 point,Wed Jun 17 20:38:00 2015 UTC,"Thank you, I'll give this a try as well."
PowerShell,3a62hx,JewStyleKungfu,2,Thu Jun 18 11:50:39 2015 UTC,"No, thank you, sir.  The 30 minutes I spent scripting this was the most fun I had all day yesterday.  It's so satisfying to be able to solve little problems like this and feel like you've accomplished something, regardless of whether or not the code helps you at all."
PowerShell,3a62hx,the_spad,1 point,Thu Jun 18 13:31:42 2015 UTC,I'm glad I could provide a little distraction -- I know we all have those days from time-to-time.
PowerShell,3a62hx,ryanbrown,1 point,Thu Jun 18 16:48:32 2015 UTC,"I don't have an AD to test against right now, but I would think just adding -erroraction silentlycontinue would work for getting rid of the scary red text.  Probably like this:    while (get-aduser $NewUsername -erroraction silentlycontinue)   Might be even better to use try-catch for this."
PowerShell,3a62hx,magneto58,1 point,Fri Jun 19 00:26:51 2015 UTC,"I actually tried that very thing, but it didn't work so I shrugged and moved on.  I figured there some hacked together subsystem manually writing out red text, but I did want to know why that didn't work..."
PowerShell,3a62hx,catfoodsci,1 point,Fri Jun 19 01:33:17 2015 UTC,"Well the first bit is easy.  $username = ""$($firstname.substring(0,3))$($surname.substring(0,3))$number""   What you need to work out is how you're going to do the number management. If they're all from scratch then it's pretty easy.  As for duplicates, samaccountname is a unique value and if you manage to abuse AD to create duplicates it will ""fix"" it for you (to $DUPLICATE-<hexchars>) when one of those accounts attempts to authenticate."
PowerShell,3a62hx,justdiver,1 point,Wed Jun 17 15:00:19 2015 UTC,"PowerShell has a Get-Random cmdlet that you can use to generate a random number if you need the numbers to be random (as opposed to sequential).  You could do something like this:  $number = (Get-Random -Maximum 999).ToString().PadLeft(3,""0"")   The above will always give you a 3 character number.  If the random number was 52, you'd get back ""052"".  Of course, you'd have to check to see if that username already existed, but you should be able to do that fairly easily with Get-ADUser."
PowerShell,3a62hx,ryanbrown,1 point,Wed Jun 17 15:24:09 2015 UTC,"if you have many Greg Smiths, you have to make each one unique somehow. I would cross reference their birthday (if you have that available) while creating them.  Chances are your duplicates would be very minimum if there are two Greg Smiths that were born on the same day/month/year. Having this, you can create unique userids.  Keep in mind that the birthday should be used to reference account creations and should never be stored in AD. If you must store it, then encrypt it."
PowerShell,3a62hx,justdiver,1 point,Wed Jun 17 15:27:36 2015 UTC,"Here's some bits i came up with which may help you get started:  $uid =  read-host ""enter a valid username: "" $user = Get-ADUser $uid $newusername = ((($user.GivenName).ToString()).substring(0,3)).ToLower() $newusername += ((($user.SurName).ToString()).substring(0,3)).ToLower() do{     $rand = (Get-Random -Minimum 000 -Maximum (999)).ToString(""000"")       $tempusername = ""$newusername$rand"" } while([bool]([adsisearcher]""samaccountname=$tempusername"").FindOne()) $newusername = $tempusername $newusername"
PowerShell,3a62hx,-neNull,1 point,Wed Jun 17 15:29:09 2015 UTC,"I'm following everything in this up until this line, can you explain?  while([bool]([adsisearcher]""samaccountname=$tempusername"").FindOne())"
PowerShell,3a62hx,justdiver,2,Wed Jun 17 19:17:15 2015 UTC,"The ""While"" keyword, causes the ""Do"" loop to repeat as long as the condition evaluates as true ($true).  The [adsisearcher] type accelerator is being used, which is essentially a shortcut to [System.DirectoryServices.DirectorySearcher] .NET class.  A DirectorySearcher object can be constructed with an LDAP search string (i.e. ""samaccountname=$tempusername"") and then the FindOne() method of the DirectorySearcher class is being called to see if an AD object (that matches the LDAP query) can be found.  The result of that method is being cast as [bool] ($true or $false).  Essentially, if an AD object is found the result will be $true.  If no AD object is found the result will be false.  All together, if an AD object with $tempusername is found, the result will be true and the while loop will continue to run.  If an AD object with $tempusername is not found, we have found a unique name, the result will be false, and the loop will stop running.  Hopefully that all makes sense, sorry for the wall of text.  $searcher = New-Object System.DirectoryServices.DirectorySearcher -ArgumentList ""samaccountname=$tempusername"" [bool]$seacher.FindOne()   would be the same as...  [bool]([adsisearcher]""samaccountname=$tempusername"").FindOne())"
PowerShell,3a62hx,justdiver,1 point,Wed Jun 17 19:58:01 2015 UTC,Very cool.  Similar to what I suggested but much more elegant.  I'm not familiar with those functions and I'm definitely thinking I'm going to incorporate them into my own.  Thanks!
PowerShell,3a62hx,justdiver,1 point,Wed Jun 17 20:09:13 2015 UTC,the ADSI LDAP searcher is to make it faster...  hard to read.   I agree.
PowerShell,3a62hx,justdiver,1 point,Wed Jun 17 20:14:55 2015 UTC,"I'm not sure if a more elegant solution has been posted, but something like this might work (first time messing with reddit formatting, so forgive me if this looks awful).  This is assuming you're importing a CSV or something like that...  I've not tested this, so ya know, mileage may vary.    $Name = $_.Firstname.Substring(0,3) + $_.Lastname.Substring(0,3) $Random = Get-Random -Maximum 999 $Account = $Name + $Random $CheckAD = Get-ADUser -Filter {sAMAccountName -eq $Account} do { if ($CheckAD -eq $Null) { write-host ""No conflict found.  Continuing."" } else { $Random = Get-Random -Maximum 999 $Account = $Name + $Random } while ($CheckAD -ne $Null) }"
PowerShell,3a62hx,-neNull,2,Wed Jun 17 19:38:41 2015 UTC,"I'm not sure how this would handle users with names shorter than 3 characters.  It might puke, might wanna check that.  Also, I'd put in a whole bunch of stuff like which OU to place the user in, default groups, homedir, etc.  But I think this should get you part of the way."
PowerShell,3a62hx,justdiver,1 point,Wed Jun 17 19:44:43 2015 UTC,"Oh! You didn't mention if you have more than one DC.  If you have more than one in different sites, you might wanna add something to bind your powershell session to one AD.  That way you don't start the script, create a new user on DC1, check if the user exists on DC2  and it not be there because of a sync delay or something like that.  It's unlikely, but just as a precaution."
PowerShell,3a62hx,Ropiak,1 point,Wed Jun 17 19:48:15 2015 UTC,"Three DCs.  The bulk creation will happen all at once when the student's info has been updated for the new school year, then individually as new students are added after the bulk creation.  We don't have a problem doing this now, but are just looking for a way to create a unique username that will follow them through graduation.  Currently duplicates can happen, and we are trying to find a way to avoid them."
PowerShell,3a62hx,justdiver,1 point,Wed Jun 17 20:30:12 2015 UTC,"Good point, will also have to take special characters in their names into consideration."
PowerShell,3a62hx,-neNull,1 point,Wed Jun 17 20:33:24 2015 UTC,Hyphens... they're all the rage now
PowerShell,3a62hx,brkdncr,1 point,Wed Jun 17 21:00:42 2015 UTC,"nice! The only thing I suggest is to change your branching, if ($CheckAD -eq $Null) can be if (!$CheckAD)"
PowerShell,3a62hx,DXPetti,1 point,Wed Jun 17 20:16:25 2015 UTC,I'm honestly not familiar with that formatting. Is that basically saying the same thing?
PowerShell,3a6jse,totheleftofwest,2,Wed Jun 17 16:55:07 2015 UTC,If you're going to be pulling fields from different cmdlets you're probably going to want to create a custom object to hold the data and then output that.
PowerShell,3a6jse,the_spad,1 point,Wed Jun 17 16:57:25 2015 UTC,agreed.... or adjust the data in the pipe if it's a one time use script
PowerShell,3a6jse,-neNull,2,Wed Jun 17 20:18:50 2015 UTC,here is a page that talks about lastlogontimestamp vs lastlogon...  https://networksafely.wordpress.com/2015/04/23/powershell-lastlogon-vs-lastlogontimestamp/
PowerShell,3a6jse,-neNull,1 point,Wed Jun 17 20:18:17 2015 UTC,"Is there a simple way to do this? I'm much more an Exchange admin than I am a PS scripter, please forgive my ignorance."
PowerShell,3a6jse,-neNull,1 point,Wed Jun 17 17:06:03 2015 UTC,you should look at the domain last logon on the exchange...  here is an article on the properties you should use https://networksafely.wordpress.com/2015/04/23/powershell-lastlogon-vs-lastlogontimestamp/
PowerShell,3a6jse,PsTakuu,1 point,Wed Jun 17 20:21:12 2015 UTC,"$output = 'C:\temp\mailboxinfo.csv'   function Get-MailboxLog {       param (         [Parameter(Position=0)]         [String[]]$Identity       )        #loops through each entry in Identity, so you can specify lists.         foreach ($user in $Identity) {           #error handling for mailboxes not found, follow the accepted values for the identity parameter of other exchange cmdlets (UPN/primarySMTP/DN/alias/etc.)           try {             #grab mailbox info, including all properties, you can filter them down later             $mbxInfo = get-mailbox $user -ErrorAction Stop             #set flag to true so the rest runs because a mailbox was found             $flag = $true           } catch {             #you could log this instead/as well as writing warning             Write-Warning ""$user not found""             #set flag to false so it doesn't bitch if you were access properties of variables that have $null values             $flag = $false           }           if ($flag) {               #grab mailbox stats info, all properties again, you can filter later               $mbxStats = $mbxInfo | get-mailboxstatistics               #use an ordered hashtable to setup properties so they are in the correct order when exporting to csv/displaying to console               #because you kept all properties above, you can expand this function to your needs               $props = [ordered] @{                      DisplayName = $mbxInfo.DisplayName                      WhenMailboxCreated = $mbxInfo.WhenMailboxCreated                      LastLogonTime = $mbxStats.LastLogonTime               }               #create a PS custom object that already has a bunch of methods and PS knows how to output it               $customObj = New-Object -TypeName PsObject -Property $props               #write the object as the return of the function               Write-Output $customObj           }       }   }   #Get-MailboxLog -Identity (get-Content C:\temp\mytemp.txt)   #Get-MailboxLog -Identity USERNAME   #Get-MailboxLog -Identity 'user1','user2'   #Get-Mailbox USERNAME | export-csv $output   #Get-Mailbox USERNAME | Export-csv C:\temp\mailboxlog.csv -NoTypeInformation"
PowerShell,3a6jse,PsTakuu,2,Wed Jun 17 17:26:05 2015 UTC,and the simple version:  $mbxInfo = get-mailbox USERNAME $mbxStats = $mbxInfo | get-mailboxstatistics $props = [ordered] @{         DisplayName = $mbxInfo.DisplayName         WhenMailboxCreated = $mbxInfo.WhenMailboxCreated         LastLogonTime = $mbxStats.LastLogonTime } $customObj = New-Object -TypeName PsObject -Property $props Write-Output $customObj
PowerShell,3a6jse,-neNull,1 point,Wed Jun 17 17:28:07 2015 UTC,wow...  that is so long it should be in VB
PowerShell,3a6jse,TheFirstRuKuS,1 point,Wed Jun 17 20:21:30 2015 UTC,"Hey man this doesn't need to be that complicated.   try this out.  you can make the objects anything you want  $Report=@() $mailbox=Get-mailbox –resultsize unlimited   $mailbox| foreach-object{ $DisplayName=$_.DisplayName $SmtpAddress=$_.PrimarySmtpAddress $WhenMailboxCreated=$_.WhenMailboxCreated $LastLogonTime=(get-mailboxstatistics -identity $DisplayName ).LastLogonTime $obj=new-object System.Object $obj|add-member -membertype NoteProperty -name ""DisplayName"" -value $DisplayName $obj|add-member -membertype NoteProperty -name ""PrimarySmtpAddress"" -value $SmtpAddress $obj|add-member -membertype NoteProperty -name ""WhenCreated"" -value $WhenMailboxCreated $obj|add-member -membertype NoteProperty -name ""LastLogonTime"" -value $LastLogonTime $Report+=$obj }    $Report|export-csv c:\Reports\report.csv -notype   Good luck!"
PowerShell,3a6jse,TheFirstRuKuS,2,Wed Jun 17 22:58:57 2015 UTC,"also here is exactly what you asked for nothing more.  $Report=@() $mailbox=Get-mailbox –resultsize unlimited   $mailbox| foreach-object{ $DisplayName=$_.DisplayName $WhenMailboxCreated=$_.WhenMailboxCreated $LastLogonTime=(get-mailboxstatistics -identity $DisplayName ).LastLogonTime $obj=new-object System.Object $obj|add-member -membertype NoteProperty -name ""DisplayName"" -value $DisplayName $obj|add-member -membertype NoteProperty -name ""WhenCreated"" -value $WhenMailboxCreated $obj|add-member -membertype NoteProperty -name ""LastLogonTime"" -value $LastLogonTime $Report+=$obj }    $Report|export-csv c:\Reports\report.csv -notype"
PowerShell,3a6jse,PsTakuu,1 point,Wed Jun 17 23:02:40 2015 UTC,"the $report = @() is not a good habit to have. build a function like I did and you now have reusable and expansible (what if tomorrow you needed the database property? ((before answer consider both options)) code.  It's the difference between typing $Report = @() and function New-Function {}.  Then instead of adding $obj to $report, you just Write-Output $obj and it can continue down the pipe."
PowerShell,3a6jse,PsTakuu,2,Thu Jun 18 13:43:34 2015 UTC,"Well, I just tried both PsTakuu's short method and TheFirstRuKuS's method, and they both worked! I have nothing to contribute to the argument, as I'm a technology manipulator, not a creator! 8o)  Thank you again for all your help."
PowerShell,3a6jse,TheFirstRuKuS,1 point,Thu Jun 18 16:26:20 2015 UTC,"Yea man really I used the blank array thing too for a long time, that's how I know it's a bad habit.  But if it's faster/easier for you to  see and use, then by all means use it!   There is more than one way to skin a cat with PowerShell!"
PowerShell,3a5lk0,eXeAmarantha,2,Wed Jun 17 12:16:02 2015 UTC,"Well for a start you're declaring ""sJ"" instead of ""$j""  You can do the Read-Host check a lot cleaner too  while(!$length){     $length = Read-Host ""Enter Array Length"" }  for($i = 0;$i -lt $length;$i++){         $value = $null         while(!$value){             $value = Read-Host ""Enter Array Value""         }         $array += $value }"
PowerShell,3a5lk0,the_spad,1 point,Wed Jun 17 12:30:42 2015 UTC,"Thanks, the sj instead of $j is actually me retyping the code on reddit rather than copy-paste. I really like your approach to the problem though I wish I could specify a message when users press Enter without inputting a value"
PowerShell,3a5lk0,the_spad,2,Wed Jun 17 12:46:01 2015 UTC,"Well you could do something like:  while(!$length){     $length = Read-Host ""Enter Array Length""     if(!$length){write-output ""You must enter a value""} }   If you want to be really clever you can do something like  while($length -notmatch ""^\d+$""){   So that they have to enter a number."
PowerShell,3a5lk0,chreestopher2,1 point,Wed Jun 17 13:02:02 2015 UTC,"if you want to be really clever, do something more alongs the lines of:  [cmdletbinding()] Param(     [parameter(mandatory=$true)]     [validatenotnullorempty()]     [string[]]     $number ) begin{} process{     foreach($num in $number){         $num     } }   Though it doesnt quite get all your requirements...  I think this does though:   $ErrorActionPreference = ""silentlycontinue"" $i = 0 $count = read-host ""How many Stuffs?"" $results = @() while($i -lt $count){     $result = [int]::Parse($(read-host ""Enter only numbers and press enter""))     if(![string]::IsNullOrEmpty($result)){         $results +=$result; $result = $null; $i +=1      }     else {$result = $null; continue} } write-output $results"
PowerShell,3a5lk0,neogohan,2,Wed Jun 17 20:20:27 2015 UTC,"$array += Read-Host ""You must enter a number: ""   This line is appending a blank value into the array if the user does not enter a number, and it's also not getting to the point where it increments $j. The end result is that the while statement is always looking at $array[0], however if you don't input a number when first asked, $array[0] will always be blank and any numbers you do eventually enter will be placed later in the array.  Fixed quickly:  $array=@()   $i = 1   $j = 0   do   {    $arrayNumber = Read-Host ""Enter a number: ""   if ($arrayNumber){$array += $arrayNumber}    while (!$array[$j])   {     Write-Host ""Value #"" $i     $arrayNumber = Read-Host ""You must enter a number: ""     if ($arrayNumber){$array += $arrayNumber} } Write-Host """"   $i++   $j++ }   until ($i -gt $length)"
PowerShell,3a54ry,FreshlyBakedMan,4,Wed Jun 17 08:33:02 2015 UTC,"Sure thing:  Get-ChildItem C:\Folder -File | Where-Object {$_.Name -like 'VKF*') | Move-Item -Destination C:\OtherFolder -WhatIf   So what we are doing here is use Get-ChildItem to gather a list of files from C:\Folder, Where-Object filters out all the files that start with VKF (not case-sensitive) and Move-Item will move them to another folder. -WhatIf prevents the script from actually moving anything and instead displays what it would do so you can safely test this code."
PowerShell,3a54ry,JaapBrasser,3,Wed Jun 17 08:38:41 2015 UTC,If you're sure none of the files have VKF anywhere in their name it's as simple as  gci <foldername> -filter {VKF*} | Move-Item -destination <destinationpath>   Otherwise you need to get more clever with the filtering.
PowerShell,3a54ry,the_spad,2,Wed Jun 17 08:39:14 2015 UTC,"That would work, but it would also attempt to move Directories matching this filter."
PowerShell,3a54ry,JaapBrasser,3,Wed Jun 17 08:40:45 2015 UTC,"Yes, sorry, that should have been  gci <foldername> -filter {VKF*} -file | Move-Item -destination <destinationpath>"
PowerShell,3a54ry,the_spad,2,Wed Jun 17 08:41:39 2015 UTC,"Yes, that will do the trick!"
PowerShell,3a54ry,JaapBrasser,1 point,Wed Jun 17 08:46:09 2015 UTC,Thank you all so much!  Works like a charm :)
PowerShell,3a54ry,JaapBrasser,2,Wed Jun 17 08:49:46 2015 UTC,"No problem, happy to help!"
PowerShell,3a54ry,the_spad,1 point,Wed Jun 17 08:50:58 2015 UTC,It's worth noting that typically if a cmdlet has a -filter option it is faster to use that than to pipe the output through Where-Object (because in the latter case it has to return every object before filtering it).
PowerShell,3a54ry,JaapBrasser,1 point,Wed Jun 17 09:06:33 2015 UTC,"That is absolutely true, the problem with the -Filter parameter of Get-ChildItem is that it is not a typical PowerShell filter. So for beginning users I would advise to use Where-Object to filter as it is easier to understand because it supports all the PowerShell comparison operators.  But in scenarios where performance is important I would recommend using the -Filter parameter of Get-ChildItem."
PowerShell,3a6uly,-neNull,3,Wed Jun 17 18:10:37 2015 UTC,"Oh this is easier said then done.  This is basically ITIL enhanced with devops. Probably impossible TBH in 99% of corporations, be it enterprise or startup.  I know... commenting on spam is ...."
PowerShell,3a6uly,majkinetor,2,Wed Jun 17 19:29:07 2015 UTC,"Thanks for reading.  Why do you think it's impossible?  The reason I ask is that I've done it with PowerShell at my company.  We're huge 60,000 + employees and I 'volunteer' at a startup to help them out with process automation."
PowerShell,3a6uly,PacketMuncher,3,Wed Jun 17 19:36:08 2015 UTC,"Not the OP buuut...  Not impossible because of limitations in the technology, more limitations in the culture. Automation is scary. People who don't understand how beneficial and consistent it can be write it off as a bad idea. Lots of ""but what if"" questions end up dominating the discussion and it goes nowhere. If the men and women in the nice suits like the idea that's one thing, but if not, good luck ever getting the go ahead to do the tiniest of business overhead reduction through automation. The benefit just isn't instantly tangible to some people and that can make all the difference in the world. Some corporate cultures don't offer the freedom necessary for middle level management to make these improvement autonomously. Not to mention who will foot the bill to do it if there are no experienced / free staff on board. Unless you can bring up hard number savings with proof it is unlikely to get paid for out of good faith.  That being said I really did like your article. Whenever I write any sort of automation scripts in my daily activities i follow a very similar guideline for my self. Who does it impact, how is it documented, what is its real value. If the script ends up not meeting the standards and would be a waste of time, it gets scrapped. I have been able to automate a good portion of the ""oh god this crap"" tasks that i have to do day to day and it has allowed me to really focus on improving, not just piloting, the environment I work in.  I really hope that your ideas become the common place more and more. Not just among management either but skilled individuals. IT or not it could benefit so many people in today's business world to learn a language like PowerShell. The beauty of ""crap work"" reduction has been noticeable since the industrial resolution. Dev-Ops and similar automation strategies are only the next logical step for business. And i will be sitting there with my little blue console helping it along :)"
PowerShell,3a6uly,majkinetor,2,Wed Jun 17 20:48:34 2015 UTC,"@PacketMuncher said it nicely but there are more problems.   It is not that easy to design process. To create all 20 something ITIL processes requires 3-5 years in large company with bunch of people involed. Large companies generally tend to have strict separation of departments. They don't like to mess with other departments and generally have more or less independent strategy from other departments. This lead to low understanding of overall IT flows in the company. There is also a lot of outsourcing and you generally need to conform to the standards of 3thd party. ITIL itself doesn't talk about any specific technology, only guidance, perhaps some excel table here and there. Most ITIL experts I met also think that automation is irrelevant, processes are important. And processes don't involve only computer stuff, but people and other resources which are not automatable etc. In devops like culture contrary to this there need to be mutual understanding - everybody needs to know pretty good about processes and tech in other department. Naturally, since that requires a lot of time and un-specialization, not many people like to do that. This is also very hard to explain to higher management.    I myself follow only one rule - if I can remove people from equation, I will do it. People make mistakes, people have their days or better things to do. Just remove people, let the machines do the job: you get many benefits - automatic documentation that is always up to date, far higher operation flow, repeatability, auditing etc..."
PowerShell,3a6uly,PacketMuncher,1 point,Thu Jun 18 06:43:30 2015 UTC,This is the conversation that I was hoping the blog would start...
PowerShell,3a6uly,the_spad,1 point,Thu Jun 18 13:21:09 2015 UTC,"This is really interesting. I had some initial push back but I was able to over come it, in some areas...  I'll do my next blog on overcoming upper managment objections...  Thank you for reading!"
PowerShell,3a6uly,what112s,2,Wed Jun 17 22:06:55 2015 UTC,"I look forward to it :). There is a lot of value to be had with automation, no question about it. I think the really big question right now is how to express that value properly to non-programming business types. Anyone who can do that effectively will be able to write their ticket for the next 20 years."
PowerShell,3a5al4,FreshlyBakedMan,2,Wed Jun 17 09:56:39 2015 UTC,"It's very similar to your first problem  gci <foldername> -filter {*DUPLICATE*.pdf} -file | <Do conversion> gci <foldername> -filter {*DUPLICATE*.tif} -file | Rename-Item -newname {$_.name -replace ""DUPLICATE""}   You might need to tweak the rename a bit to avoid things like double spaces depending on how the filenames are formatted."
PowerShell,3a5al4,the_spad,1 point,Wed Jun 17 10:15:33 2015 UTC,Do you have an idea where I need to place these in the script?  I tried replacing the   foreach($pdf in $pdfs)   But without success  I also added some more info in the main question.
PowerShell,3a3owd,907339,7,Tue Jun 16 23:56:15 2015 UTC,"You should be good to go. Even if you go with HTTP rather than HTTPS, if you're in an AD domain, traffic over HTTP will be encrypted via Kerberos.  There are a number of solid articles on the topic including this quick read from SANS. Microsoft enabling remoting by default should tell you enough : )  Other references:   Secrets of PowerShell Remoting A Layman’s Guide to PowerShell 2.0 Remoting   Definitely read up and understand the risks, but if you're using protocols like RPC, DCOM, Remote Registry, or even just using RDP, chances are PSRemoting is a safer bet. And if you add in constrained, delegated endpoints (e.g. through JEA) you're even better off.  Cheers!"
PowerShell,3a3owd,ramblingcookiemonste,1 point,Wed Jun 17 01:09:29 2015 UTC,"Wow, thanks.  I had been reading a lot of articles but they didn't break it down quite as well as these.  I really appreciate the help."
PowerShell,3a3owd,SSChicken,2,Wed Jun 17 03:27:27 2015 UTC,"Just because it might help, I addressed this previous thread about the same topic when I implemented it into my environment. There's some good info in there."
PowerShell,3a3owd,XaMLoK,1 point,Wed Jun 17 05:24:55 2015 UTC,It depends on the security requirements where you are. My friends in the security world think it is easily the biggest gaping security hole to ever be created by man. I'm am a huge fan of powershell remoting for managing remote systems. By default when it is enabled only administrators are granted permissions to access remotely. And if an attacker already has administrative rights you are having a bad day.   One easy(ish) way to limit what is available by remote powershell is by setting up constrained endpoint. With this you can assign a subset of cmdlets that a user or group is allowed to use. When they make a connection no other cmdlets will be available.
PowerShell,3a3owd,majkinetor,3,Wed Jun 17 01:10:55 2015 UTC,"My friends in the security world think it is easily the biggest gaping security hole to ever be created by man   References would be helpful. Otherwise, its just he-said-she-said."
PowerShell,3a3owd,LandOfTheLostPass,3,Wed Jun 17 07:49:17 2015 UTC,"Ya, I work with security enough that I feel competent to say, sources please?  It certainly has issues which need to be considered (I can build an execute a binary on the fly, which is fun); but, on the whole it's not that bad.  It is constrained by the security framework in .Net which can keep it pretty well in check (assuming that is configured correctly).  And really, it's just providing a convenient way to access the CLR Engine and .Net Framework.   These are built into the operating system and can be accessed in other ways.  Heck, the .Net framework comes with csc.exe compiling code is one command away.  There is even the CompilerParameters.GenerateInMemory flag if I want to be a bastard and keep my binary code from touching the disk. Really, any fears about PowerShell are not ultimately fears about PowerShell.  It's just a console to access the .Net Framework.  If you are concerned about what a user can do at the PowerShell console, you should really be worried about vulnerabilities in the .Net Framework which underlies much of the Windows ecosystem.  This is a valid worry, as there have been plenty of security holes in the .Net framework over the years.  And, if your users don't have a valid use case for PowerShell, sure block it them from running powershell.exe (might also want to catch csc.exe and MSBuild.exe for good measure).  But, on the whole PowerShell isn't that bad of an attack surface."
PowerShell,3a3owd,majkinetor,1 point,Wed Jun 17 15:27:16 2015 UTC,Excellent points. The only difference is that PS makes access to resources easier (quicker) since the shell DSL is optimized for quick system manipulation (unlike C#).You could argue that just this fact alone makes it more dangerous but that has nothing to do with security.
PowerShell,3a3owd,SEA-Sysadmin,1 point,Wed Jun 17 18:23:19 2015 UTC,Very interesting about the cmdlet limitation.  I was thinking the same thing as you regarding admin privileges and since I have to likely pitch this to a few people before I make these changes (if at all) this will be a pretty good point to make.  Thanks again.
PowerShell,3a3owd,stld52,1 point,Wed Jun 17 03:35:06 2015 UTC,"The only thing I would strongly caution against is the use of CREDSSP.   I ran a huge project to implement it at Microsoft,  and then a huge project to disable it after we became aware of how vulnerable it is to pass-the-hash attacks, and how easy it is to get creds stolen off of a server because of their persistence."
PowerShell,3a3owd,tommymaynard,1 point,Wed Jun 17 11:50:37 2015 UTC,"What alternatives do we have then? I didn't use it much, but it made scripts a lot simpler vs the alternatives I was aware of."
PowerShell,3a3owd,stld52,1 point,Wed Jun 17 12:43:33 2015 UTC,"Use constrained endpoints (or session configurations -- whatever you want to call them). These runs as an elevated user. Think about this: If I PS Remote to a member server that has the RSAT installed, I'm unable to then use the AD cmdlets. Weird, right? Not really. This is because the computer in which I connected to via PowerShell (the member server) doesn't have permission to delegate my credentials to a DC (or any other, second computer, for that matter).  If I create a constrained endpoint that runs under another account, then when I remote to that endpoint (Enter-PSSession -Computer member01 -ConfigurationName MyNewEndpoint), it will connect to the DC using not my account, but the other (run-the-endpoint-as-this) account. This eliminates the need for CredSSP."
PowerShell,3a3owd,tommymaynard,1 point,Wed Jun 17 16:09:54 2015 UTC,"Isn't this still an issue for pass the hash? Wouldn't it be just as secure to create a special account to use with credssp on those servers as it would be to use a constrained endpoint (assuming that you leave full access to the shell). In both cases, the account is an admin on that group of servers and vulnerable to pass the hash., right?"
PowerShell,3a3owd,stld52,1 point,Thu Jun 18 00:00:18 2015 UTC,"No. My local computer to member server PS Remoting session is going to use Kerberos in an AD domain, by default. Then, the member server is going to also use Kerberos using the session configuration's runAs account to connect to a DC. Kerberos doesn't pass credentials, and so we won't leave anything in memory.  If we use CredSSP, and allow the member server to pass my credentials to the DC, then we have my credentials sitting in memory, on at least, the DC. No thanks."
PowerShell,3a3owd,dindenver,1 point,Thu Jun 18 17:11:41 2015 UTC,"But that runAs account has to load credentials into memory to use Kerberos. We don't have to pass credentials for them to be hijacked. So if the attacker gets admin rights on that system, they then own that run as account and any system it has access to.  I may be moving out of scope of pass the hash and into token/session hijacking, but they are really two sided of the same coin.  Don't get me wrong, it's a good idea. I'm asking questions to dive deeper into it. It's still just one piece of a much larger pass the hash mitigation.  Mitigating pass the hash and token hijacking is such an up hill battle. It feels like you need to go all in or your leaving yourself wide open. I definitely have to dive into this more though."
PowerShell,3a2wwv,ThisAsYou,2,Tue Jun 16 20:24:34 2015 UTC,"Well, here is a function to 7zip something  # Function to zip the archived log, requires 7zip (has command line version) function Create-7zip([String] $sourceDir, [String] $zipFileName) {     [string]$pathToZipExe = ""C:\scripts\7zip\7za.exe"";     [Array]$arguments = ""a"", ""-tzip"", ""$zipFileName"", ""$sourceDir"", ""-r"";     & $pathToZipExe $arguments; }   at that point, though, you'd end up doing Get-ChildItem -Path $path -Directory -Recurse and figuring out how to crawl backwards through the tree. I don't have anything for that offhand.  I think PowerShell 4 or 5 has a -Depth flag for Get-ChildItem that should limit recursion depth, but I haven't used it.  I don't have much help on the rest of what you're doing, I'm not sure you can easily zip a blob of files currently."
PowerShell,3a2wwv,MortoftheHillPeople,1 point,Tue Jun 16 22:00:23 2015 UTC,Get-Childitem has a -depth parameter in PowerShell 5.0 that allows you to specify how deep you want to go with recurse. It also has Compress-Archive (create zip) which will accept input from the pipeline. maybe these two in combination could do the trick you're after.
PowerShell,3a2wwv,bundyfx,1 point,Tue Jun 16 22:36:03 2015 UTC,"Here is the complete script, run it from the folder that contains a folder. Change $depth -le 2 part to influence on which depth the magic happens.  ls -re | ? PSisContainer | % {     $depth = ($_.FullName -split '\\').Length - ($pwd -split '\\').Length      if ($depth -le 2 )  {         $dest = $_.FullName         7z a -t7z -r ""$dest\_files.7z"" ""$($_.FullName)\*.*""     } else {         $dest = Split-Path -Parent $_.FullName         7z a -t7z -r ""$dest\$_.7z"" ""$($_.FullName)\*""     } }   Keep in mind that extensionless files will not be packed in _files.7z with this script due to the ways 7z handles * and *.*.  But if you have those, you can run another ls before zipping to exclude folders via PSIsContainer filter and feed only the files to 7z."
PowerShell,3a2wwv,majkinetor,1 point,Wed Jun 17 06:54:08 2015 UTC,You're awesome! Thanks!
PowerShell,3a21ze,intermediatetransit,1 point,Tue Jun 16 16:53:51 2015 UTC,Just what I've been looking for. Interesting that the author prefers vi over ISE. IMO the auto completion in ISE is very powerful.
PowerShell,3a21ze,kavunr,2,Wed Jun 17 00:31:18 2015 UTC,"Depends what you're doing.  The ISE is good for one thing, and that's writing/debugging PowerShell scripts.  If you're command-line oriented, and use PowerShell as your shell, you'll want to stay in your terminal window as much as possible.  Plus, in terms of actually editing text, vi(m) is unbeatable in the opinion of many, myself included."
PowerShell,3a21ze,tehjimmeh,1 point,Wed Jun 17 00:44:02 2015 UTC,"You can get auto completition in vim too.  http://www.vim.org/scripts/script.php?script_id=4844  Nothing beats vim (except Neovim), really. I open ISE only to debug, but we now have other options for that."
PowerShell,3a1ms8,omrsafetyo,2,Tue Jun 16 15:03:11 2015 UTC,"Really weird, no idea what's going on, but you could cast it to make sure:  $($DayOfWeek -as [System.DayOfWeek])"
PowerShell,3a1ms8,PowerShellStunnah,2,Tue Jun 16 16:07:54 2015 UTC,"That is weird as /u/PowerShellStunnah said.  Somehow, in the InlineScript block, $MyDayOfWeek is getting cast as an int.  Write-Verbose $MyDayOfWeek.GetType()   The other extremely strange behavior is that it's also doing some weird interpolation.  Try doing this:  Write-Verbose $MyDayOfWeek Write-Verbose ""$MyDayOfWeek""   The top line prints out:       VERBOSE: [localhost]:Tuesday  The bottom line prints out:  VERBOSE: [localhost]:2"
PowerShell,3a1ms8,ryanbrown,2,Tue Jun 16 16:18:47 2015 UTC,"The underlying type of [System.DayOfWeek] is int, that's where the value comes from and why the cast works:  PS C:\> 0 -as [DayOfWeek] Sunday"
PowerShell,3a1ms8,PowerShellStunnah,1 point,Tue Jun 16 16:29:58 2015 UTC,That's probably what's happening then.  Powershell is trying to interpolate the value of $MyDayOfWeek and it's taking the underlying data value (the integer) and plugging it into the resulting string.  [System.DayOfWeek] has a BaseType of [System.Enum] so I guess that all makes sense even if it does have some weird behavior.
PowerShell,3a1ms8,ryanbrown,1 point,Tue Jun 16 16:38:58 2015 UTC,"Exactly. To be clear, the underlying type is inherited from [System.Enum] - by default, and Enum implementation without explicit values will have the values 0..N"
PowerShell,3a1ms8,PowerShellStunnah,1 point,Tue Jun 16 17:41:46 2015 UTC,"This makes sense, and is somewhat what I was expecting to find - I was wondering if the variable name itself was the problem - I was expecting that maybe there was some default system variable named $DayOfWeek, or etc. that might be getting confused, but I tried outputting that value on a new shell, and it was null.  I didn't even think about it being a type name.  Both:  [System.DayOfWeek]$DayOfWeek = $using:DayOfWeek and $DayOfWeek = $($using:DayOfWeek -as [System.DayOfWeek])  Work just fine.  I typically use the top method for type casting, and some of my debugging output threw me off when I tried the bottom method first, so I thought it was still doing something funny.  After the top method worked, I scrolled back up and saw the bottom method had also worked, I just hadn't seen it.  That is a really interesting bug.  Thanks for the help!"
PowerShell,3a1nys,whatshouldidowithmyl,1 point,Tue Jun 16 15:12:11 2015 UTC,{$array += $wordfiles.fullname}   That looks wrong.  I think you're looking for this:  {$array += $file.fullname}
PowerShell,3a1nys,JewStyleKungfu,1 point,Tue Jun 16 15:23:20 2015 UTC,"Yeah, that may be right, I am very new to poweshell. I tried this just now but the file still didnt show up in the output. I think it might be an issue with the document.content method?"
PowerShell,3a1nys,JewStyleKungfu,1 point,Tue Jun 16 15:39:08 2015 UTC,"$document.Content is actually a Property, rather than a Method.  I can explain if you're interested.  The way you're using it looks good.  Are you sure the regex is good?"
PowerShell,3a1nys,JewStyleKungfu,1 point,Tue Jun 16 17:07:08 2015 UTC,"Yeah the regex works. I have another section of the script that does essentially the same thing but with excel files, and that matches the regex fine. Yes I am interested if you have time, like I said I'm rather new to powershell."
PowerShell,3a1nys,JewStyleKungfu,1 point,Tue Jun 16 18:02:26 2015 UTC,"Are you using Powershell ISE?  If so, you should run the script and play around with the variables in the console to troubleshoot.  For example, you could type ""$wordfiles"" and it will show you that the $wordfiles variables actually does contain all of the files you think it does.  I just noticed your foreach loop is written wrong.  It should be Foreach($file in $wordfiles)  Was that a typo?"
PowerShell,3a1nys,durmiun,1 point,Tue Jun 16 18:23:03 2015 UTC,Yeah that was a typo in here. My work blocks reddit so I had to go mobile. Not the easiest way to type up code.
PowerShell,3a2lih,silentmage,1 point,Tue Jun 16 19:05:55 2015 UTC,"Yeah, it's probably an AD replication issue, if you've just created the user account before trying to assign the permissions.  How about using the SID instead of the domain\user format?"
PowerShell,3a2lih,SeanQuinlan,1 point,Tue Jun 16 23:31:49 2015 UTC,"No go on the SID either, same error message.  S-1-5-21-164404769-2411501212-4060915499-51573: No mapping between account names and security IDs was done.     + CategoryInfo          : NotSpecified: (S-1-5-21-16440...y IDs was done.:String) [], RemoteException     + FullyQualifiedErrorId : NativeCommandError     + PSComputerName        : localhost  Successfully processed 0 files; Failed processing 1 files No mapping between account names and security IDs was done.     + CategoryInfo          : NotSpecified: (No mapping betw...y IDs was done.:String) [], RemoteException     + FullyQualifiedErrorId : NativeCommandError     + PSComputerName        : localhost  Successfully processed 0 files; Failed processing 0 files"
PowerShell,3a2lih,SeanQuinlan,1 point,Wed Jun 17 13:31:30 2015 UTC,"Couple of options, ordered from easiest to hardest:   Add a delay for 15 mins into the script after creating the account and before assigning permissions to the home directory. You might need longer depending on your AD topology, but 15 mins is the default AD replication time for servers in the same site. Use a try/catch block and catch the error from icacls. If you get the error, delay for a minute or two and then try again. Keep looping until you don't get the error. Loop through all your domain controllers individually and check if the user exists on that DC. Delay for a minute if not, and keep looping until all the DCs confirm that the user exists. Then create the home directory."
PowerShell,3a2l65,vote4mclovin,1 point,Tue Jun 16 19:03:24 2015 UTC,"Before you're going to fire this command, you can include the -WhatIf Parameter to your Foreach-Block.   Import-Csv 'd:\UserAccounts.csv' | % { Set-ADUser -Identity $_.name –extensionAttribute1 $_.extensionAttribute1 -WhatIf}       And you need to include the underscore to reference the object from Import-Csv."
PowerShell,3a2l65,theusernamewasfree,1 point,Tue Jun 16 19:22:47 2015 UTC,What do you mean in regards to the underscore?
PowerShell,3a2l65,SeanQuinlan,1 point,Tue Jun 16 20:01:27 2015 UTC,"Reddit's formatting uses underscores before and after a block of text to mark it as italics.  When you simply copy and paste some PS commands into the Reddit comment box, it messes up the formatting, and makes it look as though you have $. instead of $_. It's interpreting the underscores as formatting commands, which is why the code you pasted is in italics, and is missing any underscores.  In future, when pasting code, add 4 spaces to the start of any lines of code. Then it will treat the text as code and not try to format it. Or use the Reddit Enhancement Suite and it will add a code button (among other formatting buttons) which allows you to more easily format blocks of text."
PowerShell,3a2l65,SeanQuinlan,1 point,Tue Jun 16 23:40:58 2015 UTC,ahh yep I see it now.  I keep forgetting to do that.  I cant use the custom site to post coding to reddit because its blocked.
PowerShell,3a2l65,magneto58,1 point,Wed Jun 17 12:31:49 2015 UTC,"There is no -extensionattribute1 parameter to Set-ADUser, so this won't work.  You need to add it a different way. Here is a blog demonstrating the correct syntax.  Also, it would help if you could supply a few lines from the CSV file, including the headers. Preferably copy the first few lines of raw text from the CSV file (open it in a text editor) and paste them here (as code). Sanitise the data as necessary."
PowerShell,3a1jjg,nduval,1 point,Tue Jun 16 14:37:05 2015 UTC,"In order to get dynamic content, you need to use a full rendering engine of a browser.  You can use http://watin.org/ to automate IE and Firefox.  I wrote a bit of a primer here: https://www.automatedops.com/blog/2014/03/27/test-all-the-things/"
PowerShell,3a1jjg,logicaldiagram,1 point,Tue Jun 16 14:55:15 2015 UTC,"Thanks for this.  I've been using IE DOM(?) to do similar tasks, and I guess I had it in my mind I could skip that and go directly to navigating and accessing content with invoke-webrequest.  Could you give me a quick rundown of why it would be better to use what you linked instead of the method I was previously using (I'm not sure what exactly to call it, but when I call IE like this:  $Site = new-object -com InternetExplorer.Application)"
PowerShell,3a1jjg,logicaldiagram,1 point,Tue Jun 16 15:26:52 2015 UTC,Watin has functionality for testing a site. If you're just scraping content from a single page it's not really any better.
PowerShell,3a1jf5,jlevy1126,1 point,Tue Jun 16 14:36:07 2015 UTC,"You could do something along these line:  'Machines failed,Error ServerA,Disk Full Machines not backed up Server1' -split '\r\n' | ConvertFrom-Csv -Delimiter ',' | Where-Object {$_.Error}"
PowerShell,3a1jf5,JaapBrasser,1 point,Tue Jun 16 15:05:19 2015 UTC,"I need that data extracted from the text in the pastebin link. It doesn't come that clean in the report i get. And sometimes there are more than one failed, or more than on that didn't back up. I do know what they are until i get the reports."
PowerShell,3a1jf5,ShippingIsMagic,1 point,Tue Jun 16 15:11:45 2015 UTC,"Depending on what is generating the reports, it's better to just get a structured version (csv, XML, json, whatever) mailed in addition to the current one (or as attachment to the existing one).  Trying to scrape data from formatted text is always problematic."
PowerShell,3a1jf5,ShippingIsMagic,1 point,Tue Jun 16 19:36:59 2015 UTC,Unfortunately this is the only format I can get.
PowerShell,3a1jf5,JaapBrasser,1 point,Tue Jun 16 19:40:08 2015 UTC,"I think /u/JaapBrasser has the right idea - the format is already basically 2 csv files, just broken up with those header bits.  How you ignore the header parts will be somewhat arbitrary, but assuming it's relatively fixed, splitting on empty lines seems like it'd work fine.  Not sure if you want the result csv on disk or what, but there's an example below.  # get the text however you already do $text =  [io.file]::ReadAllText('C:\temp\raw.txt')  # split into parts based on empty lines (consecutive newlines separated by only whitespace) $sections = $text -split '\r?\n\s*\r?\n'  $failedPart = $sections[1] | ConvertFrom-Csv $notBackedUpPart = $sections[3] | ConvertFrom-Csv  $failedPart | Export-Csv -NoTypeInformation 'c:\temp\failed.csv' $notBackedUpPart  | Export-Csv -NoTypeInformation 'c:\temp\notBackedUp.csv'   Note that you can't really spit them out as a single csv file very well, since they have separate column definitions.  If all you wanted was the output format from your post, then just replacing consecutive newlines with single newlines (IOW, removing the empty lines) would seem to be sufficient AFAICT."
PowerShell,3a1n1n,pro_slow_bro,1 point,Tue Jun 16 15:05:18 2015 UTC,"Showing the groups is no problem, the hard part is getting the properties to pop up. As far as I know there is no commandline for dsa.msc aside from /server or /domain."
PowerShell,3a1n1n,JaapBrasser,1 point,Tue Jun 16 15:13:45 2015 UTC,Is it possible to invoke an active directory item?
PowerShell,3a1n1n,JaapBrasser,1 point,Tue Jun 16 15:27:42 2015 UTC,I tried. It's not.
PowerShell,3a1n1n,jlevy1126,1 point,Tue Jun 16 17:46:08 2015 UTC,"Indeed, I think it is not. You could create your own AD properties window of course, but then why would you script it :)"
PowerShell,3a1895,majkinetor,2,Tue Jun 16 12:56:50 2015 UTC,"Cool, nice script thanks for sharing. Some things I noticed: - $result is not used anywhere in your script - You use a lot of aliases which makes the script a bit hard to read"
PowerShell,3a1895,JaapBrasser,1 point,Tue Jun 16 13:42:25 2015 UTC,"$result is the template object which gets cloned in a loop because that mechanism provides the shortest expression possible to create a custom object.  About aliases, I am not in the 'don't-do-aliases' camp, but in the 'lets-do-it-the-shortest-way' camp :) If the function is short and can fit the single screen its more readable. I use only integrated aliases which never change and everybody should know them. Many of those are also known in cross-platform way."
PowerShell,3a1895,KevMar,2,Tue Jun 16 15:15:41 2015 UTC,"everybody should know them   I don't know them. I had to look several of them up in your script to see what was going on.  sp $_ '(default)' ($r.FileType = $FileType)   This stuff is great when on the console but looking at this in someone else's code, or your own code in 6 months later slows you down. I am just so use to the verbosity of powershell now.   The more experienced I became with powershell, the more advanced my scripts, functions, modules, dsc resources got, the less I spent in an interactive prompt typing quick commands.  The real reason to be more verbose is to help the community. A lot of us leaned by reading scripts and other tools. This helps them to do more on their own."
PowerShell,3a1895,Val_0,2,Tue Jun 16 22:54:02 2015 UTC,"How do you look these things up? I always have a problem looking something like ""%(..."" using a search engine."
PowerShell,3a1895,KevMar,2,Tue Jun 16 23:54:08 2015 UTC,"There are three that you just have to learn. $_ for the pipe object, % foreach-object,  and ? Where-object.  But for aliases, get-help right from the powershell prompt. So by looking up, I used get-help."
PowerShell,3a1895,rbemrose,1 point,Wed Jun 17 00:11:08 2015 UTC,PS> Get-Alias %  CommandType     Name  -----------     ---- Alias           % -> ForEach-Object  PS> Get-Alias -Definition Foreach-Object  CommandType     Name  -----------     ---- Alias           % -> ForEach-Object Alias           foreach -> ForEach-Object
PowerShell,3a1895,rbemrose,2,Wed Jun 17 01:32:27 2015 UTC,"This stuff is great when on the console but looking at this in someone else's code, or your own code in 6 months later slows you down. I am just so use to the verbosity of powershell now.   Point of view. I am not used to verbosity, it slows me down. Also, all this alias dilemma is irrelevant with Expand-Alias around."
PowerShell,3a1895,KevMar,1 point,Wed Jun 17 04:47:27 2015 UTC,"I am in the 'lets-do-it-the-shortest-way' camp :)   I always like reading beautiful PowerShell, aliases or no, but I'm not sure I understand why this new function is needed.  cmd /c assoc seems much shorter than what you've written."
PowerShell,3a1895,KevMar,1 point,Tue Jun 16 20:01:56 2015 UTC,"Because cmd.exe might be turned off and that it is slower, isn't PS friendly, and returns wrong results:  PS> cmd.exe /c ""assoc .html"" .html=htmlfile PS>cmd.exe /c ""ftype htmlfile"" htmlfile=""C:\PROGRA~1\Plus!\MICROS~1\iexplore.exe"" -nohome  PS> assoc html | fl Extension  : .html FileType   : ChromeHTML Command    : ""C:\Program Files (x86)\Google\Chrome\Application\chrome.exe"" -- ""%1"" Executable : C:\Program Files (x86)\Google\Chrome\Application\chrome.exe   But mostly, because I can't stand cmd.exe :)"
PowerShell,3a1895,ollakolla,1 point,Wed Jun 17 04:44:39 2015 UTC,Cool. Adding right click commands to file types was always one of my favorite hacks. The command prompt here and sign script are the one I did the most.
PowerShell,3a1895,ollakolla,1 point,Tue Jun 16 14:37:57 2015 UTC,"This is not for right click, but left click :) But idea is actually not that bad to accompany this function. I am hesitant to implement it since I almost never use GUI. I will probably implement management of 'open with' list in the future since that is useful even from CLI. Currently this is used from CLI only with start xxx.ext but I imagine that open-with xxx.ext could provide you a way to select what associated app to start."
PowerShell,3a1895,tunucu,1 point,Tue Jun 16 15:26:21 2015 UTC,"Yeh, your right. You just reminded me of that with your script. The way to do that is in that area."
PowerShell,3a0r2s,alphanimal,2,Tue Jun 16 09:21:20 2015 UTC,"You could do something along these lines using calculated properties:  Get-DistributionGroup | ForEach-Object {     $DL = $_         $_ | Get-DistributionGroupMembers | Select-Object *,@{         Name = 'DLName'         Expression = {$DL.Name}     } }"
PowerShell,3a0r2s,JaapBrasser,3,Tue Jun 16 09:27:02 2015 UTC,"$_.Name would be referring to the name of each list member. Re-assign the DL to a temp variable instead:  Get-DistributionList | ForEach-Object {     ($DL = $_) | Get-DistributionListMembers | Select-Object *,@{         Name = 'DLName'         Expression = {$DL.Name}     } }"
PowerShell,3a0r2s,PowerShellStunnah,2,Tue Jun 16 09:35:04 2015 UTC,Thanks I missed that one indeed. I have updated my code so it works as I intended.
PowerShell,3a0r2s,JaapBrasser,1 point,Tue Jun 16 09:42:23 2015 UTC,"Awesome! I got this to work:  Get-DistributionGroup | ForEach-Object {     ($DL = $_) | Get-DistributionGroupMember | Select-Object Name,@{Name = 'DLName';Expression = {$DL.Name}} }   (It's DistributionGroup, not DistributionList)  Is there maybe a simpler way?"
PowerShell,3a0r2s,JaapBrasser,2,Tue Jun 16 09:50:50 2015 UTC,"Ah sorry I didn't have the cmdlets so I typed the code from memory. What do you mean by a simpler way, what would you like to simplify?"
PowerShell,3a0r2s,PowerShellStunnah,1 point,Tue Jun 16 09:55:28 2015 UTC,It seems it's pretty complex code for something that simple to do... I just expected this to be easier in PS  I wrote the wrong Cmdlets in my initial post as well
PowerShell,3a0r2s,JaapBrasser,2,Tue Jun 16 10:00:07 2015 UTC,"Seems a pretty simple pattern to me. The ""complexity"" is not so much PowerShell-specific, but stems from the fact that the member property of an AD group is only a reference to another AD object.  You could throw in a few aliases and make it more compact, although I don't really see any value in it:  Get-DistributionGroup|%{($DL=$_)|Get-DistributionGroupMember|Select Name,@{l='DLName';e={$DL.Name}}}"
PowerShell,39ywc2,karlthane,4,Mon Jun 15 22:28:09 2015 UTC,"In PowerShell 3.0 and later, Invoke-WebRequest is the cmdlet you'd be looking for.    In PowerShell 2.0 and earlier, you'd have to use .NET's [System.Net.WebRequest] class."
PowerShell,39ywc2,ryanbrown,3,Mon Jun 15 22:56:18 2015 UTC,wget is also an alias for Invoke-Webrequest I believe
PowerShell,39ywc2,Mindflux,1 point,Tue Jun 16 01:32:51 2015 UTC,Yep.  iwr  wget curl
PowerShell,39ywc2,miikkahoo,2,Tue Jun 16 04:37:46 2015 UTC,"wget.exe works well, and if you're already familiar with wget, might as well."
PowerShell,39ywc2,ShippingIsMagic,0,Tue Jun 16 05:16:33 2015 UTC,"I agree.  wget win32 and curl win32 both exist.  Don't fall into the trap that you need to make everything a .Net object, and end up reinventing the wheel because of it.  PowerShell is a shell scripting language.  You should expect to use binary programs.  That's partially why you're using PowerShell and not making a C# console application.  That's one of the languages major strengths, and it's one of the problems with the community that it's so indirectly discouraged.  Only when you need functionality that you can't get through your binary programs -- or can't be certain the programs will be present -- should you consider custom code with .Net natives."
PowerShell,39ywc2,da_chicken,1 point,Tue Jun 16 13:27:13 2015 UTC,"My mistake, I was under the impression that powershell was a true shell enviroment and wanted to use technologies native to it."
PowerShell,39ywc2,da_chicken,1 point,Tue Jun 16 22:27:39 2015 UTC,"Yes, it's a true shell environment.  Hence, you can execute binary programs.  Because it's a shell.  Executing binaries is a major function of a shell.  I guess I don't understand your point.  Look, one of the major problems with VBScript -- and one of the reasons so many people hated it -- was that you had to throw away all your knowledge and programs from batch to use it.  You could not reuse any code or logic, and always had to reinvent the wheel.  So, while you certainly can re-implement 7-Zip in PowerShell, the question you have to ask is: why would you do that?  Is it an exercise for fun?  Go for it.  Is it because you feel like everything should be a .Net native object?  Get over that feeling.  New code will be untested, will lack features, and will unreliable.  Existing code -- especially for a project like 7-Zip, wget, or curl -- is going to be heavily vetted.  Don't throw out known good code that you can reuse in exchange for new code nobody has ever run.  It's like ""not invented here"" syndrome.  The quality of the results of your scripts and code will be worse if you restrict yourself to .Net natives.  Yes, there are cmdlets like Invoke-WebRequest and Invoke-RestMethod which do similar things to curl and wget, but if you already have functioning code that you want to call from PowerShell, don't rewrite your code.  Do you want to use the methods that the objects the PowerShell cmdlets works with already has written?  If there's no benefit to rewriting your code, and the same basic code will still work, why on earth would you rewrite it?"
PowerShell,39ywc2,PowerShellStunnah,1 point,Wed Jun 17 20:53:32 2015 UTC,"You can also use the System.Net.WebClient class:  $wc = New-Object System.Net.WebClient $wc.DownloadFile(""http://interwebz.example/file.zip"",""C:\Users\karlthane\Desktop\file.zip"")"
PowerShell,39ywc2,HalalVeggieBacon,1 point,Mon Jun 15 23:26:01 2015 UTC,"Using This module from Microsoft, here's a little script I scrapped together to automate backups of remote data on a game server:  If (Test-Path .\PSFTP){Get-ChildItem ""PSFTP"" | % {Unblock-File -Path $($_.FullName)} } #Allow the Module to be quietly imported  Else {Write-Host ""Unable to find the required modules and cmdlets."" -ForegroundColor Red; Break} #If we can't find the files, stop  if (!(Get-Module PSFTP)){ import-module .\PSFTP\PSFTP.psm1 } #If the module hasn't been loaded, load it  $User = ""USERNAME"" $PWord = ConvertTo-SecureString –String ""PASSWORD"" –AsPlainText -Force $Credential = New-Object –TypeName System.Management.Automation.PSCredential –ArgumentList $User, $PWord  $Server = ""ftp://SERVERNAME:PORT"" #Set FTP connection here  $TargetPath = ""/path/to/targetfolder"" #Set target folder here  $FTPSession = ""FTPConnection""  Build the archive directory tree  $SpawnPath = (Get-Location).Path  #Make the archive directory  $Year = Get-Date -Format ""yyyy""; $Month = Get-Date -Format ""MM""; $Day = Get-Date -Format ""m""  If (!(Test-Path ""$Year"")){mkdir ""$Year""}; Set-Location ""$Year""  If (!(Test-Path ""$Month"")){mkdir ""$Month""}; Set-Location ""$Month""  If (!(Test-Path ""$Day"")){mkdir ""$Day""}; Set-Location ""$Day""  $LocalPath = (Get-Location).Path  Set-FTPConnection -Credentials $Credential -Server $Server -Session $FTPSession #Create the connection object  $Session = Get-FTPConnection -Session $FTPSession #Define the connection object as a variable  #Recursively copy all subfolders and files in the #$TargetPath variable: Get-FTPChildItem -Path $TargetPath -Session $Session -Recurse | Get-FTPItem -LocalPath $LocalPath -RecreateFolders -Verbose -Session $Session  cd $SpawnPath  Write-Host ""Done."""
PowerShell,39ywc2,jbtechwood,1 point,Tue Jun 16 00:03:04 2015 UTC,"For ftp stuff take a look at the WinSCP module that one of the community members actively develops. It uses the WinSCP dll and provides scp, sftp and ftp.  https://github.com/dotps1/WinSCP"
PowerShell,39ywc2,ShepRat,1 point,Tue Jun 16 10:47:54 2015 UTC,"Depending on what you are trying to do, it may be worth looking into Start-BitsTransfer.  It uses the windows background intelligent transfer service to asynchronously perform downloads using idle bandwidth.  It can be very useful if you need to download a large volume of data without saturating your network connection."
PowerShell,39zj26,cakes044,3,Tue Jun 16 01:32:41 2015 UTC,"$Exclude = @('Contacts','Desktop') Get-ChildItem -Exclude $Exclude | Where-Object { (New-TimeSpan -Start $_.LastWriteTime -End (Get-Date).AddMinutes(-30)).TotalMinutes -lt 30 }"
PowerShell,39zj26,Stormran,2,Tue Jun 16 04:14:05 2015 UTC,Maybe try -notlike and use wildcards to wrap?
PowerShell,39zj26,GLiMPSEiNATOR,2,Tue Jun 16 01:51:40 2015 UTC,"Hi Mate,  Try something like this. (big one liner)  Get-Childitem -Path $List | Where {$.PSisContainer -eq $true -and $.Name -ne ""dir2"" -and $.Name -ne ""dir3""} | Get-Childitem -Recurse | where {$.LastWriteTime -gt (get-date).AddMinutes(-30)}"
PowerShell,39zj26,bundyfx,1 point,Tue Jun 16 03:30:42 2015 UTC,Hmmm no dice. I didn't think it would be this complicated?  Thanks though.
PowerShell,39zj26,bundyfx,2,Tue Jun 16 03:47:07 2015 UTC,"Uhh I noticed it didn't copy across the $_ correctly for Name, LastWriteTime and IsContainer.  it works fine for me."
PowerShell,39zj26,bundyfx,1 point,Tue Jun 16 03:58:49 2015 UTC,"This is my exact script and I'm not getting the exclusions included:  Variables $Now = Get-Date  $Minutes = '30'  $List = 'C:\Users<User>\Documents\Temp\'  $dir2 = 'C:\Users<User>\Documents\Temp\Boot'  $dir3 = 'C:\Users<User>\Documents\Temp\20150306'  $LastWrite = $Now.AddMinutes(-$Minutes)  Gets based on LastWrite variable and Specified Folders $Files = Get-Childitem -Path $List | Where {$.PSisContainer -eq $true -and $.FullName -ne ""$Dir2"" -and $.FullName -ne ""$Dir3""} | Get-Childitem -Recurse | where {$.LastWriteTime -gt $LastWrite}  Loops through all the directories and searches for any files older than 30 minutes to delete  If ($Files -ne $NULL)  {write-host 'alert' -ForegroundColor Red} Else {write-host 'No alert'}"
PowerShell,39zj26,bundyfx,2,Tue Jun 16 04:21:41 2015 UTC,"$Now = Get-Date  $Minutes = '30'  $List = 'C:\dir1'  $dir2 = 'C:\dir2'  $dir3 = 'C:\dir3'  $LastWrite = $Now.AddMinutes(-$Minutes)  $Files = Get-Childitem -Path $List | Where {$_.PSisContainer -eq $true -and $_.FullName -ne ""$Dir2"" -and $_.FullName -ne ""$Dir3""} | Get-Childitem -Recurse | where {$_.LastWriteTime -gt $LastWrite}   If ($Files -ne $NULL)  {write-host 'alert' -ForegroundColor Red} Else {write-host 'No alert'}   Just tested it on my workstation. works well."
PowerShell,39zj26,JaapBrasser,2,Tue Jun 16 04:54:34 2015 UTC,try some different folder locations with the same idea in mind. it may be your folders.
PowerShell,39zj26,GLiMPSEiNATOR,2,Tue Jun 16 04:55:58 2015 UTC,"You could do this with -notcontains as well, then you make a single statement instead of comparing against multiple folder names. Looks a bit cleaner."
PowerShell,39zj26,bundyfx,2,Tue Jun 16 08:36:59 2015 UTC,"Ya, do a where-object{$exclude -notcontains  $_.fullname}"
PowerShell,39zj26,JaapBrasser,1 point,Tue Jun 16 11:35:31 2015 UTC,This works! Thank you very much!
PowerShell,39z6b9,eluther,2,Mon Jun 15 23:44:35 2015 UTC,I see a couple of possible issues.   The cloud is throttling your first request The first request gets all of the mailboxes first then gets permissions(you would see this if it is slow for a few seconds then just starts shooting out results) I believe you can go without the for each object. I will have to test that later
PowerShell,39z6b9,cablethrowaway2,2,Tue Jun 16 11:33:43 2015 UTC,"With no knowledge of your environment and just looking at the scripts, the reason that 1 takes longer than 2 is the number of objects it has to request. The first script grabs a list of every mailbox in your environment along with all the details that come with a Get-Mailbox request and this command can take a long time if you have a lot of mailboxes. Then it processes a request for each mailbox individually. The second script simply does a single request on one mailbox. You can try switching to ForEach instead of ForEach-Object to speed up the query but it will use more memory.  $mailboxes = Get-Mailbox ForEach ($mailbox in $mailboxes) { Get-MailboxFolderPermission $mailbox.Alias"":\Calendar"" -User $foo -EA SilentlyContinue | Select Identity, FolderName, user, AccessRights }"
PowerShell,39z6b9,Stormran,1 point,Tue Jun 16 13:19:37 2015 UTC,Thanks for the reply! I'm really only calling up the mailboxes so I can get all the aliases to run through Get-MailboxFolderPermission.  What really surprised me is that in the second one the $alias variable just works.  I have no idea why.  I was hoping that if that was some kind of universal (?) variable I could use it to speed up the first.
PowerShell,39z6b9,catfoodsci,1 point,Tue Jun 16 15:34:43 2015 UTC,"In your first script, this seems odd. You are both assigning the variable $mailbox and also using the same variable in the commandlet. Maybe this was a typo when posting, otherwise i don't see how this would work.   $mailbox = Get-Mailbox $mailbox..."
PowerShell,39z6b9,catfoodsci,2,Tue Jun 16 13:45:39 2015 UTC,"Well it looks like that code is doing the same as      $mailbox = get-mailbox * ... so while it looked odd to me, I see that it will work. Here is how i would run something like this though without the use of $mailbox.  $mailbox = Get-Mailbox * | %{Get-MailboxFolderPermission $_"":\Calendar"" -User $foo -EA SilentlyContinue | Select Identity, FolderName, User, AccessRights}   As others mention, the slowness is probably due to your script checking permissions on every single mailbox in your environment. If you have a lot of mailboxes you may need to use -ResultSize Unlimited with the get-mailbox command like:  $mailbox = Get-Mailbox * -ResultSize Unlimited | %{Get-MailboxFolderPermission $_"":\Calendar"" -User $foo -EA SilentlyContinue | Select Identity, FolderName, User, AccessRights}"
PowerShell,39z6b9,catfoodsci,1 point,Tue Jun 16 14:08:20 2015 UTC,"Thanks for the reply! The reason I set the $mailbox variable and then immediately called it was Office365 didn't like me calling up a list of mailboxes and piping it without assigning it to a variable. Although maybe -ResultSize would have helped with that.  Will have to try.   Also, I tried out your scripts after setting the $foo variable and for whatever reason it didn't produce any output. What does the % mean?"
PowerShell,39x6c1,BadUserNameGuy,3,Mon Jun 15 15:06:51 2015 UTC,"The xCertificate module is a part of the Windows PowerShell Desired State Configuration (DSC) Resource Kit, which is a collection of DSC Resources. This module includes DSC resources that simplify administration of certificates on a Windows Server, with simple declarative language."
PowerShell,39x6c1,SEA-Sysadmin,2,Mon Jun 15 15:07:11 2015 UTC,"Yay,  I need this like... Today."
PowerShell,39ydya,Shadowtek,3,Mon Jun 15 20:18:03 2015 UTC,"Hey mate,  This is a job for a PS Object. The best way of doing something like this would be something like this:  (Get-Content .\Active.txt) | ForEach {  If (Test-Connection -ComputerName $_ -Count 1 -Quiet) {      $nw = Get-WmiObject Win32_networkadapter -ComputerName $_ -filter 'netconnectionid = ""wireless network connection""'       $props = @{         ComputerName = $_         ID = $nw.netconnectionID      }      New-Object PsObject -Property $props  } Else {      Write-Warning ""$_ cannot be reached, skipping.""  }   } | Sort ComputerName |          Select ComputerName,ID |              Export-Csv .\computerDetails.csv -NoTypeInformation  You can just add more properties as needed to the $props so long as you've declared them and saved them in variables before hand.  let me know how you go."
PowerShell,39ydya,bundyfx,1 point,Tue Jun 16 00:16:33 2015 UTC,"Excellent thanks, I'll give it a shot!"
PowerShell,39ydya,JewStyleKungfu,1 point,Tue Jun 16 12:08:31 2015 UTC,This did the trick! I had to add another prop as you mentioned and put in my objects and such but after that it worked pretty well! Thanks!!
PowerShell,39ydya,JewStyleKungfu,1 point,Tue Jun 16 12:40:36 2015 UTC,"That's all one long string, maybe that's the issue I've just started looking at Array's and Collections and such but I want to keep it simple if I can. No parenthesis in actual script."
PowerShell,39ydya,JewStyleKungfu,1 point,Mon Jun 15 20:19:08 2015 UTC,"It looks like your formatting went a little crazy, but I think that ""Select"" cmdlet is invoked incorrectly.  I'm not sure how that would cause the behavior you're describing, but I don't believe you should have '$_' right there.  Do you have an example of what the active.txt file looks like?  I'd like to run some code over here to see what happens, but I need a sample source file."
PowerShell,39ydya,JewStyleKungfu,1 point,Mon Jun 15 20:41:27 2015 UTC,"it's literally like this in a text file, no additional spaces and such.   Domain-location-user  Domain-location-user mydomain-gsf-jsmith   When it exports in excel you see at the top mydomain-gsf-jsmith, Netconnection ID, Name  Then  (nothing here now) Wireless Network Connection, Intel Blah Blah (nothing here) Wireless Network Connection, Broadcom blah  etc..  So I know it's going through the list and it's getting the info I want mostly."
PowerShell,39ydya,Stormran,1 point,Mon Jun 15 20:46:06 2015 UTC,"Ugh, those domain items aren't listed like that they are listed straight down in a text file, not across and no additional spaces and no bullet's haha"
PowerShell,39yb8k,sphinxpup,1 point,Mon Jun 15 19:59:26 2015 UTC,"I swear, just typing my problems out on here helps me concentrate. This is what I have come up with. Probably took too long, but looks like it might lead me to what I want     If((Get-Content -Path ""C:\Powershell\test.txt"") -match ""rr-pr60"")    {    $pr60 = Get-Content -Path ""C:\Powershell\Printers\test.txt"" |     Foreach-Object {$_ -replace ""rr-pr60"", ""rrprt39""}    }"
PowerShell,39yb8k,JewStyleKungfu,1 point,Mon Jun 15 20:14:22 2015 UTC,"It looks like you might have been going for something more like this, check it out and see:  get-content ""C:\Powershell\Printers\test.txt"" | foreach-object {$_ -replace ""rr-pr60"",""rrprt39""}"
PowerShell,39x670,scopesiide,1 point,Mon Jun 15 15:05:47 2015 UTC,"+1 for CDPtoWMI  After installing WinPcap (can be done silently with nmap WinPcap installer), run CDPtoWMI.exe to get and store switch/port info in custom WMI class (NINET_ORG_WMICDP) to be queried in PowerShell."
PowerShell,39x670,ShyRonny,1 point,Mon Jun 15 22:54:47 2015 UTC,"I was hoping not to install WinPcap, any ideas?"
PowerShell,39x670,GLiMPSEiNATOR,1 point,Tue Jun 16 04:02:16 2015 UTC,If googling has yielded no results I'd see if there's a solution within c#. What you're really looking for is a library with this functionality in .net. Find that and you can build your script around reflecting that assembly.
PowerShell,39wd38,autoandshare,3,Mon Jun 15 09:50:02 2015 UTC,"Very neat, thanks for sharing!"
PowerShell,39wd38,phiber232,2,Mon Jun 15 13:07:51 2015 UTC,Neato!
PowerShell,39xqjt,cockhorse-_-,1 point,Mon Jun 15 17:34:51 2015 UTC,"The data you're looking for is probably in one of the Performance Data (""PerfFormattedData"") WMI classes.  I'm not sure which one is going to have the details you're looking for, but that's where I'd start since that's where all the Performance Monitoring data comes from.  https://msdn.microsoft.com/en-us/library/aa392738(v=vs.85).aspx"
PowerShell,39xqjt,ryanbrown,1 point,Mon Jun 15 19:48:45 2015 UTC,I've found this but I cant seem to get it to work:  http://andrewmorgan.ie/2012/11/monitoring-storage-disk-queues-and-io-with-powershell/
PowerShell,39xqjt,root-node,1 point,Mon Jun 15 20:09:26 2015 UTC,"The site is stripping out the slashes, the first function should read...  Function get-iodatabytes{$result=(get-counter -counter ""\Process(`*)\IO Data Bytes/sec"" -ea 0).countersamples | ? {$_.cookedvalue -gt 0} | select instancename,@{Name=""SessionID"";Expression={if ($_.path.contains(""#"")){($_.path.split(""#)""))[1]}else{""0""}}},@{Name=""IO Data Bytes/sec"";Expression={[math]::Round($_.cookedvalue,0)}},@{Name=""IO Data KBytes/sec"";Expression={[math]::Round($_.cookedvalue / 1024,0)}} | sort -Descending ""IO Data Bytes/sec"" | ft $currentqueue=(((get-counter -counter ""\PhysicalDisk(0 C:)\Current Disk Queue Length"" -ea 0).countersamples) | select cookedvalue).cookedvalue clear write-warning ""Hit [CTRL] + [C] to exit live capture"" write-host ""Current Disk queue: $currentqueue"" return $Result }"
PowerShell,39xqjt,ryanbrown,1 point,Mon Jun 15 21:04:07 2015 UTC,/u/root-node is correct.  The html formatting stripped the backslash characters.  It'd probably also be better to single quote the -counter parameter to have PowerShell interpret the string literally and not try to interpolate the string.  $samples = (Get-Counter -Counter '\Process(*)\IO Data Bytes/sec' -ErrorAction Ignore).CounterSamples   It looks like you do need to set the ErrorAction preference to Ignore (or maybe SilentlyContinue) otherwise the command errors out complaining about invalid data.  You can add back in all the formatting/expressions once you're sure that's the data you want.
PowerShell,39xqjt,root-node,1 point,Mon Jun 15 22:47:37 2015 UTC,"Agreed.  For me there is so much wrong with the formatting of this function.    I always single quote everything unless I need to use doubles,  Never put everything on one line, it makes it very hard to debug or change,  Never use shorthand codes (-ea / -ErrorAction) as someone coming along after you may now know what they are,  Just my OCD, but I like capitalisation.  Write-Warning/Write-Host/Return/..."
PowerShell,39xokm,tehreet,2,Mon Jun 15 17:21:01 2015 UTC,"You will probably have to keep doing the sharepoint stuff manually, and the database piece, I recommend you start logging mailbox locations daily/weekly into a database so you can automate that portion of it as well.  Then you could combine that plus... this chunk of code to do what you want"
PowerShell,39xokm,PsTakuu,1 point,Mon Jun 15 19:47:29 2015 UTC,"I accidentally left off the piece for ensuring the mailbox is disabled.  You can use 'Get-mailbox ""userid""' to search for a connected mailbox.  If it comes up blank, either it never existed, you typed the userid wrong, or it's disconnected."
PowerShell,39xokm,PsTakuu,1 point,Mon Jun 15 19:50:01 2015 UTC,"Wow...impressive. I started to put something together and i'll combine it with yours. This is awesome! I should really get better with managing Sharepoint, maybe there is a way to automatically fill in the fields on an item in sharepoint through powershell?"
PowerShell,39xokm,PsTakuu,1 point,Mon Jun 15 20:14:39 2015 UTC,There's always a way! But the infrastructure has to be there first.  Depends on where your data in sharepoint is.
PowerShell,39xokm,PsTakuu,1 point,Mon Jun 15 22:32:01 2015 UTC,"So, im going to be working on this for the next few days. If i get stumped, would you mind if i messaged you? I really appreciate you writing that!"
PowerShell,39whlu,winstonw0w,4,Mon Jun 15 10:57:09 2015 UTC,"You can use the -File parameter to only retrieve files and then delete those files, for example:  Get-ChildItem -Path Scan2Folder -File -Recurse | Remove-Item -WhatIf"
PowerShell,39whlu,JaapBrasser,2,Mon Jun 15 11:38:54 2015 UTC,"Something like  foreach($folder in gci <Scan2Folder Home Folder>){         remove-item ""$($folder.fullname)\*.*"" -Recurse -Force     } }   Should do it."
PowerShell,39whlu,the_spad,1 point,Mon Jun 15 11:03:03 2015 UTC,"kinda, but the problem is that there are <300 folders possible and I don't want to but 'em all in an array"
PowerShell,39whlu,the_spad,1 point,Mon Jun 15 11:12:58 2015 UTC,"You don't have to, given the folder format you posted you just have to start from the root folder."
PowerShell,39whlu,feelingsofwhite,1 point,Mon Jun 15 11:16:53 2015 UTC,"For each doesn't create an array,  it just  enumerates a.. um... IEnumerable.. I understand that sounds redundant,  but basically: no array.  Also a 300 length array is TINY. I'm not sure why you'd desire to avoid creating an array, again not that it is, but assuming it's memory or performance concerns, I wouldn't start worrying about it until around 3 million or so. Even then if is getting the job done who cares. now around 3 billion... that's another story"
PowerShell,39v2s6,Noghri_ViR,10,Mon Jun 15 01:12:26 2015 UTC,Looks like its only available with windows 8 and server 2012. Similar to the Add-Printer cmdlet.
PowerShell,39v2s6,kcbwya77,6,Mon Jun 15 01:18:54 2015 UTC,"Microsoft decided it would be a great idea to give Powershell 4 a wildly different set of cmdlets on Windows 8+ compared to Windows 7 and then poorly document it.  There is a lot of cool new stuff that ""requires Powershell 4"" and only works on Windows 8+."
PowerShell,39v2s6,the_spad,2,Mon Jun 15 07:27:16 2015 UTC,As Kcbwya77 said. Get-NetIpConfiguration is only available on Windows Server 2012 and Windows 8 (or later OS versions).
PowerShell,39v2s6,bundyfx,1 point,Mon Jun 15 01:23:05 2015 UTC,I always wondered why that happened.   Thanks for asking that question.
PowerShell,39uetu,itsteve,3,Sun Jun 14 21:33:46 2015 UTC,"OK, after some research here is where I stand:   WebAPI account(s) will have the MOST limited access necessary to perform the task. Passwords for WebAPI accounts will be changed manually on schedule. I will create credentials using a home grown function that will Get-Credential and Export-CliXML to a file, which I will save to our internal SVN. I will use my RMM to transfer the updated creds (XML file) down to target paths on selected servers. I will lock down permissions on my target paths to the AD account that will be running the scheduled task. I will modify my existing project to accept XML file input (instead of username/password), and credentials will be unwrapped at runtime.   Is there a better way to do this?"
PowerShell,39uetu,babypunchingrampage,1 point,Sun Jun 14 22:46:09 2015 UTC,"I'm on mobile so I can't easily find and link, but I know one time doing this I saved the credentials in the windows credential manager and then used them in my script that way. Doesn't work for versioning or central repo but it did the job."
PowerShell,39uetu,Davotronic5000,2,Sun Jun 14 23:56:47 2015 UTC,"I have been working on a module to do exactly this, the latest version is available for download on Github.  https://github.com/davotronic5000/PowerShell_Credential_Manager/releases.  The module is working but the documentation needs some work."
PowerShell,39uetu,GLiMPSEiNATOR,2,Mon Jun 15 08:10:44 2015 UTC,My understanding is you'll need to make sure you're using the same AD account to import-clixml as you did to export it... Just FYI
PowerShell,39uetu,WindosBK,2,Mon Jun 15 00:41:22 2015 UTC,"Also needs to be on the same computer, i.e. same AD account on a different computer won't be able to do the import."
PowerShell,39uetu,WindosBK,1 point,Mon Jun 15 02:33:06 2015 UTC,"Yikes, thanks for the heads up. This busts my theory in that case"
PowerShell,39uetu,majkinetor,2,Mon Jun 15 02:35:23 2015 UTC,"Look into some of the optional parameters on ConvertTo-SecureString and the ConvertFrom. You can specify your own keys, etc. Converting to a secure string is what export-clixml is doing, but with non of the option features.  You could also consider Protect-CmsMessage and Unproctect-CmsMessage, though I think these were introduced in PowerShell 5? At least the WMF5 preview release notes were where I first learnt of them. This uses a document encryption certificate to encrypt and decrypt the strings (so the computer running the code just needs the certificate installed.)"
PowerShell,39uetu,oobnate,2,Mon Jun 15 02:42:39 2015 UTC,"Here is some code I have a hand:  function load_credential($File) {     if (!$File) { return }     $u = $File.BaseName.Replace('-', '\')     $p = ConvertTo-SecureString (gc $File) -Key (1..16)     New-Object -Type PSCredential -ArgumentList $u, $p }  function export_credential($Credential, $Store, $AskMsg){     gi $Store -ErrorVariable err -ea 0 | out-null     if ($err) { return $err }      if (!$Credential -or $Credential.gettype() -ne [PSCredential]) {         $Credential = Get-Credential $Credential -Message $AskMsg         if (!$Credential) { Write-Error ""Credential input canceled."" -ev err -ea 0; return $err }     }      try {         $fp = ""{0}/{1}.sss"" -f $Store, $Credential.UserName.Replace('\', '-')         rm $fp -ea ignore         ConvertFrom-SecureString -SecureString $Credential.Password -Key (1..16) | out-file $fp     } catch { $_ }"
PowerShell,39uetu,sid351,1 point,Mon Jun 15 04:51:45 2015 UTC,"I don't think you should store your password in a file. Someone could use the same script to decode your password and get access to your files. In the SecureString PowerShell docs, it specifically says don't store in files or in registry.   I would try to use a low privilege account to do your operation and limit the exposure if the account was compromised. If you are worried about storing your password in scheduled task because of lsass dumps or some other issue, then I would research on how to prevent or alert you if any of those cases happen."
PowerShell,39uetu,majkinetor,1 point,Mon Jun 15 05:05:44 2015 UTC,"You can pass a secure string into a credentials object, then use the NetworkPassword (on mobile, think that's the right name) method to print what the plain text of the secure string is.  It can only really be thought of as security through obscurity."
PowerShell,39uetu,CaelFrost,1 point,Mon Jun 15 05:12:29 2015 UTC,"I know, but we don't live in black & white world, and context does matter.   I used this one when I had to generate new vagrant virtual machine. Since machine had to init itself from the share it needed creds for the unkown user vagrant. Host machine exported creds from the user that started the build, guest machine used the creds, and on build end host machine safely deleted the creds export. In case the host fails to delete export for some reason those will still be secured by obscurity.   So it was only transiently saved on the disk (which should be shredded etc.) but it was enough to get the job done without extensive mumbo jumbo.  Yeah, you need to know what you do anyway, so warnings are welcome.  Creds were provided on the command line as PSCredential object.   I don't really grok how much different this is from me obtaining your Windows password and decoding the securestrings anyway. Sure, its another layer of protection but the one that gets most attack methods."
PowerShell,39uetu,jbtechwood,2,Mon Jun 15 13:16:18 2015 UTC,"Hey this worked for me, thanks for the suggestion.   I ended up doing a mix of Dave Wyatt's answer here: https://social.technet.microsoft.com/Forums/windowsserver/en-US/7374eec4-aac6-4b1f-9f9b-73b7b2eb2c7d/storing-credentials-to-be-used-as-a-different-user-instantiation-issue-of-securestrings?forum=winserverpowershell  And this blog post: http://www.adminarsenal.com/admin-arsenal-blog/secure-password-with-powershell-encrypting-credentials-part-2  I ended up with three new functions:   New-AESKey  New-SecureAESCredential  Get-SecureAESCredential    You can imagine what these do and it's working like a charm. I'm saving the key and encrypted Get-Credential object to disk, and locking down the location with strong NTFS permissions. You would need Domain Admin creds to do any harm, which in that case, I assume a total loss anyway. This was a much better solution than plaintext."
PowerShell,39uetu,br0phy,2,Mon Jun 15 21:01:57 2015 UTC,"I use a user certificate's private key to encrypt the string... No cert, no decrypt."
PowerShell,39uetu,magneto58,1 point,Mon Jun 15 04:59:00 2015 UTC,Where do you store the cert for execution?
PowerShell,39tutb,superadmin1990,2,Sun Jun 14 18:46:21 2015 UTC,"There is nothing wrong with needing to Google things. As you get used to any language, you will do it all the time in the beginning, and then less so as you go on.   Can't I get do something like get-service $Service -computername $server | start-service ?   You can. Anyone with a crazy script is making it too complex. If you want to do it on a bunch of machines:  $service = ""myservice"" $listOfMachines = @(""machine1"",""machine2"") $listOfMachines | ForEach-Object { Get-Service -Name $service -Computer $_ | Start-Service }   I don't know if Start-Service will return before the service finishes starting on remote computers. My guess is that it does, so any scripts you find might also include polling the service state to ensure successful start-up."
PowerShell,39tutb,Cadoc7,1 point,Sun Jun 14 22:14:06 2015 UTC,"Yep, that's what I was shooting for. I didn't think it was supposed to be as complicated as some people were making it out to be. I'm not to the point where I'm including polling to return services states. I'm a desktop admin, so those are important and I should learn to include those. My tools are a little more focused than someone who is a full on system administrator.   I feel like I'm learning a lot, and I will frequently return to my powershell books. But when I have to google someone elses script or something more particular, it makes me realize all over again I have a lot to learn. Luckily there's a lot of scripts being shared online."
PowerShell,39tutb,Deathonus,1 point,Sun Jun 14 23:09:36 2015 UTC,"If the script is any longer than the above, then chances are they are testing the connections to the computers before attempting as well as probably have extra error handling to report back any failures in an easy to read format.  If a computer in your list was down when you run the above command, you'd get the familiar red block of next for each failure.  Really not the end of the world."
PowerShell,39tutb,dogfish182,1 point,Tue Jun 16 14:03:48 2015 UTC,"watch the virtual Academy videos from microsoft, theyre free and will teach you a lot"
PowerShell,39tutb,theb1g,1 point,Sun Jun 14 20:19:20 2015 UTC,"I have actually, they've given me a good start but I still seem to have to google stuff when I need to write a script. I probably just need more practice. I guess it's impossible to know everything in powershell. There's so much I don't know..."
PowerShell,39tutb,the_spad,1 point,Sun Jun 14 20:21:41 2015 UTC,"I write scripts that are hundreds of lines long with me creating objects,  error handling and multiple functions. That being said I still look up stuff on Google. The main thing is to understand from a logical standpoint what it is that you want to do. Google is to grab the piece you need to plug into your logically organized script. The more you script the less you need Google. Don't worry you will always use Google."
PowerShell,39tutb,KevMar,1 point,Sun Jun 14 22:22:42 2015 UTC,"And sometimes when I do google something, I see a huge long script just for starting or stopping a service on a list of remote machines. Can't I get do something like get-service $Service -computername $server | start-service ?   Annoyingly, while get-service takes the -computername parameter, neither start-service nor stop-service do so it's not as simple as you'd expect."
PowerShell,39t8yl,drumstix576,2,Sun Jun 14 15:33:28 2015 UTC,"Here is how you do it by hand using diskpart.  Attach VHD via Diskpart.exe  diskpart select vdisk file=""D:\Users\Public\Documents\Hyper-V\Virtual Hard Disks\data.vhd"" attach vdisk   Detach VHD via Diskpart.exe  diskpart select vdisk file=""D:\Users\Public\Documents\Hyper-V\Virtual Hard Disks\data.vhd"" attach vdisk   Source: http://www.thomasmaurer.ch/2010/12/howto-attach-detach-vhd-in-windows-server-2008-r2/  Diskpart does support scripting.  Why are you backing up to a remote VHD instead of just a UNC path?   Edit: I figured it out. You are using windows built in backup and for some reason it will only do incremental backups to local drives. Once the VHD is mounted, it is seen as a local drive.  This is a flaw in the server version in my opinion. Windows backup on Windows 7/8 will do incremental backups to a UNC path (most of the time)."
PowerShell,39t8yl,KevMar,2,Sun Jun 14 16:47:25 2015 UTC,"Thanks for this!  I ran across it on my own early on but dismissed it because I couldn't figure out how to check if the drive was already mounted (and couldn't make a generic version that used the local machine's hostname to obtain the VHD path, but that's minor).  Looks like this may be the way to go, though, so I'll play with it some more.    You're right about why I'm using locally-mounted remote VHDs--they're the only I can find in Windows Server Backup to do incremental backups to a remote share.  Is there a better way to approach this issue?  I'll admit I don't really know what I'm doing; I'm primarily a Linux admin..."
PowerShell,39t8yl,da_chicken,2,Sun Jun 14 17:56:47 2015 UTC,"Windows 8 and Server 2012 have additional functionality that Windows 7 and 2008 R2 lack, so the underlying code is not present for PowerShell, really.  On Server 2k8R2/Win7 it looks like it's rolled into DiskPart, which is scriptable.  Otherwise, I think you need to use vhdmount.exe or third party software."
PowerShell,39vy2x,GoMonkey13,2,Mon Jun 15 06:11:24 2015 UTC,"$v1 = ""123"" $v2 = ""asdf""  $sb = { return ""My parameters are: `""$($args[0])`"" and `""$($args[1])`"""" }  $JobResults = Start-Job  -ScriptBlock $sb -ArgumentList @($v1,$v2) | Wait-Job | Receive-Job Write-Host $JobResults   This will stop the script right at the call of the job and wait for it to return (wait-job) and then receive its results (receive-job) and proceed with the rest of the script.  If you don't want to wait for the job and proceed with the rest of the script while the job is running you have to implement a logic that, for example, checks in a periodic interval if the job has finished and then receive its results."
PowerShell,39vy2x,Feyh,1 point,Mon Jun 15 10:28:30 2015 UTC,"Okay, thanks - that worked, and I'm getting closer to what I'm trying to do.  I'm trying to use this to run a script that I wrote on multiple servers in batch instead of one-by-one; each takes around 5min to run normally.  I can't seem to get it to run multiple jobs at once though.  I'm able to pass the server name to the custom script, but it's not producing the output (text files with information for each server, kind of like an audit). I normally run the custom-script without outputting data to file, just to screen, so I didn't write that into the script itself.  When I have to run the script on many servers then I'd rather have it output to file for later perusing.  $servers = Import-CSV C:\servers.csv  Foreach ($server in $servers) {  $ServName = $server.name  Start-Job -ScriptBlock { param ($ServName) custom-script -ComputerName $ServName | Out-File (""c:\""+ $ServName + "".txt"") } -ArgumentList $ServName }   If I exclude the 'custom-script' line and keep the Out-File line, it will create the files as I expect.  If I leave the custom-script in, no files are produced, let alone with the content I'm expecting.  If I run that one line normally in PS, it runs as expected.  Am I going about this the wrong way?  Are there limitations on what can be run in the Get-Job script block?"
PowerShell,39vy2x,Feyh,1 point,Mon Jun 15 11:58:41 2015 UTC,"What exactly is your ""custom-script""? Is it a function?  If yes, you have to declare that function inside of the scriptblock because everything that is not inside of the scriptblock can't be called by your job.  To make it easy:  You are running your script in a powershell session (we will label it as Session1). Then you are calling a job. The thing the job does is pretty much starting a new powershell session (session2) with all the information you are giving via the Scriptblock. Everything that is outside of that scriptblock is not in the same session as your job and thus can't be called. it's like opening 2 powershell windows, declaring a variable in the first shell and trying to call it in the second shell.  $servers = Import-CSV C:\servers.csv  Foreach ($server in $servers)  {     $ServName = $server.name      Start-Job -ScriptBlock {         param ($ServName)         function custom-script         {             #blabla         }            custom-script -ComputerName $ServName | Out-File (""c:\""+ $ServName + "".txt"")     } -ArgumentList $ServName }"
PowerShell,39vy2x,Feyh,1 point,Mon Jun 15 12:10:05 2015 UTC,"I'm not following, sorry.  It's a standalone script - the only thing it needs is a computer name passed to it; it doesn't matter what session it's in.  I assume that's what the -ArgumentList is for."
PowerShell,39vy2x,Feyh,1 point,Tue Jun 16 10:35:40 2015 UTC,"So, you are calling that custom-script inside of your scriptblock by using it's full path?  The argumentlist is for passing parameters into the job, because the job can't access any information outside of its scriptblock. Everything you want the job to do needs to be either declared inside of the scriptblock, which you pass to the start-job command, or via the argumentlist."
PowerShell,39vy2x,KevMar,1 point,Tue Jun 16 12:24:02 2015 UTC,"The custom-script is in my autoload; I assume that means the start-job can run it without the full path.  I'm really not sure what you mean by 'everything you want the job to do needs to be declared...'.  I only want it to run the custom-script, passing the computer name to it.  The custom script contains things like 'test-path' using the computer name supplied to it, with the actual path to test already in the custom-script."
PowerShell,39vy2x,the_spad,1 point,Wed Jun 17 07:58:41 2015 UTC,"I've never heard about autoload but as far as I just read about it it's just a directory which contains some scripts. At the start of your script you are calling something along the lines like  get-childitem ""PathToMyAutoLoadDirectory\*.ps1"" | %{.$_}   . Is this correct?  If yes, you also have to add this ""autoload"" into your scriptblock.  Again, your job has no clue what happens outside of its scriptblock."
PowerShell,39vy2x,the_spad,1 point,Wed Jun 17 08:25:26 2015 UTC,"Yes, that's right.  Interesting, I assumed it would be recognized since it gets loaded with the Powershell CLI when I launch it."
PowerShell,39rj2z,neilthecellist,5,Sun Jun 14 01:31:41 2015 UTC,"I think you need to enable some auditing or logging on the DC, then search the eventlogs to get your answer.   Or have some other monitoring in place that does this for you.  What I did was write a script to dump users, groups, computers, and group policy attributes to a text file every night. It would then do a diff between tonights file and yesterdays file. That diff would basically be what changed and it would be emailed to the team."
PowerShell,39rj2z,KevMar,1 point,Sun Jun 14 01:53:02 2015 UTC,Do you have that script handy?
PowerShell,39rj2z,neztach,2,Sun Jun 14 01:55:37 2015 UTC,Seconded. Please share your script
PowerShell,39rj2z,ArmondDorleac,2,Sun Jun 14 02:13:31 2015 UTC,Yep. Me too.
PowerShell,39rj2z,Setsquared,1 point,Sun Jun 14 02:31:08 2015 UTC,Check this out https://gallery.technet.microsoft.com/scriptcenter/Audit-Active-Directory-3f4a17dd   Also you need to enable auditpol on the domain controllers
PowerShell,39rj2z,ioFAILURE42,1 point,Sun Jun 14 11:45:09 2015 UTC,"I've got a script on my work machine that scans HTML logs generated by our logging software. In my case, I needed it to scan the logs for successful logins to verify that service accounts have not been used for XXX weeks prior to us deleting them.  It's not a perfect fit for what you're looking for, but I can share it if you're interested. It won't take much to modify it to search for other events.  I think you'd want to look for events containing 4728/4732 on a 2008+ DC.  Let me know if you're interested."
PowerShell,39rj2z,KevMar,0,Sun Jun 14 06:17:06 2015 UTC,"No I don't, it was something I wrote while at  a previous employer. It's a fairly simple script for someone with a little experience in PowerShell.  Query for details, save to file, use compare-object with yesterdays file, send result via email. The trick is to have the right details on each single line so that when you see just the difference, you have all the information.  Would be a good early project."
PowerShell,39rj2z,adrianrodriguez,1 point,Sun Jun 14 03:29:10 2015 UTC,"Thanks! The ""pseudo-code"" explanation is preferred, and as a learning POSH programmer, this is probably what I really need, to be able to fend for myself.  Regards, neilthecellist"
PowerShell,39rj2z,graemejevans,2,Sun Jun 14 04:39:42 2015 UTC,"You'll want to use the Get-ADReplicationAttributeMetadata cmdlet. For example:  $UserDN = Get-ADUser -Identity adrianr | Select-Object -ExpandProperty DistinguishedName  Get-ADPrincipalGroupMembership -Identity adrianr | ForEach-Object -Process {     $_ |     Get-ADReplicationAttributeMetadata -IncludeDeletedObjects -ShowAllLinkedValues -Server bhdc1 |     Where-Object -FilterScript {         $_.AttributeName -eq 'Member' -and $_.AttributeValue -eq $UserDN     } } | Select-Object -Property Object, FirstOriginatingCreateTime"
PowerShell,39rj2z,GLiMPSEiNATOR,1 point,Sun Jun 14 16:55:38 2015 UTC,"OP - this is what you need, its what we use to determine when admins were added on customer domains when we know auditing is not turned on."
PowerShell,39rj2z,kbick675,1 point,Fri Jun 19 20:31:36 2015 UTC,"You could probably do this even easier with import/export-clixml and just comparing for changes between the old and new at regular intervals. Nightly, hourly, whatever. A get-aduser -filter * -properties * would be your variable that you're writing out/in and then just have the script load the old, compare and save the new in the spot where you imported the old...  Probably get something going in a few hours, if you want to take it to the next level you use a db instead and keep historical logging.... A week more time and you can make this thing restore properties. Ba blam, or you could buy some off the shelf solution... But what's the fun in that?!?"
PowerShell,39pl1s,norbin,1 point,Sat Jun 13 14:46:50 2015 UTC,"I'm more of a trial and error kind of guy:  [CmdletBinding()] param()  $Root   = 'C:\' $Folder = '2012SG\event3' $File   = 'process3.txt' $Path   = { (Join-Path -Path $Root -ChildPath $Folder) }  if(-not(Test-Path (&$Path) -PathType Container)) {     try {         $FolderHandle = mkdir (&$Path)     } catch [UnauthorizedAccessException]{         $Root = [Environment]::GetFolderPath([Environment+SpecialFolder]::Desktop)         if(-not(Test-Path (&$Path) -PathType Container)){             $FolderHandle = mkdir (&$Path)         } else {             $FolderHandle = Get-Item (&$Path)         }     } catch {         throw $_     } } else {     $FolderHandle = Get-Item (&$Path) }  Write-Verbose ('Writing process list to file ""{0}"" in ""{1}""' -f $File,$FolderHandle.FullName)  Get-Process | Format-Table -Property Name,Id | Out-File -FilePath (Join-Path -Path $FolderHandle -ChildPath $File) -Force"
PowerShell,39pl1s,PowerShellStunnah,1 point,Sat Jun 13 17:20:23 2015 UTC,"Here are two passes I made to your script. The first just cleans up the syntax of the script. We each have our own style and it looks like you have not developed a consistent one yet. I recommend that you find a style and stick with it for the whole script. These samples show my style.  For example, you have a foreach with a nested if statement that is all mashed together.   The second example is just me taking your script and cutting from it things that may not be needed. You put a lot of effort into checking for permissions but you didn't do anything with the result. So if it fails, the scrip continues to run.    I tend to not use the global variables for verbose or debug output. I add the [cmdletbinding()] to the function and call -verbose to get that output. I also tend to use write-verbose for all output. I don't want to say not to use write-debug, but my style tends to not use it.  If my script is super simple then I fit it all in the process block.   The third example is me over engineering your solution. I try to make all my functions work by taking pipeline input even if I think they don't need that at the time. More advanced stuff but it is common that i have more code defining all my parameters than I have inside my functions.   $VerbosePreference = 'Continue' $DebugPreference = 'Continue' $WarningPreference = 'Continue'  $Root = ""C:\"" $Folder = ""C:\2012SG\"" $NestedFolder = ""C:\2012SG\event3\"" $FullPath = ""C:\2012SG\event3\process3.txt""  function Get-MyProcess {     begin     {         $TestFolder = ($Root+""TestFolder""+(Get-Random -Minimum 1 -Maximum 1000))         Write-Debug ('Checking if user ""{2}\{1}"" has permissions to create a folder under the root drive ""{0}""' -f $Root, $env:USERNAME, $env:COMPUTERNAME)           Start-Sleep -s 3          $RootPermission = New-Item -Path $TestFolder -ItemType Directory -Force | Out-null          if ($RootPermission = $false)         {             return Write-Warning ('User ""{2}\{1}"" DOES NOT have permissions to create a folder under the root drive ""{0}""' -f $Root, $env:USERNAME, $env:COMPUTERNAME)         }         else         {             Write-Verbose ('User ""{2}\{1}"" has permissions to create a folder under the root drive ""{0}""' -f $Root, $env:USERNAME, $env:COMPUTERNAME)         }          Write-Debug ('Deleting the TestFolder we just created ""{0}""' -f $TestFolder)          Start-Sleep -s 3          $RootFolders = Get-ChildItem $Root -Directory          foreach ($ToDeleteFolder in $RootFolders)         {                     $Timecreated = ((Get-date) - $ToDeleteFolder.CreationTime).Minute              if ($Timecreated -lt 2 -and $ToDeleteFolder.FullName -match ""TestFolder*"")             {                 $ToDeleteFolder.Delete()             }         }          Write-Verbose ('TestFolder ""{0}"" successfully deleted' -f $TestFolder)         Write-Debug ('Checking if file ""{0}"" exists' -f $FullPath)          Start-Sleep -s 3          if (Test-Path -Path ($FullPath))         {              Write-Verbose ('""{0}"" exists, continuing to Process' -f $FullPath)          }         else          {             Write-Warning ('""{0}"" DOES NOT exist,' -f $FullPath)             Write-Debug ('Creating subfolders ""{0}""' -f $NestedFolder)              New-Item -Path $NestedFolder -ItemType Directory -Force | Out-Null             New-Item -Path $FullPath -ItemType File -Force | Out-Null              Write-Verbose ('Successfully created ""{0}""' -f $FullPath)         }     }      process     {         Write-Debug ('Getting process list')         Start-Sleep -s 3          Get-Process | Format-table -AutoSize -Wrap -Property Name, Id | Out-File -FilePath $FullPath -Force          Write-Verbose ('Successfully exported process list into the file ""{0}""' -f $FullPath)     }      end     {         Start-Sleep -s 3         Write-Verbose (""I think we are done, peace out"")     } }  ##################################################################    function Get-MyProcess2 {     [cmdletbinding()]     param(         [string]$Folder = ""C:\2012SG\event3\"",         [string]$Path = ""C:\2012SG\event3\process3.txt""     )      process     {         if (!(Test-Path -Path $Folder))         {             Write-Verbose ('Creating subfolders ""{0}""' -f $Folder)             New-Item -Path $Folder -ItemType Directory -Force | Out-Null         }          Write-Verbose ('Getting process list')         Get-Process | Format-table -AutoSize -Wrap -Property Name, Id | Out-File -FilePath $Path -Force          Write-Verbose ('Successfully exported process list into the file ""{0}""' -f $Path)     } }  Get-MyProcess2  ############################################################################  <# .SYNOPSIS Saves current running processes into a text file .EXAMPLE Get-MyProcess3 -Path ""C:\2012SG\event3\process.txt"" .EXAMPLE Get-MyProcess3 ""C:\2012SG\event3\process.txt"" .EXAMPLE ""C:\2012SG\event3\process1.txt"",""C:\2012SG\event3\process2.txt""  | Get-MyProcess3 .NOTES  #> function Get-MyProcess3 {     [cmdletbinding()]     param(         # Param1 help description         [Parameter(             Mandatory,             Position          = 0,             ValueFromPipeline         )]         [Alias(""File"")]         [string[]]$Path = ""C:\2012SG\event3\process3.txt""     )      begin     {         Write-Verbose ('Getting process list')         $Process = Get-Process | Select-Object Name, ID     }      process     {         foreach($file in $path)         {             $Folder = Split-Path $file              if (!(Test-Path -Path $Folder))             {                 Write-Verbose ('Creating subfolder: ""{0}""' -f $Folder)                 New-Item -Path $Folder -ItemType Directory -Force | Out-Null             }              $Process | Format-table -AutoSize -Wrap -Property Name, Id | Out-File -FilePath $Path -Force         }     } }  Get-MyProcess3"
PowerShell,39pl1s,KevMar,1 point,Sat Jun 13 17:26:21 2015 UTC,"I like to keep things simple:  $filepath = ""~\2012SG\event3\"" $file = ""process3.txt"" if (!(Test-path $filepath)) {New-Item -Path $filepath -ItemType directory -Force:$false} try{get-process | select Name, ID | Out-File -filepath ""$filepath$file"" -NoClobber} Catch{}"
PowerShell,39pl1s,catfoodsci,2,Mon Jun 15 03:16:07 2015 UTC,"Your using a try..catch, which is great, but your not actually doing anything to handle errors.  I realize that this may have been a ""quick"" example, but with all the beginners that read this subreddit it's important to do it right.  Would have between better to leave it out all together."
PowerShell,39pl1s,jbtechwood,1 point,Mon Jun 15 10:32:51 2015 UTC,"For the new guys, there is an -erroraction param on these functions that can be used to suppress errors on individual commands."
PowerShell,39pl1s,KevMar,1 point,Mon Jun 15 12:28:05 2015 UTC,I originally attempted to use -erroraction but it does not work as the error thrown by out-file is terminating. Give it a try and you'll see what I mean.
PowerShell,39pl1s,catfoodsci,1 point,Mon Jun 15 13:07:11 2015 UTC,"I was following the instructions on producing no errors, but that being said I definatly get what you are saying about sharing scripts that are more helpful for beginners and don't lead to accidental frustration. I've updated it to optionally write the error if $VerbosePreference variable is changed.  $VerbosePreference = ""SilentlyContinue"" # to hide errors $filepath = ""~\2012SG\event3\"" $file = ""process3.txt"" if (!(Test-path $filepath)) {New-Item -Path $filepath -ItemType directory -Force:$false} try{get-process | select Name, ID | Out-File -filepath ""$filepath$file"" -NoClobber -EA SilentlyContinue} catch{write-verbose $_.Exception.Message}"
PowerShell,39ohqk,bundyfx,3,Sat Jun 13 06:23:23 2015 UTC,"Very few people are doing powershell YouTube content, so that's a great niche for you to capitalize on!   I haven't watched the video yet (morning time with a toddler) but I will, and I'll let you know what I think!"
PowerShell,39ohqk,1RedOne,1 point,Sat Jun 13 13:49:13 2015 UTC,Cheers mate!
PowerShell,39ohqk,chafe,2,Sun Jun 14 00:06:30 2015 UTC,It would be helpful if you added a description of what the script accomplishes in your post or in your blog so someone can determine if they want to watch the video or not. Google Maps has my interest though so I'll probably check it out.
PowerShell,39ohqk,Daslayah,2,Sat Jun 13 12:49:24 2015 UTC,Good call. updated my post with some useful information.
PowerShell,39ohqk,MDFreaK76,2,Sat Jun 13 13:29:39 2015 UTC,I love stuff like this. Can you post the source code please?
PowerShell,39nm65,Fade2black011,2,Sat Jun 13 01:09:00 2015 UTC,"Inside your foreach, you're referencing $vmx when I think you meant $vm.  That's why it's failing."
PowerShell,39nm65,a_pwrful_friend,1 point,Sat Jun 13 01:45:33 2015 UTC,"Actually, I just looked at the link you posted.  You can use their script just replace the (Get-VM) with (Get-Content file.txt) and it should work."
PowerShell,39nm65,a_pwrful_friend,1 point,Sat Jun 13 01:46:49 2015 UTC,Yep that worked.... doh.  Made it way harder than it needed to be.  Thanks man.
PowerShell,39nm65,TheGingerHairedMan,1 point,Sat Jun 13 01:55:22 2015 UTC,If that is all your code then the problem is you have not yet created the $vmx object when you use $vmx.extraconfig and your also not calling get-vm so it doesnt have any data to pass to the objects  Use the complete code from the example and swap out  ForEach ($vm in (Get-VM)){   for  ForEach ($vm in (Get-VM -Name (Get-Content c:\name.txt)){   By passing them to Get-VM it also validates that they can be found before running the code in the foreach.
PowerShell,39nfzx,tradras,3,Sat Jun 13 00:15:15 2015 UTC,Why not just use the start-service cmdlets?   Start-service $servicename -computername $server
PowerShell,39nfzx,veggie124,1 point,Sat Jun 13 00:29:01 2015 UTC,I did not know at the time that start-service could be used on remote machines.
PowerShell,39nfzx,veggie124,1 point,Sat Jun 13 00:34:31 2015 UTC,"Everyone is correct in that start-service doesn't have the computername switch, but you can pipe get-service (which does) to start-service."
PowerShell,39nfzx,JetzeMellema,1 point,Sat Jun 13 10:04:14 2015 UTC,I'm pretty sure Start-Service does not support the -ComputerName switch.
PowerShell,39nfzx,veggie124,1 point,Sat Jun 13 07:01:10 2015 UTC,Sorry about that. I'm on vacation. You can use get-service  $Service -computername $server | start-service
PowerShell,39nfzx,xenokira,1 point,Sat Jun 13 10:02:56 2015 UTC,"However, this does not work if you need to provide credentials as there's no -Credentials option for Get-Service. This is particularly important in multi-domain environments."
PowerShell,39nfzx,veggie124,1 point,Sat Jun 13 13:20:55 2015 UTC,Ah good point.
PowerShell,39nfzx,anklegrinder,1 point,Sat Jun 13 19:37:30 2015 UTC,"Doesn't provide a credential parameter is the main reason. Only somewhat reasonable other thing I can think of is that they may use different ports (RPC vs. WinRM), so in some companies firewalls may be an issue. Lastly, I'm not sure if get-service will run against 2003, but hopefully most of us have retired 2003 servers by now."
PowerShell,39nfzx,TheGingerHairedMan,3,Sun Jun 14 19:02:09 2015 UTC,"instead of  IF ($ServiceInput -eq ""IIS"") {$Service = ""W3SVC""}   ELSEIF ($ServiceInput -eq ""pipeline"") {$Service = ""pipeline""} ELSEIF ($ServiceInput -eq ""activityservices"") {$Service = ""activityservices""}  ELSEIF ($ServiceInput -eq ""billingserver"") {$Service = ""billingserver""}      Else {$ServiceInput = ""invalid""} }   you can use  switch($ServiceInput) {    ""IIS""               {$Service = ""W3SVC""}      ""pipeline""          {$Service = ""pipeline""}    ""activityservices""  {$Service = ""activityservices""}     ""billingserver""     {$Service = ""billingserver""}       default            {$ServiceInput = ""invalid""} }   Also for the credentials part of the script, this is something you can reuse in another script. Check out making them into functions and adding them to a module. Then you can call it from any script that you create"
PowerShell,39nfzx,GLiMPSEiNATOR,1 point,Sat Jun 13 02:28:13 2015 UTC,Thanks! I was not aware of switch but in reading about it I think I will use it.
PowerShell,39nfzx,t0xie,2,Mon Jun 15 23:10:06 2015 UTC,"I would also suggest using export-clixml and import-clixml for your $pw variable. Much more secure, although I've read(not tested) that it can only be successfully reimported by the user who was running the session at the time of export."
PowerShell,39nfzx,GLiMPSEiNATOR,1 point,Sat Jun 13 05:12:44 2015 UTC,"Not only is it only able to be successfully re-imported by the user who was running the session at the time of export, if the user changes their password it will also fail and need to be re-exported."
PowerShell,39nfzx,JetzeMellema,1 point,Sat Jun 13 05:57:16 2015 UTC,"Gotcha. In that case it may limit some use cases, but maybe this kind of credentialed 'tooling' solution should sit be executed in powershell via a service account?"
PowerShell,39nfzx,rpesta,1 point,Sat Jun 13 14:13:05 2015 UTC,"This may be an easier way to start or stop services on a remote server: PowerShell one-liner: Start a service on a remote server  Ideally you would use Start-Service, Stop-Service but those cmdlets don't support the -ComputerName parameter. Set-Service does."
PowerShell,39nfzx,ButterCupKhaos,1 point,Sat Jun 13 07:04:00 2015 UTC,I wrote a script some time ago and have just been too lazy to put it on my blog. The original script actually took commands from a specific email address and was able to remotely restart services via email. I cut down on the code and finally posted it on my blog. This might help you out.  http://ryanpesta.com/blog/2015/06/13/remotely-restart-services-in-powershell/
PowerShell,39krkj,sysadm1n,8,Fri Jun 12 12:26:53 2015 UTC,"Yes, this year was my second year : ) If I had a free ticket to Ignite, Build, and the PowerShell Summit, I would go with the summit.   Day one bits General takeaways   Excerpt from day one post:  ...  I'm not particularly social. I have a tough time starting conversations, or joining a group discussion. That being said, over the course of a pre-event-pub-gathering and the official first day, I've had the opportunity to talk to someone who (will have) contributed code to Windows, PowerShell MVPs galore, a number of talented folks who use PowerShell on a daily basis, and ended up sitting with a few PowerShell PMs for a 'hackathon' - more food and drinking than coding, thankfully for me.  I have a laundry list of ideas and technologies to check out when I get home, and this was the first day.  Oh. There's also a good deal of content, and being on site allows you to ask questions, and follow-up with the experts after the talks.  ...  /u/tommymaynard was there as well, and kept a more in-depth blog on his experience.  Cheers!"
PowerShell,39krkj,ramblingcookiemonste,1 point,Fri Jun 12 13:19:04 2015 UTC,"@RJasonMorgan   2015-04-20 20:12 UTC  Quote of the day, ""Dave's code is shipping with Windows."" @MSH_Dave @jsnover     This message was created by a bot  [Contact creator][Source code]"
PowerShell,39krkj,TweetsInCommentsBot,1 point,Fri Jun 12 13:19:09 2015 UTC,Thank you for all the information. I'm reading though it now. Looks like a great time!
PowerShell,39krkj,tommymaynard,1 point,Fri Jun 12 18:30:11 2015 UTC,"Thanks for linking my blog, Warren; I'm so glad all that writing didn't go to waste. It was awesome hanging out -- oh, and it was fun hearing you on the podcast. Me to myself, while listening: I know that guy.  The PowerShell Summit is like no other conference. If you didn't read my posts, it's pretty much like this: many of the smartest PowerShell people in the world, great sessions (with so much information), lunch while talking to Jeffrey Snover and Don Jones, dinner out with people you don't know, but you have an amazing time. You should definitely attend. It's intermediate to advance content, so know as much as you can, going in."
PowerShell,39krkj,alinroc,1 point,Fri Jun 12 18:34:20 2015 UTC,"oh, and it was fun hearing you on the podcast. Me to myself, while listening: I know that guy.   Yeah, that was fun when he was on the show. He even mentioned me (I haven't been to PoSH Summit, we just live in the same area & he's been to a few of my PASS-related events), even if he did pronounce my name wrong :)"
PowerShell,39krkj,1RedOne,1 point,Fri Jun 12 18:45:18 2015 UTC,"Hi Tommy! Are you on Twitter? If so, I should totally be following you!   E: nevermind, find and followed you! I remember meeting you at the summit! You did a great job on your write up, by the way."
PowerShell,39krkj,tommymaynard,1 point,Sat Jun 13 01:55:17 2015 UTC,"Yeah, you found me. It shouldn't have been too hard; I've only been following you for the last year. ;) It was awesome meeting you in person!"
PowerShell,39krkj,1RedOne,1 point,Mon Jun 15 15:05:39 2015 UTC,"Thanks for saying all of that!  When I met you at the time, I don't know how I failed to put the two together.  You're pretty much the only Tommy I know who does PowerShell too!"
PowerShell,39krkj,alinroc,2,Mon Jun 15 22:57:08 2015 UTC,Pretty sure /u/ramblingcookiemonste & /u/dlwyatt have.
PowerShell,39krkj,1RedOne,1 point,Fri Jun 12 13:19:44 2015 UTC,Did you go this year?
PowerShell,39krkj,alinroc,1 point,Sat Jun 13 01:55:43 2015 UTC,"I've never been, likely won't really ever get a chance. I'm more of a SQL guy of late."
PowerShell,39krkj,thebeersgoodnbelgium,2,Sat Jun 13 02:04:39 2015 UTC,"I missed the deadline last year, so I didn't get to go, but I went to the Dutch UG meeting the day after. Most of the people there had been at the Summit, and I heard nothing but great things about it.  If you get the chance, you should definitely go. The PowerShell community is extremely friendly, and there's a certain excitement that I really appreciate."
PowerShell,39krkj,mgjohansen,2,Fri Jun 12 13:59:38 2015 UTC,"Was at the Summit in Amsterdam last year. If you're interested in PowerShell - no matter how deep you knowledge on the subject is; this is the event to go to! It was great sessions all day long and in the evening as already mentioned, socializing and dinner with people you don't know. Looking forward to Stockholm this year."
PowerShell,39krkj,1RedOne,2,Fri Jun 12 18:51:21 2015 UTC,"I went, and it was awesome!  Everyone who does powershell is there and being all together in one spot, you can easily find a lot to talk about with anyone you happen to meet.   Some of my friends from here, like Warren (/u/ramblingcookiemonster) were there as well. We had a great time seeing each other, as were a number of people you'd know from Twitter and PowerShell.org.   So, from the people perspective, the crowd is wonderful.   The presentations and sessions were absolutely top notch as well, tons of great material was covers from the 200 to the 400 level. We got a sneak preview of server Nano (a week before Ignite and build) and were shown some secret stuff way to the public at large.   If you like PowerShell enough to post here, the summit should be your choice. After hearing what I heard about Ignite, I'd say it's the best Microsoft related conference (possibly tied with MMS, but only if you do enterprise client management).   Honestly, Warren already gave a better answer than I, but the Powershell summit was fantastic, and I plan to go again next year, for sure!"
PowerShell,39krkj,Lokkion,1 point,Sat Jun 13 01:53:46 2015 UTC,I'm going to the euro powershell summit this September :) cannot wait!!
PowerShell,39krkj,Iczer1,1 point,Fri Jun 12 18:33:18 2015 UTC,"I went to the North American one last year and highly enjoyed it. The small size means you get a lot of face time with some awesome and highly knowledgeable PowerShell people inside and outside of Microsoft. I missed this years and was sent to Ignite instead and really missed that chance the summit provided to easily talk to people like Jeffery Snover, Don Jones, etc on multiple occasions instead of being at the right place at the right time.  That being said I really did like the size and breath and overall excitement of Ignite. Also there was a lot of afterhours events going on at Ignite compared to the summit, which makes sense given the size different."
PowerShell,39o775,wasted_bytes,4,Sat Jun 13 04:26:00 2015 UTC,"Hi wasted_bytes,  Not saying its impossible although it would require a fair chuck of time to get something concrete that did such a task. A couple of reasons being that PowerShell and such formats as .PDF and .ppt are tricky to deal with. There is some extensions that can deal with PDF files (itextsharp) but that's mostly for reading/getting content.  If they are docx files then they are an OpenXML format. Several solutions exists of reading docx files from code without requiring Office. Most are in C# but translating that to PowerShell should prove little problems if you give it a go. Or have a go with PowerTools (http://powertools.codeplex.com/) for Open XML if you want to use PowerShell commands. Here is some more documentation on that subject http://ericwhite.com/blog/powertools-for-open-xml-expanded/.  Cheers"
PowerShell,39o775,bundyfx,1 point,Sat Jun 13 06:07:19 2015 UTC,"I've spent a couple of hours playing around with PS and have figured out how to open a .docx file, however opening a .pptx file is another story...  i was almost hoping that i could Frankenstein bits of code together to accomplish he task, but it seems that making a working script will be an involved task."
PowerShell,39o775,SeanQuinlan,2,Sun Jun 14 03:09:09 2015 UTC,"Is it possible? Definitely.  Is it worth the effort? Depends on how many files you're going to be processing.  If you have to process 10s of millions of files (or more), and it will take weeks or months to do by manually, then it might be worth it. But if you're a novice scripter, it will take you even longer to learn PS first, then to code up something, which will be very complex and time consuming to an experienced scripter.  For a few hundred files, you will spend longer learning the basics than just doing the work manually. Let alone coding up the script itself.  However you may consider using PS for just part of the work. For example, converting the PDF to DOCX should be possible (depending on how the PDF file is created). That might save you a bit of time for minimal effort. A google search shows up a lot of results, so that might be worth looking at."
PowerShell,39mobd,huyzee,2,Fri Jun 12 20:42:31 2015 UTC,"I don't like to overload the first powershell.exe command line - I never get quite what I want out of it. Error checking feels less predictable... if it returns a non-zero errorlevel you have to sort out if elevation failed or the script moved or if something in the script bombed or, or, or... meh.  I prefer to keep the logic in the powershell script. Add a call to force elevation as necessary to the start of the script and let it take care of things on its own.  I posted the elevation function I use here.   Another Option - instead of using a batch file directly, create a .LNK file to it with the ""run as administrator"" option checked. Then you get to start out in the right place and your script doesn't need to worry."
PowerShell,39mobd,ribond,1 point,Sun Jun 14 05:22:41 2015 UTC,Not quite sure what command you're actually running as the quote only shows  ps c:\users\company\desktop\initialsetup>
PowerShell,39mobd,derpinsteins_monster,1 point,Fri Jun 12 21:49:08 2015 UTC,Updated with .ps1 file
PowerShell,39mobd,derpinsteins_monster,1 point,Sat Jun 13 00:09:05 2015 UTC,"Out of curiosity, is there any reason why you aren't using the native powershell cmdlet for adding computers to a domain?"
PowerShell,39mobd,SomnambulicSojourner,1 point,Fri Jun 12 22:44:20 2015 UTC,"We have computers that I have no physical access to, so I'm always working with new users to get their machine on the domain remotely. So I'm trying to have them run the script so it's automated"
PowerShell,39mobd,astraburgan,1 point,Fri Jun 12 23:57:22 2015 UTC,"If you have network access, you should be able to run something like:  $domain = ""Domain"" $system = Get-WmiObject win32_computersystem -ComputerName $ip $compname = ""<usernamehere>-$($system.model)""  Rename-Computer $compname -ComputerName $ip  Add-Computer -DomainName $domain -ComputerName $ip    Minus the current users name, you should be able to do most of it remotely."
PowerShell,39mobd,SeanQuinlan,1 point,Sat Jun 13 00:25:17 2015 UTC,does running the script manually from the elevated Powershell session do anything? Running your batch file against one of my scripts worked perfectly each time. Without more information my guess would be there is a problem in the AddPC.ps1 script.
PowerShell,39ke1f,tomerc10,13,Fri Jun 12 09:55:36 2015 UTC,Well...you can also get your date's measurements?  Get-Date | Measure-Object   I'll show myself out...
PowerShell,39ke1f,replicaJunction,4,Fri Jun 12 14:04:07 2015 UTC,"Get-Command *date Get-Help | Get-Date Get-Date | Get-Member Measure-Command { Get-Date | Measure-Object }  # No. Days til Christmas Write-Output "" There are $(((Get-Date '12/25/2015') - (Get-Date)).Days) days remaining until Christmas"""
PowerShell,39ke1f,xalorous,8,Fri Jun 12 18:54:44 2015 UTC,In bash we just go straight to $ unzip; strip; touch; finger; grep; mount; fsck; more; yes; fsck; fsck; umount; sleep
PowerShell,39ke1f,thelerk,0,Fri Jun 12 19:42:03 2015 UTC,you're a bad person with a wicked mind  or I am  or both
PowerShell,39ke1f,xalorous,8,Fri Jun 12 20:26:59 2015 UTC,"Well, one thing that sets it apart from other languages is powershell remoting.   What other language allows you to get a list from active directory, connect to every one of them and have them all run the same command at the same time as easily as powershell?  Invoke-command -computer (get-adcomputer *).name -script { update-help}   That command would update the language documentation on every system and I wrote it from memory on my phone. I have no idea how to do that simpler and faster in any other language."
PowerShell,39ke1f,theb1g,5,Fri Jun 12 12:32:20 2015 UTC,"That sounds horrifying to me as I have 40,000 computers in my environment. But I guess it could be useful in a much smaller environment."
PowerShell,39ke1f,Get-ADUser,5,Fri Jun 12 13:26:17 2015 UTC,s/horrifying/hilarious
PowerShell,39ke1f,scuba7183,3,Fri Jun 12 13:41:38 2015 UTC,It would be super easy to batch
PowerShell,39ke1f,PsTakuu,3,Fri Jun 12 15:37:57 2015 UTC,"thats not the point. its logical and simple to do in powershell with descriptive verb-noun paired cmdlets that your everyday administrator can understand simply and execute on their system. with a very simple background in object notations ((get-adcomputer *).name), the everyday admin can turn the English sentence:  Run a command on each computer that updates the PowerShell help files.  into  Invoke-command -computer (get-adcomputer *).name -script { update-help}"
PowerShell,39ke1f,scuba7183,3,Fri Jun 12 15:57:22 2015 UTC,"I'm not arguing with you, I'm supporting you"
PowerShell,39ke1f,PsTakuu,2,Fri Jun 12 16:06:51 2015 UTC,"Actually you know what, this is should be an answer to OP's post."
PowerShell,39ke1f,theb1g,2,Fri Jun 12 15:58:25 2015 UTC,Oh I love powershell and write scripts in it all the time but I looked at that simple command and thought about what it could do in a large environment.
PowerShell,39ke1f,KevMar,2,Fri Jun 12 16:45:05 2015 UTC,It is beautiful in a small environment. Mine was 600 or so machines. Add in a Wake on Lan before any command and you really have something.  The biggest issue is that you think you are fixing every machine but not every machine is online or accessible at the time. So you still have to account for those cases.
PowerShell,39ke1f,theb1g,2,Fri Jun 12 20:01:39 2015 UTC,If(test-connection $computername){}  Has gotten me through a lot of situations.
PowerShell,39ke1f,KevMar,2,Fri Jun 12 20:33:42 2015 UTC,"I decided that I didn't care if they were online or not.  Get-ADComputer * | %{Invoke-Command -ComputerName  $_.name -AsJob -ScriptBlock {...}}   Because it was starting a job for each one, the offline jobs would fail and the others would not. Then I could use get-job to see where the failures were. I could save those to a file and run it again another time.  I was effectively multi-threading the work. Putting the delays and timeouts on another thread. My workstation could maintain the 600 or so concurrent sessions, but I am sure there is a limit (probably less than 40,000).   It is this job/multi threaded remoting of commands that I love."
PowerShell,39ke1f,alinroc,1 point,Fri Jun 12 21:51:03 2015 UTC,"Lol. That would be terrifying. You could target an ou or a subset easy enough. Once you have that many, I would hope that you have other tools in place.  But lets say you sccm server goes to shit and you have to rebuild it. Every thing works, except the clients won't connect. You find there is one command you need to run on the client to fix it. This is where you can turn to PowerShell to save you.  There was an issue where sccm clients broke when WMF 4.0 (or was it 3.0) was installed on x86 machines. MS pulled the update after 2 days. After removing the update, you had to run a command to fix it. We used powershell. If I didn't have that, I would have used psexec."
PowerShell,39ke1f,JaapBrasser,3,Fri Jun 12 14:11:08 2015 UTC,PowerScripting Podcat #218 - lots of one-liners with /u/midnightdba
PowerShell,39ke1f,savehonor,5,Fri Jun 12 12:48:13 2015 UTC,"Get-Command, Get-Help, Get-Member.  The speed with which you can learn how to use a new cmdlet, because of the extended and professional help that has been added to PowerShell makes it a great language."
PowerShell,39ke1f,JaapBrasser,2,Fri Jun 12 11:42:33 2015 UTC,"$heart = [char]3 Write-Host ""Because, PowerShell "" -NoNewline Write-Host $($heart) -ForegroundColor ""red"" -NoNewline Write-Host ""s you!"""
PowerShell,39ke1f,savehonor,1 point,Fri Jun 12 15:34:39 2015 UTC,This is the character code you are looking for:  [char]0x0003
PowerShell,39ke1f,xalorous,1 point,Mon Jun 15 07:51:17 2015 UTC,"Yeah, much better (more correct/less ambiguous) way of doing it. The way I had it works for me though."
PowerShell,39ke1f,chrgeorgeson1,1 point,Mon Jun 15 14:38:41 2015 UTC,"$heart = [char]3  Write-Host ""Because, PowerShell "" -NoNewline  Write-Host $($heart) -ForegroundColor ""red"" -NoNewline  Write-Host ""s you!""   Yeah, non-printing character.  Nice try though."
PowerShell,39ke1f,Computermaster,2,Fri Jun 12 18:56:35 2015 UTC,"Speaking of get-date,  powershell 4.0 has new-timespan cmdlet and it rocks for time/date comparison."
PowerShell,39ke1f,TAz00,2,Fri Jun 12 15:45:49 2015 UTC,"Because it's as easy as taking candy from a baby.  $candy = ""delicious""  Get-ChildItem $candy"
PowerShell,39ke1f,jheins3,3,Tue Jun 16 19:49:14 2015 UTC,"Because there's always a frustrating quirk whenver you try to handle a specifc task, which sets you off on a wild goosechase for the 'correct' way"
PowerShell,39ke1f,malice8691,1 point,Fri Jun 12 12:57:35 2015 UTC,I'd say benefits is syntax is easy to read/understand. Its similar to bash and easy for a professional administrator to pick it up from Linux. Automation is easy and remotely controlling computers/programs that arent programmed to be remotely accessed. Object oriented. That's all I got
PowerShell,39ke1f,dmgctrl,3,Fri Jun 12 11:52:02 2015 UTC,I have had a hiatus from powershell for the last 2 years and have been doing python. I recently had to write a powershell script  and could not believe how difficult it was to read/understand. Also the equivalent of remoting in python is ssh which works very well. I'm not trying to be a jerk but just going from powershell to python and now back to powershell made me realize just how lackluster powershell is.
PowerShell,39ke1f,JaapBrasser,2,Fri Jun 12 12:40:30 2015 UTC,"This happens no matter the language. If you do powershell for 6 months then go back to python, python will be impossible to read."
PowerShell,39ke1f,malice8691,1 point,Fri Jun 12 14:13:02 2015 UTC,"I guess it's a personal preference, there's pro's and con's for every language. I do think it's hard to argue against PowerShell in an environment with predominantly Microsoft infrastructure, as it is so ubiquitous."
PowerShell,39ke1f,xalorous,2,Fri Jun 12 12:49:32 2015 UTC,"Exactly. The best language on a windows server is powershell, and the reason I had to write a powershell script recently was because I moved from supporting a linux environment to a windows server environment. But I must admit, while strugling to write that simple powershell script I briefly thought about doing it in python. :)"
PowerShell,39ke1f,malice8691,1 point,Fri Jun 12 13:12:27 2015 UTC,Also the equivalent of remoting in python is ssh which works very well.    Invoke-Command doesn't do the trick?
PowerShell,39ke1f,ramblingcookiemonste,1 point,Fri Jun 12 18:57:59 2015 UTC,"not everything works over a winrm connection for example :  Working with the windows update interfaces simply don't work.  Accessing network resources like network shares, databases or web sites that normally leverage your current windows logon context  will fail unless using the correct authentication protocol  Installing MSIs or other installers that depend on either of the above  resources (SQL Server, most .Net Framework installers) will not install successfully"
PowerShell,39ke1f,bakunin,1 point,Fri Jun 12 21:34:28 2015 UTC,"Hi!  It's not the best language in the world, nothing fits that description : )  That being said, here are some reasons why PowerShell is quite nice.  There are others for sure, but those sum it up for me.  Cheers!"
PowerShell,39ke1f,RulerOf,1 point,Fri Jun 12 13:25:25 2015 UTC,Because it powersHell.
PowerShell,39ke1f,tehjimmeh,1 point,Fri Jun 12 18:09:24 2015 UTC,"If hell runs on Windows, then slap me silly and call me Job.  It can't be that nice... I'd bet it runs the Hurd, and all the code is written in Lisp and Brainfuck."
PowerShell,39mmit,joerod,2,Fri Jun 12 20:29:47 2015 UTC,"I didn't go through all of that, but you don't have to use ""ConvertTo-Html"" right there at the end.  ""ConvertTo-Html"" takes a .NET object as input and outputs an HTML string.  Your string is already HTML, you just need to write it to a file."
PowerShell,39mmit,JewStyleKungfu,1 point,Fri Jun 12 21:05:18 2015 UTC,Thanks for the idea I ended up removing the ConvertTo-Html and it worked.
PowerShell,39mkzg,Bliss86,1 point,Fri Jun 12 20:18:46 2015 UTC,"Replace activate.bat in the batch file to   Powershell -file ""c:\path\to\activate.ps1""   Obviously you can use those environment variables to point the correct path"
PowerShell,39lfiu,Pr0xyWash0r,2,Fri Jun 12 15:36:36 2015 UTC,"You have to wrap references to sub objects when evaluating in strings  $myUser = @{ ""Name"" = ""Fred"" } Write-Host ""$myUser.Name""   Will give @{Name=Fred}.Name as it only evaluates $myUser as the object  to get what you want you need to pre-evaluate it ...  $myUser = @{ ""Name"" = ""Fred"" } Write-Host ""$( $myUser.Name )"""
PowerShell,39lfiu,real_parbold,2,Fri Jun 12 15:48:01 2015 UTC,"Another way to expand the property is by expanding it when you select it:  $userFolders = Get-ChildItem \\FileSVR\Homes$\ | Where{PSIsContainer -and $_.Name -like 'jsmith'} | Select-Object -ExpandProperty Name $userFolders | ForEach-Object { Set-ADUser -Identity $_ -HomeDrive 'H' -HomeDirectory ""\\FileSVR\Homes$\$_"" }   Select-Object -ExpandProperty $Object gives just the value.  Also another way to combine the two lines into a one-liner, getting rid of the variable $userFolders:  Get-ChildItem -Directory -Filter 'jsmith' | Foreach { Set-ADUser -Identity $_.Name -HomeDrive 'H' -HomeDirectory ""\\FileSVR\Home$\$($_.Name)"" }   -or, using aliases since this is a CLI oneliner-  gci -Directory -Filter 'jsmith' | % {Set-ADUser -Identity $_.Name -HomeDrive 'H' -HomeDirectory ""\\FileSVR\Home$\$($_.Name)"" }   2 different ways to expand the property.     $() parens forcing evaluation explicitly expanding the property using Select -ExpandProperty   /u/Pr0xyWash0r, you should avoid using aliases in scripts, especially if you want to be able to go back to them in 6 months and be able to read them.  Aliases often make them more difficult, at least more time consuming, to puzzle out.  Also, using Get-ChildItem with -Directory and -Filter 'string' will cause PS to only store in memory matches.  No big deal if you're working with 20 folders.  But if you've got 200, or 2000, you'll want to filter as soon as possible.  Normally, I say keep things as objects as long as possible, passing the directory objects is fine, but if you're going to be removing the username filter and running against all of the folders and you have thousands of folders, I'd recommend something like:  $Server = 'FileSVR' $UserFolders = Get-ChildItem -Directory | Select -ExpandProperty Name Foreach ($User in $UserFolders) {     Set-ADUser -Identity $User -HomeDrive 'H' -HomeDirectory ""\\$Server\Home$\$User""  }"
PowerShell,39lfiu,xalorous,1 point,Fri Jun 12 19:17:51 2015 UTC,This worked perfectly Thank you!
PowerShell,39l4vb,enchanted_salad,4,Fri Jun 12 14:20:35 2015 UTC,"Didn't test, but something like this  $Cases = Get-Content X:\Cases | ?{ $_.PSIsContainer } foreach ( $Case in $Cases ) {     New-Item -Path $Case.FullName -Name Archive -ItemType Directory     $ArchiveDirectory = Join-Path $Case.FullName 'Archive'     $Subfolders = Get-ChildItem $Case.FullName | ?{ $_.PSIsContainer }     foreach ( $Subfolder in $Subfolders ) {         if ( $SubFolder.Name -le '2011' ) {              Robocopy $Subfolder.FullName $ArchiveDirectory #Whatever parameters you want.         }     } }   Edited to utilize ?{ $_.PSIsContainer } to confim that the ChildItem is a directory and not a file."
PowerShell,39l4vb,ShwnStrmn,3,Fri Jun 12 15:19:26 2015 UTC,"If you have PowerShell 3.0 or later, change  $Cases = Get-Content X:\Cases | ?{ $_.PSIsContainer }   To  $Cases = Get-ChildItem X:\Cases -Directory   And Change   $Subfolders = Get-ChildItem $Case.FullName | ?{ $_.PSIsContainer }       To   $Subfolders = Get-ChildItem $Case.FullName -Directory   Changing from a command that lists directories then filters them to a command that loads a filtered list of directories will have a significant performance boost with 1337 (LEET!) folders.  Plus it is more understandable in a self-documenting code sense."
PowerShell,39l4vb,xalorous,1 point,Fri Jun 12 20:46:40 2015 UTC,Cheers!
PowerShell,39l4vb,xalorous,2,Tue Jun 16 08:49:07 2015 UTC,"Thanks! Im on my phone right now, i'll decypher and test it asap."
PowerShell,39lfwy,eugene5786,1 point,Fri Jun 12 15:39:11 2015 UTC,"In Exchange 2010 SP1 and higher (I believe), you cannot delete content from specific folders without using EWS.  The following works in Exchange 2010 SP3 RU 8v2 and is analogous to your last command:  Search-Mailbox -Identity userid -SearchQuery ""received:>12/31/2014"" -DeleteContent   This will delete all items NEWER than December 31, 2015 in the specified mailbox. If you aren't sure you want to actually get rid of them for real, this will delete them from the specified mailbox but copy them to the target mailbox:  Search-Mailbox -Identity userid -SearchQuery ""received:>12/31/2014"" -TargetMailbox targetuserid -TargetFolder foldername -DeleteContent   I created this script awhile ago to delete anything in DeletedItems older than a specified date. It uses EWS. It should be possible to change the folder to any other default folder in the mailbox: Script"
PowerShell,39lfwy,RickSaysMeh,1 point,Fri Jun 12 16:05:08 2015 UTC,"So the command would be ""received:<12/31/2014"""" for anything before?"
PowerShell,39lfwy,RickSaysMeh,1 point,Fri Jun 12 16:10:07 2015 UTC,"Yes, although I like to hedge my bets and use a rage like this:  ""received:1/1/1970..12/31/2014""   That would include any items between and including* those two dates. But that is just received, if you wanted to clear out sent as well:  ""received:1/1/1970..12/31/2014 or sent:1/1/1970..12/31/2014""   That will include any items in the entire mailbox that were sent or received prior to and including* 12/31/2014.      May not include that date. Not 100% sure."
PowerShell,39lfwy,xalorous,1 point,Fri Jun 12 17:16:19 2015 UTC,Thank you very much! That worked out well!
PowerShell,39kjkk,Swarfega,1 point,Fri Jun 12 11:02:09 2015 UTC,"Based on the comments then it looks like really I just need to be looking at the LastLogonDate property and filtering in the right place.  $90Days = (Get-Date).AddDays(-90) Get-ADUser -Filter {LastLogonDate -lt $90Days} -SearchBase ""OU=Users,DC=domain,DC=local"""
PowerShell,39kjkk,kcbwya77,1 point,Fri Jun 12 13:28:13 2015 UTC,List Inactive Users in Active Directory http://bwya77.com/knowledge-base/list-inactive-users-in-active-directory/  you can also export it to a CSV
PowerShell,39kjkk,the_spad,1 point,Fri Jun 12 15:45:02 2015 UTC,"If you have SSO in your environment, keep in mind that LastLogonDate and LastLogonTimestamp won't increment. Find the domain controllers utilized by SSO, get LastLogon (non-replicated attribute for the given user object) and use W32Tm /NTTE to convert the time."
PowerShell,39kjkk,After_8,1 point,Fri Jun 12 22:18:25 2015 UTC,lastlogontimestamp where logoncount is greater than 0  Don't use lastlogon as thats unique to each domain controller and so could give you incorrect results depending on your network configuration.  Or just use  Search-ADAccount -AccountInactive -TimeSpan 90
PowerShell,39kjkk,the_spad,3,Fri Jun 12 11:17:34 2015 UTC,"Note that the LastLogonDate attribute that OP's using is just Get-ADUser's friendly conversion of LastLogonTimeStamp to a datetime object, so can be used safely."
PowerShell,39kjkk,xalorous,1 point,Fri Jun 12 12:16:30 2015 UTC,"Ah, fair enough, I misread it."
PowerShell,39kjkk,the_spad,2,Fri Jun 12 13:00:57 2015 UTC,"And keep in mind that lastlogontimestamp is only replicated if it is off by more than 9-12 days.  Which means that you should probably do a check on the accounts before doing anything drastic.  So maybe something like this:  Setup:   Create a disabled users OU. Filter for accounts over 60 days. Use an extended property, or an unused one, to store the name of the origin OU. Move stale accounts to the disabled users OU.   Regular process:    Accounts -ge 90 days old, do a round robin check of dc's vs lastlogon (not last logon timestamp) to ensure they didn't sneak in a logon.  Restore them if they did.  Export stale account data get-aduser -properties * | export-csv -notypeinformation ""\\path\to\archive\$($_.samaccountname).csv"" and delete the account.  You may want to take steps to list the groups and add them as part of the dump.  You may want to limit the information dumped.  I hate deleting account without a way to get it back.  Accounts older than 60 days go in the disabled users OU.  Send them an email first.  ""Your account is stale and will be deleted in 30 days if you do not do [blah blah blah procedure].""  Accounts older than 30 days get a warning by email.  ""Your account has not been used in 30 days.  If it reaches 60 it will be disabled and at 90 days it will be deleted.  Please log in to refresh your account.""  Repeat every 30 days.   Added round-robin  Give support staff permissions and instructions on how to recover account (look in the notes field and move the account to that location and ensure the user can log on)."
PowerShell,39kjkk,sphinxpup,1 point,Fri Jun 12 20:57:30 2015 UTC,"Thing is, assuming you're not still running a 2003 functional level domain (in which case, God help you anyway) the AD Recycle Bin provides all the CYA you need. Not much point emailing them either unless your mail system is decoupled from your AD, as they would otherwise have to authenticate to their account to access their mail.  And LLTS is perfectly safe to use as long as you're dealing with periods longer than 14 days. If you're disabling accounts that haven't been used in 90+ days then the LLTS replication offset just isn't a concern because (all things being equal) it's not possible for them to have logged in more recently without updating the LLTS."
PowerShell,39kjkk,xalorous,2,Fri Jun 12 22:04:54 2015 UTC,I wasn't ware of this command. Thanks for the heads up. The TimeSpan parameter seems to be ignored though. I get the same number of results regardless if I use or don't use it.
PowerShell,39kjkk,JaapBrasser,1 point,Fri Jun 12 12:27:11 2015 UTC,I believe it has to be like this:     Search-ADAccount -AccountInactive -TimeSpan 90.00:00:00
PowerShell,39kjkk,JaapBrasser,1 point,Fri Jun 12 17:56:00 2015 UTC,"Check my other comment for a description of a cautious way of doing this.  I used 30/60/90, but you can use whatever."
PowerShell,39kjkk,JaapBrasser,1 point,Fri Jun 12 21:04:41 2015 UTC,"For a more efficient query, I would recommend that you filter in the first cmdlet instead of using Where-Object. For example by using a LDAPFilter or a Filter parameter for the Get-ADUser cmdlet. I have written a similar post on retrieving users with unchanged passwords for 90 days, feel free to borrow the code from my post: Active Directory Friday: Find user accounts that have not changed password in 90 days"
PowerShell,39kjkk,xalorous,2,Fri Jun 12 11:40:39 2015 UTC,I have no idea why I completely ignored the fact I used -Filter * then to only filter it later down the pipeline.  Thanks for pointing this out!
PowerShell,39kjkk,JaapBrasser,2,Fri Jun 12 12:41:30 2015 UTC,"No problem, you can speed up your queries significantly and also place less load on your Active Directory infrastructure as your queries are returning less results."
PowerShell,39l787,ephos,2,Fri Jun 12 14:38:15 2015 UTC,You're missing the PSDesiredStateConfiguration module from this statement...  Import-DscResource –ModuleName ’PSDesiredStateConfiguration’   Check to make sure the module name is correct. If you're using the resource kit most likely you need to change it to 'xPSDesiredStateConfiguration'
PowerShell,39l787,phiber232,1 point,Fri Jun 12 15:35:06 2015 UTC,"I tried to change the name, I also tried having both resources imported making sure 'xPSDesiredStateConfiguration' was on the server that was trying to pull its configuration but still got the error.  I thought that 'PSDesiredStateConfiguration' was part of PowerShell 4 and on all machines which is why I have been so confused in the error that its throwing when it tries to do its pull."
PowerShell,39l787,phiber232,2,Fri Jun 12 16:11:02 2015 UTC,"Assuming you used the defaults when setting up your pull server, make sure the xPSDesiredStateConfiguration module is in the folder C:\Program Files\WindowsPowerShell\DscService\Modules with the checksum file as well. Remember you also need the version number on the end of the zip file.  Goodluck, I've moved away from DSC and went to puppet because of these types of issues and difficulty in debugging modules."
PowerShell,39l357,Elementix,1 point,Fri Jun 12 14:07:03 2015 UTC,"You're not foreaching the right thing, which is why it's not working with multiple folders.   ForEach-Object{ New-Share -foldername $foldername -sharename $($sharename + ""$"")}    Foreach what? It doesn't have any way to know. Try:  Get-ChildItem -Path c:\Home | ?{ $_.PSIsContainer } | %{New-Share -foldername $_.fullname -sharename ""$($_.name)`$""}   Edit: In 2012/Win 8 there's the Grant-SMBShareAccess cmdlet for share permissions, prior to that it's really fiddly to set them with Powershell. There's also a New-SMBShare to create the share in the first place."
PowerShell,39l357,the_spad,1 point,Fri Jun 12 14:23:25 2015 UTC,"Awesome! That at least gets the folders shared...I'm still running Server 2008 r2, so yea...can't get any of those nice new commands to make this easy...  I'm assuming by your comment, there's a way to set the share permissions...just difficult, or you don't know how to accomplish it?"
PowerShell,39l357,the_spad,1 point,Fri Jun 12 17:10:20 2015 UTC,"Looks like the common way to do it is either by using WMI, which looks remarkably convoluted, or using Net Share, which doesn't appear have a way to set permissions other than if you use it to create the share in the first place."
PowerShell,39kjxv,Otacrow,6,Fri Jun 12 11:06:10 2015 UTC,"As a rule, domain users have read permissions to the vast majority of the domain, what specifically are you trying to grant them access to?"
PowerShell,39kjxv,the_spad,1 point,Fri Jun 12 11:18:35 2015 UTC,"I support this, any user can by design read any object/attribute in Active Directory. So if reading AD is your requirement, New-ADUser is all you need..."
PowerShell,39kjxv,JaapBrasser,1 point,Fri Jun 12 11:30:27 2015 UTC,I'm just blindly following a document detailing a service accounts AD delegation rights. It mentiones granting Read permissions as well as other stuff.
PowerShell,39kjxv,the_spad,1 point,Thu Jun 18 08:47:58 2015 UTC,"You need to be very careful with delegating rights in AD, especially if you're doing it at or near the root as they can easily break things and are frequently difficult to unpick at a later date.  With the exception of some really shitty systems like Blackberry Enterprise Server, there shouldn't generally be a need to fiddle with AD delegation too much from an application/service account perspective."
PowerShell,39kjxv,fonzie588,1 point,Thu Jun 18 08:54:19 2015 UTC,"I had been struggeling with this for the better part of two hours, and 5 minutes after posting, I found the solution.  Create a null guid:  $nullGUID = [guid]'00000000-0000-0000-0000-000000000000'   Then add the null guid to the acl AddAccessRule:  # Give read rights to everything $acl.AddAccessRule((New-Object System.DirectoryServices.ActiveDirectoryAccessRule $p,""ReadProperty"",""Allow"",""All"", $nullGUID))   Then it works, finally."
PowerShell,39kir7,paul_emploi,1 point,Fri Jun 12 10:52:48 2015 UTC,You'll need to parse the PropertyItems and find the value of the ExifDTOriginal tag. MSDN has an example here of how to read the metadata: https://msdn.microsoft.com/en-us/library/xddt0dz7.aspx
PowerShell,39kir7,PowerShellStunnah,1 point,Fri Jun 12 10:58:48 2015 UTC,"I already have a bit of code using The ProperItems, I'll try to parse them.  Thanks"
PowerShell,39kir7,JaapBrasser,1 point,Fri Jun 12 11:04:18 2015 UTC,"You could also look into the extended file attributes. I wrote a script to help you retrieve those, it is available in the Microsoft TechNet Script Gallery: Get-ExtensionAttribute"
PowerShell,39hxh6,1RedOne,3,Thu Jun 11 20:54:21 2015 UTC,"I've been meaning to play around with the Partial Configs as well so would love to see that article.  In my opinion the single MOF file is the DSC weakness and I think Partial Configs may be the solution based on my current understanding.  What you would/should want is a Baseline DSC configuration file (Partial Config:Baseline) that sets your independent OS policies and settings. Then you should want your Role specific configuration files that install your Windows Features and setup the role specific config (Partial Config:DHCP). So when you deploy a config via Push or Pull you should be able to do something like Deploy-Config -ConfigFiles {Baseline, DHCP, DC, Bleh}. And DSC will read all the separate configs and put them into one unique MOF essentially at run/deploy time.  I've been thinking about building a open source solution specifically for DSC and this purpose."
PowerShell,39hxh6,ButterCupKhaos,1 point,Fri Jun 12 02:11:51 2015 UTC,"The tricky part as I see it is that you can only do partial configs when you have a pull server.  That's not hard to set up, but its an extra layer of complexity.  And then layering the configs is...bleh.  It's like managing group policy inheritance with no Group Policy Management console.  I feel like I'm working with the raw API and just hoping someone comes along to write to GUI for me to make this all easier.    Build it, man!"
PowerShell,39hxh6,Krunk_Fu,1 point,Fri Jun 12 13:23:03 2015 UTC,"Hey guys, I didn't forget about you.  I've finally finished my one-click Domain Controller build here on the ol' blog.  If you haven't seen the series, that's fine, this is a great starting point for anyone interested in DSC, or who just wants to get a domain controller up and running in the minimal amount of time and worry!"
PowerShell,39hxh6,Ana_Ng,1 point,Thu Jun 11 20:55:15 2015 UTC,Just wanting to say first time seeing this and I really like what you're doing.  Found myself in the GUI section and I'll be playing around with that now.  Keep up the great work!
PowerShell,39hxh6,iwantagrinder,1 point,Thu Jun 11 22:34:40 2015 UTC,"Thanks!  I feel like this is stuff I should be able to understand, and will need to understand, so I challenge myself to learn it enough to teach it to others.  I actually learn a lot by presenting info to others, so it's a win-win, I think!"
PowerShell,39hxh6,RulerOf,0,Fri Jun 12 13:24:19 2015 UTC,"Typo alert: in paragraph for dhcp configuration, ""DHCP score"" should be ""DHCP scope""."
PowerShell,39jpnp,LarryBobson,4,Fri Jun 12 05:12:27 2015 UTC,"I'd suggest starting with PowerShell App Deployment Toolkit. It's designed to work with SCCM and works fine by itself or with MDT, and it does everything you want and lots of extras."
PowerShell,39jpnp,connava,2,Fri Jun 12 06:32:30 2015 UTC,Upvoted. PADT is the tits.
PowerShell,39jpnp,Freon424,1 point,Fri Jun 12 10:08:37 2015 UTC,"Would you say ''The tits"" is better than ""the shit""?"
PowerShell,39jpnp,xStimorolx,1 point,Fri Jun 12 10:38:40 2015 UTC,This looks perfect. Thank you!
PowerShell,39jpnp,pouncer11,2,Fri Jun 12 12:14:00 2015 UTC,"Just had a look through the guide. Got to say, very impressed with this."
PowerShell,39jjg1,nits3w,4,Fri Jun 12 04:13:34 2015 UTC,How 'bout this one: Learn Active Directory Management in a Month of Lunches by Richard Siddaway.  It teaches AD using the GUI and PowerShell.
PowerShell,39jjg1,MShepard70,2,Fri Jun 12 13:07:48 2015 UTC,"The MoL series are generally a good place to start, I've found them to be well written and a great way to learn in a well structured manner."
PowerShell,39jjg1,notatomic,2,Fri Jun 12 14:38:04 2015 UTC,"Disclaimer: Do not have the book, have only skimmed through in passing. Ignore me  PS 2.0 is ageing now, and there are alot of new AD cmdlets with 3/4.0 that took away alot of the pain points from the early days. I'd say you would be better off with a more updated PowerShell fundamentals book to teach you the core ""language"" then you can easily look around TechNet to see all the AD Specific cmdlets for your automation needs."
PowerShell,39jjg1,ButterCupKhaos,1 point,Fri Jun 12 06:04:54 2015 UTC,Sounds like a better way to go.  Thanks!
PowerShell,39jjg1,JaapBrasser,2,Fri Jun 12 17:01:19 2015 UTC,"Active Directory didn't really change the past few years. The domain functional levels / forest functional levels have not added any new features in recent versions of Windows. I think it would still be a solid option. I released a free ebook from my own blog articles as well, feel free to check it out:  Active Directory Friday Tips Bundled"
PowerShell,39jjg1,connava,2,Fri Jun 12 07:06:47 2015 UTC,"Along with /u/ButterCupKhaos I wouldn't bother getting a book on a specific part of PowerShell like AD. If you're new to the language then you'd be better off getting to know the language well. Once you know the language then managing AD isn't very different from anything else. You load the module (even this step is optional):  Import-Module ActiveDirectory   Then you can use Cmdlets such as:  New-ADUser Get-ADGroupMember Remove-ADComputer   I think the most recommended beginners book (which I like as well) was: Learn Windows PowerShell in a Month of Lunches. I'm now part of the way through Learn PowerShell Toolmaking in a Month of Lunches. I've also heard good things about PowerShell in Depth. There are lots of free resources out there as well, check the sidebar of this subreddit."
PowerShell,39jjg1,connava,1 point,Fri Jun 12 13:09:54 2015 UTC,Very valid point. That makes more sense.  Thanks!
PowerShell,39hv59,RickSaysMeh,3,Thu Jun 11 20:39:42 2015 UTC,"Quick optimization tip:    inside Simple-Gui  $ArrayOfButtons[$i].Tag = $ListOfScript[$i].FullName;   Then inside button_onClick, ditch the loop and get the filename using    $this.Tag"
PowerShell,39hv59,supermamon,1 point,Fri Jun 12 00:10:28 2015 UTC,"That's pretty nice.  Also, if you want the scripts to launch in the same session as the GUI, just change  Start-Process PowerShell -ArgumentList ""-File `""$($this.Tag)`""""   to  . ""$($this.Tag)"""
PowerShell,39flj5,marzme,3,Thu Jun 11 11:48:25 2015 UTC,Nice collection! Would be cool if you had a screenshot for each in the readme.md :)
PowerShell,39flj5,MattHodge,4,Thu Jun 11 12:29:14 2015 UTC,"There's an example screenshot in each of the folders, but great idea, will definitely put them in the readme also soon!"
PowerShell,39flj5,MattHodge,1 point,Thu Jun 11 12:37:17 2015 UTC,Man you are on top of it!
PowerShell,39flj5,MattHodge,3,Thu Jun 11 12:47:50 2015 UTC,Done now. Thanks for the suggestion. :)
PowerShell,39flj5,mav_918,1 point,Thu Jun 11 13:08:25 2015 UTC,Thanks you :) Looks great.
PowerShell,39flj5,MortoftheHillPeople,2,Thu Jun 11 13:31:38 2015 UTC,Tried out the VS 2013 Dark one and I had to make one small adjustment. Semi-Colons are pretty much black (at least they were on my monitor) - I changed them to dark orange and it seems to work much better.
PowerShell,39flj5,MDFreaK76,1 point,Thu Jun 11 19:00:48 2015 UTC,Can't see the semicolon in the screenshot either.
PowerShell,39flj5,kcbwya77,1 point,Thu Jun 11 20:05:42 2015 UTC,Thanks for letting me know. Now fixed with MortoftheHillPeople's assistance. :)
PowerShell,39flj5,accountnumber3,2,Fri Jun 12 00:01:10 2015 UTC,"Sweet! Now, who wants to write the auto-import function? :-)  edit: looks like this guy beat me to it! He's got a few additional themes as well."
PowerShell,39flj5,rngr,1 point,Thu Jun 11 20:11:14 2015 UTC,Nice find!
PowerShell,39flj5,MortoftheHillPeople,1 point,Fri Jun 12 00:08:22 2015 UTC,I love it
PowerShell,39flj5,gangstanthony,1 point,Thu Jun 11 14:19:51 2015 UTC,Pretty...
PowerShell,39flj5,bundyfx,1 point,Thu Jun 11 15:35:11 2015 UTC,Nice! All my favorite themes are there. Obsidian is installed now; I'll have to try out some others later.  Thanks for sharing :)
PowerShell,39ityv,Setsquared,1 point,Fri Jun 12 00:43:50 2015 UTC,"That is a lot of people, would seem like more hassle than its worth."
PowerShell,39ityv,iwifia,1 point,Fri Jun 12 06:18:47 2015 UTC,That would be cool!
PowerShell,39hquz,ERROR_EXIT,2,Thu Jun 11 20:12:48 2015 UTC,"Yeah, you can do that.  Specify -NoProfile option and load profile yourself in -Command, after you set the variable (. $PROFILE)."
PowerShell,39hquz,majkinetor,1 point,Thu Jun 11 21:45:02 2015 UTC,Of course! That's so simple.   Thanks for the help!
PowerShell,39gz2z,cannibalsock,1 point,Thu Jun 11 17:28:15 2015 UTC,What's wrong with that?
PowerShell,39gz2z,JewStyleKungfu,1 point,Thu Jun 11 18:30:29 2015 UTC,"Nothing I guess, it just feels dirty"
PowerShell,39gz2z,JewStyleKungfu,1 point,Thu Jun 11 19:47:35 2015 UTC,"Oh, ok.  I know that feeling.  I can't think of a better way to do that, though.  I didn't know you could use net view to see other workgroup computers.  That's pretty cool."
PowerShell,39gz2z,occamsrzor,1 point,Thu Jun 11 20:12:29 2015 UTC,"wtf?  $slaveName = [string]$slaveName   does nothing... the variable $slaveName is already an object of type system.string so strongtyping/typecasting it is unnessary (this is is called an explict type conversion) and essential is the same as 1=1 (if the IEnumerable integer '1' weren't const resulting in an invalid operation)  $slaveName = $slaveName.Trim()   also does nothing....it would trim leading white space...white space isn't even valid in a NetBIOS name...  $_ -replace $env:computername, ''}   is just a needless operation...  Why is this script even needed? If this is the extent then....if it's just a glimpse at a larger operation you may need to rethink your methodology"
PowerShell,39gz2z,occamsrzor,1 point,Fri Jun 12 00:02:24 2015 UTC,"Well it actually returns as an array, so all of those commands are for pulling the right name out of the array.  Since both the master and slave are part of the workgroup I have to eliminate the master computer name. Then I'm just turning it into a string and trimming it.   I need to start a script on a network computer who's only distinguishing characteristics are its workgroup, the first 4 letters of its computer name, and the fact that it's one of only two with that naming pattern on the network."
PowerShell,39gz2z,occamsrzor,2,Fri Jun 12 02:27:40 2015 UTC,"[Text.RegularExpressions.RegEx]::Matches((&""C:\Windows\System32\net.exe"" view /domain:workgroup), ""(?<=\\\\(?!$env:computername))CFA-.+?(?=\s)"")"
PowerShell,39gtho,ellisgeek,1 point,Thu Jun 11 16:56:40 2015 UTC,"PowerShell profiles are just .ps1 files and they have to exist before the session is created to apply.  Here is a TechNet article about PowerShell Profiles.  Edit:  Hey, Scripting Guy! has a blog that goes into better detail."
PowerShell,39gtho,ryanbrown,1 point,Thu Jun 11 17:17:06 2015 UTC,"You can create a new session configuration, or endpoint, on the remote computer using the New-PSSessionConfigurationFile cmdlet, adding a local file path to ScriptsToProcess in this file (make sure the actual .ps1 exists), and then using Register-PSSessionConfiguration to register a new endpoint.  Or, you can modify one of the already existing endpoints using the Set-PSSessionConfiguration cmdlet. For instance, if you want to run a script any time someone connects to the default endpoint (Microsoft.PowerShell), enter this:   Set-PSSessionConfiguration -Name Microsoft.PowerShell -StartupScript C:\helloworld.ps1   Make sure the file is in place on the remote computer on the C:\ drive, and run Enter-PSSession -ComputerName <thecomputername>. Let me know if you have any questions."
PowerShell,39frne,alexbevi,1 point,Thu Jun 11 12:43:32 2015 UTC,Someone may find this useful :)
PowerShell,39frne,MattHodge,1 point,Thu Jun 11 12:43:51 2015 UTC,This is a great idea..
PowerShell,39frne,WindosBK,1 point,Thu Jun 11 14:24:41 2015 UTC,"Left this as a comment on the blog post, but may be of interest to someone:  Not sure if there is a special reason for your VerboseOutput parameter, but as you're using CmdletBinding, you automagically get the -Verbose switch/Common Parameter.  You just need to change out your  if ($VerboseOutput -eq $true) {     $Host.UI.WriteDebugLine(""Stuff"") }   blocks to a: Write-Verbose -Message ""Stuff""and you can then remove the custom parameter from the script (if wanted.)  Apologies if you already know all this and there is a reason that is over my head. And if it is new to you, you can find out more about this sort of thing in about_CommonParameters"
PowerShell,39frne,ButterCupKhaos,1 point,Fri Jun 12 03:36:33 2015 UTC,"Honestly, I didn't know about Write-Verbose... Thanks! :)"
PowerShell,39foty,underscorecounter,1 point,Thu Jun 11 12:19:33 2015 UTC,"This will exclude the publisher based on their exact names, so you need to check the names of the publishers and put them in there correctly. It is also possible to filter by wildcard but in the following example we don't:  Import-Csv -Path OutPut.csv | Where-Object {     @('Microsoft','Nvidea','AMD') -notcontains $_.Publisher }"
PowerShell,39foty,JaapBrasser,1 point,Thu Jun 11 12:49:00 2015 UTC,Would that be a separate script? The issue I have is the original script makes a separate csv file for each computer name on our domain. If that goes in the script where would I put it? Thanks  Edit: I am really not good at Powershell or script writing in general. Sorry for my ignorance.
PowerShell,39foty,JaapBrasser,1 point,Thu Jun 11 12:54:18 2015 UTC,"I took a look at the script on TechNet, you can replace this:  Soft-Inventory $Comp | select ComputerName, Name, Publisher, InstallDate, EstimatedSize, Version, Wow6432Node | Sort-Object @{Expression={$_.InstallDate};Ascending=$True}`    By this:  Soft-Inventory $Comp | Where-Object {@('Microsoft','Nvidea','AMD') -notcontains $_.Publisher} | Select-Object ComputerName, Name, Publisher, InstallDate, EstimatedSize, Version, Wow6432Node | Sort-Object @{Expression={$_.InstallDate};Ascending=$True}"
PowerShell,39foty,JaapBrasser,1 point,Thu Jun 11 15:04:55 2015 UTC,Awesome! You are amazing!
PowerShell,39gcq8,OpCode1300,1 point,Thu Jun 11 15:16:23 2015 UTC,Try starting the service by hand. Rule out your script vs manually setting it.  You may be missing the run as a service attribute for your account.
PowerShell,39gcq8,KevMar,1 point,Thu Jun 11 16:33:54 2015 UTC,"I have tried starting the service in the Services management console(ui). if I set the creds in the ui, I can start and stop as needed. if I set the creds via script or sc.exe I cannot start the service in the ui or PS via start-service."
PowerShell,39gcq8,ryanbrown,1 point,Thu Jun 11 17:29:19 2015 UTC,"This is kind of the obvious answer, but are you sure the password is correct?  Or does the system have some way of authenticating it if it's a domain account?"
PowerShell,39gcq8,ryanbrown,1 point,Thu Jun 11 18:48:40 2015 UTC,"Yes, I've copy/pasted the username and password from the script into a 'runas' for powershell and ran a whoami to ensure they are correct.  EDIT I also confirmed the account also has the logon as service policy enabled"
PowerShell,39g78c,djbr22,1 point,Thu Jun 11 14:42:08 2015 UTC,There is this I created. Feel free to modify it to suit your needs.   https://www.dropbox.com/s/gv9gntr1lxbb7ye/Uninstaller.ps1?dl=0
PowerShell,39d0cu,jcotton42,1 point,Wed Jun 10 23:01:16 2015 UTC,This is great! Thanks for the link.
PowerShell,39fb4u,ItsKingboo,2,Thu Jun 11 09:49:56 2015 UTC,"You can use  [Net.DNS]::GetHostEntry(""MachineName"")"
PowerShell,39fb4u,the_spad,1 point,Thu Jun 11 09:51:51 2015 UTC,"Hey,  Cheers for the reply, that only returns the HostName of the machine, and not the actual DNS Name record?"
PowerShell,39fb4u,the_spad,1 point,Thu Jun 11 09:53:49 2015 UTC,"What do you mean by the ""DNS Name Record""?  It gives you both the FQDN and IP address(es) - you can supply either a hostname, FQDN or IP address to GetHostEntry() to retreive the information."
PowerShell,39fb4u,the_spad,1 point,Thu Jun 11 10:00:03 2015 UTC,"What i mean is what the DNS Has registered to IP Address, The setup that i am currently in requires you create a DNS Record and manually create the AD computer before joining the domain.   So i am wanting to pull that name down from the dns records (Via IP) and then change the computer name to the DNS Records name.  If you have a windows 8 machine you can try run the script it might make a bit more sense then me explaining it :P  Thanks"
PowerShell,39fb4u,the_spad,2,Thu Jun 11 10:06:25 2015 UTC,In that case   $Computerdnsname = [Net.DNS]::GetHostEntry($computerIP).hostname   Should get you the information you're looking for
PowerShell,39fb4u,the_spad,1 point,Thu Jun 11 10:12:11 2015 UTC,"Unfortunately that still only returns its current ""Computer Name"".  This is a print screen of the function running from the 7 machine: http://i.imgur.com/J2ewvhO.png  and this is result i am trying to achieve from windows 2012:  http://imgur.com/7vzy0pA  SO the 2012 version with the Resolve-DNSname is returning the name i want,  But the windows 7 is only returning the Current computer name of the machine.  hope that makes sense,  Thanks"
PowerShell,39bi1e,BadSysadmin,9,Wed Jun 10 17:14:04 2015 UTC,"Wow all of the convenience of curling a script into an interpreter, but in Powershell!  It's so wonderfully horrible I don't have any more words.   Also, relevant sample script. 10/10.  Ona slightly more serious note, it's interesting that iex bypasses Powershell's execution policy. I'm assuming you actually tested it, but I think I'm going to have to play around with it later on.  Edit: Cursory Googling for anyone interested: https://blog.netspi.com/15-ways-to-bypass-the-powershell-execution-policy/"
PowerShell,39bi1e,Ssoy,3,Wed Jun 10 18:14:53 2015 UTC,Saving for devious deeds in the future.
PowerShell,39bi1e,itsteve,2,Wed Jun 10 18:41:39 2015 UTC,"Assisting in your devious needs: https://raw.githubusercontent.com/mattifestation/PowerSploit/master/Exfiltration/Get-Keystrokes.ps1  In case you are forgetful and you would like PowerShell to remember your keystrokes for you, never forget a password again!"
PowerShell,39bi1e,JaapBrasser,3,Wed Jun 10 19:22:38 2015 UTC,Because its always good to run scripts straight from the web. They are always trustworthy!
PowerShell,39bi1e,sntxrr,3,Wed Jun 10 23:49:47 2015 UTC,Easier to just pipe it to iex.  You don't need to specifically select the Content property either:  iwr http://pastebin.com/raw.php?i=sWacjDpa | iex
PowerShell,39bi1e,tehjimmeh,1 point,Thu Jun 11 03:13:57 2015 UTC,Nice
PowerShell,39bi1e,JaapBrasser,2,Thu Jun 11 08:33:47 2015 UTC,Especially powerful when combined with a pentester tool like RubberDucky: http://hakshop.myshopify.com/products/usb-rubber-ducky-deluxe?variant=353378649
PowerShell,39bi1e,unknown_host,1 point,Wed Jun 10 19:23:55 2015 UTC,Putting this in ducky script tonight.
PowerShell,39bi1e,WaraiOtoko,1 point,Wed Jun 10 21:03:28 2015 UTC,I'd recommend using a URL shortening service unless they are blocked.. (If that would work.)
PowerShell,39bi1e,WaraiOtoko,1 point,Wed Jun 10 17:51:16 2015 UTC,If you know one that outputs raw text I'd be interested to hear about it.
PowerShell,39eeey,gangstanthony,2,Thu Jun 11 04:31:41 2015 UTC,"Hey mate, if you click up on 'Language' in Notepad++ and under 'P' you will see 'PowerShell' This may be what you're after. :)  Also, you can define your own scheme in this menu under the 'Define your language' option."
PowerShell,39eeey,bundyfx,3,Thu Jun 11 05:02:27 2015 UTC,Indeed and once you create this color scheme you can share it with /r/PowerShell and be showered in upvotes :)
PowerShell,39eeey,JaapBrasser,1 point,Thu Jun 11 08:08:04 2015 UTC,and so my search begins... Will be sure to let you guys know if/when i find something or create it myself
PowerShell,39eeey,JaapBrasser,1 point,Thu Jun 11 13:53:19 2015 UTC,"Thanks, let us know if you find anything like it. It sounds like something someone else should have run into in the past. I remember looking for it a few years ago and there wasn't anything available at the time."
PowerShell,39d3ji,harthin,3,Wed Jun 10 23:22:54 2015 UTC,try Export-CSV.
PowerShell,39d3ji,supermamon,1 point,Thu Jun 11 00:31:51 2015 UTC,"Yep, this is the right commandlet to get the job done. I believe by default, Export-CSV adds double quotes as text qualifiers so commas in the data shouldn't affect your columns.   If I read your code right, this might work: $users | Export-CSV -path $outputFile  But if commas are still messing with your output, you can set your delimiter to t for tab delimited: $users | Export-CSV -delimiter ""`t"" -path $outputFile  You should be able to export directly to an excel spreadsheet as well with Export-Excel."
PowerShell,39d3ji,mikorun,1 point,Thu Jun 11 02:09:59 2015 UTC,"OK, that's kinda quickly done, just to see if it's feasible that way but I've got that:  $domainControllers = Get-ADDomainController -Filter *   Get-ADGroupMember -Identity 'Domain Admins' -Recursive | ForEach-Object -Process {     $user = $_     $domainControllers |     ForEach-Object -Process {         Get-ADUser $user.SamAccountName -Server $_.Name -Properties lastLogon, cn, employeeNumber, accountExpires, PasswordNeverExpires, Enabled, LockedOut, pwdLastSet     } |     Sort-Object -Property LastLogon |     Select-Object -Last 1 -Property SamAccountName,                              @{ name = 'LastLogon' ; expression = { [DateTime]::FromFileTime($_.LastLogon) } },                              cn, employeeNumber,                              @{ name = 'accountExpires' ; expression = { [DateTime]::FromFileTime($_.accountExpires) } },                             PasswordNeverExpires, Enabled, LockedOut,                              @{ name = 'pwdLastSet' ; expression = { [DateTime]::FromFileTime($_.pwdLastSet) } } } | Export-Csv .\banana.csv   Basically, I create a list of domain controllers (I could have put it in the loop, but there's no point retrieving the list several time.  Then the loop: for each member of ""Domain Admins"", you interrogate every domain controller for the relevant information. You sort those by LastLogon and select only the last one, and you output the properties you want. Time to send everything to the CSV file.  Note: you don't care about LastLogonTimeStamp. It's a replicated value that can be off by up to four weeks. Its purpose is to offer a consistent value on every domain controller, but it shouldn't be used unless you're hunting accounts that haven't been used for months. LastLogon on the other hand, is the last time the user logged on this particular domain controller, hence the loop where you interrogate every DC, sort your result by that info, and keep only the last (most recent) one.  And the select makes use of the mighty calculated properties to convert all those weird time formats to something you can read."
PowerShell,39bvxz,Kaysyn,8,Wed Jun 10 18:44:32 2015 UTC,"PowerShell natively supports compressing and extracting from Powershell version 5.0. I have two articles posted on PowerShell Magazine in which I explain how to compress, extract and test compression ratio of zip files: Compress files and folders with System.IO.Compression.FileSystem class  Determine compression ratio of compressed files  Let me know if you have any further questions in regards to this topic."
PowerShell,39bvxz,JaapBrasser,7,Wed Jun 10 19:16:16 2015 UTC,"PowerShell doesn't have any native zip/unzip cmdlets.  However, if you're running PowerShell 3+ and .Net 4.5+ you can do something like this:  Add-Type -AssemblyName System.IO.Compression.FileSystem [System.IO.Compression.ZipFile]::ExtractToDirectory('c:\path\to\zip','c:\path\to\destination')   You could probably wrap that up into a function pretty easily to get a one-liner."
PowerShell,39bvxz,ryanbrown,4,Wed Jun 10 19:04:28 2015 UTC,"I have this wrapped up into a nice function:  Function Export-ToDirectory {     param(     [Parameter(         Mandatory         = $true,         HelpMessage       = ""Path to the compressed file"",         Position          = 0,         ValueFromPipeline = $true,         ValueFromPipelineByPropertyName = $true         )]     [Alias(""FullName"")]     [string[]]$Path,      [Parameter(         Mandatory         = $true,         HelpMessage       = ""Path to the destination directory"",         Position          = 2,         ValueFromPipelineByPropertyName = $true         )]     [string]$Destination     )      begin     {         [System.Reflection.Assembly]::LoadWithPartialName(""System.IO.Compression.FileSystem"") | Out-Null         if( -not (Test-Path $Destination -PathType Container))         {             Write-Verbose ""creating folder $Destination""             mkdir $Destination         }     }     process     {         $DestinationPath = (Resolve-Path $Destination).Path         Write-verbose ""Destination Directory: '$DestinationPath'""          foreach($CurrentFile in (Resolve-Path $Path))         {                Write-verbose ""/t Processing '$CurrentFile'""              Write-Verbose ""/t/t Unblock file""             Unblock-File $CurrentFile              Write-verbose ""/t/t Extract to Directory""             [System.IO.Compression.ZipFile]::ExtractToDirectory($CurrentFile, $DestinationPath)         }     } }"
PowerShell,39bvxz,KevMar,1 point,Wed Jun 10 21:27:33 2015 UTC,PowerShell doesn't have any native zip/unzip cmdlets   v5 will.
PowerShell,39bvxz,alinroc,3,Wed Jun 10 21:08:18 2015 UTC,"Been using this for years.   $ZipPath = ""$Path"" $zipfile = (new-object -com shell.application).NameSpace($ZipPath) $destinationPath = ""$outputdirectory""  $destination = (new-object -com shell.application).NameSpace($destinationPath)  $destination.CopyHere($zipfile.Items())"
PowerShell,39bvxz,kenks84,1 point,Thu Jun 11 06:32:33 2015 UTC,I generate a few reports and use the same to compress them before they are emailed off as an attachment.  Will be great though to have some native commands in v5!
PowerShell,39bvxz,Swarfega,2,Thu Jun 11 08:26:53 2015 UTC,"Lol, first thing that jumped to my mind was ""pkz204g.exe has some command line switches, we can make this work"" :)  yes, I am now officially old. No, I don't know wtf I was thinking, lol"
PowerShell,39bvxz,AthlonRob,2,Wed Jun 10 20:04:41 2015 UTC,Did you download that using Super ZModem?
PowerShell,39bvxz,lemon_tea,1 point,Thu Jun 11 06:38:31 2015 UTC,"Zmodem was the best, but i always used Kermit when I could. 'Cause frogs."
PowerShell,39bvxz,ribond,2,Sun Jun 14 05:28:08 2015 UTC,"PowerShell 5 (currently out as a preview) adds the cmdlets:   Compress-Archive Expand-Archive   Prior to those being included, what I would normally see people do when they needed to deal with zip files was use the 7zip command line tool, or leverage .Net as /r/ryanbrown shows in his comment."
PowerShell,39bvxz,WindosBK,2,Wed Jun 10 20:35:56 2015 UTC,"7-zip has a command line utility.  Outside of that, you'd need .NET 4.5+ or WMF5.0+"
PowerShell,39bvxz,MortoftheHillPeople,2,Wed Jun 10 20:38:32 2015 UTC,The PowerShell Community Extensions (https://pscx.codeplex.com/releases) Module has some cmdlets for compression.  Works if you can't install WMF 5.0.  Using the .NET functions works too.  I wrote a blog about it last year when I was looking to do the same: http://www.seanblake.ca/2014/05/20/zipping-files-in-powershell-without-pscx/
PowerShell,39cx3h,majkinetor,1 point,Wed Jun 10 22:38:35 2015 UTC,How do I get advanced options (TLS v support etc)?
PowerShell,39cx3h,vrsuresh,2,Thu Jun 11 07:25:54 2015 UTC,It uses the same proxy for all types. Autosettings I didn't write but that is quite easy to add if you need that (never needed it anywhere tbh).
PowerShell,39bryc,ShiftNick,4,Wed Jun 10 18:18:50 2015 UTC,"Sure, parameter sets are the way to go. Here is an example in which FilePath is mandatory in both parameter sets, but the other parameters are only mandatory if on of the other three is specified EmailRequired,A and B. Here is the code and let me know if you have any questions:  Function Test-Parameter {     [CmdletBinding(DefaultParametersetName = ""Default"")]     Param (         [Parameter(             ParameterSetName = ""Default"",             Mandatory,             valueFromPipeline,             Position=0         )]         [Parameter(             ParameterSetName = ""EmailRequired"",             Mandatory,             valueFromPipeline,             Position=0         )]         [String]$FilePath,         [Parameter(             ParameterSetName = ""EmailRequired"",             Mandatory         )]         [Switch]$EmailRequired,         [Parameter(             ParameterSetName = ""EmailRequired"",             Mandatory         )]         [string]$A,         [Parameter(             ParameterSetName = ""EmailRequired"",             Mandatory         )]         [string]$B     ) }"
PowerShell,39bryc,JaapBrasser,2,Wed Jun 10 18:32:11 2015 UTC,"Thanks so much.  I lay out my code differently from you, so I wasn't completely understanding what yours was doing.  Changed the layout and now I get it.  Here's what I'm using it for.  Function test-function{ [CmdletBinding(DefaultParametersetName = ""Default"")] Param (     [Parameter(ParameterSetName = ""Default"",Mandatory,valueFromPipeline,Position=0)]     [Parameter(ParameterSetName = ""EmailRequired"",Mandatory,valueFromPipeline,Position=0)]     [String]$FilePath,      [Parameter(ParameterSetName = ""EmailRequired"",Mandatory)]     [Switch]$EmailRequired,      [Parameter(ParameterSetName = ""EmailRequired"",Mandatory)]     [ValidateSet(""CA"",""US"",""CN"")]     [string]$UL,      [Parameter(ParameterSetName = ""EmailRequired"",Mandatory)]     [ValidateSet(""Standard"",""Enterprise"")]     [string]$LT )   }"
PowerShell,39bryc,JaapBrasser,1 point,Wed Jun 10 18:43:55 2015 UTC,"Glad to hear you liked the code, there are a lot of different coding preferences so I am glad you were able to make sense of mine :)  Your code is solid though, good to see a different approach!"
PowerShell,39bch0,whatshouldidowithmyl,2,Wed Jun 10 16:36:51 2015 UTC,"This is what I came up with:  $listA = #Path To Master List $listAContent = Get-content $listA $listB = #Path To New List $listBContent = Get-content $listB  $differences = Compare-Object $listAContent $listBContent  ForEach($line in $differences){     If($line.SideIndicator -eq ""=>""){         $text = $line.InputObject          Add-content $listA ""`n$text""     } }   For some reason using $text >> $listA was not doing what I wanted it to do."
PowerShell,39bch0,Mannheim_Bear,1 point,Wed Jun 10 18:10:25 2015 UTC,Was it overwriting existing data?
PowerShell,39bch0,Mannheim_Bear,1 point,Wed Jun 10 18:35:47 2015 UTC,"No, it was appending the changes to the end of the last line and putting a space in between each character.  So for example it would look like this:  Test T h i s I s W h a t W a s D i f f e r e n t  I hadn't been using `n so that was part of my issue, but the spacing is what really threw me.  Add-Content is probably the better way to do it anyway, but I usually use >>"
PowerShell,39bch0,Mannheim_Bear,1 point,Wed Jun 10 18:52:10 2015 UTC,"Strange. I actually used the >> operator with no issue. This script works exactly as need through either way, thank you! Very much appreciated."
PowerShell,39bch0,RulerOf,1 point,Wed Jun 10 19:24:09 2015 UTC,Hmmm... I'll play with it some more later to see what I was doing wrong.  Glad it's working for you.
PowerShell,39bch0,gyrferret,1 point,Wed Jun 10 19:41:22 2015 UTC,"Shoehorn it into a database schema, then use SQL on it?  The UPDATE command is pretty notorious for being really useful.  And wrecking my life. ;)"
PowerShell,39bch0,catfoodsci,1 point,Wed Jun 10 17:34:06 2015 UTC,"I'm not near a working computer, but does the compare function also have a sub method that allows you to display the differences that were found between two files? At that point, all you would need to do is a   $differences >> masterfile.txt"
PowerShell,39avz6,meowingtons96,2,Wed Jun 10 14:38:06 2015 UTC,"Maybe this:  1. Get a list of groups starting with GA. For each group,     2a. Check for members.     2b. If there are members, bounce back out. Otherwise, go to 2c.     2c. Check for members in GE group.      2d. If there are members, bounce back out. Otherwise, go to 2e.     2e. Check for members in GL group.     2f. If there are members, bounce back out. Otherwise, go to 2g.     2g. Check for members in GN group.     2h. If there are members, bounce back out. Otherwise, go to 2i.     2i. Move groups to new location."
PowerShell,39avz6,ArmondDorleac,1 point,Wed Jun 10 17:02:12 2015 UTC,"Oh, and you probably want something like this: (Get-ADGroup <group> -Properties *).member.count"
PowerShell,39avz6,ArmondDorleac,2,Wed Jun 10 17:03:21 2015 UTC,"This should be pretty fast. You get all groups and filter out any that have members. Remove the first two characters and then by using group-object, you can find any name that occurs 4 times.   $groups = Get-ADGroup -Filter * -Properties member $emptygroups = $groups | ? { !($_.member) } | Select @{ l=""name""; e={($_.Name).Remove(0,2)}} $emptygroups | Group-Object -property name | ? { $_.Count -eq 4 }"
PowerShell,39avz6,chade1979,1 point,Wed Jun 10 17:22:59 2015 UTC,This is perfect. Thank you!
PowerShell,39avz6,the_spad,1 point,Wed Jun 10 17:54:04 2015 UTC,"Roughly, get a list of groups, trim off the first 2 characters, select unique entries in the list.  Foreach entry check each of the 4 groups and if they're all empty then do whatever."
PowerShell,39a1mt,Pavix,5,Wed Jun 10 09:40:41 2015 UTC,"Since you are currently storing a TimeSpan object in the Uptime field, you can easily retrieve the days,hours and minute properties from this object. This in combination with the -f operator you end up with something along these lines:  $os = Get-WmiObject -class win32_OperatingSystem -cn localhost $uptime = (get-date) - $os.converttodatetime($os.lastbootuptime)     New-Object psobject -Property @{         computer= $s         uptime = ""{0} Days {1} Hours {2} Minutes"" -f $uptime.Days,$uptime.Hours,$uptime.Minutes     }"
PowerShell,39a1mt,JaapBrasser,5,Wed Jun 10 10:01:15 2015 UTC,"Here's my version. I detest the lack of readability in the original script so I've fixed that too.  Function Get-UpTime { Param ([string[]]$servers)  $computers = @()  Foreach ($s in $servers)  {   if(Test-Connection -cn $s -Quiet -BufferSize 16 -Count 1)    {     $os = Get-WmiObject -class win32_OperatingSystem -cn $s      $uptime = (get-date) - $os.converttodatetime($os.lastbootuptime);      $fancy_uptime = ""Uptime: "" + $uptime.Days + "" days, "" + $uptime.Hours + "" hours, "" + $uptime.Minutes + "" minutes""      $computer = New-Object  –TypeName PSObject      $computer | Add-Member –MemberType NoteProperty –Name Name -Value $s     $computer | Add-Member –MemberType NoteProperty –Name Uptime -Value $uptime     $computer | Add-Member –MemberType NoteProperty –Name FancyUptime -Value $fancy_uptime     $computer | Add-Member –MemberType NoteProperty –Name Online -Value ""UP""     }    else    {      $computer = New-Object  –TypeName PSObject      $computer | Add-Member –MemberType NoteProperty –Name Name -Value $s     $computer | Add-Member –MemberType NoteProperty –Name Online -Value ""DOWN""     }    $computers += $computer   }  return $computers }  #end function Get-Uptime"
PowerShell,39a1mt,InvisibleTextArea,1 point,Wed Jun 10 10:38:46 2015 UTC,"This can be much simpler too.  This is the beauty of PowerShell. I don't like the use of Add-member when I can do the following with great result.  Here's another version of the very nice script:  Function Get-UpTime {     Param ([string[]]$servers)  $computers = @()  [Array] $global:Systems = Foreach ($s in $servers) {     if (Test-Connection -cn $s -Quiet -BufferSize 16 -Count 1)     {         $os = Get-WmiObject -class win32_OperatingSystem -cn $s         $uptime = (get-date) - $os.converttodatetime($os.lastbootuptime);         $fancy_uptime = ""Uptime: "" + $uptime.Days + "" days, "" + $uptime.Hours `         + "" hours, "" + $uptime.Minutes + "" minutes"";          [PSCustomObject]$computer = New-Object PSObject -Property @{             Name = $s;             Uptime = $uptime;             FancyUptime = $fancy_uptime;             Online = ""UP"";         };         $computer     }     else     {         [PSCustomObject] $computer = New-Object PSObject -Property @{             Name = $s;             Uptime = 'NONE';             FancyUptime = 'NONE';             Online = ""DOWN or Doesn't Exist!"";         };         $computer;     }; }; $global:Systems   }; #end function Get-Uptime  This will display all properties residing in the $global:Systems object.  Now you can pick the properties for the best result:  [Array]$ComputerNames = ""Server1"", ""Server2"", ""Server3""; Get-UpTime -servers $ComputerNames  | Select-Object name, Online, FancyUptime | Format-Table -AutoSize;  - Or:  $global:Systems  | Select-Object name, Online, FancyUptime | Format-Table -AutoSize;  Here you got a few ways to work with it. :)  Max"
PowerShell,39a1mt,MaxTrinidad,1 point,Wed Jun 10 13:02:07 2015 UTC,"Slightly off-topic, but do you have a C# background?"
PowerShell,39a1mt,JaapBrasser,1 point,Wed Jun 10 13:27:36 2015 UTC,I would recommend you use a hash table instead of using Add-Member or using the -Property parameter of the New-Object cmdlet. This is mostly a performance issue as you are creating an object and then putting that object through the pipeline a number of times. This is significantly slower than other method of creating custom objects. Have a look at the following results:  Measure-Command {     1..10 | ForEach-Object {         $Property1 = 1         $Property2 = 'Hello'         $Property3 = Get-Date         $Property4 = Get-Process         $Property5 = Get-Service         $Object = New-Object -TypeName PSCustomObject         $Object | Add-Member –MemberType NoteProperty –Name Property1 -Value $Property1         $Object | Add-Member –MemberType NoteProperty –Name Property2 -Value $Property2         $Object | Add-Member –MemberType NoteProperty –Name Property3 -Value $Property3         $Object | Add-Member –MemberType NoteProperty –Name Property4 -Value $Property4         $Object | Add-Member –MemberType NoteProperty –Name Property5 -Value $Property5     } }  Measure-Command {     1..10 | ForEach-Object {         $HashProperty = @{             Property1 = 1             Property2 = 'Hello'             Property3 = Get-Date             Property4 = Get-Process             Property5 = Get-Service         }         New-Object -TypeName PSCustomObject -Property $HashProperty     } }   On my system it is 100ms versus 30ms when using hash tables. Since the output is similar and the faster method is actually shorter to type I would recommend using the short and fast method over the longer pipelined alternative.
PowerShell,39a1mt,JaapBrasser,1 point,Wed Jun 10 13:26:52 2015 UTC,"Can I impose on peoples kindness for one more thing, I'm trying to get it to return more than 1000 results. I've found this article But any attempt at adding the .PageSize line results in an error. It may be due to the way the string is written as listed below  [array]$servers = ([adsisearcher]""(&(objectcategory=computer)(OperatingSystem=*7*))"").findall() |   foreach-object {([adsi]$_.path).cn}"
PowerShell,39a1mt,Mannheim_Bear,1 point,Wed Jun 10 13:42:06 2015 UTC,Is there a reason you didn't use the formatting that is in the link you provided?  I think the issue is that you are creating the searcher and doing the findall() in the same motion so it is going to use default parameters.  I think the only way you can change it would be to mimic the example in the link.
PowerShell,39a1mt,Mannheim_Bear,2,Wed Jun 10 17:01:56 2015 UTC,"So it would be something more like this  $searcher = [adsisearcher]""(&(objectcategory=computer(OperatingSystem=*7*))"" $searcher.PageSize = 1000 [array]$servers = $searcher.findall()"
PowerShell,39a1mt,Mannheim_Bear,1 point,Wed Jun 10 17:08:52 2015 UTC,"I tried your code above and it errors out for some reason   PS C:\Scripts> .\QueryAD_HTML_Uptime_FreespaceReport.ps1 Cannot convert value ""System.DirectoryServices.SearchResultCollection"" to type ""System.Object[]"". Error: ""The (&(objectcategory=computer(OperatingSystem=7))  search filter is invalid."" At C:\Scripts\QueryAD_HTML_Uptime_FreespaceReport.ps1:64 char:16 + [array]$servers <<<<  = $searcher.findall()     + CategoryInfo          : MetadataError: (:) [], ArgumentTransformationMet    adataException     + FullyQualifiedErrorId : RuntimeException   Test-Connection : Cannot validate argument on parameter 'ComputerName'. The arg ument is null or empty. Supply an argument that is not null or empty and then t ry the command again. At C:\Scripts\QueryAD_HTML_Uptime_FreespaceReport.ps1:20 char:24 +  if(Test-Connection -cn <<<<  $s -Quiet -BufferSize 16 -Count 1)     + CategoryInfo          : InvalidData: (:) [Test-Connection], ParameterBin    dingValidationException     + FullyQualifiedErrorId : ParameterArgumentValidationError,Microsoft.Power    Shell.Commands.TestConnectionCommand  Test-Connection : Cannot validate argument on parameter 'ComputerName'. The arg ument is null or empty. Supply an argument that is not null or empty and then t ry the command again. At C:\Scripts\QueryAD_HTML_Uptime_FreespaceReport.ps1:50 char:27 +     if(Test-Connection -cn <<<<  $s -Quiet -BufferSize 16 -Count 1)     + CategoryInfo          : InvalidData: (:) [Test-Connection], ParameterBin    dingValidationException     + FullyQualifiedErrorId : ParameterArgumentValidationError,Microsoft.Power    Shell.Commands.TestConnectionCommand  PS C:\Scripts>"
PowerShell,39a1mt,Mannheim_Bear,1 point,Sun Jun 14 03:35:25 2015 UTC,"I think the filter is missing a closed parenthesis... that first line should be:  $searcher = [adsisearcher]""(&(objectcategory=computer)(OperatingSystem=*7*))""   See if that fixes the issue"
PowerShell,39a1mt,GoodShitLollypop,1 point,Sun Jun 14 04:15:35 2015 UTC,"That fixes that problem, but now presents a new one   Server Uptime Report  The following report was run on 06/13/2015 23:35:27  Name   Online  System.DirectoryServices.SearchResult  DOWN  System.DirectoryServices.SearchResult  DOWN  System.DirectoryServices.SearchResult  DOWN  System.DirectoryServices.SearchResult  DOWN  System.DirectoryServices.SearchResult  DOWN  System.DirectoryServices.SearchResult  DOWN  System.DirectoryServices.SearchResult  DOWN   It's not passing the actual machine hostnames to the rest of the script."
PowerShell,399uqk,xStimorolx,5,Wed Jun 10 08:10:53 2015 UTC,"I've just put together a VERY simple GUI by using Sapien Powershell Studio.  http://pastebin.com/qGtajHFP  Just copy everything into a ps1-File and run it. You can edit the ""$btnSend_Click"" event to add a text input validation and add the code that handles the sending."
PowerShell,399uqk,Feyh,3,Wed Jun 10 10:28:23 2015 UTC,"Take a look at this.  Though they do overcomplicate things a little as you can accomplish it all from within a single file with something like this:  $xaml=@"" <Window x:Name=""Main""     xmlns=""http://schemas.microsoft.com/winfx/2006/xaml/presentation""     xmlns:x=""http://schemas.microsoft.com/winfx/2006/xaml""     Title=""My GUI"" Height=""400"" Width=""300"">  <Grid>    <Label Content=""Label"" HorizontalAlignment=""Left"" Margin=""68,38,0,0"" VerticalAlignment=""Top"" Width=""197""/>   <Button Content=""Button"" HorizontalAlignment=""Left"" Margin=""307,41,0,0"" VerticalAlignment=""Top"" Width=""75""/>  </Grid> </Window> ""@  [xml]$xmlWPF = $xaml  try{     Add-Type -AssemblyName PresentationCore,PresentationFramework,WindowsBase,system.windows.forms }catch{     Throw ""Failed to load Windows Presentation Framework assemblies."" }  $xamGUI = [Windows.Markup.XamlReader]::Load((new-object System.Xml.XmlNodeReader $xmlWPF))  $xmlWPF.SelectNodes(""//*[@Name]"") | %{     Set-Variable -Name ($_.Name) -Value $xamGUI.FindName($_.Name) -Scope Global }  #Event handler code & rest of script goes here"
PowerShell,399uqk,the_spad,2,Wed Jun 10 08:28:30 2015 UTC,"Disclaimer, I hate PowerShell for GUI applications.  But, when you get down to it, it's not particularly hard without the third party stuff.    Load the Forms Namespace:  try {     Add-Type -AssemblyName System.Windows.Forms } catch {     throw ""Unable to load Assemblies, what did you do to your system?"" }   Create your Form object:  $Form = New-Object System.Windows.Forms.Form $Form.Text = ""Do stuff"" $Form.Height = 680 $Form.Width = 1000   Add controls:  $NameBox = New-Object System.Windows.Forms.Textbox $NameBox.Top = 20 $NameBox.Left = 5 $NameBox.Width = 300 $Form.Controls.Add($NameBox)   Add more controls (say a button):  $FindButton = New-Object System.Windows.Forms.Button $FindButton.Text = ""&Find Users"" $FindButton.Top = 107 $FindButton.Left = 405 $FindButton.Width = 110 $FindButton.Enabled = $false $FindButton.add_click({FindNames}) $Form.Controls.Add($FindButton)   Notice that line $FindButton.add_click({FindNames}) that is an event handler.  What that does is tell PowerShell that when the Click event is raised, do whatever is inside the curly braces.  In this case, I am telling it to run a function I defined elsewhere in the script.  For any control event you can add a handler by using the syntax $object.add_<eventName> replacing <eventName> with the actual event you want to handle (e.g. click, keyUp, SelectedIndexChanged, etc.) You may need to look at the class references on MSDN to sort out what events are available from each control.  Though, you'll probably mostly need KeyUp for text boxes (for things like automatic text validation) and the Click event for buttons (you know, when they are clicked).  DropDownLists have SelectedIndexChanged which is fired when the choice is changed.  Otherwise, Google the control name (e.g. System.Windows.Forms.TextBox) and you should get the MSDN article on the class in the first couple results.  You can create handlers for any event listed for a control of that class.  It's worth noting that form control variables (e.g.: $NameBox I created above) are scoped to the entire script.  This means that inside a function within the same script I can just use $NameBox to reference the TextBox I created with that name. Once you have your form put together, use $Form.ShowDialog() | Out-Null to run it."
PowerShell,399uqk,LandOfTheLostPass,1 point,Wed Jun 10 14:24:18 2015 UTC,Personally I find WPF to be far easier than Windows Forms for knocking together a quick GUI for Powershell.
PowerShell,399uqk,the_spad,2,Wed Jun 10 14:58:25 2015 UTC,"For the quick and dirty:  Function test { [cmdletbinding()] param(     $FullName,     $Initials,     [ValidatePattern(""\d{7,10}"")]     $Phonenumber,     [ValidatePattern(""\d{7,10}"")]     $CellNumber     ) }   Show-Command test"
PowerShell,399uqk,KevMar,2,Wed Jun 10 16:18:33 2015 UTC,"Why not make it a web site with IIS? Create a service account for the app pool, have the user authenticate and fill out a form. Then, on submit the service account runs set-aduser with their params."
PowerShell,399uqk,2girls1netcup,1 point,Thu Jun 11 00:29:46 2015 UTC,sounds awesome! link to tutorial?
PowerShell,399uqk,gangstanthony,2,Thu Jun 11 21:20:58 2015 UTC,"I haven't found any and I literally feel like I'm making it all up as I go. I haven't really done anything with JavaScript or php before a few weeks ago but the things I've made are definitely functional.   The only issue I'm having is that it's slow from button press to response. I'm not sure if it's the jquery/ajax or the php but it's noticeably slower than what running the script should take and I haven't had s chance to look into why.    That said, if you know of a blogging (or other sort of) platform, I can probably whip up a tutorial. What is your use case? A scenario like OP's? How much detail do you want? Full IIS setup instructions or just the general things like ""set the app pool to run as a service account, turn on kerberos authentication""?"
PowerShell,399uqk,2girls1netcup,1 point,Fri Jun 12 02:56:47 2015 UTC,"Ah, no need for all that. No use case - I just like learning! :-)"
PowerShell,399uqk,gangstanthony,1 point,Fri Jun 12 03:26:35 2015 UTC,Look here. These 2 little functions I made had accomplished big things for me.
PowerShell,399uqk,supermamon,1 point,Wed Jun 10 16:04:08 2015 UTC,"I made one out of a GUI I built a while ago. It's very simple but I think it's pretty easy to follow.  [void] [System.Reflection.Assembly]::LoadWithPartialName(""System.Drawing"")  [void] [System.Reflection.Assembly]::LoadWithPartialName(""System.Windows.Forms"")  function ExampleGUI() { $Frame = New-Object System.Windows.Forms.Form  $Frame.Text = ""ExampleGUI""#you can change the name here $Frame.Size = New-Object System.Drawing.Size(400,400) $Frame.StartPosition = ""CenterScreen"" #$Frame.set_BackColor(""White"")#You can change the background color here if you want $Frame.Add_Shown({$Frame.Activate()})  #Label/Field Creation #First Name $FNameLabel = MakeLabel ""First Name:"" $Frame.Controls.Add($FNameLabel) $FNameLabel.Location = New-Object System.Drawing.Size(5,20)  $FNameField = MakeTextBox 200 20 $Frame.Controls.Add($FNameField) $FNameField.Location = New-Object System.Drawing.Size(110,20)  #Middle Name $MNameLabel = MakeLabel ""Middle Name:"" $Frame.Controls.Add($MNameLabel) $MNameLabel.Location = New-Object System.Drawing.Size(5,50)  $MNameField = MakeTextBox 200 20 $Frame.Controls.Add($MNameField) $MNameField.Location = New-Object System.Drawing.Size(110,50)  #Last Name $LNameLabel = MakeLabel ""Last Name:"" $Frame.Controls.Add($LNameLabel) $LNameLabel.Location = New-Object System.Drawing.Size(5,80)  $LNameField = MakeTextBox 200 20 $Frame.Controls.Add($LNameField) $LNameField.Location = New-Object System.Drawing.Size(110,80)  #Phone Number $PhoneNumLabel = MakeLabel ""Phone Number:"" $Frame.Controls.Add($PhoneNumLabel) $PhoneNumLabel.Location = New-Object System.Drawing.Size(5,110)  $PhoneNumField = MakeTextBox 200 20 $Frame.Controls.Add($PhoneNumField) $PhoneNumField.Location = New-Object System.Drawing.Size(110,110)  #Cell Number $CellNumLabel = MakeLabel ""Cell Number:"" $Frame.Controls.Add($CellNumLabel) $CellNumLabel.Location = New-Object System.Drawing.Size(5,140)  $CellNumField = MakeTextBox 200 20 $Frame.Controls.Add($CellNumField) $CellNumField.Location = New-Object System.Drawing.Size(110,140)  #Button Creation $Send = MakeButton 'Send' $OnButtonSend $Frame.Controls.Add($Send) $Send.Location = New-Object System.Drawing.Size(150,180)  $Cancel = MakeButton 'Cancel' $OnButtonCancel $Frame.Controls.Add($Cancel) $Cancel.Location = New-Object System.Drawing.Size(225,180)  $Frame.ShowDialog() }  #Button Events $OnButtonSend = {  param($Sender, $e)  #Whatever you want the event to do can be written here.   #This simply writes the host with the field info. I think you want to make it  #email but these calls will get the text from the fields. You also need to validate  #that the information in the fields is filled out correctly. Also you probably should  #add a line to close the frame at the end with $Frame.Close() or $Frame.Dispose()  Write-Host $FNameField.Text  Write-Host $MNameField.Text  Write-Host $LNameField.Text  Write-Host $PhoneNumField.Text  Write-Host $CellNumField.Text }  $OnButtonCancel = {  param($Sender, $e)  #Whatever you want the event to do can be written here.  $Frame.Dispose()#Closes the Frame }  #Widget Creation #Makes a button object  function MakeButton($Label, $ButtonScript){ $Button = New-Object System.Windows.Forms.Button $Button.Size = New-Object System.Drawing.Size(75,25) $Button.Text = $Label $Button.Add_Click($ButtonScript) return $Button }  #Makes a textbox object  function MakeTextBox($width, $height){ $txtBox = New-Object System.Windows.Forms.TextBox  $txtBox.Size = New-Object System.Drawing.Size($width,$height) return $txtBox }  #Makes a Label object  function MakeLabel($Text){ $Label = New-Object System.Windows.Forms.Label $Label.Text = $Text return $Label }  ExampleGUI|Out-Null"
PowerShell,39ajxr,useratlocalhost,4,Wed Jun 10 13:02:20 2015 UTC,"At a guess....  $Completion = Test-Path \\2008SRVR14\Home\$MailUser\Email\$Backup   Is erroneously continuing the script before completion. The PST file appears in the export location as soon as the export starts, not when it completes. As a consequence the latter steps are probably failing before the PST isn't valid file.  That import failure may be a terminating error, which would prevent the cleanup steps from running."
PowerShell,39ajxr,the_spad,2,Wed Jun 10 13:11:42 2015 UTC,"You know I'm not sure now why I did it that way when I could have pulled the actual status using powershell...  Thanks for the help, I'm going to try testing Get-MailboxExportRequest -Status Completed instead as my condition for completion."
PowerShell,398xw2,loriden,1 point,Wed Jun 10 02:48:53 2015 UTC,"I am very rusty on my WQL, so I am going to do this more with just powershell. I also don't have a sccm server handy so I am writing this untested.  Get-WmiObject SMS_R_USER -ComputerName $SCCMServer -Namespace $SCCMNamespace |   where-object {$_.UserGroupName -match $groupname -and $_.objType -ne ""User""} | Remove-WmiObject -WhatIf   This should delete the object from your SCCM server if that is what you are trying to do. If you want to just exclude it from your results, drop the Remove-WmiObject and just use the Where-Object filter."
PowerShell,396thq,StPaddy81,3,Tue Jun 9 17:52:22 2015 UTC,"This is what I use to set home drive ACLs, it goes through AD and sets home drive folders to Domain Admins to Full Control and the users to Modify on their home drive.  Add-PSSnapin Quest.ActiveRoles.ADManagement  $Users = Get-QADUser -SearchRoot ""OU=Domain Users,DC=hwl,DC=com,DC=au""  ForEach ( $User in $Users ) {      $ACL = Get-Acl $User.HomeDirectory     $ACL.SetAccessRuleProtection($true, $false)     $ACL.Access | ForEach { [Void]$ACL.RemoveAccessRule($_) }     $ACL.AddAccessRule((New-Object System.Security.AccessControl.FileSystemAccessRule(""DOMAIN\Domain Admins"",""FullControl"", ""ContainerInherit, ObjectInherit"", ""None"", ""Allow"")))     $ACL.AddAccessRule((New-Object System.Security.AccessControl.FileSystemAccessRule($User.NTAccountName,""Modify"", ""ContainerInherit, ObjectInherit"", ""None"", ""Allow"")))     Set-Acl $User.HomeDirectory $ACL }"
PowerShell,396thq,essaydave,1 point,Tue Jun 9 22:00:25 2015 UTC,"This is the right direction.  You likely won't have the Quest cmdlets installed already, and if you have a sufficiently newish environment you wont have to as the Active Directory cmdlets (get-ADUser) will be all you need to get your usernames.  But the key bits here are they $ACL stuff.  get-ACL gets the ACL of a folder and the methods of that object allow you to modify it, with the key method being the AddAccessRule method.  It's a .NET method through-and-through though, so you have to pass it a special .NET object, not just words and text you type in.  That's what the giant line:  (New-Object System.Security.AccessControl.FileSystemAccessRule(""DOMAIN\Domain Admins"",""FullControl"", ""ContainerInherit, ObjectInherit"", ""None"", ""Allow""))   is doing.  Building a special object to specify the rule you want to add.  Once you have the $ACL object modified appropriately via enough .AddAccessRule calls, then you use set-ACL to actually save your changes.  See https://msdn.microsoft.com/en-us/library/sfe70whw(v=vs.110).aspx for the reference on how to create the FileSystemAccessRule object if you need to get special with it.  Generally speaking, leaving it more or less as /u/essaydave has it will be your best bet.  Just change the DOMAIN\Username bit."
PowerShell,396thq,edgevb,1 point,Tue Jun 9 23:37:37 2015 UTC,What's the CSV?
PowerShell,396thq,JewStyleKungfu,1 point,Tue Jun 9 18:04:05 2015 UTC,Care to share your PS script? I'm curious what you're using to dump the AD info to a CSV.
PowerShell,396thq,nastypnass,1 point,Tue Jun 9 18:51:16 2015 UTC,"I just planned on dumping it using dsget or something equivalent. That part seems to me like it's the easy part, it was reading and applying the permissions that I'm more confused about."
PowerShell,396thq,xalorous,1 point,Tue Jun 9 20:01:41 2015 UTC,"Powershell Active Directory module will let you use a cmdlet to pull a user, or collection of users.    If you want help with your script you need to share it.  Nobody's gonna guess or just, blam, here's one that does what you want.  General hints we can provide. :)  At a previous organization, we had a storage admin who made a script that reset permissions on home folders.    Set up and maintain a .default home drive with the proper folder structure AND permissions.  Useful for new user provisioning and for holding your default permissions for resets. 2a.  Control access to home folders by ownership and inheritance, not by explicit permissions. 2b.  -OR- build ACE for user and apply to all items.  Use inheritance to propagate permissions.  Create and maintain a provisioning and reset script.  Advanced functions are your friend.  One function I can think of that you need is to build the ACL by adding the ACE's.  Another strips ACL from an item and replaces it  with an ACL. (Get-ACL c:\temp\temp.txt).access  Replace filename with one on your system and look how they're used.  Get-Help ACL and Get-ACL [file] | Get-Memberwill show you most of what you need to know."
PowerShell,396thq,keseykid,1 point,Tue Jun 9 20:05:40 2015 UTC,"I've accomplished the same recently. You can use the script  here  This method strips away all ACLs then re-adds the ones you have defined. There is another script in that repo that will only change ACLs for people who still have the default ""Domain Users"" ACL."
PowerShell,3965hj,ItsKingboo,9,Tue Jun 9 15:13:49 2015 UTC,Or you can use .NET:  [System.Net.Dns]::GetHostEntry('COMPUTER')
PowerShell,3965hj,agressiv,2,Tue Jun 9 16:05:26 2015 UTC,"This is even simpler, because it doesn't care if you give it an IP address or a DNS name:  C:\> [system.net.dns]::resolve('8.8.8.8')  HostName                       Aliases AddressList --------                       ------- ----------- google-public-dns-a.google.com {}      {8.8.8.8}"
PowerShell,3965hj,jsproat,1 point,Wed Jun 10 01:22:45 2015 UTC,"Oops, actually its just getting the ""hostname"" not the dns name - Hostname is ""XXXX"" - DNS name is ""Dale"""
PowerShell,3965hj,KevMar,3,Tue Jun 9 16:10:13 2015 UTC,[System.Net.Dns]::GetHostByName(($env:computerName))
PowerShell,3965hj,xalorous,1 point,Tue Jun 9 16:36:27 2015 UTC,"$NewHostName = [System.Net.Dns]::GetHostEntry($IPAddress) | select -expandProperty HostName | % {$_ -replace "".lancs.ac.uk"",""""}"
PowerShell,3965hj,lemon_tea,3,Tue Jun 9 20:46:20 2015 UTC,"There is a powershell specific command.  I'm not in-front of my computer but it is something like resolve-host.  If you google ""powershell nslookup"" you should hit it quickly.  Edit, did a quick google from my phone.  Look here http://blogs.technet.com/b/josebda/archive/2015/04/18/windows-powershell-equivalents-for-common-networking-commands-ipconfig-ping-nslookup.aspx"
PowerShell,3965hj,lemon_tea,2,Tue Jun 9 15:26:27 2015 UTC,"Hey,  Thanks for the reply I believe it is ""resolve-Dnsname"" however the machines I'm trying to run the script / create the script from is a windows 7 machine and doesn't have the cmdlet :("
PowerShell,3965hj,SEA-Sysadmin,1 point,Tue Jun 9 15:37:06 2015 UTC,"Can you upgrade to PS3?  Or better yet, 4?  Otherwise you will need to use string parsing and regex and hack away at result from nslookup."
PowerShell,3965hj,xalorous,3,Tue Jun 9 17:21:49 2015 UTC,"Nope,  just use. Net"
PowerShell,3965hj,xalorous,1 point,Tue Jun 9 18:20:09 2015 UTC,"It's not in PS v3, only in v4."
PowerShell,3965hj,ryanbrown,1 point,Tue Jun 9 20:34:49 2015 UTC,What this blog does not tell you is that the network commands are all PS v4 commands.
PowerShell,3965hj,tohuw,2,Tue Jun 9 20:39:06 2015 UTC,"Hey, Scripting Guy! has an article about this.  It looks like /u/agressiv was on the right track."
PowerShell,3965hj,dogfish182,2,Tue Jun 9 17:14:21 2015 UTC,"If you're using Windows 8 or Server 2012 or higher, there's Resolve-DnsName. Otherwise, /u/agressiv's solution is the best."
PowerShell,3965hj,SteveSchofield,2,Tue Jun 9 17:52:09 2015 UTC,"I've found nslookup works kind of... horrible in powershell  try using this below   Get-WmiObject -Namespace 'root\MicrosoftDNS' -Class MicrosoftDNS_CNAMEType -Filter ""ContainerName = $domain"" -ComputerName $DnsServer  |        select @{N='Alias'; E={$_.Ownername}}, Primaryname | where Primaryname -like ""$computername""   variables should be as follows   $dnsserver = your dns server $domain = the domain scope to search for the record  $computername = the target  if you want to search for the machine you're on I guess you could replace $computername for $env:computername?   EDIT: I'm sorry I forgot I wrote this to actually find the existing aliases for my server I enter... however should be along the right lines."
PowerShell,3965hj,throwaway09563,1 point,Tue Jun 9 15:25:21 2015 UTC,"You can use NsLookup, provided it's not being run interactively. Just create a one liner for NsLookup with all of the parameters."
PowerShell,3965hj,xalorous,1 point,Tue Jun 9 15:54:14 2015 UTC,here is a function and foreach loop I used recently.  Sorry for the formatting not coming out.  http://pastebin.com/5PwAC9J6
PowerShell,3972zn,wigrif,3,Tue Jun 9 18:54:33 2015 UTC,Have you taken a look at the PoShRSJob module created by BoeProx: https://github.com/proxb/PoshRSJob
PowerShell,3972zn,JaapBrasser,1 point,Tue Jun 9 19:09:12 2015 UTC,"hard to say exactly what you're after. Although, have you tried using Out-Gridview (ogv) for better display?"
PowerShell,396iuw,anon2anon,1 point,Tue Jun 9 16:43:01 2015 UTC,"I decided to wrap psexec into powershell.  Final Code:  $Computers = gc ""C:\Temp\Test1\Comps.txt""  foreach ($computer in $Computers){     if (Test-Connection -Cn $Computer -Quiet) {         if (Test-Path -Path ""\\$Computer\c$\Temp\Test1""){Write-Host ""Test1 Already Exist""}else{New-Item \\$computer\c$\Temp\Test1 -type directory}         Copy-Item -Path C:\Temp\Test1\UnquotedServi.VBS -Destination \\$computer\c$\Temp\Test1         & C:\Temp\Software\PSTools\PsExec.exe -s \\$computer cscript ""C:\Temp\Test1\UnquotedServi.VBS""     } else {         Write-Host ""$Computer is offline""     } }   The UnquotedServi.VBS Source  I remarked the prompt for computer name by adding a single quote ( ' ) before this line:  strComputer = InputBox(""Fix Unquoted Service Paths on what computer?"",""Name?"",strComputer)   When Remarked:  ' strComputer = InputBox(""Fix Unquoted Service Paths on what computer?"",""Name?"",strComputer)   While this wasn't the answer I wanted, it worked."
PowerShell,396iuw,mr_furious7,1 point,Tue Jun 9 19:17:59 2015 UTC,I'm wondering if you're running into a double-hop problem.  Have you tried using credssp?
PowerShell,3959f9,nilekada,7,Tue Jun 9 10:19:27 2015 UTC,Both the Month of Lunches books to start with.
PowerShell,3959f9,cantorisdecani,1 point,Tue Jun 9 11:21:38 2015 UTC,"I bought this book. I haven't even started it yet, because I haven't set up an environment it requests. How important is it to have the setup they suggested?"
PowerShell,3959f9,curly_spork,1 point,Tue Jun 9 18:19:17 2015 UTC,If you are running Windows 8.1 just install the Hyper-V role and make some virtual machines. Just grab the server 2012 R2 .ISO from an online 'source' and away you go.
PowerShell,3959f9,bundyfx,1 point,Tue Jun 9 22:35:31 2015 UTC,that source can be ms   https://www.microsoft.com/en-us/evalcenter/evaluate-windows-server-2012
PowerShell,3959f9,kramit,1 point,Tue Jun 9 23:02:31 2015 UTC,exactly!
PowerShell,3959f9,bundyfx,8,Tue Jun 9 23:15:39 2015 UTC,"No, you will be running PowerShell 32bit but there is no noticeable difference in the PowerShell language. As for books, there are a number of books, I personally like the Windows PowerShell Best Practices by the Microsoft Scripting Guy, Ed Wilson.  Some people swear by Don Jones' books, like a month of lunches. I think it depends on your personal preference. My personal favorite book is PowerShell in Action by Bruce Payette. There are also many free ebooks available which can help you get started with PowerShell.  I wrote a blog post on how to get started with PowerShell which includes a list of free ebooks: How to Learn PowerShell"
PowerShell,3959f9,JaapBrasser,2,Tue Jun 9 10:38:19 2015 UTC,Agree on PowerShell in Action. It is dense but every page seems to have something useful.   And of course find things you actually want to do with PowerShell. Use it in place of cmd for everything too.
PowerShell,3959f9,throwaway09563,1 point,Tue Jun 9 11:12:25 2015 UTC,"So I have heard. I had initially wanted to start with cmd, but I felt the learning curve would be too steep, since I'm coming from a *nix background. Powershell seems better."
PowerShell,3959f9,xalorous,1 point,Tue Jun 9 12:01:45 2015 UTC,"Agree.  Skip cmd.  Most cmd shell commands work in posh.  Blog about PS from a Linux Guru  Many resources are listed in the sidebar of this sub.  The big names to look for are anything by Ed Wilson (Hey Scripting Guy blog), Don Jones, Bruce Payette, Shay Levy."
PowerShell,3959f9,bundyfx,2,Tue Jun 9 21:24:40 2015 UTC,"All of Jaap's suggestions are solid. Also, the CBT nugget for PowerShell is actually quite good and its also done by Don Jones. If you prefer visual learning that is."
PowerShell,3959f9,JaapBrasser,1 point,Tue Jun 9 22:37:47 2015 UTC,"Indeed and as an addition to the CBT Nuggests, there's a lot of PowerShell enthusiasts putting up good quality recordings on youtube as well. Those might be worth checking out as well."
PowerShell,3959f9,theb1g,1 point,Wed Jun 10 06:49:08 2015 UTC,"That's worth checking out as well. However, the only CBT Nuggets presentation I have enjoyed are the ones by Jeremy Ciora. But I'll see."
PowerShell,3959f9,chardIII,1 point,Wed Jun 17 22:48:38 2015 UTC,Thanks. I guess I'll focus on Ed Wilson's Best Practices and Bruce Payette's Powershell in Action.
PowerShell,3959f9,BoardWithLife,3,Tue Jun 9 11:08:29 2015 UTC,Powershell three in a month of lunches. The difference between two and three was pretty large.
PowerShell,3959f9,Mobile_Version,4,Tue Jun 9 11:14:19 2015 UTC,"Link to the Don Jones book - http://www.amazon.com/Learn-Windows-PowerShell-Month-Lunches/dp/1617291080   I like this one, but there are a ton out there.   Also, I found this to be a good starting point - https://www.microsoftvirtualacademy.com/en-US/training-courses/getting-started-with-powershell-3-0-jump-start-8276"
PowerShell,3959f9,Empath1999,1 point,Tue Jun 9 11:15:15 2015 UTC,JaapBrasser's blog included a link to the Microsoft Virtual Academy as well. It seems well worth checking out.
PowerShell,3959f9,SpecsMcGee,1 point,Tue Jun 9 12:05:17 2015 UTC,"The videos on MVA are great! Jeffrey Snover, the inventor of PowerShell references the Month of Lunches book as a great resource. I watched the Getting Started series and went from knowing absolutely nothing to making my own Cmdlets in a matter of months.. It helped using repetitive tasks I did at work and figuring out how to use PowerShell to automate it. I've amassed a large collection of bookmarks to little snippets online that have made my life so much easier. Best of luck on your journey!"
PowerShell,3959f9,netmadmin,2,Thu Jun 11 06:24:47 2015 UTC,Thanks man.
PowerShell,3959f9,jlevy1126,0,Wed Jun 17 22:49:19 2015 UTC,Here is the mobile version of your link
PowerShell,3959f9,xkevinxpwndu,5,Tue Jun 9 11:15:22 2015 UTC,I like learn powershell in a month of lunches book. It's pretty easy to understand.
PowerShell,3959f9,pandiculator,6,Tue Jun 9 12:45:06 2015 UTC,Learn PowerShell in a Month of Lunches
PowerShell,3959f9,flaccidicus,3,Tue Jun 9 13:13:43 2015 UTC,"Just a friendly heads up:  Your title, Suggest Powershell Books for a Beginner in google comes up with Powershell.org's guide to getting started, including choosing the right book for you."
PowerShell,3959f9,xalorous,1 point,Tue Jun 9 12:44:56 2015 UTC,"Thanks. I just used Amazon though, hoping to go with my gut [instinct] and find the right book for me. As I said earlier, I come from a *nix background and I expected that browsing the Powershell titles would be something akin to browsing the *nix ones."
PowerShell,3959f9,poi88,2,Wed Jun 17 22:52:55 2015 UTC,Not a book but there is a great powershell podcast to listen to. The first 10 or so episodes are a great starting point and a good companion to any book you pick up.   http://feeds.feedburner.com/PowerScripting
PowerShell,3959f9,majkinetor,2,Tue Jun 9 11:21:02 2015 UTC,"As everyone else has suggested, Learn Powershell in a Month of Lunches.  Can't recommend this book enough!"
PowerShell,396hw2,poi88,6,Tue Jun 9 16:36:35 2015 UTC,"Welcome to the Kerberos Double Hop Problem.  It solvable (see the link); but, always a bit of a PITA."
PowerShell,396hw2,LandOfTheLostPass,2,Tue Jun 9 16:41:36 2015 UTC,"Ugh, i had to figure this out the hard way. Luckily it was easy enough to push it out through group policy. Where were you a week ago when I had this problem? I needed you."
PowerShell,396hw2,spoonstar,1 point,Tue Jun 9 22:45:29 2015 UTC,"Probably beating my head against the brick wall which is WebDAV on IIS.  That's where I first learned of this little bit of ""fun""."
PowerShell,397oh1,cyborgcommando0,1 point,Tue Jun 9 21:13:22 2015 UTC,"If you want to be more concise:  Get-ADUser $env:USERNAME | select @{n='ParentContainer';e={$_.distinguishedname -replace '^.+?,(CN|OU.+)','$1'}}   You can also use the ADSI provider that returns a Parent property as LDAP ADsPath:  Get-ADUser $env:USERNAME | select *,@{l='Parent';e={([adsi]""LDAP://$($_.DistinguishedName)"").Parent}}"
PowerShell,397oh1,Scrimbo,1 point,Tue Jun 9 22:15:56 2015 UTC,I always love seeing the other ways people solve the same problems. Nice.
PowerShell,3966ni,dogfish182,1 point,Tue Jun 9 15:21:31 2015 UTC,It seems to work for me.  Does your server have the same version of Powershell as your workstation?
PowerShell,3966ni,JewStyleKungfu,1 point,Tue Jun 9 17:09:32 2015 UTC,yeah 2012r2 server win 8.1 workstation. both on version 4.
PowerShell,3966ni,majkinetor,1 point,Wed Jun 10 18:08:14 2015 UTC,"Returns blank like a) there is simply no output or b) $results is false. To see if it is b) add out-file instead write-output and see if file exists after the command finishes. BTW, why don't use use resolve-path instead manually crafting the $file ?  To see if it is a) perhaps try adding write-host instead write-output."
PowerShell,3966ni,majkinetor,1 point,Tue Jun 9 18:22:37 2015 UTC,actually what I get is as below. Note that the spacing between lines is no accident. it's exactly how many rows of select string output I get if I run it via 'enter-pssession' except I get the line of text I wanted.   windows 8.1 client and 2012R2 server.  thanks for the tip on resolve-path by the way. I manually crafted the file as I wasn't aware of resolve-path :D I'll stop doing that now...   C:\inetpub\Test\website1\Web.config    C:\inetpub\Test\website2\Web.config    C:\inetpub\Test\website3\bin\Web.config    C:\inetpub\Test\AerData.MFiles.Web\Web.config   C:\inetpub\Test\website4\Web.config  C:\inetpub\Test\website5\Web.config
PowerShell,392laq,majkinetor,2,Mon Jun 8 20:15:43 2015 UTC,"PowerShell has native support for both datetime and timespan object types, so my suggestion for improving this thing of yours:  -At (Get-Date 'July 4, 2015 2:45:10 pm') -Repeat ([timespan]::Parse('01:00:00'))   This is readable and human-understandable input. Cron syntax isn't."
PowerShell,392laq,mtnielsen,1 point,Tue Jun 9 10:59:41 2015 UTC,"Maybe. The truth is, task scheduling is used so often that I miss cron syntax on windows so much. The general rule for me is that when you use something very often, you want to be as expressive as possible with lowest input as possible and not write books about your intention. Ideally, both syntaxes should be supported."
PowerShell,392laq,MShepard70,1 point,Tue Jun 9 18:10:46 2015 UTC,"Interesting.  I have a lot of one-off monitors and am thinking about how to make a useful framework to ""unify"" them.  This will give me something to think about."
PowerShell,392laq,Brekkjern,1 point,Tue Jun 9 03:09:06 2015 UTC,"I may be missing something here, but isn't this doing more or less the same as the built in Task Scheduler?"
PowerShell,392laq,Brekkjern,2,Tue Jun 9 06:24:12 2015 UTC,"The main difference is that this needs to be near real time and very easily changeable. You can schedule functions to run each second or whatever, while in task scheduler 1 minute is lowest value possible. Then   Maintaining task scheduler is up to this date problematic as integrated PS module does not exist prior to Win81. So you have to use 3tdh party module to cover all cases or schtasks.exe. Maintaining multiple separate jobs in TS is yet more work. Further, there is no easy way to look into TS (or scripted TS) and tell: those are the metrics I follow on these servers. With flea you can look at the single file in familiar syntax and know what is measured everywhere. You can't easily keep the code on the repository unless you fancy XML there which is too much verbose for humans.   By the time you work this out you will basically reimplement flea, one way or another.  You could ofc implement something like this using TS but that would require you to focus on things not related to metrics.   So this is basically domain specific TS. I never liked TS very much, prior to the Powershell module in Win2012. Even with module there are some not so easily visible stuff happening in the background - session isolation, default 3 day shut down, things that you can't easily find the way to setup out of GUI etc. Those things will certainly make you problems until you are well aware of the TS architecture. Me, I needed very simple TS and the one that runs powershell scripts. ScheduledJob is way forward but not too much in my opinion."
PowerShell,392laq,nastypnass,1 point,Tue Jun 9 07:59:24 2015 UTC,"Thanks for the explanation! I haven't used the scheduler for PS. I just knew it was there. When you explain it like that, I really do see the point."
PowerShell,392laq,work-work-work-work,1 point,Tue Jun 9 08:36:55 2015 UTC,How do you not have a job with any major RMM provider?
PowerShell,3932vb,Rooks4,2,Mon Jun 8 22:15:39 2015 UTC,Do you have DirSync setup? You can query AD for the relevant attribute to find all users with an O365 mailbox.
PowerShell,3932vb,adrianrodriguez,2,Tue Jun 9 01:22:48 2015 UTC,"Dirsync only pulls accounts that are in AD. If you create a contact or a mailbox directly in 365, AD will not know about it."
PowerShell,3932vb,gex80,1 point,Tue Jun 9 09:41:32 2015 UTC,That only gives me the mail users.  I want counts for all Recipient Types.  I imagine PublicFolders wouldn't be pulled from AD.. or am I mistaken?  (I do not have an exchange background.  I am learning as I go.)
PowerShell,3932vb,gex80,1 point,Tue Jun 9 02:18:26 2015 UTC,Dirsync does all non-mail enabled public folders.
PowerShell,3932vb,lostmojo,1 point,Tue Jun 9 09:38:55 2015 UTC,"AD Store sthat information if I remember correctly, it has been a while since I looked at that in AD with our o365.  I could be wrong in that though.. How long is this taking to run and how long are you expecting it to run?  200k objects coming back from 365 can take a while no matter what you do."
PowerShell,3932vb,gex80,1 point,Tue Jun 9 07:02:07 2015 UTC,"AD will only store it if AD knows about it. If you create a mailbox directly in 365 with dirsync, AD won't have any records."
PowerShell,3932vb,lostmojo,1 point,Tue Jun 9 09:38:21 2015 UTC,"It's not awful - the truth is that I was hoping I could get to the number without having to pull back all Recipient Types in the first place and JUST pull back the count.  It doesn't look like there is  away to do that, so I am probably stuck with what I have.   Thanks!"
PowerShell,3932vb,gex80,1 point,Tue Jun 9 11:14:34 2015 UTC,"Since you are doing this for a project you could cache all of the information you need in to an xml and create a process to cache that once a day, or hour or any time interval you need, then you can just pull the data back from that to work from."
PowerShell,392zzb,imhavoc,2,Mon Jun 8 21:55:22 2015 UTC,"Instead of trying to do a filter to find the computer name, use the ""-Identity"" parameter."
PowerShell,392zzb,HalalVeggieBacon,2,Mon Jun 8 22:29:00 2015 UTC,Unfortunately that would not work for the purpose of this script because -Identity requires the full SAM Name and it does not accept wildcards. I wrote this script to search AD for computers matching a query
PowerShell,392zzb,HalalVeggieBacon,2,Tue Jun 9 03:28:58 2015 UTC,"Oh, gotcha. The Active Directory cmdlets could use a whole slew of improvements.  Unfortunately, if you use filters, the cmdlet recursively queries the entire directory partition for the domain. There's no fast way to do this, unless you instruct the script to stop at the first match."
PowerShell,392zzb,HalalVeggieBacon,2,Tue Jun 9 03:34:02 2015 UTC,"I definitely agree that the cmdlets could use improvements. I'm all about powershell and since we just moved from a 2003 AD to 2012, I've been itching to use it. Unfortunately, some things are just still easier to do through the GUI than remembering all the different powershell cmdlets and what not."
PowerShell,392zzb,etepemllactnod,1 point,Tue Jun 9 03:42:43 2015 UTC,"Quest's AD cmdlets are supposed to be the bee's knees, though I haven't personally used them."
PowerShell,392zzb,lostmojo,1 point,Tue Jun 9 03:43:45 2015 UTC,"2003 AD to 2012   Jesus, wait long enough?"
PowerShell,392zzb,BoardWithLife,2,Tue Jun 9 21:23:35 2015 UTC,"The only thing I could think of that would cause the slowdown based on what I have looked at is the get-adcomputer is taking longer when you are searching with attempting to grab the different properties vs the full computer information and then formatting the list later.  All of the commands broken down return within a few milliseconds on my test system.  If I you measure-command against the full search, -properties included, im curious what your time is to accomplish that."
PowerShell,392zzb,BoardWithLife,1 point,Tue Jun 9 00:08:32 2015 UTC,"It looks like the -Properties is what is adding a bulk of the time, but nowhere near the 10 seconds. Looks like I will have to do some trimming somewhere.  PS C:\Windows\System32> Measure-Command {Get-ADComputer -Filter {Name -like ""*mp*""} -Properties Name,DNSHostName,Enabled,DistinguishedName,IPv4Address,lastLogonDate,LockedOut,OperatingSystem,PasswordExpired,PasswordLastSet}   Days              : 0 Hours             : 0 Minutes           : 0 Seconds           : 4 Milliseconds      : 533 Ticks             : 45330555 TotalDays         : 5.24659201388889E-05 TotalHours        : 0.00125918208333333 TotalMinutes      : 0.075550925 TotalSeconds      : 4.5330555 TotalMilliseconds : 4533.0555     PS C:\Windows\System32> Measure-Command {Get-ADComputer -Filter {Name -like ""*mp*""} -Properties * }   Days              : 0 Hours             : 0 Minutes           : 0 Seconds           : 10 Milliseconds      : 821 Ticks             : 108219831 TotalDays         : 0.000125254434027778 TotalHours        : 0.00300610641666667 TotalMinutes      : 0.180366385 TotalSeconds      : 10.8219831 TotalMilliseconds : 10821.9831"
PowerShell,392zzb,calladc,1 point,Tue Jun 9 03:20:01 2015 UTC,"So after /u/lostmojo pointed out that I should take a look at how long it is taking powershell to grab the -Properties and I noticed that is where a bulk of the time is being spent. I decided to rework the code so that it is not pulling all that data that is not going to be displayed anyways. Although this means calling Get-ADComputer twice for the some scenarios, my queries now have sub-second execution times. Updated code below if you guys are interested  Function SU-GetADComputer {     [cmdletBinding()]     Param(         [string]$computerName     )      $CN = ""*$($computerName)*""     $member = ActiveDirectory\Get-ADComputer -Filter {Name -Like $CN}     $count = ($member | measure).count      If($count -eq 0) {         Write-Host ""No matches found""     } ElseIf($count -eq 1) {         ActiveDirectory\Get-ADComputer $member.Name -Properties Name,DNSHostName,Enabled,DistinguishedName,IPv4Address,lastLogonDate,LockedOut,OperatingSystem,PasswordExpired,PasswordLastSet | Format-List Name,DNSHostName,Enabled,DistinguishedName,IPv4Address,lastLogonDate,LockedOut,OperatingSystem,PasswordExpired,PasswordLastSet     } Else {         $member | Format-Table Name     } }   Edit: Also throwing in some execution times in here if you want to see the gains.  PS C:\Windows\System32> Measure-Command { SU-GetADComputer mp }  Days              : 0 Hours             : 0 Minutes           : 0 Seconds           : 0 Milliseconds      : 653 Ticks             : 6537785 TotalDays         : 7.56688078703704E-06 TotalHours        : 0.000181605138888889 TotalMinutes      : 0.0108963083333333 TotalSeconds      : 0.6537785 TotalMilliseconds : 653.7785"
PowerShell,391wb1,CheckYourPermissions,10,Mon Jun 8 17:29:07 2015 UTC,I probably would have just used Robocopy. It can retain that information as well as the NTFS permissions.
PowerShell,391wb1,HamQuestionMark,6,Mon Jun 8 19:01:57 2015 UTC,"Thanks! I guess you learn something new everyday. I didn't realize robocopy would let you create empty files.  robocopy ""C:\testdir"" ""C:\testdirTarget"" *.* /e /create   Does the same thing (but a hell of a lot better) than what I wrote. I'm very green with systems stuff so I just was doing my best to create a test environment. That's why I posted it though. I was pretty sure someone would come along and point me in a better direction."
PowerShell,391wb1,phorkor,3,Mon Jun 8 19:39:10 2015 UTC,"Still probably learned a bit by writing the script. Even if there is already a program that can do it, writing your own script is better experience."
PowerShell,391wb1,majornerd,1 point,Mon Jun 8 20:27:09 2015 UTC,We use robocopy for this exact reason.
PowerShell,391wb1,ReturnOfThePing,1 point,Mon Jun 8 19:14:56 2015 UTC,rsync -av /sourcedir/ /destdir
PowerShell,391tvi,gimmeafuckinname,2,Mon Jun 8 17:11:56 2015 UTC,"Looks good. I'd probably go with something simple like this for the new loop.  $dbNames = @('DBName1','DBName2') Get-ChildItem D:\directory\that\has\.sql\files | ForEach {     ForEach ($dbName in $dbNames) {         & $exe $dbName $_.FullName     } }"
PowerShell,391tvi,Waxmaker,2,Mon Jun 8 17:31:57 2015 UTC,"If I understood the question right, a nested foreach* is what you're after.  Just move the Get-ChildItem so you only do that once.  $dbs = 'db1','db2','db3','db4','db5','db6'  $files = Get-ChildItem D:\directory\that\has\.sql\files  foreach ($dbname in $dbs) {     $files | ForEach-Object {&$exe $dbname $_.FullName} }   *not actually nested here as you're using foreach and Foreach-Object which aren't the same thing."
PowerShell,391tvi,pandiculator,1 point,Mon Jun 8 17:27:11 2015 UTC,"I would actually nest them.  $dbs = 'db1','db2','db3','db4','db5','db6'  $files = Get-ChildItem D:\directory\that\has\.sql\files  foreach ($dbname in $dbs) {     foreach ($file in $files) {         &$exe $dbname $_.FullName     } }   Or do it as a one-liner:  ('db1','db2','db3','db4','db5','db6') | % { $db = $_; gci ""\\path\to\files"" | select -expandProperty FullName | %{& d:\path\to\vendor.exe $db $_}"
PowerShell,391tvi,xalorous,0,Tue Jun 9 20:56:26 2015 UTC,"They are the same, foreach is an alias for ForEach-Object  PS C:\Windows\System32\WindowsPowerShell\v1.0> Get-Alias foreach  CommandType     Name                                               Version    Source                                                                                      --------  ----   -------    ------                                                                                      Alias           foreach -> ForEach-Object"
PowerShell,391tvi,Derpington_Fosworth,2,Tue Jun 9 00:20:07 2015 UTC,"No they're not the same.  It's a common mistake, this article explains the differences."
PowerShell,391tvi,pandiculator,0,Tue Jun 9 09:31:26 2015 UTC,"See Edit2:  foreach IS an alias of ForEach-Object; however, it does not work the same way.  /u/Derpington_Fosworth just PROVED that it is an alias with screen capture.    Edit:  Your article also shows that it is an alias.  The difference between the two ways he used the cmdlet is the difference between storing the data in a variable and processing it in the pipeline.  foreach -InputObject (1..10) { $_ } vs. (1..10) | foreach { $_ }  ForEach-Object -InputObject (1..10) { $_ } vs ( 1..10 ) | ForEach-Object { $_ }  (1..10)|%{$_}  edit2:  foreach -InputObject (1..10) { $_ } does not work, so there is special handling attached to that alias, as it does not accept the -InputObject parameter.  However, you can substitute ForEach-Object for foreach, and it does work."
PowerShell,391tvi,xalorous,2,Tue Jun 9 20:57:25 2015 UTC,"The article is quite clear that the alias and the statement are different:   As an alias, foreach actually equals ForEach-Object! Now, do you see where the confusion comes from? In reality, foreach is an alias to the ForEach-Object cmdlet, and foreach (not the alias) is a statement. Each has its purpose.   PowerShell decides, based on the context, whether you're using the foreach as an alias for the Foreach-Object cmdlet or whether you're using the foreach keyword.  This is also explained in Get-Help about_foreach:  The Foreach Statement Outside a Command Pipeline   The part of the Foreach statement enclosed in parenthesis represents a   variable and a collection to iterate. Windows PowerShell creates the    variable ($<item>) automatically when the Foreach loop runs. Prior to    each iteration through the loop, the variable is set to a value in the    collection. The block following a Foreach statement {<statement list>}   contains a set of commands to execute against each item in a collection.  The Foreach Statement Inside a Command Pipeline   When Foreach appears in a command pipeline, Windows PowerShell uses the   foreach alias, which calls the ForEach-Object command. When you use    the foreach alias in a command pipeline, you do not include    the ($<item> in $<collection>) syntax as you do with the Foreach    statement. This is because the prior command in the pipeline provides    this information.   This is why, in your example, foreach -InputObject (1..10) { $_ } doesn't work.  It's not that there's special handling for the alias, it's that because the foreach does not appear in the pipeline PowerShell is treating it not as an alias but as a keyword."
PowerShell,391tvi,pandiculator,2,Tue Jun 9 21:41:13 2015 UTC,"Just thought of a way to demonstrate that they're not the same.  I haven't provided the output because it's too long to post, but if you run the two examples below in the ISE and examine the output, you'll see how when foreach is being used as an alias, the debug output references the Foreach-Object cmdlet.    When it's being used as a keyword statement, the cmdlet is not shown in the debug logs.   # This demonstrates foreach as a keyword statement # The debug info will not reference the Foreach-Object cmdlet # Because in this context, foreach is *not* an alias for Foreach-Object  $letters = 'a','b','c'  Trace-Command -pshost -name parameterbinding -expression {      foreach ($letter in $letters) {         Write-Host $letter     }  }      # This demonstrates foreach as an alias # The debug info will reference the Foreach-Object cmdlet # Because in this context, foreach is an alias for Foreach-Object   $letters = 'a','b','c'  Trace-Command -pshost -name parameterbinding -expression {      $letters | foreach {Write-Host $_}  }"
PowerShell,391edx,intrntpirate,3,Mon Jun 8 15:26:30 2015 UTC,"FileSystemRights are showing as identical in that situation because they actually are.   The simple permissions labels (e.g., ""List folder contents"") used in a filesystem item's Properties/Security window are only identifiers for more complex combinations. Use the ""Advanced"" button at the bottom of that window to see a more literal list. Note that the only difference between the two security lists is the ""Apply to"" at the top indicating whether it applies to just folders or also to files within the folders.  In the Get-ACL result, both folders are set to the same ""FileSystemRights"" values, but the RO one has an additional InheritanceFlags entry: ""ObjectInherit"". If you want your script to return equivalent simple labels like in the security UI, you'll need to evaluate both properties and do it manually.  Also note that if you create a new file in that folder and do a Get-ACL against it, the FileSystemRights for the two groups will be different for the file.  Edit: I haven't tried it myself, but maybe something like this will help: https://ntfssecurity.codeplex.com/"
PowerShell,391edx,Waxmaker,1 point,Mon Jun 8 17:11:57 2015 UTC,"I don't think there is a native (i.e. easy) way to do this.  You're probably going to need to look at the SDDL definition   (Get-Acl $path).Sddl    and parse out the ACE strings.  The third value in the ACE string will either be a group of 2-character abbreviations strung together or a hex value.  ACE Strings  Access Mask - Binary Format  Common Access Mask Constants  If you get a hex value, here's the easiest way to convert it to binary:  $hex = ""0x1301bf"" $binary = [convert]::ToString($hex,2)   Edit:  fix links."
PowerShell,391edx,ryanbrown,1 point,Mon Jun 8 20:22:34 2015 UTC,Powershell access control module from rhon Edwards ftw
PowerShell,390s71,poshn00b,3,Mon Jun 8 12:23:57 2015 UTC,"Please post the section of vbscript that deals with printers.  Generally I don't like to port vbscript, but there may be some black magic going on that we should be aware of.   It will also show us what wmi or other objects they are working with"
PowerShell,390s71,KevMar,2,Mon Jun 8 12:32:08 2015 UTC,"It uses prnadmin.dll, but I read that that doesn't mesh too well with PowerShell, and I figured there must be a native way to do the same thing anyway.       on error resume next     'Register prnadmin.dll file on client computer          WshShell.Run ""regsvr32.exe /s \\""+ bootServerName +""\netlogon\Tools\prnadmin.dll"", 0, TRUE      set portName = WshNetwork.EnumPrinterConnections     set oMaster = CreateObject(""PrintMaster.PrintMaster.1"")     set oPrinter = CreateObject(""Printer.Printer.1"")     set oPort = CreateObject(""Port.Port.1"")      ' Get printers     o.open ""GET"", ""http://"" + bootServer + ""/getentityvarval?var=printers"", False     o.send      printers = split(Left(o.responseText, Len(o.responseText) - 2), VBCRLF)      ' Perfoms a check to see if the printer already exists     For Each Printer in oMaster.Printers("""")         printerCheck = 0         For Each PrinterPath in printers             portCheck = 0             ' Update printer port of printer              If StrComp(PrinterPath,Printer.PrinterName) = 0 then                  oPort.PortName = ""\\"" +  bootServerName + ""\"" + Printer.PrinterName                 oPort.PortType = 3                 printerCheck = 1                 For Each Port in oMaster.Ports("""")                     If StrComp(oPort.PortName,Port.PortName) = 0 then                         portCheck = 1                         exit for                     End If                 NEXT                 If portCheck = 0 then                     oMaster.PortAdd oPort                 End If                 oMaster.PrinterGet """", Printer.PrinterName, oPrinter                 oPrinter.PortName = oPort.PortName                 oMaster.PrinterSet oPrinter                 exit for             End If         NEXT          ' Remove unused printers '       on error resume next         If printerCheck = 0 and Instr(Printer.portname,""\\"") <> 0 then               set tempPrinter = CreateObject(""Printer.Printer.1"")                 set tempPort = CreateObject(""Port.Port.1"")                 tempPrinter.PrinterName = Printer.PrinterName                         tempPort.PortName = Printer.PrnterName                         tempPrinter.ServerName = Printer.ServerName                         tempPort.ServerName = Printer.ServerName                         oMaster.PrinterDel tempPrinter                         oMaster.PortDel tempPort          End If     NEXT      ' Remove unused ports '   on error resume Next     For Each Port in oMaster.Ports("""")           If Instr(Port.PortName,""\\"") <> 0 then                         if instr(Port.PortName,bootServerName) = 0 then                                 set tempPort = CreateObject(""Port.Port.1"")                                 tempPort.PortName = Port.PortName                                 tempPort.ServerName = Port.ServerName                                 oMaster.PortDel tempPort                         end if         End If     NEXT      ' Get Default Printer     on error resume next     o.open ""GET"", ""http://"" + bootServer + ""/getentityvarval?var=defaultprinter"", False     o.send     'Shorten the response by 2 because there is a return at the end     DefaultPrinter = Left(o.responseText, Len(o.responseText) - 2)     oMaster.DefaultPrinter = DefaultPrinter"
PowerShell,390s71,InvisibleTextArea,3,Mon Jun 8 12:40:00 2015 UTC,"On Windows 7 you must talk directly to the WMI to manipulate the printers. This should work in Powershell 2 and up.  (New-Object -ComObject WScript.Network).AddWindowsPrinterConnection(""\\Printserver01\HPLaserJet"") (Get-WmiObject -ComputerName . -Class Win32_Printer -Filter ""Name='HP LaserJet'"").SetDefaultPrinter() (New-Object -ComObject WScript.Network).RemovePrinterConnection(""\\Printserver01\HPLaserJet"")"
PowerShell,390s71,JaapBrasser,1 point,Mon Jun 8 13:03:12 2015 UTC,"I'll try this now, but in the meantime, I'm going to tell you that when I try to manually try to create a new printer port with the UNC name, it tells me unknown username or bad password. Now, I have no idea where it gets the username and password, or why it works in the script, but could you tell me more about this?"
PowerShell,390s71,InvisibleTextArea,1 point,Mon Jun 8 13:06:51 2015 UTC,"I came to this thread to say this, if you are on Windows 7 I would also recommend to do as InvisibleTextArea advised you."
PowerShell,390s71,InvisibleTextArea,1 point,Mon Jun 8 13:07:31 2015 UTC,"I know I said this worked in the script, but I could have sworn something similar did work. Anyway, I get unknown username or bad password when calling AddWindowsPrinterConnection and This network does not exist when calling RemovePrinterConnection."
PowerShell,390s71,m0po,1 point,Mon Jun 8 13:20:25 2015 UTC,I would suspect there is something not right with the Printer ACLs on the server. However you can specify a username and password in the AddPrinterConnection Method call as per the API docs (You can't with AddWindowsPrinterConnection as that obviously runs under the context of the user).  https://msdn.microsoft.com/en-us/library/kxsdca3c%28v=vs.84%29.aspx
PowerShell,390s71,m0po,1 point,Mon Jun 8 13:42:33 2015 UTC,"Actually, I managed to get AddWindowsPrinterConnection to work by authenticating with net use first. However it still behaves kind of strange; the new connection doesn't show up under Print Server Properties as it should, and it comes up with a list of all the servers on that network somehow! I'll try AddPrinterConnection. Still getting ""This network connection does not exist"" with RemovePrinterConnection though."
PowerShell,390s71,After_8,1 point,Mon Jun 8 14:24:46 2015 UTC,"That makes me think the machine isn't quite hooked up to the domain properly. Do you get any other Auth errors when you're using these systems (I'm suspicious of the whole 'run a boot image' in a windows environment, sane people would use a terminal server)."
PowerShell,390s71,After_8,1 point,Mon Jun 8 15:37:29 2015 UTC,"How it works is, the image starts up a program that logs you into the university's lab network. The account that's actually logged into Windows is the Administrator account, but the script knows who you are and handles the network stuff.   And I couldn't get AddPrinterConnection to work, it kept spitting out an Invalid Device Name error."
PowerShell,38z0kf,bundyfx,6,Mon Jun 8 01:14:28 2015 UTC,This is one of those why not projects just for fun. Love it
PowerShell,38z0kf,silentmage,2,Mon Jun 8 01:18:34 2015 UTC,Thank you! just doing it for the love of PowerShell really haha.
PowerShell,38z0kf,creamersrealm,4,Mon Jun 8 02:28:46 2015 UTC,"That's cool, you should post pictures of it in action."
PowerShell,38z0kf,creamersrealm,3,Mon Jun 8 02:41:37 2015 UTC,"Hey mate, there's a picture of it in action in the previous blog post:  https://flynnbundy.wordpress.com/  Cheers!"
PowerShell,38z0kf,twowordz,1 point,Mon Jun 8 02:44:25 2015 UTC,"Derp on my part, I didn't even think to navigate the site. Very cool and the underlying code looks simple."
PowerShell,38z0kf,nduval,2,Mon Jun 8 03:21:15 2015 UTC,Website optimized for 640x480.
PowerShell,38z0kf,JaapBrasser,1 point,Mon Jun 8 02:13:32 2015 UTC,Heh yeah noticed it pasted the code a bit wildly.
PowerShell,38z0kf,nduval,1 point,Mon Jun 8 02:28:26 2015 UTC,"It was definitely cool.  Though, I had like 8 things open in my ISE where I ran this, and it closed them all out without any recovery when I closed the channel selection.  Lesson learned.  Seriously though, it was cool."
PowerShell,38z0kf,nduval,2,Mon Jun 8 03:01:33 2015 UTC,"I had the same problem, comment out line #10 and you won't have the problem anymore. Also you can recover your tabs by killing the powershell_ise process. After reopening it you will have your tabs back as the window was only hidden."
PowerShell,38z0kf,JaapBrasser,1 point,Mon Jun 8 06:40:04 2015 UTC,Good tip. and apologies to any work i may have accidentally destroyed!
PowerShell,38z0kf,800oz_gorilla,1 point,Mon Jun 8 08:52:31 2015 UTC,"All is well!  It was just hidden, and everything is back to normal.  =)"
PowerShell,38z0kf,TotesMessenger,1 point,Mon Jun 8 14:42:45 2015 UTC,Thanks for the tip!  Everything is back up.
PowerShell,38yxne,sleeper1320,1 point,Mon Jun 8 00:49:53 2015 UTC,"What confuses me the most is:  C:\Development> Test-ModuleContext |fl name,privatedata  Name        : PowerClient PrivateData : {cloudDDI, cloudUsername, cloudAPIKey, identityProvider}"
PowerShell,38wzm7,newwag,5,Sun Jun 7 15:34:43 2015 UTC,"$Files = Get-ChildItem | ? {$_.PSIsContainer -eq $False} | Select -ExpandProperty Name,Extension  ForEach ($File in $Files){                        $DestinationFolder = ""$($Folder)"" + '\' + ""$($File.Extension.Replace('.',"""").ToUpper())""                        If (!(Test-Path $DestinationFolder)){mkdir $DestinationFolder}                        Move-Item -Path .\$File -Destination $DestinationFolder                       } #Close ForEach   This should move all files into a folder by extension name for a single folder. If you want to recursively go through subfolders, some additional scripting would be necessary.  Edit: Amended the split with just grabbing the extension, thanks /u/Brekkjern."
PowerShell,38wzm7,HalalVeggieBacon,5,Sun Jun 7 16:00:24 2015 UTC,Wouldn't it be better to use the file extension property of the file object instead of splitting the string?
PowerShell,38wzm7,Brekkjern,1 point,Sun Jun 7 17:27:14 2015 UTC,Absolutely. I forgot about that. I'll amend the script to use it.
PowerShell,38wzm7,HalalVeggieBacon,4,Sun Jun 7 17:40:32 2015 UTC,Can you expand on what is going on here?
PowerShell,38wzm7,ichegoya,7,Sun Jun 7 16:11:33 2015 UTC,"Sure.  First, we're grabbing a list of all the files in the directory you're operating out of, and filtering out containers (directories). We only want a list of the file names, so we're instructing Powershell to select and expand the ""name"" property. Usually, the ""-ExpandProperty"" is reserved for properties which are arrays, but doing it this way cuts out the ""Name"" header and gives us a raw list of files. Not necessary for this application, but if you were exporting the files list as text, it can be useful.  From that list of files we just grabbed, we're going to do the following to each file:   Split the filename text by every instance of ""."", and store the subsequent array in a variable $SplitName.   It works like this: If we split ""two.purple.turtles.txt"" by ""."", the result would look like this:  two  purple  turtles  txt   Define an index variable and subtract one from the number of items in the $SplitName variable. This is important, because array indexes start at the number 0, which is the first entry in the array.   In the previous example, if we saved our output as $Variable, the following indexes would give us the following values:  $Variable[0] - two  $Variable[3] - txt    We then define ""$DestinationFolder"" as the last item in the split filename, and we make it uppercase by Adding the .ToUpper().   Now that we have everything we need, we're going to see if a foldername with the extension exists. If it doesn't, we're going to create a new folder with that extension name. Then we just move the file to the folder.  Rinse and repeat, for every filename stored in the initially defined variable $Files."
PowerShell,38wzm7,HalalVeggieBacon,2,Sun Jun 7 16:32:30 2015 UTC,"Thanks this is really useful. I think I understand what's going here, except $Extensions = @()  How would you make it recursive (would this script need to run inside of ForEach loop)?"
PowerShell,38wzm7,HalalVeggieBacon,1 point,Sun Jun 7 16:37:50 2015 UTC,"I pulled the $Extensions array out. I was going to do this a different way, but I said ""Hell, let's keep it simple"". You can ignore the empty array.  To make it recursive, you'd want to instruct Get-ChildItem to recursively enumerate all files.   For ""Select"", you'd want to get both the ""Name"" and the ""FullName"" properties. This is because FullName gives you the full path of the file, which makes grabbing the files from a static location much easier.  I'll add that functionality and post it."
PowerShell,38wzm7,HalalVeggieBacon,1 point,Sun Jun 7 16:42:17 2015 UTC,"$Files = Get-ChildItem -Recurse | ? {$_.PSIsContainer -eq $False} | Select Name,FullName  ForEach ($File in $Files){                        $FullPath = $File.FullName                        $FileName = $File.Name                        $SplitName = $FileName.Split('.')                       $Index = $SplitName.Count - 1                        $DestinationFolder = $SplitName[$Index].ToUpper()                        If (!(Test-Path $DestinationFolder)){mkdir $DestinationFolder}                        Move-Item -Path $FullPath -Destination $DestinationFolder                       } #Close ForEach"
PowerShell,38wzm7,HalalVeggieBacon,1 point,Sun Jun 7 16:46:13 2015 UTC,"Thanks! You're being a great help.  Could this be modify, so that it would only sort files at each directory level. So that the $DestinationFolder = the file extension added to the original file path?"
PowerShell,38wzm7,HalalVeggieBacon,1 point,Sun Jun 7 17:05:29 2015 UTC,"No worries bud, I like helping in problem solving.  Do you mean that, for each directory, you create an extension directory and move the files into those new folders? Absolutely. But if you mean something else, let me know and we'll make it happen."
PowerShell,38wzm7,KevMar,1 point,Sun Jun 7 17:08:24 2015 UTC,Yes.  eg Path\SubPath\File.ext becomes Path\SubPath\EXT\file.ext
PowerShell,38x7at,tnorton76,1 point,Sun Jun 7 16:40:04 2015 UTC,I think you just missed the foreach-object (%) designation on that command:  get-adgroupmember Group | foreach-object{ get-aduser $_ -filter {....
PowerShell,38x7at,KevMar,1 point,Sun Jun 7 17:17:09 2015 UTC,"Thanks, tried that with the same result.    Looking at the get-aduser  -Filter parameter it looks like it doesn't accept pipeline input."
PowerShell,38x7at,JaapBrasser,1 point,Mon Jun 8 00:45:42 2015 UTC,"Seems to be working fine here, both with Get-ADUser and Get-ADObject:  Get-ADGroupMember 'Domain Admins' | Get-ADObject -Filter 'name -like ""admin*""'  Get-ADGroupMember 'Domain Admins' | Get-ADUser -Filter 'name -like ""admin*""'"
PowerShell,38x7at,JaapBrasser,1 point,Mon Jun 8 06:46:46 2015 UTC,It will get the one account but as it tries to go through the rest of the objects in the pipeline I receive    The input object cannot be bound to any parameters for the command either because the command does not take pipeline input or the input and its properties don't match any of the parameters that take pipline input.   I'll post a screenshot later.
PowerShell,38x7at,impatienthypnotic,1 point,Mon Jun 8 13:05:26 2015 UTC,"You could also filter using Where-Object, as Get-ADUser does not filter if you put a specific object into it through the pipeline. Which properties do you want to filter for exactly?"
PowerShell,38x7at,JaapBrasser,2,Mon Jun 8 13:37:11 2015 UTC,"This was my thought too. I tested this and it works.  Get-ADGroupMember ""Domain Admins"" | Get-ADUser -Properties smartCardLogonRequired | Where-Object {$_.Enabled -eq $true -and $_.smartCardLogonRequired -eq $true}   You'll need to add an additional Where-Object or similar if your group contains objects that aren't users."
PowerShell,38x7at,wookiestackhouse,2,Mon Jun 8 18:43:26 2015 UTC,Great minds think alike...that was my method 2 :)
PowerShell,38x1k2,thunderchld,1 point,Sun Jun 7 15:51:21 2015 UTC,Maybe it accepted your invite anyway because you're an Exchange admin?
PowerShell,38x1k2,butthole-scientist,1 point,Mon Jun 8 00:33:37 2015 UTC,Try with a test account. I ran into a similar issue and I found that I had to manually go in through the GUI to do this for the room for only one of them.
PowerShell,38x1k2,iwifia,1 point,Mon Jun 8 03:01:32 2015 UTC,"add the following     -AllRequestOutOfPolicy $false   You need to have it set up so on the Resource out of policy requests page, it is set to selected recipients that is blank."
PowerShell,38wanq,joakimbs,2,Sun Jun 7 10:57:12 2015 UTC,Nice to see you around here as well joakimbs! Thanks for sharing your script.
PowerShell,38wanq,JaapBrasser,2,Sun Jun 7 11:34:57 2015 UTC,"Or in Windows 8+, this is supported natively: https://technet.microsoft.com/en-us/library/jj649816(v=wps.630).aspx"
PowerShell,38wanq,Get-ADUser,1 point,Sun Jun 7 16:21:12 2015 UTC,"Check out Get-ScheduledTask, part of the Carbon module, so it comes with a lot of other goodies, including functions for creating scheduled tasks."
PowerShell,38wanq,splatteredbits,1 point,Sat Jun 13 15:19:05 2015 UTC,"Je t'en prie (if this doesn't make sense, blame Microsoft Translator)."
PowerShell,38wayo,Prozac500,2,Sun Jun 7 11:01:30 2015 UTC,Is there a reason you aren't naming the columns instead of using *? It's about the only thing you can do aside from resorting to SMO or ADO.NET (the latter not being too hard). The way it deals with it is to stick a 1/2/3 etc columns onto the end of the duplicates.
PowerShell,38wayo,im_cody,1 point,Sun Jun 7 11:08:09 2015 UTC,"Not especially but I am trying to get a indication of what the cmdlet can and can't do. That sort of script wouldn't be used as I intend for this to run scripts which will affect data and schemas, not return results. Coudl you elaborate on the issue for me? The cmdlet can't handle results if there are 2 or more columns with the same name in the result-set unless named in the select?"
PowerShell,38wayo,im_cody,1 point,Sun Jun 7 11:50:07 2015 UTC,"Yes that's what it looks like. I'm as surprised as you but some apps are like that and I guess this is one of them.   PowerShell of course can't have an object with two columns of the same name though I'm surprised the cmdlet doesn't rename them accordingly (as ADO.NET does under the covers).   Still, and I'm going to be frank here, a query like that with select * AND multiple columns of the same name is not good practice. It's so rare I suspect that's why they didn't handle it.   Like I said you can do a simple ADO.NET wrapper and you'll get a DataTable out of it which is just as good for object work. Invoke-SqlCmd has been literally chock full of bugs (especially when handling error conditions which it can completely swallow depending on the version you're using) and I don't use it unless I'm being extremely lazy. I'm not sure if they've been fixed or not, would be fun to try out I guess."
PowerShell,38wayo,ramblingcookiemonste,1 point,Sun Jun 7 11:58:19 2015 UTC,"Thanks for the response, I'll do some more testing around this. Not sure how useful invoke-sqlcmd is in that case. Seems like a really odd limitaiton, most databases are going to have an ID column in each table which from the sounds of makes this cmdlet fall over. Cheers again"
PowerShell,38wayo,KevMar,1 point,Sun Jun 7 12:03:10 2015 UTC,"Hi!  That is odd. There are no conflicting column names in the tables you are joining?  On a side note, folks are mentioning ADO.NET; you can do that by hand, or borrow an abstraction, Invoke-Sqlcmd2. It adds a number of features, including parameterized queries, and avoids a few bugs in Invoke-Sqlcmd (that may have since been fixed?).  The one downside: no using the MSSQL specific 'GO' statement. Just execute separate queries if you really need that; in your case, you would use the -Database 'databasename' parameter to skip that first statement.  Lastly, if sqlcmd works, I see no reason not to just use that. That being said, I suspect queries that return multiple columns with the same name is not something you want to get used to doing...  Cheers!"
PowerShell,38skxz,im_cody,7,Sat Jun 6 13:24:54 2015 UTC,"A pattern that has worked well for me in managing complex data access(parsers especially, ugh!) has been this:      Write a C# class library(dll) that does exactly what I need.  C# is just better at this- better supported and better equipped for the complexity.  Use that C# library in my Powershell scripts.   I get all the nice parts of PowerShell - interactivity, interpreted language so no typing futsing, etc.  But I also get the good parts of C#, and I get to shove all that complexity in a box and use it as ""semi-compiled"" code.  Hope this helps!"
PowerShell,38skxz,SEA-Sysadmin,3,Sat Jun 6 18:39:21 2015 UTC,"This is the right answer.  It is very easy to use that dll. So you get to leverage visual studio for your more complex C# code, but execute it from powershell.   I have not looked into it, but there is a way to even white your cmdlets in C#."
PowerShell,38skxz,KevMar,1 point,Sat Jun 6 19:26:24 2015 UTC,I like this method. I think I might try this for what he is thinking above. Right now I'm writing a module that stores it's information in SQL and it would be so much easier if I could write all the data access and in EF6 and then write to the objects instead of writing all that tsql out.
PowerShell,38skxz,mav_918,1 point,Sat Jun 6 20:24:24 2015 UTC,"+1; PowerShell is really powerful but it has its limitations (lack of real OOP and threading in a way that doesn't suck is a big one, for example)"
PowerShell,38skxz,mrcrassic,1 point,Sun Jun 7 02:42:09 2015 UTC,"I don't think the threading is that bad!  Having to learn to use jobs was a great primer on design for distribution and parallelism! I never really missed classes in powershell.   If I want those,  I'll make a dll.   I don't think they belong in uncompiled code because of readability,  but that's just my 2c.  I tend to want powershell to be about ""what's being done"",  not about data structures."
PowerShell,38skxz,SEA-Sysadmin,1 point,Sun Jun 7 21:26:04 2015 UTC,"It depends on what you're trying to do. .NET threads consume ~1 or ~4MB overhead (for the thread's stack) and can access objects on the process's heap. So invoking threads within a thread pool to do the needful and having them share objects allocated by the main process is ""easy"" as long as you make your objects thread-safe (i.e. the objects being shared can be accessed one thread at a time).  This is not the case at all with PowerShell jobs. Jobs are, more or less, individual PowerShell sessions executing serialized scriptblocks. This means that the jobs have (a) no access to whatever state their parent script has, at all, (b) have MUCH bigger overhead than threads (20MB at a minimum) and (c) are a lot more difficult to debug (for one, you can't even share the parent host with them, so any debug messages you print will appear on the parent host once those job finishes).   While they solve the problem of running processes or simple scripts concurrently, they aren't great for things that are typically better suited for real .NET threading.  (You could hack your job invocations so that they run within the same runspace of the parent host instead of within isolated sessions, but that only addresses the memory overhead problem. You can also use Powershell workflows instead of Jobs, but the shared state problem is still a problem and has its own interesting quirks, like some cmdlets not being suitable for use within workflows).  Disclaimer: I tried writing a managed Powershell job queue that alleviated many of these problems."
PowerShell,38skxz,mrcrassic,2,Mon Jun 8 15:00:46 2015 UTC,"This is one way to load a DLL, create objects and call functions on them.  [System.Reflection.Assembly]::LoadFrom("".\myProject.dll"") $myObject = New-Object myNamespace.myClass $myObject.MyFunction()"
PowerShell,38skxz,KevMar,2,Sun Jun 7 00:00:55 2015 UTC,So I was on vacation when I read your post and I started thinking about it. I actually responded because I was curious about the exact same thing. I really like EF Code First because its so easy to develop with and I was wondering how I would bridge that gap from PowerShell (the main tool of getting my data) and SQL (the storage of the data).  I just got home and I started researching..  Check out these links and let me know if they help..  found this one on Pluralsights blog:  http://blog.pluralsight.com/tooling-with-powershell  https://github.com/beefarino/EntityShell  Also this.. (might not be in active development)  https://powerquery.codeplex.com/  I dont know which one I'm going to try but EntityShell looks promising - even though i dont really like using a PSProvider..
PowerShell,38skxz,mav_918,1 point,Tue Jun 9 00:41:24 2015 UTC,Currently working with EF 6 and PowerShell separately. I would absolutely love to use and see what you describe. It would save me so much time.  EDIT: I write my functions to correspond with the tables I wrote in EF and my functions will always write to those tables. It would be really cool to define those table objects in PS so you could write to them without all that boilerplate. Smelling a module opportunity...
PowerShell,38skxz,mav_918,1 point,Sat Jun 6 16:34:23 2015 UTC,"Check out LINQPad, it has nothing to do with PS but you can save scripts and what not.   Sounds to me like the tool you need. Since you know some C# you should feeel right at home."
PowerShell,38skxz,flaccidicus,1 point,Sat Jun 6 17:41:46 2015 UTC,"does anyone know of an active record / ORM tool written in powershell? i have had some success with nhibernate, but it was a lot of work compared to just doing it in pure c#. haven't really tried EF yet, but it's definitely on my list along with dapper and massive. i know the lack of support for generic methods in powershell was frustrating the last time i tried nhibernate ~2 years ago. i think there could be a huge opportunity here to develop an ORM like tool for powershell, which would help build the powershell ecosystem IMO."
PowerShell,38s6fp,NzNacer,2,Sat Jun 6 10:15:15 2015 UTC,"So at first you create a function, but then you never execute a function. By creating a function you only load the function in memory, waiting to be executed. Here I have taken your function and after defining the function I call it with some parameters to run Test-Connection:  Function pingme {     Param (         $subnet = ""192.168.1"",         $start = 200,         $end = 210     )      $start..$end | ForEach-Object {         Test-Connection ""$subnet.$_"" -Count 1 -Quiet     } } #end pingme PingMe -Start 1 -End 10 -SubNet 10.10.10"
PowerShell,38s6fp,JaapBrasser,1 point,Sat Jun 6 10:38:57 2015 UTC,So you mean when ever I want to use that function first I need to run the script file pingme.ps1 and then I use the cmdlet ?
PowerShell,38s6fp,JaapBrasser,2,Sat Jun 6 11:13:53 2015 UTC,"Saving your code as a script and running it will do nothing. It will load the function in the scope of the script and once the script finishes running, after doing nothing the scope of the script will also disappear.  Basically if you want to save this function when it is stored in a script file, you need to dot source it. For example:  . .\pingme.ps1   This will load the functions from the script in your current scope."
PowerShell,38s6fp,i_me_me,1 point,Sat Jun 6 14:50:35 2015 UTC,Yes.  To simplify it you could also add that script to your profile so that it loads the function for you any time you own up the shell.  Just Google PowerShell profile to see how to set it up.
PowerShell,38s6fp,Vennell,1 point,Sat Jun 6 12:42:17 2015 UTC,Ok. thanks I_me_me :) i'll google it and see
PowerShell,38s6fp,joe_cool88,1 point,Sat Jun 6 12:46:33 2015 UTC,Can't tell but are you calling the function you created?  Once created you should be able to call the function with the command pingme
PowerShell,38s6fp,WindosBK,1 point,Sat Jun 6 10:28:13 2015 UTC,what do you mean /(and how) call it ? sorry my English is not so good
PowerShell,38s6fp,MKmsftFan,1 point,Sat Jun 6 11:12:08 2015 UTC,"In order to call the function the code should like this:  function pingme{  code here  }  pingme #this line calls the function ""pingme"" to run."
PowerShell,38s6fp,Ropiak,1 point,Tue Jun 9 21:13:05 2015 UTC,"Hey again :)  Idid what you told me to do mates , but here is the issue   when I call the function from the console nothing happen  but when I copy/paste it and then do the cmdlet that I create ""pingmee""  every thing work nice   see here  http://i.imgur.com/DphXT1Y.png"
PowerShell,38s6fp,Ropiak,2,Sat Jun 6 11:24:07 2015 UTC,"In order to run the script file as you're showing there you need to 'dot source' it. That is, put a period, then a space before the path to the script. In this case:  . .\pingme.ps1   Basically, if you just 'run' the script file, the functions are only available within the script file itself (so if you had called the function inside the script file, it would have run), but if you dot source the script file, it makes that function available to the session you're running your commands from.  I'm sure others can explain this more clearly, but using the term dot sourcing should bring up a bunch of info if you go looking."
PowerShell,38pe8k,jcotton42,10,Fri Jun 5 18:53:38 2015 UTC,"1) Object oriented pipes   In my experience, this one separates the folks who thoughtfully consider their toolset from the ones that are just rabidly anti-MS or resistant to all change.  I'm longing for the day that Pash is complete enough for Real Work on Linux."
PowerShell,38pe8k,tangobravoyankee,5,Fri Jun 5 21:06:09 2015 UTC,"I'm fairly anti-MS in a lot of ways, but my view of them has been changing over the last few years.  Hands down the object-oriented nature of the powershell pipeline is in every way superior. I can't count how many times I've created one-off minature DSL ""communication protocol"" languages to glue scripts together in bash. And I always have to think about special characters that might break the formatting and make the text ambiguous.  The only real qualms I have about powershell is the expensive startup - sometimes it takes more than a minute for me to get a prompt - and the somewhat clunky syntax. That last one might be a bit of my Linux biases showing, but it just feels off a bit.  So what's this I hear about SSH being included in powershell? Controlling a windows machine from Linux is painful in many many ways, cygwin's SSH just doesn't cut it, especially if you want to deal with powershell scripts."
PowerShell,38pe8k,beltorak,3,Fri Jun 5 23:37:12 2015 UTC,"The only real qualms I have about powershell is the expensive startup - sometimes it takes more than a minute for me to get a prompt   I think something must be seriously janky with your setup. My work laptop is a couple generations behind using a McAfee-encrypted spinning disk and PS starts up as fast as anything else does.   and the somewhat clunky syntax   That turned me off at first as well. It takes a while for ?, %, and $_ to become intuitive, Verb-Noun makes everything feel verbose, and while there are K&R-style aliases for a bunch of commonly used cmdlets, I've come to dislike them for other reasons.  But I got over it as soon as I needed to do something non-trivial where no viable alternative to PowerShell existed. Over the course of a few weeks I put together a 600+ line module to automate a painful VMware process. Looking at it five years since I last maintained it, the only WTF I see is that I did something unusual in a place where a HashTable would have been appropriate and I've got some lines where Write-Output is at the start of a pipeline that gets swallowed by something else. The code is still very understandable and so far as I know still in frequent use.  At this point it pains me to use anything besides PowerShell for anything that isn't throw-away code. PowerShell's foundation for building modular, discoverable, and maintainable scripts is just so much better and simpler than anything else that I've been exposed to."
PowerShell,38pe8k,tangobravoyankee,2,Sat Jun 6 02:10:25 2015 UTC,"Neither ?, %, or $_ are unique to powershell and all should be at least somewhat familiar concepts to sysadmins from any background. ? Is an alias for where-object and behaves just like SQL's WHERE. % is an alias for foreach-object and behaves the same as any number of for each statements in any number of object oriented languages. I learned in perl in Linux initially. Likewise, $_ is used to address members or functions of the current object in the pipe just like you'd see in most object oriented languages, again perl has had this for a very long time as well. The verb-noun structure is new, given. ?, %, $_ (or what they alias) have all been around far far longer than powershell has though."
PowerShell,38pe8k,SSChicken,2,Sat Jun 6 03:15:38 2015 UTC,"Controlling a windows machine from Linux is painful in many many ways   There is pywinrm and openwsman. Tho I think you're much better off with Chef, Puppet, or writing PS scripts that expose themselves as web services depending on the use case."
PowerShell,38pe8k,tangobravoyankee,2,Sat Jun 6 02:24:40 2015 UTC,clunky syntax   Verb-Object -SomeOption someValue seems straightforward enough.   Was there something in particular that you meant?
PowerShell,38pe8k,Catsler,3,Sat Jun 6 01:07:42 2015 UTC,"I'm longing for the day that Pash is complete enough for Real Work on Linux.   As a Mac user at home, I'm right there with you."
PowerShell,38pe8k,alinroc,1 point,Fri Jun 5 22:59:28 2015 UTC,"Posh on linux is a dream come true. Waiting for that for years. Linux shells suck big time, IMO.  There were OO shell projects tho, but all not successful, for instance rush (ruby shell)."
PowerShell,38pe8k,majkinetor,2,Sat Jun 6 07:25:52 2015 UTC,I'm on Linux daily and as much as I love some parts of it...I really really seriously miss powershell.
PowerShell,38pe8k,pohatu,1 point,Fri Jun 5 21:24:12 2015 UTC,My most recent former job forced me to use a bastardized RHEL 6.5 workstation. On hardware new enough to only work well with newer distros. And my work was 100% Windows / VMware / PowerShell.   I died a little every day.
PowerShell,38pe8k,tangobravoyankee,1 point,Sat Jun 6 02:16:48 2015 UTC,I don't see which comment you're referring to :-/
PowerShell,38pe8k,No1Asked4MyOpinion,1 point,Fri Jun 5 22:45:52 2015 UTC,The one authored by user h4rm0ny
PowerShell,38pe8k,alinroc,1 point,Fri Jun 5 22:58:57 2015 UTC,He had some very good points and I agree with all of them. Powershell does good of each item does one thing and it does it well. Its amazing how you can manipulate data down the pipeline to get what you want. Powershell has it quirks like I can't pipe from get-itemproperty in the registry to set-itemproperty and certificate management with powershell really sucks right noe. But the language is still very new and will evolve over time.
PowerShell,38r49v,tangobravoyankee,2,Sat Jun 6 02:36:39 2015 UTC,"I have to ask, what are you using floppy disk image files for? Whatever you are doing, there must be another way."
PowerShell,38r49v,KevMar,1 point,Sat Jun 6 05:21:57 2015 UTC,Windows unattended installation files for virtual machines. I'm looking to re-write and Open Source a collection of scripts I have to build up-to-date Windows OS images from scratch and in bulk.  I'd like to have a script that can generate the floppy images from scratch on any Windows workstation. Might not be achievable but I figure I should exhaust the possibilities before going another route.
PowerShell,38r49v,KevMar,2,Sat Jun 6 12:53:56 2015 UTC,"That sounds interesting. I think you can use a floppy or a USB drive for your unattend file. So if you can't find a reliable way to make a floppy, an iso or vmdk (or vhdx) may work too.  I think WDS injects the answer file into the WIM file on deploy."
PowerShell,38r49v,invoke-coffee,1 point,Sat Jun 6 16:47:06 2015 UTC,Probably worth investigating if setup would find autounattend.xml on a regular disk image.  Ideally I want as little prep work as possible to get started with my scripts so WIM extraction or non-stock ISOs are things I want to avoid.
PowerShell,38r49v,_Unas_,1 point,Sat Jun 6 17:57:37 2015 UTC,Take a look at MDT. It's really easy to set up and is excellent for creating images.
PowerShell,38pc5w,spiritbear872,17,Fri Jun 5 18:41:01 2015 UTC,"Learn how to program. It's not magic, it's just logic. Start off by dropping the ""I am an old DOS man who is a Windows Sysadmin"" mindset. You're just using and learning a tool and there is nothing in your background that prevents it.  http://programming-motherfucker.com/become.html  Yes there is some powershell specific stuff there."
PowerShell,38pc5w,mhurron,2,Fri Jun 5 18:49:27 2015 UTC,"To elaborate on your ""drop the 'i am an old...'"" comment:  OP, If you have ever taken a logic or an algebra class, then you have what it takes to be successful. At this point, it's about learning the ""language"".   you learned english because that's the language you were exposed to, but not everyone was. Others learned different languages. If you know what you want to do (ask where the bathroom is, or look an object in AD), then the hard work is done, you just have to translate it. Powershell, more than anything else, is great for the ""learn by doing"" approach.   In addition to that:  http://www.amazon.com/Learn-Windows-PowerShell-Month-Lunches/dp/1617291080  https://www.youtube.com/playlist?list=PL6D474E721138865A"
PowerShell,38pc5w,IANALAMA,1 point,Fri Jun 5 21:08:00 2015 UTC,That link made me almost piss myself!
PowerShell,38pc5w,hailGunslinger9,6,Fri Jun 5 23:27:17 2015 UTC,"I know the above poster's criticism may be a bit harsh, but in my experience it's exceedingly true. For the longest time I made all sorts of excuses for why I didn't need to learn an automation language... But the harsh reality of technology is if you don't adapt to the skills that are in demand you won't be in demand. Automation is taking over, get with the program or let some young punk who isn't making excuses take your job when management starts to see the benefits of moving to more of a devop's style of system administration."
PowerShell,38pc5w,GLiMPSEiNATOR,1 point,Fri Jun 5 19:03:20 2015 UTC,"Recently termed ""undifferentiated IT"" by Jeffrey Snover on the Arrested Devops podcast.  https://overcast.fm/+BvUXJwGV8/34:32  Don't be the guy whose job is to click the Next button."
PowerShell,38pc5w,Catsler,1 point,Fri Jun 5 22:04:02 2015 UTC,I used to be the guy who talks to Engineers so customers dont have to. Think Office Space.
PowerShell,38pc5w,Sinisterly,1 point,Fri Jun 5 22:26:06 2015 UTC,The guy whose job gets eliminated because the Bobs deem it needless?
PowerShell,38pc5w,drh713,3,Sat Jun 6 13:24:43 2015 UTC,Relevant: https://youtu.be/nuHfVn_cfHU
PowerShell,38pc5w,xinehp,1 point,Fri Jun 5 21:26:15 2015 UTC,"There's a subreddit for that! http://www.reddit.com/r/learnprogramming  Start with learning variables. Variables allow the same code to work on different things.  You need to know how variables work to use loops. Arrays are sets of variables with one name, and normally an index at the end.  Then after loops, I'd say the biggest hurdle in learning programming is boolean logic. If you can do a loop, and have a solid understanding of booleans to make conditionals, you can pretty much figure anything out.    To your question, you mentioned ForEach,  foreach (which is an alias of ForEach-Object) isn't that complicated.  Its input is an array, it is a functional version of a for loop. It's an abstracted version of iterating through numbers, then having to manually reference the index of an array.  Think of it in terms of math..  You have a function. The code block of the loop is now the contents of the function.  f(x) = {do this to x}  if you have set (x1, x2...)  f(x1, x2...) = {do this to x1, then x2, then ...}"
PowerShell,38pc5w,robotblum,1 point,Fri Jun 5 21:31:37 2015 UTC,"Try writing your own scripts, and when you get tired of doing every item manually you might be more motivated to learn about foreach loops and working with the object currently in the pipeline $_."
PowerShell,38pc5w,dbrees,1 point,Fri Jun 5 22:56:38 2015 UTC,"A lot of people are saying ""go learn programming"".  You don't have to do that.  Just take one piece of your day to day work and learn how to do that in powershell.  Once you know how to do that, then learn how to do that task on multiple machines.  Once you know how to do that learn how to get the success codes/logs from that task on those multiple machines.  After that it get's easier, because then all you need to learn is the next task, because you will already know how to script for multiple machines."
PowerShell,38pc5w,ramblingcookiemonste,1 point,Sat Jun 6 00:08:57 2015 UTC,"Hi!  It can be tough if you don't spend some time with a formal PowerShell reference like a book, and then reinforce that knowledge by using it on a regular basis and asking questions / participating in the community. Those are three things that can help you get started learning PowerShell.  Also, PowerShell is a task based language - this means you can focus on what you want to do - get, sort, group, filter, etc. You do not need to know how to define the code behind the sorting, grouping, filtering and so forth. Don't underestimate how incredibly valuable this is. Think of what you want to accomplish in English. Break it down into pseudo-code, and then google how to do each step.  Do this on a regular basis. Like anything, it gets easier with practice.  Cheers!"
PowerShell,38pc5w,TheDewser,1 point,Sat Jun 6 02:46:46 2015 UTC,"Like most of the other responses, your best bet is to go through a ""learn <insert language here>"" class.  Python is a useful one.  There are a ton of free classes on that.    Powershell isn't too bad once you get the understanding of when and where to use some of the more advanced functions.  For example, simple explanation of the ""foreach"" loop.  You want to go through a bunch of stuff and ""for each"" object in that stuff, you want to run a command against it.  For example, you have a list of AD users and they may be scattered around the domain in different OUs, but you want to move them from wherever they are into a single OU, that could take a while if you do it by hand from the GUI, so script it!  It might look something like this:  $UserList = Get-Content C:\Temp\aduserlist.txt foreach ($user in $UserList)     {          Move-ADObject -Identity $user -TargetPath ""OU=DisabledUsers,OU=HQ,DC=Constoso,DC=LAN""      }   Something like that, here is a reference for a similar function.  In this day and age of agile computing, cloud deployments, and overall efficiency, learning to code will help a great deal, not only with helping you make things easier, but also allowing you to keep your job.  A friend of mine joked once that he wrote someone out of a job with a script.  It is funny but very true.  Automating the simple SysAdmin tasks will allow you more time to focus on more important projects like patch management, network health, log management, etc...  Got a simple task?  Sure it may take you a couple minutes to click through, but why not take the opportunity to script it out.  Might require some research but StackOverflow is your friend!  Good luck!!!  Also go look for any powershell user groups in the area, they can be pretty helpful as well."
PowerShell,38pc5w,mav_918,1 point,Sat Jun 6 12:09:24 2015 UTC,I agree with most of the people here when they say drop the old dos guy mindset. Conditional logic is tough at first but keep plugging away at it! It's all syntax once you get it. Specifically with the foreach statement. The confusing part is that the first variable is defined in the statement itself.   Foreach ($one in $many) {     $one.object }    $one isn't defined anywhere in the script until the foreach statement and it's scope is inside the foreach statement.   This was tough for me at first because like you I wasn't a programmer but once I got conditional logic the rest came quite a bit easier.
PowerShell,38pc5w,HalalVeggieBacon,1 point,Sat Jun 6 13:55:42 2015 UTC,"The key to writing scripts is to break down a task into its component steps. Writing a script is nothing more than creatively instructing the shell to accomplish the task at hand by providing instructions on to complete the steps which lead up to completing that task.  Powershell provides a lot of different tools to help you with your task, including the ability to store data in memory, text and arithmetic manipulation, and conditionals and loops. If you think about Powershell as not only a way to retrieve information, but as a way to manipulate, analyze and play with it, you may find it easier to jump over the mental hurdle."
PowerShell,38pc5w,Geekfest,1 point,Sat Jun 6 16:30:30 2015 UTC,"As an old BASIC tinkerer, transitioning to object oriented languages was the toughest transition for me.  It took me ages to get away from wanting to dump everything in to arrays.  :)  Some concepts which I really spent some time getting a handle on were objects (properties, and methods), collections, and classes.  If you are like me, I highly recommend spending enough time on each of these so you develop a good, intuitive grasp of each concept.    My code still tends to be little more like sequential programming than stuff I see from other folks, but I'm slowly getting there."
PowerShell,38p05i,norbin,3,Fri Jun 5 17:27:58 2015 UTC,"You don't really need to set your vars to $null. You only have to initialise them if you want to make sure they're set to something other than $null when you start - unless you're running things in the console/ise rather than from script or you're dealing with global: variables, then you need to be a little more careful.  It's a good idea to prefix your msiexec line with an ampersand (&) which tells powershell to execute the line as is rather than treating it as a cmdlet or string.  There are some weird issues with arguments passed to executables in powershell, you can read about the issue here but the TL;DR is that you can't always expect them to be passed to the command as you would expect if you were doing the same thing in a cmd window, especially if they have special or reserved characters in them."
PowerShell,38p05i,the_spad,1 point,Fri Jun 5 17:45:14 2015 UTC,"Thank you for the tips! noted the & call operator and vars part, i am yet to 'play' with global variables, will get to it at some point, so much new info i go through _^ endless waves of new stuff for me.  trying to keep it together heh. Will post more examples i write when I have them :)"
PowerShell,38p05i,sid351,1 point,Sat Jun 6 05:26:15 2015 UTC,"You can add a parameter to your function and give it a default value.  Something like this:  #Simple function to install the .MSI package if  Function Install-Package { Param(     $msipackage = 'c:\users\shay\desktop\package.msi'     )      msiexec /i /a $msipackage /qn }   You can also do parameter validation to ensure it conforms to a file path or other criteria.  Have a look for info on [cmdletbinding()] for more details on how to accomplish this.  Also, you could move the If...Else logic in to your function, if it's something that needs to be checked every time."
PowerShell,38p05i,root-node,1 point,Sat Jun 6 15:31:06 2015 UTC,"personally, I like to define my variables  [string]$cpu = '' [string]$cpupath = '' ...   This way anyone who reads my script after me can tell what type a variable is."
PowerShell,38p05i,sid351,2,Sat Jun 6 12:25:34 2015 UTC,"That doesn't just define what type of variable it is, that strong-sets them.  What this means is that the variable will only ever be allowed to be what type you set (strings in your example).  While this probably isn't a massive problem day-to-day I'm sure there would be examples where it's handy to use the same variable to go from a string to an int to a double to a custom object.  With that said, none come to mind immediately."
PowerShell,38p05i,JaapBrasser,2,Sat Jun 6 15:25:13 2015 UTC,"This just initially sets the variable, it could be changed at any point later in the script by using the -as operator or the method you are using here. If knowing the type of object is important you could always include it in the variable name or note it in the comments in your script."
PowerShell,38pc3h,kilkor,2,Fri Jun 5 18:40:38 2015 UTC,You want the -Properties flag (and quotes instead of parentheses around the filter):  Get-ADUser -Filter 'EmployeeID -eq $EmployeeID' -Properties EmployeeID
PowerShell,38pc3h,Waxmaker,2,Fri Jun 5 19:14:51 2015 UTC,"Bleh.. I had tried that, but it told me EmployeeID wasn't a recognized property.  Turns out it was the parenthesis causing the issue I guess.  Changed them to single quotes and it works now."
PowerShell,38pc3h,LandOfTheLostPass,1 point,Fri Jun 5 19:22:22 2015 UTC,"Get-ADUser has a Property property, I believe that you can use that to explicitly select the properties to return.  I'm not sure if you can filter on them though.  You may have to use the LDAPFilter property and a valid LDAP filter (e.g.: ""(EmployeeID=1234)"") which can be built using string formatting."
PowerShell,38pecq,sphinxpup,2,Fri Jun 5 18:54:17 2015 UTC,"The best I've ever come to this is to run it via powershell remoting. It's the dumbest thing, but this is a lot harder than it sounds"
PowerShell,38pecq,artvandelay440,2,Fri Jun 5 20:11:52 2015 UTC,i have run into this as well.  the issue is that the wmi process runs as 'SYSTEM' on the remote client.  The local system account does not have access to the network printers.  I got around this by looking at the registry hive of a known service account that logs into every one of our workstations.  but now i find this...and it works great!  http://powershell.com/cs/media/p/16643.aspx
PowerShell,38pecq,GenuineRanchDressing,2,Sat Jun 6 13:19:52 2015 UTC,Thanks! I'll check this out Monday. Appreciate it.
PowerShell,38pecq,geostude,1 point,Sat Jun 6 13:35:16 2015 UTC,"I checked this out and it looks awesome. I cant get it to finish though. It pings then says its getting printer information, but I never get the logs or any confirmation. I cant really understand it why its not going through. It says your logs are $here, but nothing is there. Was it smooth for you?"
PowerShell,38pecq,RC-7201,1 point,Tue Jun 9 15:12:11 2015 UTC,I'm thinking I am getting the Computer printers and not the User printers when I query remotely. I'm researching that.  Edit: I am going to try to query the HKEY_USERS and see if I can get that to work.
PowerShell,38pecq,invoke-coffee,1 point,Fri Jun 5 19:26:11 2015 UTC,"I'm fairly certain you'll either need to scrape the hku registry, or use PS Remoting..."
PowerShell,38ooc8,exaltedgod,2,Fri Jun 5 16:13:06 2015 UTC,"$computerlist = ""c:\Path\to\computer\list.txt"" $outputlist = ""C:\path\to\output\file.txt"" $errorlist = ""C:\path\to\error\file.txt""  $Computers = gc $computerlist foreach ($computer in $computers){     $Profiles = gwmi win32_userprofile -ComputerName $Computer | Where-Object {($_.SID -notmatch ""^S-1-5-\d[18|19|20]$"")} # ignore system account profiles      # Empty Array of Profiles     $colProfiles = @()      foreach ($Profile in $Profiles)     {     Try{     # Get the SID of the account who had logged in     $UserSID = New-Object System.Security.Principal.SecurityIdentifier($Profile.SID)      # Get the Domain\Username details from the SID     $User = $UserSID.Translate([System.Security.Principal.NTAccount])      # Get the DateTime values     $Time = ([WMI] '').ConvertToDateTime($Profile.LastUseTime)     $LogonTime = $Time.ToShortTimeString()     $LogonDate = $Time.ToShortDateString()      # Create an Object with the $User, $LogonDate &amp; $LogonTime properties     $LastLogons = New-Object system.object     $LastLogons | Add-Member -MemberType noteproperty -Name UserName -Value $User     $LastLogons | Add-Member -MemberType noteproperty -Name LastLogonDate -Value $LogonDate     $LastLogons | Add-Member -MemberType noteproperty -Name LastLogonTime -Value $LogonTime      # Populate the properties of the $LastLogons object with User, Logon Date and Time from the profiles     $colProfiles += $LastLogons     }      Catch [System.Exception]     {     ""Cannot query a local account's SID against the Domain""         $computer | out-file -append $errorlist     }      Finally {}     }      $colProfiles | ft -AutoSize     $colProfiles | out-file -append $outputlist }"
PowerShell,38ooc8,geostude,2,Fri Jun 5 17:35:34 2015 UTC,"Just change the variables up top, otherwise, not many edits needed.  Wrapped the entire thing in a foreach loop, Then added a few ""out-file""'s where appropriate.  the computer list needs 1 computer per line, not a CSV"
PowerShell,38ooc8,geostude,1 point,Fri Jun 5 17:36:54 2015 UTC,"Right on. Thank you very much.  After going through Technet, I was starting to append some of the things together but this is much cleaner than my solution. lol  Right now I am getting one error and I think it is because of the first ""foreach"" loop. Getting an error output in the console:   gwmi : Invalid parameter At C:\Users\exaltedgod\Desktop\Last_Logonv2.ps1:7 char:17 +     $Profiles = gwmi win32_userprofile -ComputerName $Computer +                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : InvalidOperation: (:) [Get-WmiObject], ManagementException     + FullyQualifiedErrorId : GetWMIManagementException,Microsoft.PowerShell.Commands.GetWmiObjectCommand     I did change the variable locations at the top to my directory, so I am a little stumped. It all looks right.  edit: Reading through the GCI (Get-ChildItem) I wonder if that might be the issue. Instead maybe I should be using Get-Content making a call to the file? Thoughts?"
PowerShell,38ooc8,geostude,1 point,Fri Jun 5 18:42:17 2015 UTC,You should.  Sorry.  This is why you shouldnt use aliases.  GCI and GC are very similar.   Replace GCi with GC or get-content.
PowerShell,38ooc8,xalorous,1 point,Fri Jun 5 20:40:53 2015 UTC,"Haha just after I posted that I put in the Get-Content and it worked. Awesome when I get back to a computer again, I will update the OP. Thank you so much for helping me out in this."
PowerShell,38nq6q,robotblum,3,Fri Jun 5 12:03:36 2015 UTC,"Well I have 2 that I use personally and started as 'just for fun'.      Text-Based Menu - This creates a menu where you can pass functions to each item. It's not something bulletproof to errors and not even hierarchical but works enough for now. It also cannot be used with PowerShell ISE since it uses the $host.UI.RawUI.ReadKey to capture the arrow keys. GUI Based - Something more advanced. Yes, like others say, it's counter-intuitive to build a GUI that will need to be launched via a command-line tool that will run command-line scripts. But it's quite fun!. The real bugger is how do you show console output."
PowerShell,38nq6q,supermamon,1 point,Mon Jun 8 02:25:11 2015 UTC,Could you share the code for the simple menu ?
PowerShell,38nq6q,HeXDeMoN,2,Tue Jun 9 03:55:22 2015 UTC,Here's a bare bones sample. Beware. Incoming ugly code.
PowerShell,38nq6q,supermamon,1 point,Tue Jun 9 06:02:06 2015 UTC,Thanks and no worries my code is always ugly do it mostly in notepad.
PowerShell,38nq6q,HeXDeMoN,2,Tue Jun 9 12:18:23 2015 UTC,WPF and Winforms are the most common ways to do Powershell GUI stuff - personally I prefer WPF as it's much more straightforward to code IMO.
PowerShell,38nq6q,the_spad,2,Fri Jun 5 12:12:47 2015 UTC,"Sure, it is quite easy to create forms using Win Forms. Have a look at the following code, I'm sure it will seem familiar to you:  Add-Type -AssemblyName System.Windows.Forms $Form = New-Object system.Windows.Forms.Form $Form.Text = ""Example Form"" $Form.ShowDialog()"
PowerShell,38nq6q,JaapBrasser,1 point,Fri Jun 5 12:18:54 2015 UTC,"Thanks for the info guys. I was hoping someone had a screenshot posted on imgur or something so I could compare the image I have in my head to something that's currently being used. I imagine this toolbox staying open on my admin station with different tabs ""Active Directory"" ""Exchange"" ""Servers"" ""Logs"" and I just have a centralized toolbox making all of my common duties a click away.  Also, what are some useful scripts to use? I currently have only written 1 powershell script which creates an org chart showing all managers and their direct reports."
PowerShell,38nq6q,JaapBrasser,2,Fri Jun 5 12:23:51 2015 UTC,It really depends on your role and day-to-day activities. I generally look for one or more out of three things before scripting: - Do I do this on multiple systems - Do I do this more than once - Is it important that is happens precisely as planned  So if I would advice you to look at your tasks and see what you would like to see automated or scripted. To give you an idea of what you can script here are some of my scripts that I shared with the community: TechNet Script Gallery
PowerShell,38nq6q,JaapBrasser,1 point,Fri Jun 5 12:36:12 2015 UTC,Thank you for the link Jaap! I think I will just write down some of the more tedious day to day tasks I do and start scripting them in my free time. Hopefully I don't automate myself out of a job.
PowerShell,38nq6q,the_spad,3,Fri Jun 5 12:51:20 2015 UTC,"You never automate yourself out of a job, you might automate yourself into a nicer job though. And the knowledge you gain by automating is something that is becoming increasingly important in today's industry.  A good time saver is to look for scripts online, before attempting to build something yourself. And when you are trying to learn, still get something online: use it, break it, understand it and then improve it. It's a good way to learn scripting and you get a bit of a feel of the different scripting styles."
PowerShell,38nq6q,xalorous,2,Fri Jun 5 13:02:11 2015 UTC,"I haven't built a GUI for my Powershell scripts because it seems kind of backwards to use a commandline tool to write a GUI that allows me to launch commandline tools :)  Most of the scripts I write are for myself or similarly competent users so I don't both with any UI stuff as I don't need it. If I'm writing for a servicedesk or regular users then I'll usually give them a UI to work with.  I've got a bank of scripts for everything from copying DHCP scopes between servers to remotely deleting Windows profiles to enabling & configuring users for Lync to creating new AD accounts to managing GPOs to getting account lockout events to mapping physical to virtual VMware disks. You name it, I've probably half-assedly written a Powershell script for it at some point."
PowerShell,38nq6q,ramblingcookiemonste,2,Fri Jun 5 12:36:29 2015 UTC,"I understand what you mean about writing a GUI for command line scripts, seems a little redundant. However, I think it will be a fun project to work on and if I share it with my co-workers/bosses they may be impressed with it. Like I said before my organization is on the smaller side but the good thing about scripts is how well they scale up.  Thanks for the ideas on the different scripts you are using!"
PowerShell,38nq6q,ramblingcookiemonste,1 point,Fri Jun 5 12:50:20 2015 UTC,"Also consider a custom mmc, if those can still be made."
PowerShell,38nq6q,rwoeirj,2,Tue Jun 9 21:51:31 2015 UTC,"Hi!  Here's a list of a few options for GUIs.  Can I ask... Why do you want to build a GUI, rather than stick to PowerShell? Quite frankly, you are going to be adding significant overhead and difficult to maintain code.  On the rare occasions that someone convinces me that a GUI is required, I generally spend ~25% of my time writing the PowerShell, 75% of the time writing the code behind the GUI.  If you really, really want a GUI, consider using 'Show-Command' and other features in the ISE, where you can plug in parameters in a GUI, but you don't need to write the GUI.  Building a toolbox is a fantastic idea. Re-usable tools will save you time, are easy to share, and will help you learn PowerShell. As an application programmer, you likely already realize how wonderful modular code is. Layering a GUI over these will provide minimal value, and may even hold you back from learning more, IMHO.  If I haven't convinced you, check out some of the work from /u/boeprox and /u/1RedOne on using Visual Studio to build WPF forms for your PowerShell work. But... please consider whether you really need this : )  Cheers!"
PowerShell,38nq6q,ramblingcookiemonste,1 point,Fri Jun 5 13:39:33 2015 UTC,"I've built a few C# applications that use GUIs already, and I just kind of like the layout and idea of it, though it may not be that practical. Right now, I have a limited number of scripts that I use, they are stored in a file that I copy and paste into powershell to reuse them. I think it would be impressive to just have this GUI, with a nice logo that says ""Admin Toolbox"" and you can search for the script you need, click it, maybe answer a few questions to set some initial variables and the code is executed.  I'm not too worried about the time invested, as i'm doing this mainly as a learning project and to keep myself busy (or improve my skillset to become more valuable and efficient to my employer).  *edit* For example, I get a ticket to create some new users. I have a powershell script for this already, but instead of opening power shell, finding the script in my documents and copy, pasting into the window, I click my ""create new user"" button from my GUI, enter the relevant information (considering i'm not adding many users from a csv which I have a different script for) and i'm good to go. As i'm doing this, I get a ticket that a printer isn't working, so I navigate in my Admin Toolbox GUI my script to restart the print spooler on my print server, with the click of a button. Etc."
PowerShell,38nq6q,rwoeirj,3,Fri Jun 5 13:47:37 2015 UTC,"If it helps, here are a few example GUI projects:   LazyWinAdmin Several tools from Rich Prescott   If you do go this route, consider writing and wrapping re-usable PowerShell functions that you can use in more automated or CLI solutions as well, rather than a monolithic GUI with no modular components.  Cheers!"
PowerShell,38nq6q,ramblingcookiemonste,1 point,Fri Jun 5 13:56:42 2015 UTC,"Thanks for the screenshots. I was visualizing something similar to the LazyWinAdmin. Also, nice blog, I'll bookmark it and i'm sure i'll check it frequently once I get started on this project. Thanks again for the information!"
PowerShell,38nq6q,tehreet,1 point,Fri Jun 5 14:02:36 2015 UTC,"I disagree.  I've built a support GUI that lets me search by user or computer. Automatically launch Remote Control, Remote Desktop, psexec, computer management, etc. all in one pane of glass.  All of the scripts behind it are modular though."
PowerShell,38o6me,jhulbe,2,Fri Jun 5 14:13:36 2015 UTC,"Sure, PowerShell Profiles. A PowerShell profile is a .ps1 file that is loaded everytime a PowerShell session is started (except when -NoProfile is specified).  To create your personal profile simply type notepad $profile and add those two lines in the file.  For more information about all the profile paths type the following:  $Profile | Select-Object -Property *   For detailed information of the different profiles and when to use them: Understanding PowerShell Profiles"
PowerShell,38o6me,JaapBrasser,1 point,Fri Jun 5 14:18:00 2015 UTC,Thanks man!
PowerShell,38o6me,JaapBrasser,1 point,Fri Jun 5 14:21:44 2015 UTC,No problem!
PowerShell,38nssa,coderwolf,6,Fri Jun 5 12:26:50 2015 UTC,"Start-Transcript -path ""C:\somefile.txt"" <Do some stuff> Stop-Transcript"
PowerShell,38nssa,the_spad,3,Fri Jun 5 12:29:08 2015 UTC,"This can be done, albeit in a rather hacky way. Unfortunately, ""Start-Transcript"" has several frustrating limitations. The only way I know to easily get a record of everything from a script's console output is to execute a new powershell instance with stdout/stderr redirection.  Here's an example. Save a test file to C:\test.ps1 with the following:  $WarningPreference      = 'Continue' $ErrorActionPreference  = 'Continue' $VerbosePreference      = 'Continue' $DebugPreference        = 'Continue' $WhatIfPreference       = $true  $ConfirmPreference      = 'None'      Write-Host ""PS Host"" Write-Verbose ""PS Verbose"" Write-Output ""PS Output"" Write-Warning ""PS Warning"" Write-Error ""PS Error"" [Console]::Error.WriteLine('Console Error') New-Item -Type File -Path C:\whatif -Whatif   Now run the following command in a CMD window or a .BAT file (the ""2>&1"" at the end redirects stderr to stdout):  powershell -file C:\test.ps1 > C:\test.log 2>&1   All output will be captured to the log file formatted exactly like you'd see it in the console (with the exception of things like Write-Progress refreshes and the like). And you won't get console colors, obviously.  If you want output in both console and log file, you'll need to use something like wtee with a command like this:  powershell -file C:\test.ps1 | C:\wtee C:\test.log 2>&1   This solution probably kills kittens every time you run it, but it does work."
PowerShell,38nssa,Waxmaker,1 point,Fri Jun 5 15:53:20 2015 UTC,"$WarningPreference      = 'Continue' $ErrorActionPreference  = 'Continue' $VerbosePreference      = 'Continue' $DebugPreference        = 'Continue' $WhatIfPreference       = $true  $ConfirmPreference      = 'None'      Write-Host ""PS Host"" Write-Verbose ""PS Verbose"" Write-Output ""PS Output"" Write-Warning ""PS Warning"" Write-Error ""PS Error"" [Console]::Error.WriteLine('Console Error') New-Item -Type File -Path C:\whatif -Whatif   redirection is fine, and the kittens will have to die (hiding from ASPCA).  This is not something I am using very often, so they probably repopulate faster than I would kill them :P  The problem with this solution however is that I want it to allow for an interactive command session, not a script file.  (ps I was unable to complete a test with this, but it sounds like a solution I could be looking for.  Would this also catch Dos commands and output?)"
PowerShell,38nssa,Waxmaker,1 point,Fri Jun 5 19:00:12 2015 UTC,"Yes, it should. The CMD session basically serves as a powershell wrapper in this instance, soaking up and redirecting everything.  Users can still interact using 'read-host' commands and the like; those will still work, but if you're trying to capture 100% of all dynamic input and output at the powershell prompt, you're probably not going to be able to pull that off without A) Writing a custom console, or B) Leveraging a third-party capture app of some kind."
PowerShell,38nssa,topherrr,2,Fri Jun 5 19:40:55 2015 UTC,"Yea, that is basically what I was trying to pull off, except that I basicly want it to 'screen scrape', no object data.  I dont have anywhere near the time to try to do custom dev for the prompt, so it sounds like I am back to just copying the buffer over to a text file via clipboard, and hoping I dont accidentally pass the console buffer.  Unless someone knows of an wrapper that can do this?  Please."
PowerShell,38nssa,SeanQuinlan,2,Mon Jun 8 14:47:22 2015 UTC,"I've used in this past when I'm sending quick, easy to read logs to teammates.   It will capture everything in the console buffer so you are limited to interactive powershell.exe sessions.   Still for repeatable logging and automated tasks, you're going to want to go with Start-Transcript and output redirection."
PowerShell,38nssa,JaapBrasser,1 point,Fri Jun 5 17:07:30 2015 UTC,"Start-Transcript is what you want. Bear in mind that it won't log text written via Write-Host, so use Write-Output instead if you want to capture that."
PowerShell,38nssa,KevMar,3,Fri Jun 5 12:39:55 2015 UTC,"Theses caveats may be the problem.  I literally want a wholesale text save (without the color information if possible, but if I have to read past color codes I will live), regardless of output location(Host, Output, etc...).    I did a test using dos commands like netstat and net use.  the output was not included in the output file."
PowerShell,38nssa,xalorous,2,Fri Jun 5 12:55:58 2015 UTC,"Indeed, and then there's all the Warning-Debug-Error and Verbose streams to consider."
PowerShell,38mchr,Snedeker,9,Fri Jun 5 03:38:04 2015 UTC,Warren Frame put together a good list that I reference from time to time -http://ramblingcookiemonster.github.io/Building-PowerShell-Functions-Best-Practices/
PowerShell,38mchr,gblansandrock,6,Fri Jun 5 04:24:55 2015 UTC,"Thanks for the shout out : ) Mostly just borrowed from MSDN and other best practice posts!  Back on topic for /u/Snedeker:  There's a recent effort to build up a style and best practices guide here - definitely worth a peak, and flip through the issues or submit a PR if you have any tips, contributions, suggestions, etc.  I haven't read it yet, but I suspect Learn PowerShell Toolmaking in a Month of Lunches addresses similar questions.  One key item that isn't necessarily PowerShell, but good practice in general: build re-usable tools. Don't write a monolithic script that serves one purpose. Break it down into components. If any of these seem re-usable, turn them into 'functions', which act just like Cmdlets. You can ideally group those functions into Modules. As you write more of these, you can use them as building blocks for other re-usable tools/functions/modules. Once you need to write a script, you will find you can just reach for one of these re-usable tools, and cut out hundreds of lines of code with a Import-Module or dot sourcing a function.  Oh. Draft in progress for a longer post on this, but always consider 'what could go wrong'. What will happen if you see unexpected input? What if the data you get back is in a different form? What if the operating environment is in a funky state? What if your code isn't doing what you think it's doing? Input validation, sanitization, expectation management, and error handling are incredibly, incredibly important, but are often overlooked. Things happen, unintentionally or intentionally - try to handle these, to a reasonable extent.  Cheers!"
PowerShell,38mchr,ramblingcookiemonste,1 point,Fri Jun 5 11:50:56 2015 UTC,Yes indeed the toolmaking book is very good. The author has a youtube profile with some very useful content as well. https://www.youtube.com/user/powershelldon
PowerShell,38mchr,footzilla,0,Fri Jun 5 14:45:11 2015 UTC,"RemindMe! 14 days ""Powershell Best Practices"""
PowerShell,38mchr,Blog_Pope,1 point,Fri Jun 5 13:20:43 2015 UTC,Messaging you on 2015-06-19 13:20:50 UTC to remind you of this comment.  CLICK THIS LINK to send a PM to also be reminded and to reduce spam.    [FAQs] | [Custom Reminder] | [Feedback] | [Code]
PowerShell,38mchr,RemindMeBot,2,Fri Jun 5 13:20:55 2015 UTC,"Start looking at other Powershell scripts. When you see something that looks good to you, ask yourself why. If you want to post a small sample, I can show you how I would clean it up."
PowerShell,38mchr,KevMar,1 point,Fri Jun 5 03:56:49 2015 UTC,"Not necessarily just the look. I want to be able to write them like a programmer would, and not just cobbling together a bunch of commands.  I wrote this a couple of days ago to extract some info from SCCM. If I give it a user collection, it will give me back a list of the usernames and their primary device.   $SiteServer = 'server' $SiteCode = 'XXX' $CollectionName = 'CollName*'  $Collections = Get-WmiObject -ComputerName $SiteServer -Namespace  ""ROOT\SMS\site_$SiteCode"" -Class SMS_Collection | where {$_.Name -like ""$CollectionName""} $DeviceAffinity = Get-WmiObject -ComputerName $SiteServer -Namespace  ""ROOT\SMS\site_$SiteCode"" -Class SMS_UserMachineRelationship  foreach ($Collection in $Collections){     $SMSClients = Get-WmiObject -ComputerName $SiteServer -Namespace  ""ROOT\SMS\site_$SiteCode"" -Query ""SELECT * FROM SMS_FullCollectionMembership WHERE CollectionID='$($Collection.CollectionID)' order by name"" | select *     foreach ($SMSClient in $SMSClients){         $UUserName = $SMSClient.SMSID         $PrimaryDevices = $DeviceAffinity | Where {$_.UniqueUserName -eq ""$UUserName"" -and $_.Types -eq ""1""}         foreach ($PrimaryDevice in $PrimaryDevices){             $SMSClient.Name + "", "" + $PrimaryDevice.ResourceName + "", "" + $Collection.Name | out-file -append C:\list.txt         }     } }   It works, but when I compare it to something like this it just looks amateurish to me."
PowerShell,38mchr,KevMar,2,Fri Jun 5 04:07:10 2015 UTC,"You have a good core to your script and I think you will make the transition easily. compare yours to the two below. See how little I changed on the first one. The second has some extra polish and changes it slightly.  ## first Pass function Export-SCCMCollection {     [cmdletbinding()]     param(         [Parameter(             Mandatory         = $true,             Position          = 0,             ValueFromPipeline = $true,             ValueFromPipelineByPropertyName = $true             )]         [string]$CollectionName = 'CollName*',          [string]$Path = ""$env:TEMP\list.txt"",          [Alias(""SiteServer"")]         [string]$ComputerName = 'server',          [string]$SiteCode = 'XXX'            )      process     {          $NameSpace = ""ROOT\SMS\site_$SiteCode""         $Collections = Get-WmiObject -ComputerName $ComputerName -Namespace  $NameSpace -Class SMS_Collection | where {$_.Name -like ""$CollectionName""}         $DeviceAffinity = Get-WmiObject -ComputerName $ComputerName -Namespace  $NameSpace -Class SMS_UserMachineRelationship          foreach ($Collection in $Collections)         {             $WMIQuery = ""SELECT * FROM SMS_FullCollectionMembership WHERE CollectionID='$($Collection.CollectionID)' order by name""             $SMSClients = Get-WmiObject -ComputerName $ComputerName -Namespace  $NameSpace -Query $WMIQuery | select *              foreach ($SMSClient in $SMSClients)             {                 $UUserName = $SMSClient.SMSID                 $PrimaryDevices = $DeviceAffinity | Where {$_.UniqueUserName -eq ""$UUserName"" -and $_.Types -eq ""1""}                  foreach ($PrimaryDevice in $PrimaryDevices)                 {                     $SMSClient.Name + "", "" + $PrimaryDevice.ResourceName + "", "" + $Collection.Name | out-file -append $Path                 }             }         }     } }      ## Second Pass function Get-SCCMCollection {     [cmdletbinding()]     param(         [Parameter(             Mandatory         = $true,             Position          = 0,             ValueFromPipeline = $true,             ValueFromPipelineByPropertyName = $true             )]         [Alias(""Name"")]         [string[]]$CollectionName = 'CollName*',          [Alias(""SiteServer"")]         [string]$ComputerName = 'server',          [string]$SiteCode = 'XXX'            )      process     {         $WMIOptions = @{             ComputerName = $ComputerName             NameSpace    = ""ROOT\SMS\site_$SiteCode""         }          foreach($Name in $CollectionName)         {             $Collections = Get-WmiObject @WMIOptions -Class SMS_Collection | where {$_.Name -like ""$Name""}             $DeviceAffinity = Get-WmiObject @WMIOptions -Class SMS_UserMachineRelationship              foreach ($Collection in $Collections)             {                 $WMIQuery = ""SELECT * FROM SMS_FullCollectionMembership WHERE CollectionID='$($Collection.CollectionID)' order by name""                 $SMSClients = Get-WmiObject @WMIOptions -Query $WMIQuery | select *                  foreach ($SMSClient in $SMSClients)                 {                     $UUserName = $SMSClient.SMSID                     $PrimaryDevices = $DeviceAffinity | Where {$_.UniqueUserName -eq ""$UUserName"" -and $_.Types -eq ""1""}                      foreach ($PrimaryDevice in $PrimaryDevices)                     {                                             Write-Output ([PScustomObject][ordered]@{                             ComputerName = $SMSClient.Name                             ResourceName = $PrimaryDevice.ResourceName                              Collection = $Collection.Name                         })                     }                 }             }         }     } }  # Usage  Get-SCCMCollection ""Adobe*"" | Export-Csv c:\list.txt  ""Adobe*"",""Java*"" | Get-SCCMCollection | Export-Csv c:\list.txt  ""Adobe*"",""Java*"" | Get-SCCMCollection | Test-Connection -Count 1"
PowerShell,38mchr,KevMar,1 point,Fri Jun 5 04:37:49 2015 UTC,Here is how I wrote almost the same thing you did: https://github.com/kmarquette/Powershell/blob/master/Modules/KevMar%20User/KevMar_SCCM/KevMar_SCCM.psm1  I think my code has gotten a lot more professional from when I wrote that just a year ago.
PowerShell,38mchr,KevMar,1 point,Fri Jun 5 04:43:20 2015 UTC,"That looks much better. How did you learn how to write the scripts like that? I see stuff like the ""cmdletbinding"" section in other scripts, but I don't know the purpose of it."
PowerShell,38mchr,marzme,5,Fri Jun 5 04:46:17 2015 UTC,"I have been working with powershell for 7+ years and now have a job focused around my powershell skills. For me, TechED videos that feature Jeffery Snover or Don Jones will teach me something every time I watch them demo. Once I started thinking of my powershell scripts as tools, I started to see them differently.  Notice how I changed that second one to accept input over the pipe and to output objects. That output could then feed into another tool like test-connection to a file.  [cmdletbinding()] enables the support of -Verbose -Debug -WhatIf. With the -Verbose param, you can use Write-Verbose to output troubleshooting or status messages when needed. I think it also enables does parameter validation. The short answer is that I added to every function. http://blogs.technet.com/b/heyscriptingguy/archive/2012/07/07/weekend-scripter-cmdletbinding-attribute-simplifies-powershell-functions.aspx"
PowerShell,38mchr,KevMar,2,Fri Jun 5 05:02:23 2015 UTC,"+1 for videos with Jeffrey Snover and Don Jones, always excellent information presented very well. I really got started with PowerShell with their Jump Start course in the Microsoft Virtual Academy for PSv3 (https://www.microsoftvirtualacademy.com/en-US/training-courses/getting-started-with-powershell-3-0-jump-start-8276). I watch their videos multiple times through and still learn new things each time.  Also, for help with laying out your scripts as a function, in the PowerShell ISE either press Ctrl+J or just right-click in the script pane and select ""Start Snippets"". The snippets are basically code templates to help you lay things out consistently, and they also contain some (albeit brief) example data to help you understand what each part of the script is for (especially the ""Cmdlet - Advanced Function (Complete)"" snippet).  Also, as KevMar suggested, check out other peoples scripts. GitHub will be your best resource for that, if you don't use it already."
PowerShell,38mchr,KevMar,0,Fri Jun 5 12:38:28 2015 UTC,"I am also very naturally curious. So when I see stuff like that, I go figure it out."
PowerShell,38mchr,JaapBrasser,1 point,Fri Jun 5 05:04:11 2015 UTC,Agreed. That goes back to the core of my question because I think that one of my biggest problems is that I don't know what I don't know.
PowerShell,38mchr,colinmcleod,1 point,Fri Jun 5 12:37:00 2015 UTC,This is why I love consuming content from those that are better than me. It's always a chance to learn something new.   Try working for that next thing. Create functions and then create modules. Think about making tools that you can reuse.
PowerShell,38mchr,nadrii,1 point,Fri Jun 5 13:17:48 2015 UTC,"Recently a number of PowerShell bloggers got together and did a week of blog posts on writing advanced functions. That should give you a good idea of how to start writing more solid scripts. #PSBlogWeek  I have to say I am very impressed that you know 30%-40% of the PowerShell cmdlets, I cannot say the same :)  If you'd like I can take a look at one of your scripts and give you pointers on what I would do differently."
PowerShell,38mchr,colinmcleod,1 point,Fri Jun 5 05:31:34 2015 UTC,"An IDE might assist, I've been drooling over Powershell Studio myself."
PowerShell,38mchr,nadrii,1 point,Fri Jun 5 08:38:07 2015 UTC,I recommend you buy it. I am quite satisfied with it.
PowerShell,38mchr,colinmcleod,1 point,Fri Jun 5 19:27:24 2015 UTC,"Pitched the tool to my boss today, outlook is positive. He's been in a purely management role and his tech skills are slipping so he's expressed a genuine interest learning PowerShell. Though in this instance, unlike other software requests I've made, he didn't plop the corporate credit card on my desk.  If he changes his mind I may bite the bullet and buy it for myself. I did that with PDQ Deploy, paid for the license out of my own pocket. He assigned a ticket for me to install an app on all the computers for the Marketing dept I closed the ticket ~5 minutes after his request. His immediate, out loud response (we share an office), was ""Bullshit, no way you did that"". He then confirmed action'd the request and said ""How did you do that so quickly!?"". Showed him PDQ Deploy, he told me to buy it, told him I bought it already on my credit card, he demanded the receipt so the company could pay for it.  Have you tried Visual Studio w/ PowerShell? If so, how does it compare?"
PowerShell,38mchr,Waxmaker,1 point,Thu Jun 11 09:25:09 2015 UTC,"I have tried Visual Studio but it always felt like overkill for the language. I'm certain its intellisense is more robust for advanced .NET usage but for everything I've done Powershell Studio has been great. I can build GUI tools, generate an msi to install it, convert a script to an exe to alleviate the need for execution policy changes, etc.   I'm currently using it more now to create modules and it keeps track of my functions and also lets me save code snippets for later use. I continue to recommend it."
PowerShell,38pkwy,br0phy,4,Fri Jun 5 19:35:01 2015 UTC,"Had a bit of a nose through PowerShell in Depth to see what it says about Workflows.  They're not something I've used before.  In a Workflow, each command executes in isolation    Because a workflow can be interrupted and later resumed, each command has to assume that it's running in a completely fresh, brand-new environment.  That means variables created by one command can't be used by the next command.   The workaround is to to use an InlineScript block  so this doesn't work:  workflow test {      'Hello' -match 'ello'     Write-Output $matches  }  test   but this does:  workflow test {     InlineScript {         'Hello' -match 'ello'         Write-Output $matches     } }  test"
PowerShell,38n52u,JaapBrasser,5,Fri Jun 5 08:07:05 2015 UTC,There is also a module available at CodePlex to do this - PSRemoteRegistry
PowerShell,38n52u,TheHobbitsGiblets,2,Fri Jun 5 09:29:39 2015 UTC,"Cool, even that is even easier."
PowerShell,38n52u,TheHobbitsGiblets,1 point,Fri Jun 5 09:46:10 2015 UTC,BUT I've worked in a lot of environments where you can only use raw out of the box PowerShell. So in that situation yours is the better way to go.
