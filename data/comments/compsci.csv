compsci,3e3z30,Macabear,4,Tue Jul 21 19:49:37 2015 UTC,Have a look at these seminal research papers to start for distributed DBs.  GFS: http://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf  Big Table: http://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf  Dynamo: http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf
compsci,3e3z30,elmhouse,2,Tue Jul 21 23:34:35 2015 UTC,"seminal papers in database research   You want the ""Red Book"". It's a bit dated right now. The next edition is coming out later this year.  http://redbook.cs.berkeley.edu/bib4.html"
compsci,3e3z30,assface,1 point,Wed Jul 22 01:38:56 2015 UTC,Just my opinion but two things I can think that might be worth looking into are:   Multi-master replication for RDB's Databases in docker containers
compsci,3e3z30,Dwaligon,-6,Tue Jul 21 23:13:28 2015 UTC,"Most DB research happens behind closed doors, at companies like SAP or Google - or even the NSA.  Databases aren't unique in that regard - the field of formal verification has the same problem, Intel has basically all the manpower."
compsci,3e3z30,PM_ME_UR_OBSIDIAN,11,Tue Jul 21 23:10:32 2015 UTC,"Most DB research happens behind closed doors, at companies like SAP or Google - or even the NSA.   Ignore this person. They don't know what they are talking about.  It's true that the major DB vendors do some things behind closed doors (query optimizers are usually the most guarded secret), but there are a lot of features that they will openly talk about and publish papers (usually after they fill the patents). You should check out the latest proceedings of the major DB conferences: SIGMOD, VLDB, and to a lesser extent CIDR and ICDE. The companies listed above will publish in the industrial track of those conferences.  You can also check out the websites for the DB groups at the major research universities to see what they are up to:   Berkeley Wisconsin MIT Stanford CMU Brown Michigan Washington Columbia   The DB research field is very active these days because of the ""big data"" buzz. You are seeing a lot more DB papers published in other more traditionally systems conferences (SOSP, OSDI, NSDI)."
compsci,3e3z30,assface,-15,Tue Jul 21 23:24:14 2015 UTC,"I'm not very into Databases. But on ething I know for sure, NoSQL and distributed databases are overpowering RDBs. I know on the former you can get tons of research papers (researchers at Google and Yahoo, p.e.) but I'm not so sure about the latter as I'm not a big fan of DBs."
compsci,3e1zty,shriphani,5,Tue Jul 21 09:58:36 2015 UTC,"Hi everyone, this is a new blog post that explores relations between two great ideas - testing for syphilis and steganography. A WW2 era technique proposed by an economist that is today used for building secure communications."
compsci,3e1zty,vanderZwan,1 point,Tue Jul 21 09:59:55 2015 UTC,"Hey, thanks for the article, it's very interesting! And written in accessible terms too, which is very much appreciated. The general scheme feels kind of similar to spatial partitioning approaches used in collision detection, where the idea is that objects only have to be tested against objects in the same or neighbouring cell, reducing the number of required tests (and putting objects into a cell is relatively cheap).  As an aside: mind if I give some minor proofreading feedback not relevant to the content itself?   ""a mere 20 years ago"" would probably be clearer if you used ""before"" instead of ""ago"", since the latter kind of implies it is relative to the present ""There is a way to apply the test to a small group of individuals testing a group is no different from testing an individual."" I suspect this was supposed to be two sentences?"
compsci,3e1zty,sixstringartist,2,Tue Jul 21 13:11:17 2015 UTC,"Hi,  Thanks for the comments - I shouldn't be outsourcing proofreading to readers; sorry about that :)"
compsci,3e1zty,CantHugEveryCat,1 point,Tue Jul 21 15:29:44 2015 UTC,"I feel the need to point out that steganography is a very niche category and has really nothing to say about the ""secure"" part of communications as well as checksums being more about detecting data corruption than giving any kind of cryptographic assurance. This should not be confused with hashing."
compsci,3e3chl,kirby_lennox,5,Tue Jul 21 17:16:38 2015 UTC,Another good consideration for that career field would be a math major or minor
compsci,3e3chl,MuffinMasochist,2,Tue Jul 21 18:12:16 2015 UTC,I'll second this. Math + Comp Sci would be a strong combo and set you up well for grad school.
compsci,3e3chl,TheMiamiWhale,2,Tue Jul 21 19:46:40 2015 UTC,Good question. I don't know too much about computer engineering other than it has to do with the hardware side of things. Before you look too deeply into this make sure you are allowed to do both of them at your university. At my university you are not allowed double major (or major and minor) in computer science and software engineering because too many required classes overlap. I do not know about computer science and computer engineering though. Your university may be different but I'd definitely check that out first. Good luck!
compsci,3e3chl,Crippled_shadow,1 point,Tue Jul 21 17:39:55 2015 UTC,"I don't know too much about computer engineering other than it has to do with the hardware side of things.    It's not entirely hardware. That's electronics engineering. CE can be both hardware and software, engineered together."
compsci,3e3chl,alwaysonesmaller,3,Tue Jul 21 18:44:45 2015 UTC,"I'm currently a senior finishing up my major in comp engineering. Essentially it's a mix of electrical engineering and computer science. This last year I have left I get to choose if I want to focus more on hardware or software. I went with the software side since I enjoy that more.  So to have a major in one and a minor in the other doesn't make sense to me.  While it will look decent on a resume you'll spend more money on school to get a similar paying job. My advice, do computer engineering. You'll be well trained in both hardware and software which is a huge bonus compared to focusing on just one aspect. Or like someone else already said, choose one and get a math minor."
compsci,3e3chl,PetersLilPickle,2,Tue Jul 21 18:53:50 2015 UTC,"I'd personally recommend flipping it to majoring in Computer Engineering and minor in Computer Science.  Generally CE is better at teaching you how things work which is more practical for security. Unless you specifically want to go into cryptography, in which case CE is probably not very useful."
compsci,3e3chl,jbetten,0,Tue Jul 21 17:59:56 2015 UTC,"yes, that is redundant. most colleges will offer 3 majors that have a certain amount of overlap and often share some of their core pre-requisite courses, but end in a different focus for electives and graduate work.   Computer Science focuses on the math and theory of computation. Computer science is really a branch of applied mathematics and advanced work in CS ends up being theoretical work in areas of math that have applications to computer programming (cryptography, type theory, formal logic, automated theorem proving, etc.).  Computer Engineering focuses on computer hardware development and bridging the gap between the machine and the human programmer. Advanced work in Computer Engineering is often multi-disciplinary in nature but emphasizes the design and fabrication of computer systems (thats the hardware and software together) and their specific applications in industry and research. Some of the topics here include compiler research (very large amount of overlap with advanced topics in computer science here), hardware and software implementations of algorithms, and assembly language programming.   Electrical Engineering focuses on electric and electronic devices of all kinds, and is a larger discipline that has many specializations within it. Arguably Computer Engineering is just a specialization within Electrical Engineering. This is a very purely hardware focused field.   All 3 of these fields will share a common core of math and science and basic computer programming. Computer Science will eventually diverge into math and theory, and possibly more practical aspects as well like Software Engineering, Database design, etc. Computer Engineering has a huge amount of overlap with Computer Science except it will generally have a more hardware focus compared to CS greater emphasis on software. EE will put you right into circuits all day every day once you finish your pre-requisites.   A minor in Computer Engineering is probably pointless. It is already a rigorous curriculum and you might want to just not take a minor and focus fully on your primary course work. A good choice for Minor would be something you have more of a personal interest in. Trust me, your major curriculum by itself will be plenty of work. You don't need to double up."
compsci,3e3chl,metaphorm,1 point,Tue Jul 21 19:58:04 2015 UTC,"It's not redundant because, even though there's a lot of overlap, each major has a different focus and unique classes."
compsci,3e3chl,nerdshark,1 point,Tue Jul 21 23:24:58 2015 UTC,Just make sure you get accreditation as a professional engineer.
compsci,3e3chl,Devvils,1 point,Tue Jul 21 22:43:09 2015 UTC,"There is a LOT of overlap between the two, but computer engineering will give you additional background in lower-level electronics, how computers function at the physical level, circuit design, and embedded development. Depending on what you want to do, that additional background can be incredibly useful."
compsci,3e3chl,nerdshark,1 point,Tue Jul 21 23:24:14 2015 UTC,"Security involves a ton of math (like number theory, abstract algebra, discrete math). I think if you did a minor in math you could take those classes earlier in your college years. Then you could easily breeze past the proofs in cryptography, algorithms, etc."
compsci,3e5l47,raatkokarfida,1 point,Wed Jul 22 03:16:36 2015 UTC,<<<WATCH LIVE HERE >>>  <<<WATCH LIVE HERE >>>  <<<WATCH LIVE HERE >>>  <<<WATCH LIVE HERE >>>  <<<WATCH LIVE HERE >>>  <<<WATCH LIVE HERE >>>  <<<WATCH LIVE HERE >>>
compsci,3e5jo9,mancityjuly2015,0,Wed Jul 22 03:04:15 2015 UTC,WATCH LIVE HERE ==> مشاهدة مباراة مانشستر يونايتد وسان خوسيه إيرثكويكس بث مباشر  WATCH LIVE HERE ==> مشاهدة مباراة مانشستر يونايتد وسان خوسيه إيرثكويكس بث مباشر  WATCH LIVE HERE ==> مشاهدة مباراة مانشستر يونايتد وسان خوسيه إيرثكويكس بث مباشر  WATCH LIVE HERE ==> مشاهدة مباراة مانشستر يونايتد وسان خوسيه إيرثكويكس بث مباشر  WATCH LIVE HERE ==> مشاهدة مباراة مانشستر يونايتد وسان خوسيه إيرثكويكس بث مباشر  WATCH LIVE HERE ==> مشاهدة مباراة مانشستر يونايتد وسان خوسيه إيرثكويكس بث مباشر
compsci,3e2pdr,A_Tasty_Penguin,5,Tue Jul 21 14:30:02 2015 UTC,oh god what a horrible question. I got an A in compiler design and I'd still answer it wrong at a glance.
compsci,3e2pdr,UpBoat420,6,Tue Jul 21 18:51:26 2015 UTC,"Variables declared in the body of a loop are limited in scope to each iteration of the loop, not the whole loop. The question is kind of vaguely worded, though."
compsci,3e2pdr,bluelite,1 point,Tue Jul 21 14:36:33 2015 UTC,"Right, but does that make the statement false? Thanks for the reply"
compsci,3e2pdr,bluelite,3,Tue Jul 21 15:11:07 2015 UTC,"Assuming the instructor meant ""the whole loop,"" it's false because you get a new variable (which happens to have the same name) each iteration."
compsci,3e2pdr,Methil,2,Tue Jul 21 15:19:15 2015 UTC,"Seems like they may have left something out of the question or made a typo.  As /u/bluelite says its a very vague question in itself.  I know I've made minor mistakes on questions before that have compromised the intended answer and it hasn't been until a student asked during the test or until grading afterward that I caught the mistake.  The best bet is to always ask for clarification, even during the exam itself if you catch it there, but especially if the instructor goes over the answers when returning the tests or afterward if not."
compsci,3e2pdr,bluelite,2,Tue Jul 21 16:11:31 2015 UTC,"Here's why I think the question is somewhat vague. Consider this loop:  for (int x = 0; x < 10; x++) {     int y = 100;     System.out.println(x + "" "" + y);     y++; }   The output will be:  0 100 1 100 2 100 3 100 ... 9 100   Technically, both x and y are declared ""in the loop"" but only y is declared in the body. Therefore, you get one instance of x and ten instances of y. It doesn't matter that y is being incremented; that statement is useless.  The scope of x is ""the loop"" and the scope of y is also ""the loop,"" but the subtly different lifetimes. The variable x gets created at the top of the loop and exists throughout the entire loop; y gets created and destroyed with each iteration.  I think the wording is vague because it's a little unclear what ""inside a loop"" means.  That said, what isn't vague is the definition of scope. In my experience, novices misunderstand that scope refers to both the name of a variable and its value. While the names x and y exist throughout the loop, the value of y is reset with every iteration. Conceptually, you need to think of the variabley (that is, the ""storage box"" that holds a value) as being created and destroyed each time through the body of the loop. It's a different variable that just happens to have the name."
compsci,3e2pdr,Capn_Cook,-1,Tue Jul 21 16:26:19 2015 UTC,"EDIT: I'm wrong  I figured it was false because you can still use that y once you're out of the loop.   for (int x = 0; x < 10; x++) {     int y = 100;     System.out.println(x + "" "" + y);     y++; } System.out.println(""y exists as: "" + y);"
compsci,3e2pdr,bluelite,1 point,Tue Jul 21 16:33:58 2015 UTC,It won't work. The variable y doesn't exist outside the loop. The compiler throws the error cannot find symbol - variable y
compsci,3e2pdr,Capn_Cook,1 point,Tue Jul 21 16:37:37 2015 UTC,"Ah, okay. Makes sense. I haven't played with Java in a while"
compsci,3e2pdr,alwaysonesmaller,3,Tue Jul 21 16:57:55 2015 UTC,"Surely the best thing to do is to ask the professor to explain why. That way you'll find the misunderstanding, misinterpretation, or mistake."
compsci,3e0g60,Crysis473,9,Tue Jul 21 00:24:13 2015 UTC,"If you haven't read it, Gödel Escher Bach by Douglas Hofstadter does a great job at examining the interplay between computer science, mathematics, and philosophy, and is definitely worth reading"
compsci,3e0g60,person594,2,Tue Jul 21 01:59:43 2015 UTC,Reading it right now. Brilliant book.
compsci,3e0g60,sanjeetsuhag,5,Tue Jul 21 12:28:05 2015 UTC,"You'll find mostly essays on the subjects rather than books, but here's a few suggestions: On formally undecidable principals of P.M. [mathematics] - Kurt Gödel  On computable numbers - Alan Turing  Governing Lethal Behavior in Autonomous Robots - Ronald Arkin  Other authors: Warren Goldfarb, Daniel Dennett, Ben Goertzel, Richard Feynman, Sergey Brin  It would help to know more specifics about what you're interested in."
compsci,3e0g60,Noideal,4,Tue Jul 21 02:52:43 2015 UTC,Timothy Colburn: Philosophy and Computer Science https://www.routledge.com/products/9781563249914
compsci,3e0g60,snim2,3,Tue Jul 21 10:20:53 2015 UTC,"I feel like the intersection of computer science and philosophy is basically logic + a subset of mathematics. For example, there are deep philosophical implications to the Curry-Howard isomorphism.  Also, Scott Aaronson loves to apply complexity theory to philosophical problems. Look up his musings on consciousness as quantum computation,  or P and NP."
compsci,3e0g60,PM_ME_UR_OBSIDIAN,2,Tue Jul 21 17:23:09 2015 UTC,"A draft of Philosophy of Computer Science by William J. Rapaport (University at Buffalo, The State University of New York)"
compsci,3e0g60,comtedeRochambeau,2,Tue Jul 21 11:11:51 2015 UTC,The Recursive Universe - William Poundstone Vehicles Experiments in Synthetic Psychology - Valentino Braitenberg Meta Math! The Quest for Omega - Gregory Chaitin   On the philosophical side philosophers like Hilary Putnam ( Representation and Reality etc) would be a springboard
compsci,3e0g60,cratylus,2,Tue Jul 21 12:34:27 2015 UTC,Incompleteness: The Proof and Paradox of Kurt Gödel by Rebecca Goldstein.  Goldstein is a philosopher and explains Gödel's Incompleteness Theorem from a philosophical point-of-view. It also touches on the life of Gödel and his association with Einstein.
compsci,3dyaaj,AJPelley,1 point,Mon Jul 20 14:58:38 2015 UTC,"""NIC Card"". Also if you can't afford 40gb interfaces you probably can't afford the systems that will saturate 10gb interfaces with real data. Bonding is much more useful as a ultrafast failover than a data rate booster."
compsci,3dvatr,SuperAgonist,104,Sun Jul 19 20:38:13 2015 UTC,"In a professional context, it's highly dependent on situational factors. If you are getting to write new code in an autonomous way, it's the best. If you are a cog in a machine working with an ugly codebase, or having to push out a deliverable in an impossible time frame, then it's more like being Frodo, carrying the ring to Mt. Doom."
compsci,3dvatr,boompleetz,25,Sun Jul 19 23:29:41 2015 UTC,"Mr Frodo, I can't carry the stack overflow for you..."
compsci,3dvatr,InvisibleEar,8,Mon Jul 20 04:53:15 2015 UTC,But I can carry you!
compsci,3dvatr,adribat96,8,Mon Jul 20 09:37:11 2015 UTC,Both sound like something HR would say.
compsci,3dvatr,king_of_the_universe,1 point,Mon Jul 20 11:39:32 2015 UTC,I don't think I'll ever again be able to think of stack overflow without thinking of Frodo frothing at the mouth.
compsci,3dvatr,ButtStallionn,6,Mon Jul 20 10:12:25 2015 UTC,If you are neck-deep in hairy and hoary legacy code and you fix a bug or implement a new feature without breaking anything else ... that's an art and the accomplishment can be very satisfying.
compsci,3dvatr,WhackAMoleE,171,Mon Jul 20 06:31:49 2015 UTC,Yes.
compsci,3dvatr,tias,5,Sun Jul 19 20:49:18 2015 UTC,I also approve of your ETLA nick.
compsci,3dvatr,logi,-6,Sun Jul 19 23:47:55 2015 UTC,^
compsci,3dvatr,Butthole_Berserker,33,Mon Jul 20 02:36:25 2015 UTC,Does anyone not?
compsci,3dvatr,3jt,35,Sun Jul 19 22:48:08 2015 UTC,"I hate writing code. I really enjoy coming up with algorithms and data structures, but translating it to code is the worst part."
compsci,3dvatr,Cugel_TheClever,51,Sun Jul 19 23:04:17 2015 UTC,Spotted the system architect :)
compsci,3dvatr,skydivingdutch,33,Sun Jul 19 23:25:38 2015 UTC,"Nah, I just like theory and math and I don't like typing :)"
compsci,3dvatr,Cugel_TheClever,28,Sun Jul 19 23:34:15 2015 UTC,Get a good keyboard and that might change. I really enjoy my keyboard and sometimes I will just mash keys because the tactile feedback is quite satisfying.
compsci,3dvatr,AtriusII,9,Mon Jul 20 00:05:32 2015 UTC,"second this, I have two custom built keyboards and my fingers hurt when typing on rubber domes now."
compsci,3dvatr,snowe2010,3,Mon Jul 20 03:25:37 2015 UTC,"Hah I do that too. Sometimes I have a mech keyboard lying around that's not even connected to a computer, and I type on it anyway.  Something else that helped me was getting pretty good with a text editor. When I was doing a lot of sql it'd drive me crazy after a while, then I installed a vim emulator and all the repetitiveness went away.  More concise languages help a lot too, of course."
compsci,3dvatr,ItsAConspiracy,3,Mon Jul 20 12:05:46 2015 UTC,"As soon as I started using Sublime Text it was like ""What's this stupid mouse for?"" I am way more productive and able to type code much faster than ever before. Plus the dark theme really helps since my eyes don't feel as strained after hours of going through code."
compsci,3dvatr,dream_in_code,4,Mon Jul 20 17:49:00 2015 UTC,I'm exactly the opposite. We'd make a good team
compsci,3dvatr,MaxGhost,3,Mon Jul 20 01:08:10 2015 UTC,Found the Mathematician / Phycisist!
compsci,3dvatr,InformationCrawler,1 point,Mon Jul 20 04:49:35 2015 UTC,"My degrees are in Math & Physics, and I love writing code."
compsci,3dvatr,alwaysonesmaller,1 point,Mon Jul 20 13:18:58 2015 UTC,You and me both. :)
compsci,3dvatr,Smashninja,0,Mon Jul 20 01:49:48 2015 UTC,Try a different language? APL maybe?
compsci,3dvatr,Stino_Dau,2,Mon Jul 20 05:37:59 2015 UTC,Same. I like big picture stuff.
compsci,3dvatr,Hollyw0od,1 point,Mon Jul 20 02:08:51 2015 UTC,Interesting. Would you say it's more that you like the theory or dislike the practice (of writing code)?
compsci,3dvatr,3jt,6,Mon Jul 20 01:26:42 2015 UTC,"I don't like typing, for one. Also, worrying about stuff like syntax and off-by-one errors are annoying to me. :)"
compsci,3dvatr,Cugel_TheClever,1 point,Mon Jul 20 01:51:42 2015 UTC,"I go back and forth. I'll go weeks at a time where all I want to design, and think about data structures, and writing code just doesn't fit in with where my mind is at at all. Then, the coin flips, and I feel like I need to mash at the keyboard until all the 1's and 0's get out of my head. Tonight is definitely a code-heavy night, which admittedly, is a nice change."
compsci,3dvatr,weffey,1 point,Mon Jul 20 09:48:14 2015 UTC,You're using the wrong programming language then.
compsci,3dvatr,runT1ME,4,Mon Jul 20 04:12:29 2015 UTC,It's not always your choice what language you use.
compsci,3dvatr,Cugel_TheClever,1 point,Mon Jul 20 04:33:41 2015 UTC,Spotted the functional programmer :)
compsci,3dvatr,quiteamess,1 point,Mon Jul 20 17:26:07 2015 UTC,"I don't. I want out of the industry, it just pays well and I have no other skills. I like big picture stuff (system architecture) but when it comes to brass tacks I'm really not that interested in writing the code."
compsci,3dvatr,BrainInAJar,27,Mon Jul 20 15:37:37 2015 UTC,"Yeah, I enjoy making everything as neat as I can, especially when refactoring someone else's code."
compsci,3dvatr,thingshappen-xuras,34,Sun Jul 19 21:47:02 2015 UTC,code properly formated and commented is my fetish
compsci,3dvatr,Butthole_Berserker,-4,Mon Jul 20 02:38:44 2015 UTC,I never comment. I think I am really good at navigating code without them and whenever they are there I feel it slows me the fuck down. I'm your worst nightmare then?
compsci,3dvatr,thepancake36,12,Mon Jul 20 07:23:15 2015 UTC,Spotted the grad student.
compsci,3dvatr,ifdef,3,Mon Jul 20 15:30:32 2015 UTC,"Eh, there are some people out there purporting to build code so readable that you don't need comments - but it sounds like an ideal that doesn't translate to reality for me."
compsci,3dvatr,eygrr,1 point,Mon Jul 20 18:47:39 2015 UTC,"I learned the hard way that my 'self-documenting' code is only self-documenting for as long as I can remember wtf was going on with that part of the codebase. Average lifespan of self-documentation is between 3 days and 2 weeks.  (Of course I can work through it and figure out what it does again, but it takes more time than reading a good, concise, informative comment would.)"
compsci,3dvatr,zeezle,-1,Mon Jul 20 18:51:11 2015 UTC,no i can navigate it without.  its just nice to have it incase the previous person used terrible variable names ans such
compsci,3dvatr,Butthole_Berserker,1 point,Mon Jul 20 17:46:20 2015 UTC,That is what I like
compsci,3dvatr,Plazmatic,22,Mon Jul 20 04:30:01 2015 UTC,"If you do it the right way it's an art in a strange geeky form, so yeah, absolutely."
compsci,3dvatr,DusanDJovanovic,9,Sun Jul 19 21:43:50 2015 UTC,Code has been compared to prose and poetry in various ways.
compsci,3dvatr,christian-mann,10,Mon Jul 20 03:50:16 2015 UTC,//Shakespeare 06/12/1609 //This needs to be here if (music_be_the_food_of(love | play))      play_on();
compsci,3dvatr,Warfinder,21,Mon Jul 20 08:57:22 2015 UTC,"Or, as Voltaire famously said,   i = 0x5f3759df - ( i >> 1 );  // what the fuck?"
compsci,3dvatr,ButtStallionn,1 point,Mon Jul 20 10:17:28 2015 UTC,if(liveOn) { } else { }
compsci,3dvatr,king_of_the_universe,8,Mon Jul 20 11:52:02 2015 UTC,I have not heard of many programmers that just enjoy writing lines of code.   Sometimes it can feel that all of the rules that are told to you by the ones above you take out creativity. This is why it can stop being as enjoyable
compsci,3dvatr,fuzzynyanko,7,Sun Jul 19 21:48:25 2015 UTC,"Yes. I just finished writing a morse code audio translator, and it was incredibly satisfying to see the correct output appear.  I also enjoy writing things like emulators, where a relatively simple piece of code can allow complex and intresting outputs to occur."
compsci,3dvatr,Name0fTheUser,2,Sun Jul 19 22:15:09 2015 UTC,"I know this may be too difficult to explain, but how exactly do you program an emulator? I just can't imagine them being ""relatively simple."""
compsci,3dvatr,ConcealClunkMinds,6,Sun Jul 19 22:40:49 2015 UTC,"I made a chip8 emulator, which is a pretty easy place to start. Here is a pretty detailed and well explained guide: http://www.multigesture.net/articles/how-to-write-an-emulator-chip-8-interpreter/"
compsci,3dvatr,Name0fTheUser,1 point,Sun Jul 19 23:26:54 2015 UTC,"Actually not too bad. It can be time consuming, and you better love test-driven development. One approach is to read the tutorial on writing a Chip8 emulator (as linked by someone else), and then find a good reference guide for the Chip8 system itself to implement it properly. This is how I did it.  But I think what really helped me understand all the finer details was doing a computer  systems course. We learnt assembly language for a very simple RISC CPU, and I started to understand the instruction cycle, opcodes and operands, von neumann architecture, implementation of functions in Assembly. In the course, we did all of our assignments by writing in an ordinary text file, and then feeding that information to a emulator my lecturer had wrote himself for this very simple system. And I started to think about how he was taking my assembly instructions and storing them in his ""fake"" memory he had  made for this system, and interpreting every line of my text file and performing the action that my assembly language had specified (i.e.  store this in memory, change that register). And after a while, I started to understand that what he wrote wasn't actually that complicated. He had arrays of data (representing memory and registers), and he was reading my text file to interpret what to do with that data. And it was a fully function emulator.  Writing an emulator for a simple old-school game system isn't much harder. The games have assembly instructions that change registers, memory, etc. You just have to write a system that understands those instructions and interprets them.  So yes, if you can find a computer systems course with a very simple RISC style CPU that helps you understand representation of data, the parts of a computer and how they communicate, the instruction cycle, and builds from there, you should be good to go."
compsci,3dvatr,DashAnimal,-6,Mon Jul 20 15:43:38 2015 UTC,"I mean, why not do a little Googling first?"
compsci,3dvatr,-_-_-_-__-_-_-_-,1 point,Sun Jul 19 22:43:40 2015 UTC,I made an ARM emulator with JIT and whatnot and it's really fun to finally see linux boot on it after hours of hard work.
compsci,3dvatr,Vogtinator,7,Mon Jul 20 13:15:48 2015 UTC,Try TIS-100. That will determine whether or not you like Comp Sci or programming.
compsci,3dvatr,DontThrowMeYaWeh,2,Mon Jul 20 01:40:07 2015 UTC,"It’s the assembly language programming game you never asked for!    Well, that's certainly true.  And if it's anything like SpaceChem then it'll probably stay true.  That shit's Nintendo-hard."
compsci,3dvatr,GlowInTheDarkDonkey,5,Mon Jul 20 03:48:06 2015 UTC,"I do as well. There's something about typing that word ""class"" when creating a new module for my system that sort of charges me up a little bit. Likewise, pulling out a big bunch of outdated code feels just as good, if not better.  I'm converting thoughts into code into results, and that's damn cool. But writing elegant and well-designed code that produces the same results is even better."
compsci,3dvatr,BlackDeath3,4,Sun Jul 19 22:22:11 2015 UTC,I have not heard of many programmers that just enjoy writing lines of code.   That's one of the major reasons for NIH syndrome.  Programmers generally much prefer to write code than do anything else with it.
compsci,3dvatr,kurin,2,Mon Jul 20 02:04:49 2015 UTC,"Didn't know the term (but the thing). From the Wikipedia article:   Not invented here (NIH) is the philosophical principle of not using third party solutions to a problem because of their external origins. False pride often drives an enterprise to use less-than-perfect invention in order to save face by ignoring, boycotting, or otherwise refusing to use or incorporate obviously superior solutions by others.   Though ""reinventing the wheel"" isn't necessarily a pride problem or somesuch. E.g. I always see people in /r/javahelp and /r/learnjava using Scanner(System.in) and struggling with the intricacies of using methods other than just .nextLine(). I never use those methods, so I don't have to ponder all that for a second. I just use .nextLine() and do any required parsing/checking in utility methods that I made over time.  Another example are cases where you just prefer to do things a certain way, but the available libraries do it differently, so either you adapt (which might not always be easily possible), or you make your own. Also, there might be solutions that you just don't happen to hear about."
compsci,3dvatr,king_of_the_universe,2,Mon Jul 20 12:09:47 2015 UTC,"There are valid reasons to write things that already exist.  In fact I usually fall into the build camp when it comes to build v buy.  But a lot of the time you'll see programmers writing Yet Another RPC Retry Library, or whatever, because they know how and they like writing code, when there's already a perfectly good one in the code base."
compsci,3dvatr,kurin,4,Mon Jul 20 13:24:55 2015 UTC,Yes. But not for other people..
compsci,3dvatr,crawler23,3,Mon Jul 20 09:13:08 2015 UTC,"I love it. I have no ideas, but I love doing prompts or problems and stuff I find online."
compsci,3dvatr,SoftwareJunkie,3,Sun Jul 19 21:58:35 2015 UTC,I enjoy writing code that works. But sometimes you don't want to write the same thing over and over again so then I try to write something different. Eventually thats how I usually learn new things.
compsci,3dvatr,zitterbewegung,3,Sun Jul 19 23:01:59 2015 UTC,Mmhmm.
compsci,3dvatr,oconnor663,3,Mon Jul 20 03:18:50 2015 UTC,"Absolutely!   It's the same pleasure you get from putting a puzzle together... sure, seeing the final product is the big payoff you're anticipating, but every time you get just a few pieces to fit together you get a smaller jolt from it. Same with writing code.   Every time you solve a problem, no matter how small... every time something works, no matter how small...  the simple act of creating something from nothing is exhilarating, and the thing is, you get that from every line of code, every statement. At least, I do.   There's also a joy in writing code that looks clean, purely on an aesthetic level... there's something fun about bringing order to something that didn't even exist before. When you create an API that is logical and simple, for example, just writing it becomes an enjoyable thing. Programmers have to have logical, orderly minds, and manifesting that in the real world is exciting.  It's all very weird sounding until you experience it for yourself, I realize :)"
compsci,3dvatr,fzammetti,2,Mon Jul 20 00:45:15 2015 UTC,"I tend to make everything into small sub-routines, and I enjoy finishing one and having it work the way I designed, especially if I thought of an especially clever way to do it.  I don't like getting out paper and drawing out class diagrams for bigger projects, I like to just start typing and work my way through it which can sometimes go horribly wrong.  What I don't like is typing the same things over and over again. Keyboards and syntax isn't the fun part for me, if someone could come up with a way for me to just think ideas at the computer with something like the emotiv eeg headset that would be nice.   I don't like typing for (int i = so much, I almost need a macro keybinding for it. I don't like fiddling around with the mouse to copy and paste things around, or retype the same long words over and over. Or crawling back over resources for names of functions or parameters."
compsci,3dvatr,rageling,3,Mon Jul 20 03:44:30 2015 UTC,"Not having to use your fingers to write, and not having to use your eyes (or fingers) to read would greatly improve the coding experience. It's all text, the brain should have standard inputs and outputs for that.  If you find yourself C&Ping code snippets often, don't use the mouse. Use vim. (Or something like it. Kate has vi-bindings and code-completion and c-scoping, and a command line widget.) That's just my opinion, but 'HdMLp' is much better than waving my hand around. You can also have ad-hoc macros, like qfafor(int i=0;i<;i++){<ESC>5hq to append a for-loop header with @f, or anything else you like. It doesn't have to be f.  Repetition should be factored out in programs. for-loops have better syntax in other languages than C (C++/Java/D). In python it's 'for i in range', which is barely an improvement, but in functional languages you would just map a list to a lambda or function, or recurse. I don't know if this helps you in any way."
compsci,3dvatr,Stino_Dau,1 point,Mon Jul 20 06:31:04 2015 UTC,"It's all text, the brain should have standard inputs and outputs for that.   Ha. I love this. Couldn't agree more ;D"
compsci,3dvatr,AndrewOfBraavos,2,Tue Jul 21 20:57:45 2015 UTC,I used to absolutely love doing it until I spent way too much time coding things I did not enjoy. Now I am really struggling to get that feeling back.
compsci,3dvatr,failurepile,1 point,Mon Jul 20 04:54:30 2015 UTC,I find I use coding to distract me when I'm depressed.
compsci,3dvatr,shaggorama,2,Mon Jul 20 13:46:38 2015 UTC,"When I can get in the zone (read: no interruptions at work), then coding for me is meditative."
compsci,3dvatr,N45HV1LL3,2,Mon Jul 20 14:33:00 2015 UTC,"Ah, yes.  This. I recognize this.  It doesn't happen in Cube farms though, so I haven't had it happen in 20 years."
compsci,3dvatr,Geohump,2,Mon Jul 20 15:33:25 2015 UTC,"When working on fresh code or some kind of test, it feels so warm and inviting to sit and just write code. Once you start having to dig into a codebase to fix an issue or add a feature, it becomes an exercise of reading and deciphering code more than writing it. For some people, this is all they ever really get to do. Some others get to write new code more often so the experience varies on what you are working on. I enjoy digging in and finding problems to fix so to me it's like I never get tired of programming because in my current position, I get to do a healthy mix of both."
compsci,3dvatr,dream_in_code,2,Mon Jul 20 17:53:49 2015 UTC,"I love writing code, until my code doesn't work.  I enjoy the mechanical feeling of typing, and knowing that what I'm typing is creating something awesome. I hate the reading through every letter and symbol and deciphering what in the fuck I did to cause that bug that made my monsters cause a thermonuclear explosion that kills every entity on the map with hp by walking into a torch."
compsci,3dvatr,jimmahdean,2,Mon Jul 20 20:36:57 2015 UTC,"Writing code in conjunction with designing a new application, system, or platform is a beautiful experience. I especially enjoy API design for services, followed by a prototype implementation. This phase of development moves so quickly and produces the sheer joy of construction.  Coding is a pleasure when certain criteria are met. It's not fun in all circumstances. The ideal circumstances are:   IDE introspection. Working in a language with a strong IDE with code introspection, such as Java with Eclipse. I'll discuss Java in my advice, but the ideas apply to many languages. IDEs are crucial for providing insight into code, such as showing the types of variables, or navigating to their definition. Learn the keystrokes to perform actions like ""show me the definition of the thing I've selected"" and practice them so that navigation is automatic. The IDE helps you navigate code semantically. IDE code generation & refactoring. The IDE should also provide code generation and refactoring. For example, if I'm writing a function and realize that I need a new class, I will write the code new Foo(x). When the class Foo does not exist, Eclipse will offer through auto-complete to create a new class Foo, create its source file, and create a constructor taking the type of x, all with a single command.  The IDE provides much similar support such as assigning expressions to new fields or variables. Use the IDE to generate classes and methods as you reference them in code you're writing. Need a method f taking x and y? Just write f(x, y) and ask the IDE to generate it.  It is much faster to write code this way than to type it all out yourself, or issue commands like creating new files. This style is especially quick once you've mastered IDE navigation. Create a new class with a click, then navigate back to the code from which you're instantiating it, all in a few seconds. Rapid interactive iteration. As you're writing new code, it's crucial that you interact with it frequently. As you're writing code, find a way to run it every few minutes. One solution is to use unit tests. Eclipse has built-in support for JUnit, making it easy to define tests and run them from within the IDE. Defining and running a class with a main method is similar. When I'm prototyping a new application, I frequently start by writing a unit test or simple utility with a main method. (If I'm not ready for specific tests, and there's no utility that I want to write, I'll simply write a ""Demo"" class with a main method that does nothing other than exercise some functionality.) The point is to start with the simplest possible meaningful program, hello world style, and build features gradually. My unit tests initially may not even have any classic testing behavior like assertions; I'm just writing code to exercise the behavior I'm developing.  The first step is running it and getting it to work minimally (no unexpected exceptions). The next step is to add assertions and scrutinize the behavior. The step after that is to add additional tests and ensure completion.  This will sound similar to test-driven design, but I'm not quite suggesting that exactly. What I am saying is that it's crucial that you be able to run code while you're writing it, and tests that invoke a unit and explore its behavior are a great way to do that. Run code in small pieces, interactively, while you develop it. For languages that have command-line REPLs, REPLs are another good solution.If you don't run small pieces of your code regularly, software engineering will be far more frustrating. Debugging. As you're writing the code and its tests, or demo functionality, eventually you'll run into a defect that you'll have difficulty tracking down. At this phase, it's useful to be able to run the logic in a debugger and step through it incrementally. A strong IDE again will make it easy to ""run the last thing that I ran within the debugger"". Building and running the application. This has got to be super simple. A strong IDE takes care of everything for you, giving you a high level command like ""Run this test"" or ""Run this main method"". If you don't have an IDE, find some way to make building and running everything simple, with a single command. (Ideally, make this easy for people who are new to the project.) IDE refactoring. As you flesh out your prototype, you'll find that you made design mistakes along the way. You'll need to change things, perhaps as simple as renaming a class or method, or changing its arguments; perhaps breaking up a large subsystem into smaller pieces and utilities.  As you make these changes, it's crucial that you have support of automated refactoring. Refactoring really should just be understood to mean ""changing things"", preferably in a tool-assisted way. IDE refactoring support should make it dead simple to issue commands that perform semantic manipulation like:   Rename a class or method Convert a literal string or number into a constant Convert to/from static Extract a function   Automated refactoring support makes these changes semantically across your codebase. Mentally, changing the name of a class is simple. Automated refactoring makes the execution simple too, no matter how large the codebase is. Source control. Become proficient in source control. I'd recommend Git. Make small commits regularly. Source control is crucial because as you make changes, you will eventually break something that was previously working. It will be frustrating if you cannot trivially restore to the past working state, and examine the changes since then. As you are making small changes to the application, perhaps accompanied by a test run / demo run iteration cycle, commit those changes.  I suggest Git specifically because it provides workflows that make this easy to do in a way that is local, and such that you can clean up and reorganize your changes before pushing them upstream. IDE, not text editor. The power of the best text editors rarely approaches the power of the best IDEs, such as Eclipse & IntelliJ for Java, and Visual Studio for Windows / .NET. Text editors definitely provide a leg up on the problem of text manipulation. However, text manipulation is not the layer in which you want to operate ideally. You want to operate in the conceptual layer. For example, renaming a variable is not conceptually equal to a textual search-and-replace. The latter can match the wrong things. It's far more productive to operate in an IDE that understands the code in a deep semantic way, and can implement your commands in terms of that understanding.   All of these steps above need to be frictionless in order to take full advantage of them. A certain level of proficiency is needed with the tools, and then they become second nature. A strong degree of tool-assistance frees you from thinking about changing your code mechanically and textually. It frees up your mind to think of changes conceptually. When these criteria are met, you can truly fly."
compsci,3dvatr,Xiphorian,1 point,Mon Jul 20 21:17:44 2015 UTC,"IDE, not text editor   Thank you so much for mentioning this in your already-excellent post. I have colleagues who prefer text editors over IDEs and it drives me nuts..."
compsci,3dvatr,AndrewOfBraavos,1 point,Tue Jul 21 20:55:55 2015 UTC,"I love to get ready to sit down and begin a long session.  Go to the bathroom, get a cup of coffee and a glass of water, get some snacks, get my headphones, etc.  Then I sit down and start working.  If I'm lucky I can get about an hour into my work before I get a (work) call or (work) text that will steer me off course."
compsci,3dvatr,metaobject,1 point,Sun Jul 19 22:44:47 2015 UTC,I really enjoy writing functions in javascript. Especially if I'm directly passing it as a parameter.
compsci,3dvatr,bird_eggs,1 point,Sun Jul 19 23:40:54 2015 UTC,Absolutely!  I have a real appreciation for being able to open a blank file and start immediately mocking up logic. It's beautiful to see an idea come together!
compsci,3dvatr,Grisk13,1 point,Mon Jul 20 00:26:37 2015 UTC,I hate feeling you get when you complete a program or debug it is so refreshing
compsci,3dvatr,hammad22,1 point,Mon Jul 20 00:41:01 2015 UTC,"Yes, I love it."
compsci,3dvatr,coral7,1 point,Mon Jul 20 01:20:20 2015 UTC,Definitely.
compsci,3dvatr,robot_lords,1 point,Mon Jul 20 01:25:42 2015 UTC,"I hate writing code when I don't know what to do next, but that's just because I hate not knowing what I'm doing in any context. This translates to coding somethings being really frustrating, and other times very satisfying."
compsci,3dvatr,Godzoozles,1 point,Mon Jul 20 02:02:23 2015 UTC,"I love the process of writing code. I love working through and solving problems. Of course, I only like working on interesting problems."
compsci,3dvatr,nerdshark,2,Mon Jul 20 02:16:58 2015 UTC,I especially enjoy refactoring.
compsci,3dvatr,HomemadeBananas,1 point,Mon Jul 20 03:17:08 2015 UTC,"I will say that I like writing it a lot more than I like making it work. One of the problems I have though is the planning. I don't like having to plan out how to write a program, and I'm not good enough to fly by the seat of my pants, so. . ."
compsci,3dvatr,wolfman1911,1 point,Mon Jul 20 05:13:29 2015 UTC,"Programming is like describing how to solve a problem with minimal verbosity, the only fun part about that is the problem solving and optimizing after everything already works."
compsci,3dvatr,unambig,1 point,Mon Jul 20 06:45:27 2015 UTC,"Writing a compiler, writing code that will generates aesthetic  working code is an even greater feeling."
compsci,3dvatr,alexrio,1 point,Mon Jul 20 11:31:40 2015 UTC,"There's a very enjoyable element about writing code, I think it's in the feeling of success from actually getting over any problems faced or the idea that you'll have made something supposedly useful at the end. It does have the reverse effect too, the anger of having a problem faced or the idea that it could just be completely useless."
compsci,3dvatr,dyolLkcaJ,1 point,Mon Jul 20 13:51:02 2015 UTC,"Not the writing of code as much as the creation of code solving a problem.  That is the act of physically creating code is not where the enjoyment comes from. The enjoyment comes from making a working solution, or fulfilling a desired functionality, (scratching an itch).  (for me)"
compsci,3dvatr,Geohump,1 point,Mon Jul 20 15:31:48 2015 UTC,"Writing code on flights is how I pass the time. It's like a much more enjoyable version of sudoku. Then again, I guess what I like is solving problems in code -- not the actual typing and syntax."
compsci,3dvatr,obious,1 point,Mon Jul 20 19:49:15 2015 UTC,"The main reason I chosed computer programming for a linving, as an ADD guy, is the relatively quick exitement as well as the psychological reward I get when I contemplate my code in action, that differs from other scientific jobs in which results come out (or don't) after decades of hard work."
compsci,3dvatr,Crysis473,1 point,Tue Jul 21 00:13:14 2015 UTC,"Yes, certainly. Its the adrenaline rush you get after successfully watching the desired output. Nothing, Nothing matches that feeling."
compsci,3dvatr,saabr,4,Sun Jul 19 21:50:03 2015 UTC,adrenaline rush   You probably mean dopamine.
compsci,3dziiz,Nlkoolk,2,Mon Jul 20 20:11:54 2015 UTC,"I had taken the AP Computer Science courses, which gave me plenty of experience with programming. However, I hadn't done much ""IT""-type work (i.e. installing something, having it fail, reading and Googling the error message), which led to some trouble in courses beyond entry-level.   Regardless, I would take seriously the course prerequisites - if it says it's entry-level, then it is. That doesn't mean that the person next to you won't be obnoxious about how he's been programming since he was five, but you can safely ignore him."
compsci,3dziiz,joenyc,2,Mon Jul 20 20:23:01 2015 UTC,What did you get on the AP test if you took it? I got a four on mine and I'm on the fence on skipping the first class.
compsci,3dziiz,joenyc,2,Mon Jul 20 20:28:59 2015 UTC,"I got a 5, but I wouldn't recommend skipping the first class. Of course you already know what an if statement is, but they'll probably introduce the TAs, tell you how the course is graded, etc."
compsci,3dziiz,slashcom,1 point,Mon Jul 20 20:36:40 2015 UTC,"At my Uni, the first class also contained information about using the computer resources at the Uni, like compiling programs, or using the shared filesystem, or submitting homework, etc. All of this would be expected by the second class, as projects were expected to work on University machines."
compsci,3dziiz,wmcscrooge,1 point,Tue Jul 21 08:29:43 2015 UTC,"if you meant course instead of class, don't do it. I had a friend that took ap cs and passed and thought it would help him and it didn't. obviously it depends on the course, but we had a tough teacher who expected a lot out of you and ap cs doesn't prepare you well enough in imo. There's a lot more to programming that ISN'T taught in ap cs. I never took it but taught myself to program and it helped me a lot more. You learn a lot of things out of curriculum that would help more with college classes. Take the first class (unless it is SUPER rudimentary). i skipped the intro to python class but took the intro to c class. Defniitely don't skip any c/c++ class as it is essential to a lot of programming"
compsci,3dziiz,Caffeine_Crazy,1 point,Mon Jul 20 20:40:46 2015 UTC,I could mess around with html a bit before I started but thats it
compsci,3dziiz,Helen___Keller,1 point,Mon Jul 20 20:24:41 2015 UTC,One AP Computer Science course and a little bit of calculator programming during math courses.  Not much of an effect. I would have taken one extra intro CS course.
compsci,3dziiz,kyle2143,1 point,Mon Jul 20 20:48:24 2015 UTC,"I had taken 2 semester long courses in CS my senior year of high school (not AP), which was the first time I considered Computer Science at all. First was using VB and the next used C++, loved it so I took it in college.   I'd say that it helped me a decent amount in my first year of CS courses, but not in math or anything. I pretty much breezed through those with almost no effort at all and it was still fun. Though that's about it, I wouldn't say I was ahead of anyone else by a considerable amount and after that, you're pretty much all at the same level and then it gets hard."
compsci,3dziiz,foxox,1 point,Mon Jul 20 21:59:33 2015 UTC,"I taught myself some HTML at the end of middle school, then javascript, then C++. Plus the silly TI-83+ programming stuff from math and physics classes. Took a couple of C++ programming classes at my HS (no AP class was offered until after I graduated) and I was already at such an advantage from teaching myself that the teacher made me into a sort of teaching assistant in the class haha. Then I entered college for Architecture FOR SOME REASON and transferred to a combined compsci & art major after a year. My experience made it VERY easy to transfer schools in my university... when they interviewed me, I showed them things I had made thinking they might not be good enough but really it was more than many of the other students in the program had to show for themselves at that point (granted many of them went on to be much more skilled than me by the end haha). The programming-focused classes were all VERY easy given my prior experience, but my school is theory-heavy and the theory classes were probably as difficult for me as for everyone else. I went from that to pure compsci for PhD and here my experience helps a little sometimes but I'm probably on equal footing with everyone else. Sometimes it's a little tough because I didn't do pure CS in undergrad so I missed a few things from the full CS curriculum."
compsci,3dziiz,slashcom,1 point,Mon Jul 20 22:12:08 2015 UTC,"The first CS class at Universities doesn't have any expectation of experience.  I was one of those people who started young and had years of experience before I started. It helped with the first two classes. After that, we switched from learning coding to learning CS (data structures, math, etc), and everyone who wrote their first line of code in Uni was just as prepared as those who started coding at a young age."
compsci,3dysm3,prolifious,3,Mon Jul 20 17:09:55 2015 UTC,"Can you please provide the exact definitions you're using? After all, on the Internet there are no cells or packets; there are datagrams. It would be helpful if you can define your terms."
compsci,3dysm3,WhackAMoleE,2,Mon Jul 20 17:17:52 2015 UTC,"UDP is defined as a datagram, TCP as a segment and IP as a packet."
compsci,3dysm3,pugl33t,1 point,Mon Jul 20 21:18:24 2015 UTC,"I should have mentioned that I'm talking about Ethernet, not Internet.  I also shouldn't have said ""smaller cells"" because cells are 53 bits, standard.  What would I need to measure how energy is used to push these groups of information?   I want to know how I'd go about measuring these two methods."
compsci,3dropc,supBot,7,Sat Jul 18 20:23:54 2015 UTC,"""Ghost in the Wires: My Adventures as the World's Most Wanted Hacker"" by Kevin Mitnick"
compsci,3dropc,BenMcLean,7,Sun Jul 19 00:42:21 2015 UTC,I wouldn't say it's compsci however I would agree it's a great book. An amazing window into another world and a completely different set of ethics to me.
compsci,3dropc,benfitzg,9,Sun Jul 19 01:22:17 2015 UTC,"There's been a similar question over on /r/audiobooks in the last few months, so you should definitely check there.  One of my answers was Gleick's ""The Information"".  It's a great history of information in the last few centuries and has some great stories about telegraphy, Babbage, Lovelace, up to the modern day and Wikipedia."
compsci,3dropc,grandzooby,1 point,Sat Jul 18 22:47:06 2015 UTC,"The start is good, the end goes on about big data and doesn't do a good job of it. I much preferred the parts about Shannon's work but I work in big data so I guess I just get Fatigued"
compsci,3dropc,alexgmcm,25,Sun Jul 19 07:16:51 2015 UTC,Eeee... How should a fiction CS audiobook look like?
compsci,3dropc,RiiGii45,20,Sat Jul 18 21:21:41 2015 UTC,cryptonomicon by Neil Stephenson
compsci,3dropc,spacelibby,11,Sat Jul 18 22:40:34 2015 UTC,Also Snow Crash by the same.
compsci,3dropc,MrDOS,7,Sun Jul 19 05:37:25 2015 UTC,"There are CS-related fiction books! See, for instance: Off to Be the Wizard."
compsci,3dropc,fermion72,3,Sat Jul 18 21:43:41 2015 UTC,"I quite like Daemon and Freedom(TM) by Daniel Suarez. Brainjack by Brian Falkner is alright, and The Blue Nowhere by Jeffrey Deaver is also great, keeping in mind that it was released in 2001."
compsci,3dropc,mexicanweasel,1 point,Sun Jul 19 08:20:12 2015 UTC,"I'd be glad to hear some recommendation for CS fictions, let alone audio book."
compsci,3dropc,ginger_beer_m,8,Sun Jul 19 14:31:11 2015 UTC,"Believe it or not, there is a pretty decent CS-related fiction series: Off to Be the Wizard."
compsci,3dropc,fermion72,1 point,Sat Jul 18 21:38:49 2015 UTC,"Tried the sample on amazon - is the whole book this crude and boring, or does it get better?"
compsci,3dropc,AustinCorgiBart,1 point,Sun Jul 19 13:26:28 2015 UTC,It does get better; Martin becomes much more likeable.
compsci,3dropc,sheephunt2000,5,Sun Jul 19 14:23:52 2015 UTC,Also interested in CS podcasts or similar.
compsci,3dropc,rebelhead,9,Sat Jul 18 21:17:04 2015 UTC,Talking Machines is a great podcasts if you are interested in machine learning and AI.
compsci,3dropc,sreeck,1 point,Sun Jul 19 01:34:06 2015 UTC,"Thanks! I just listened to the first episode, and it's fantastic."
compsci,3dropc,JustinCampbell,6,Sun Jul 19 19:30:45 2015 UTC,"How about ""Masters of Doom"" about the creation of iD software and the development of Doom.  As a bonus, Wil Wheaton is the narrator."
compsci,3dropc,douglasjsellers,1 point,Sun Jul 19 02:36:32 2015 UTC,"It's not on audible but also ""Just for fun"", the Linus bio. There are a good number of ""CS history"" and ""CS Biography"" books like this."
compsci,3dropc,AmaDaden,3,Mon Jul 20 12:29:48 2015 UTC,"Books that actively include computer science (like the main character being a computer scientist) or books that are at least accurate when they mention CS?  If it's the latter, and you want something fun to read, then The Martian isn't a bad pick. Andy Weir, the book's author, is a computer scientist who self-published The Martian and, as such, it's filled with all kinds of hard science (including some CS). Much of the story is very sarcastic and humor-rich so it makes for a great audiobook."
compsci,3dropc,PastyPilgrim,3,Sat Jul 18 22:26:08 2015 UTC,Cryptonomicon by Neal Stephenson might be a good candidate.
compsci,3dropc,FrogTosser,3,Sun Jul 19 00:56:14 2015 UTC,For fiction you got to go Isaac Asimov. I've listened to the Foundation audio book and it was good.
compsci,3dropc,schwiz,2,Sun Jul 19 02:07:55 2015 UTC,"There is a Dilbert audio book. Also ""I am feeling lucky"" about Google's history was kind of fun. Not directly CS related though one can learn some lessons from these books."
compsci,3dropc,omon-ra,2,Sun Jul 19 02:06:02 2015 UTC,"Not a book, but I'm working on a podcast called CS Book Club. Each episode is a section from a book we're reading. The assumption is that you've already read the section, but I'd be curious if people enjoy it without having read the book.  We're starting with Understanding Computation. Check it out on iTunes or http://csbookclub.com"
compsci,3dropc,JustinCampbell,2,Sun Jul 19 12:58:10 2015 UTC,"This might be tangential, but it is related to Computer Security, in particular Social Engineering.  Two books by Kevin Mitnick:   Ghost in the Wires: My Adventures as the World's Most Wanted Hacker - autobiographical, I really enjoyed it, quite an amazing story. The Art of Deception - more fictional sort of case study, I haven't read all of it, but I did read some parts during my Computer Security course, and it seemed to have a very similar style to the other book."
compsci,3dropc,Moffen,1 point,Sat Jul 18 22:01:03 2015 UTC,Avogadro Corp is a fun one
compsci,3dropc,Rytherix,1 point,Sun Jul 19 01:19:02 2015 UTC,Rudy Rucker had some entertaining computer science lectures available.
compsci,3dropc,cratylus,1 point,Sun Jul 19 02:27:09 2015 UTC,The Phoenix Project- not comp sci but it hits some of the crap you'll run into in industry
compsci,3dropc,yxon,1 point,Sun Jul 19 04:17:20 2015 UTC,I am listening to nexus trilogy right now. Really enjoying it.
compsci,3dropc,my_amazing_user_name,2,Sun Jul 19 04:38:25 2015 UTC,I remember a good fiction book where Internet Explorer was the fastest browser.
compsci,3dropc,RiiGii45,1 point,Sun Jul 19 21:55:53 2015 UTC,Stupid question: what is CS? Couldn't find it on the internets. Thanks :3.
compsci,3dq7go,zombiecodekill,2,Sat Jul 18 11:19:09 2015 UTC,I feel there should be laws surrounding basic software architecture. Logging and security mostly
compsci,3dq7go,jstillwell,3,Sat Jul 18 23:56:45 2015 UTC,If I could make some changes it would be to label software engineer a protected term and require them to sign off work as meeting various standards in a similar vein to the way electrical works work here in the UK.   It is also worth noting that shoddy practice and letting each other off has caused our Medical Doctors to lose the right to be the peers by which they are judged (something which vets are very very aware of).   Can you imagine the ball ache if the guilt of serious programming mistakes was derived from the decisions of non programmers?   Whilst I don't think we are next on the firing line we are close.
compsci,3doyvy,Kiuhnm,6,Sat Jul 18 01:48:21 2015 UTC,"[] A true means that the proposition [] A is true; truth conditions for the proposition [] A internalize the validity conditions for A.  So, ""is valid"" is still a judgement (i.e. at the same level as ""is true"") and is not part of the proposition. But we have a proposition that internalizes the content of that judgement...  Another example of such a thing is in type theory, we have an equality judgement ""M = N : A"", and we also have an equality proposition ""Id(A; M; N)"", which internalizes the content of that judgement as a proposition."
compsci,3doyvy,jonsterling,1 point,Sat Jul 18 02:07:22 2015 UTC,What happens when □ is only applied to a term of a proposition? We can't say that the entire proposition is valid.
compsci,3doyvy,jonsterling,1 point,Sat Jul 18 11:33:32 2015 UTC,"It would be analogous to any other propositional operator, like negation, etc."
compsci,3doyvy,jonsterling,1 point,Sat Jul 18 16:33:48 2015 UTC,I mean semantically. What's the meaning of (□A ⊃ A) true? Does it mean A valid ⊢ A true?
compsci,3doyvy,mhd-hbd,2,Sat Jul 18 16:40:24 2015 UTC,"Not quite...  The meaning of . ; . !- ([] A => A) true is . ; [] A true !- A true. There is an elimination rule for [] which lets you hypothesize A valid, as you have done, however."
compsci,3doyvy,IJzerbaard,1 point,Sat Jul 18 17:00:13 2015 UTC,"OK, thank you."
compsci,3doyvy,IJzerbaard,5,Sat Jul 18 18:37:34 2015 UTC,"In logic, there are two levels: Judgements, and propositions.  Judgements can most of the time express a lot more than propositions: consider the judgement X 𝘁𝗲𝗿𝗺, which means that X is a well-formed formula in the propositional language. Such a judgement is used to specify the structure of the logical connectives:  A 𝘁𝗲𝗿𝗺     B 𝘁𝗲𝗿𝗺 ──────────────────     A ∧ B 𝘁𝗲𝗿𝗺   Another such judgement is X 𝘁𝗿𝘂𝗲, which means that the well-formed formula X is in the set of our true propositions.  Another common judgement is the Sequent A ⊢ B, meaning that it is proven that A 𝘁𝗿𝘂𝗲 gives us B  𝘁𝗿𝘂𝗲 for ""free.""  A third common judgement is the Modeling Relation 𝓜 ⊨ A meaning that the universe of discourse 𝓜 has the proposition A being true.  A fourth common judgement is eqiuvalence: A ≡ B meaning that A and B are  indistinguishable for all propositional purposes.  For a lot of logic, one deals with the notion of internalization, that is, embedding Judgements as propositional elements. For instance A ⊢ B can in classical logic be embedded as A ⊃ B and A ≡ B can be embedded as (A ⊂ B) ∧ (A ⊃ B).  It gets a little more tricky with the unary judgments: A 𝘁𝗿𝘂𝗲 embeds as just A and A 𝗳𝗮𝗹𝘀𝗲 embeds as ¬A.  What you're looking at is the judgement A 𝘃𝗮𝗹𝗶𝗱 which embeds as □A in this particular Modal Logic. That's why □A 𝘁𝗿𝘂𝗲 is not a syntax error: □A is a proposition, and we can go from □A 𝘁𝗿𝘂𝗲 to A 𝘃𝗮𝗹𝗶𝗱 and back with an inference rule."
compsci,3doyvy,dmwit,5,Sat Jul 18 06:54:43 2015 UTC,"This post is full of unrendered unicode boxes for me, how do I read it?"
compsci,3doyvy,mhd-hbd,3,Sat Jul 18 13:59:03 2015 UTC,"No, they are really boxes. □A is read ""box A""."
compsci,3doyvy,jonsterling,4,Sat Jul 18 14:23:34 2015 UTC,Yes but X 𝘁𝗿𝘂𝗲 looks like X boxboxboxbox to me
compsci,3doyvy,mhd-hbd,1 point,Sat Jul 18 14:29:02 2015 UTC,Install a font with good Unicode coverage.
compsci,3doyvy,jonsterling,1 point,Sat Jul 18 17:58:01 2015 UTC,Depends on your operating system and browser. Look for guides about unicode support.
compsci,3doyvy,mhd-hbd,1 point,Sat Jul 18 18:29:32 2015 UTC,It is unreadable on the iphone.
compsci,3doyvy,comtedeRochambeau,2,Sat Jul 18 20:44:11 2015 UTC,Oh well. :( Damn Apple and their poor Unicode support.
compsci,3doyvy,PM_ME_UR_OBSIDIAN,1 point,Sat Jul 18 22:07:24 2015 UTC,no worries. very nice explanation.
compsci,3doyvy,PM_ME_UR_OBSIDIAN,1 point,Sun Jul 19 04:34:14 2015 UTC,What's the meaning of (□A ⊃ A) true? A valid ⊢ A true?
compsci,3dm1lg,saabr,25,Fri Jul 17 10:48:45 2015 UTC,"In terms of things that annoy me: the fact that we don't know the computational complexity of integer multiplication!    The algorithm you know from grade school has a complexity of n2 to multiply two n digit numbers, as can be seen below:     1212 x  3434 -------    6868   3434  6868 3434 ------- 4162008   However there are algorithms known which are significantly faster, although we don't know any limit other than the lengths of the numbers themselves  That said, this probably also falls into the category of a bit too well researched of problem to be where you start off if you are a beginning researcher, however it is a nice place to try and get a feel for annoying questions in CS, and maybe you get very lucky and toss a square-root over one of the logarithms or something ;).  [edit: formatting.]"
compsci,3dm1lg,R4_Unit,61,Fri Jul 17 17:59:30 2015 UTC,"Sorry for Bullshit answer, but my most annoying computer science problem is the ever growing list of project ideas and the lack of time.  :("
compsci,3dm1lg,DebuggingPanda,4,Fri Jul 17 15:44:09 2015 UTC,"I'm the opposite, I have a crapload of time but can never think of anything to make."
compsci,3dm1lg,schurmanr34,7,Fri Jul 17 20:37:25 2015 UTC,Maybe you and /u/DebuggingPanda need to hook up. =]
compsci,3dm1lg,bekroogle,2,Fri Jul 17 21:41:41 2015 UTC,"If you don't have any ideas of things to implement, there are two paths I can think of:   Start studying. Computer networks, operating systems, compilers are a good time sink, and they're surprisingly applicable skills! Pick a technology, and design your project around it. Maybe you want to pick up AWS, or Puppet, or TypeScript."
compsci,3dm1lg,PM_ME_UR_OBSIDIAN,1 point,Sun Jul 19 05:06:54 2015 UTC,Project Euler
compsci,3dm1lg,ex_ample,9,Sun Jul 19 11:05:27 2015 UTC,/r/basicincome
compsci,3dm1lg,spiff531,10,Fri Jul 17 16:14:36 2015 UTC,Your suggestion reminds me of Toady and Dwarf Fortress- maybe more Toadys and more Dwarf Fortresses (motivated people and 'unique' projects) would exist with basic income.
compsci,3dm1lg,neozuki,-6,Fri Jul 17 16:28:42 2015 UTC,"I recently figured out why basic income ""doesn't work"". (I'm a math prof but I have one publication in econometrics).  You need two numbers. r is the fraction of average income you want to provide as basic income. For example, if the average income in the USA is 50K$ and you want to provide 20K$ basic income, r is 40%. The second number c, is the percent tax rate you need to run your government. So if the US government needs 30% taxes to run the military, health care and so on, then c = 30%. (For this simplified example, assume we have a flat tax regime.)  OK so in order to do the above, the federal tax rate has to be increased to c+r = 70%.  That's the problem.  Edit: I realize what I say is unpopular but you guys are just shooting the messenger. There is quite a lot of respected peer-reviewed research on this; for example: ""We believe these estimates suggest that the cost of moving further toward income equality by using tax and transfer programs is much higher than generally recognized."" (Browning and Johnson, 1984)"
compsci,3dm1lg,foreheadteeth,8,Fri Jul 17 22:34:35 2015 UTC,"Hmm your numbers are strange, because that would raise to average income of the US to to $70k, which is not what I would want, I guess the ideal would be to maintain the average income about equal but make sure everyone has a minimum guaranteed.   Ideal basic income for me is a nonlinear function Total_income = f(regular_income)+regular_income, which would start at something like 20k and go to 0 after 50k, and then get negative. It sure wouldn't be cheap, but saying it ""does't work"" is misleading imo."
compsci,3dm1lg,darkmighty,-3,Fri Jul 17 23:46:48 2015 UTC,"Just to keep things simple, let's make the basic income truly universal and make the tax rate progressive -- you can recover the exact effect of your progressive basic income in that way (your ""negative basic income"" is a tax by another name).  There's no doubt you could decrease taxes for the 99% but it's surprisingly hard to do this. If you wanted the 99% who make on average 50K$ per year to pay only 65% tax instead of 70%, so the gov't now needs to make up a hole of 250K$ per 100 persons, which must be paid by the 1%. If the average income of the 1% is 500K$ their tax rate must go up by 50%. So the 1% would pay 120% tax rate.  I think the point of the calculation is that BI is very expensive. This is probably why Milton Friedman proposed to give a BI in lieu of government services. If your government costs c = 10% to run instead of c = 30%, you can give a BI of r = 25% and your people only have to pay 35% in taxes; pretty reasonable. But the only way it works is if you cut the size of government to a tiny size."
compsci,3dm1lg,foreheadteeth,6,Sat Jul 18 00:23:30 2015 UTC,But... taxes are allowed to be nonlinear?
compsci,3dm1lg,Lalaithion42,3,Fri Jul 17 23:51:16 2015 UTC,"Yeah, I seriously doubt his claim to be a math professors.   Pre-algebra introduces concepts that can help understand the idea of nonlinear rates."
compsci,3dm1lg,Anjeer,3,Sat Jul 18 01:23:10 2015 UTC,It only looks like crap when you don't finish the equation and add back in the basic income.  50k * 70% + 20k = 55k   so the effective tax rate on an average income is then -10%.
compsci,3dm1lg,AmaDaden,3,Sat Jul 18 03:29:29 2015 UTC,"For example, if the average income in the USA is 50K$ and you want to provide 20K$ basic income, r is 40%. [..] OK so in order to do the above, the federal tax rate has to be increased to c+r = 70%.   Suppose that you have 10 people, with incomes going from $10k to $100k. That gives you $55k average. To ensure basic income of $20k you have to give the first dude $10k, which is less than 2% of their combined income of $550k.   I'm a math prof   LOL."
compsci,3dm1lg,xXxDeAThANgEL99xXx,2,Sat Jul 18 17:10:31 2015 UTC,"We could completely shift taxes to the top 10% of earners very very easily and not miss a dollar of revenue, perhaps even make more in revenue than we had before. But that involves everyone agreeing that it would be a good idea to aggressively tax high earners. In other words, the only thing stopping it from working is politics, not math.  Go look at the cites that the guys on /r/basicincome use when coming up with data. It's not just a good idea morally, it's economically beneficial."
compsci,3dm1lg,ummwut,2,Mon Jul 20 01:57:40 2015 UTC,"How would a basic income system work? I mean, if the choice is to be a CEO or to be on basic income I can see it working, but as the things stand now, for a lot of people the choice would be between waking up at 5am and flipping burgers in exchange for the bare necessities or staying at home and doing what they want in exchange for the bare necessities."
compsci,3dm1lg,snailking1,9,Fri Jul 17 23:27:56 2015 UTC,"Well, burger flipping jobs are prime candidates for being automated out of existence, so that's not really an option after the next few years. Driving trucks? That'll be automated out of existence too. Construction? Yeah, that's a no go soon enough too.   They just have to build the robots and people lose their jobs.   This doesn't have to be a bad thing, but it is. People's well being is tied directly to their ability to convince those with money to purchase their time. What happens when there is no one willing to purchase these people's time?   So, if these people are out of work because structural unemployment has jumped to 75% (because robots) do they jump through the bureaucratic mess that is the current welfare state?   Or would a tiny stipend help these people stabilize their lives to the point where they can begin building their own businesses?   Let's say someone wants to build something like Dwarf Fortress; a massively specialized product that 99.9% of people will never even hear about, but still has several thousand users. How does the creator support themselves when doing this?  The creator could try to look for investors. I wouldn't. Investors demand too much control because they are paranoid (rightly so) about their money. What about the users? Well, if their jobs have been automated out of existence, they can't do shit to help their favorite creator.   But, with the stipend provided by a basic income, the creator could take the entire risk on themselves. They won't lose anyone else's money but their own and could provide an amazing product.  Just like the farming economy was decimated by industrialization, automation will do the same to what we have now. A basic income will provide a much easier transition without risking violence and despair."
compsci,3dm1lg,Anjeer,1 point,Sat Jul 18 02:21:31 2015 UTC,"But I know a lot of jobs (actually, the most part) that, while as dehumanizing and as little satisfying as flipping burger, aren't likely to be automated in the near future (administration staff, code monkeys, etc.). I wonder, will the people who do this jobs keep doing them if they can have their basics covered without? I'm pretty sure I won't, and I can't be the only one."
compsci,3dm1lg,snailking1,2,Sat Jul 18 11:44:18 2015 UTC,"for a lot of people the choice would be between waking up at 5am and flipping burgers in exchange for the bare necessities or staying at home and doing what they want in exchange for the bare necessities.   Yeah that's the point. Do we really need cheap hamburgers flipped by wage slaves in our lives?   Most low-wage jobs suck ass and quality of life would improve for those workers if they could just sit home and play video games instead.   For other people, quality of life goes down slightly, because they can no longer get $5 footlongs and dollar menu items at McDonald's. But it doesn't really go down all that much."
compsci,3dm1lg,ex_ample,1 point,Sun Jul 19 11:08:03 2015 UTC,"It was an extreme example, but my guess is that even jobs that are not automatable would be quit in the blink of an eye if there was an alternative income.   Let's be honest, even if you are doing something you love you must wake up early, structure your time by rigid patterns (both daily and in the year), take orders from other people, be forced to get along with people you hate, do things not always in your way but in the way your boss wants them to be done, work hard for the success of something that is not yours and from which you could be kicked out any day, etc.   and for many people all this hell is in exchange of a wage that is just barely higher than the minimum living necessities that (I imagine) would be covered by a working basic income system"
compsci,3dm1lg,snailking1,2,Sun Jul 19 12:27:01 2015 UTC,"It was an extreme example, but my guess is that even jobs that are not automatable would be quit in the blink of an eye if there was an alternative income.    Yeah but so what? If those people don't like their jobs why should they be forced to do it just to survive? That's the question the basic income people are asking? It's not like doctors, lawyers, computer programmers, etc are going to quite their jobs because they make so much money that basic income would be a huge step down."
compsci,3dm1lg,ex_ample,2,Sun Jul 19 17:27:31 2015 UTC,"I personally know lawyers and computer programmers that hate their job and don't make a lot of money. I even know a lot of teachers who hate their job and only keep at it for the money (and teaching is the proverbial vocational job). Not to talk about administration workers. Plus a lot of other people would quit just because they are angry that someone who is free to live their day as they want is still taking money while they have to ""sacrifice"".   Yeah but so what? If those people don't like their jobs why should  they be forced to do it just to survive?    How would society keep working once all this people have quit their job?"
compsci,3dm1lg,snailking1,1 point,Sun Jul 19 17:38:09 2015 UTC,How would society keep working once all this people have quit their job?    Only low wage workers would quit their jobs.  People aren't going to take a 90% pay cut. They won't be able to afford their current homes/cars/etc.
compsci,3dm1lg,ex_ample,2,Sun Jul 19 17:53:13 2015 UTC,"Maybe it depends on the area? Where I live, engineers, doctors and lawyers don't earn the sort of money you are thinking of. Only the high profile ones and the ones with a private practice do, but there is an army of them who earn only marginally more than a cleaner. Some of them can't even afford the rent of a whole apartment and must share with others."
compsci,3dm1lg,snailking1,1 point,Sun Jul 19 17:57:29 2015 UTC,"I have a lot of time, a lot of ideas, but little motivation/confidence."
compsci,3dm1lg,5bits,26,Fri Jul 17 22:18:46 2015 UTC,"The insecurity of software and networks. The difficulty of defending against network attacks. Governments and agencies who insist on A) spying on everyone and all data on the net, and B) controlling what users can do online. Old software that is still used and now needs to be updated but won't be. The disruptiveness of trolls in social forums. Software that bneeds to be refactored but won't be (esp. big programs that were written in a language that makes refactoring very hard)."
compsci,3dm1lg,randcraw,9,Fri Jul 17 15:55:00 2015 UTC,"Visual Basic for Applications... coded with a 1980s ""we need to save bytes when coding"" style.   Why would you use a global single-character variable referred to in a four character LoC long function. ARHGRJENGKJRWNGJEKRNG  ARE YOU TRYING TO BREAK MY BRAIN?!?! Because that's what happens."
compsci,3dm1lg,SpaceSteak,3,Fri Jul 17 18:22:43 2015 UTC,Now those are my kind of problems. Add humans into the mix and all your supposedly solved problems become almost completely unpredictable.
compsci,3dm1lg,calinet6,-2,Fri Jul 17 22:02:54 2015 UTC,"The disruptiveness of trolls in social forum   Or as Reddit has found, balancing policing with free speech"
compsci,3dm1lg,fuzzynyanko,2,Fri Jul 17 17:36:19 2015 UTC,"uh oh, seems like you're getting disagreement-arrowed"
compsci,3dm1lg,UpBoat420,1 point,Mon Jul 20 20:30:28 2015 UTC,People are infringing on my free speech! Blaarrggh
compsci,3dm1lg,fuzzynyanko,-3,Mon Jul 20 21:18:03 2015 UTC,balancing policing and free speech lol... that's like balancing slavery and free will.
compsci,3dm1lg,jpastore,1 point,Fri Jul 17 22:04:59 2015 UTC,"Amusingly enough, I got downvoted for that statement"
compsci,3dm1lg,fuzzynyanko,1 point,Mon Jul 20 01:10:24 2015 UTC,I guess Bernie Sanders supporters. They get sensitive about pointing out manufactured consent for bad ideas.
compsci,3dm1lg,jpastore,1 point,Mon Jul 20 13:50:15 2015 UTC,"Isn't that one of the basic ideas behind Marxism? If we are all required to work in order to receive pay, the idea is that we are slaves to the paycheck... And yet, we have the right and the ability to spend that money as we wish, giving us an amount of freedom."
compsci,3dm1lg,devDorito,-2,Fri Jul 17 22:41:33 2015 UTC,"Lol. Centralism in general: you can speak freely, except this list of whims"
compsci,3dm1lg,jpastore,-2,Fri Jul 17 22:42:54 2015 UTC,This needs to go back to top comment
compsci,3dm1lg,jpastore,16,Sat Jul 18 03:09:44 2015 UTC,I think for all of us who understands what an algorithm and an algorithmic proof entails; the Collatz conjecture is one such algorithm whose elusive mathematical proof is quite irksome! :D
compsci,3dm1lg,ParseTree,4,Fri Jul 17 12:21:51 2015 UTC,"But you multiply by 3 and add 1 half the time, and only divide by 2 the other half. How does it ever reach 1?  It is a fun bit of brain-crack.  I've even written a sed script that runs a cellular automaton of the binary representation of hailstone sequences."
compsci,3dm1lg,sfw1984,8,Fri Jul 17 14:29:03 2015 UTC,"Actually, since you always do divide-by-2 immediately after multiply-by-3-then-add-1, it's less surprising when you improve your estimate to roughly half of the operations being (3x+1)/2 and the other half x/2."
compsci,3dm1lg,kops,11,Fri Jul 17 16:43:24 2015 UTC,you could look into the field of program verification.
compsci,3dm1lg,wlu56,8,Fri Jul 17 14:46:58 2015 UTC,"Challenging, but extremely practical. Arguably something you'd write your thesis on, as opposed to casually working on it."
compsci,3dm1lg,ZeroCool2u,2,Fri Jul 17 15:28:00 2015 UTC,Can you please elaborate on this?
compsci,3dm1lg,pythonista_barista,6,Fri Jul 17 15:53:37 2015 UTC,"Proving certain properties of a program, to show that it is correct according to the specification. In general this is not possible because many such situations devolve to the halting problem. For certain restricted conditions, you can prove correctness. This is my basic understanding, I am not involved in the field."
compsci,3dm1lg,danltn,3,Fri Jul 17 16:08:38 2015 UTC,I am involved in part of this field if anyone has any questions. (I'm off to CAV right now)
compsci,3dm1lg,grencez,3,Fri Jul 17 19:51:55 2015 UTC,"What do you think is the most promising tool / approach for using verification in practice? (I.e., fit for a good programming team rather than a formal methods team). I'm in a related field but don't have a great answer for it."
compsci,3dm1lg,pythonista_barista,3,Fri Jul 17 20:50:03 2015 UTC,"Is your goal to prove an existing program to be correct, or to build a provably correct program?"
compsci,3dm1lg,grencez,2,Sat Jul 18 03:04:22 2015 UTC,Either. Some code could be written in a certain way to be easier to verify/prove.
compsci,3dm1lg,blufox,5,Sat Jul 18 03:29:44 2015 UTC,"Sound and Complete program verification, due to the implications of Rice's theorem is impossible for an arbitrary program. So we make do with compromising on either soundness or completeness.  That is, we can A) either verify some (incomplete) of the properties of the programs making sure that what we point out as errors are in fact always errors (sound), or B) we can provide an exhaustive listing of all possible violations (complete) of some properties, which may or may not be actual violations (unsound).  The problem with (A) is that only mostly trivial properties can be verified this way, losing out on deeper problems, and these could be caught easily by a review. The problem with (B) is that the number of false positives are huge, making their evaluation time consuming. (There exist another approach (C) which hybridizes both, providing both unsound and incomplete results but reducing the disadvantages.)  Ameliorating approaches exist such as to rank the false positives and sampling, but they are still not mature."
compsci,3dm1lg,PM_ME_UR_OBSIDIAN,4,Fri Jul 17 17:47:31 2015 UTC,"Anyone looking to learn more on the subject should investigate model checking and total functional programming. Both are mature, production-ready techniques."
compsci,3dm1lg,UncleMeat,3,Fri Jul 17 17:57:37 2015 UTC,I wouldn't say that model checking is a completely mature technology. The older techniques only work for a very small set of domains (network protocols being classic). Massive advancements in SAT and SMT solvers in the last decade have opened up new doors for model checking but they still remain difficult to integrate into many production systems.
compsci,3dm1lg,blufox,1 point,Fri Jul 17 21:13:35 2015 UTC,"What model checkers do you use?  And which total functional language do you recommend from some one only tangentially connected to PL Research? I had picked up Coq, but seems Idris is more recommended these days?"
compsci,3dm1lg,PM_ME_UR_OBSIDIAN,4,Fri Jul 17 18:12:07 2015 UTC,"What model checkers do you use?   SPARK and Microsoft SLAM (with the SDV front-end for driver development) are the two best ones I'm aware of for production software development. If you're looking to implement your own, Z3 is a high-performance, MIT-licensed SMT solver from Microsoft Research.   And which total functional language do you recommend from some one only tangentially connected to PL Research?   Stick with Coq for now, especially for production development. It has more resources, more users, it's more mature. Idris is cool, but if I were starting a new project right now I'd go with what's proven to work well."
compsci,3dm1lg,mediocreHaskeller,2,Fri Jul 17 21:31:26 2015 UTC,"Isn't Idris actually a usable programming language though? I've only used Coq and Agda, but I really preferred Agda's Haskell style syntax to the tactics thing Coq has going on."
compsci,3dm1lg,danltn,1 point,Sun Jul 19 16:41:45 2015 UTC,State space explosion problem.
compsci,3dm1lg,IndorilMiara,7,Fri Jul 17 19:50:39 2015 UTC,"I can't remember the technical term for it, and I am by no means suggesting that this is one of the most important or most annoying problems, but I remember reading a while ago about this and while the name of it is lost to me (perhaps someone will be able to help me) it has always stuck in my mind as an incredibly useful concept.  The concept, as I recall understanding it, was a cryptographic concept that, were it solved, would allow a program to run in a fully obfuscated/encrypted way. That is, even someone able to look at the machine code instructions could not discern any information about the internal structure or data of the program.  The obvious industrial application is to prevent reverse engineering, but far more interesting to me is the possibility of some kind of distributed processing that would not reveal any information (like keys) to those helping to host it.  Anybody know what I'm talking about? Been ages since I read about it. I might be crazy, here."
compsci,3dm1lg,Hmm_Yes,6,Fri Jul 17 20:21:41 2015 UTC,I think you're talking about fully homomorphic encryption.
compsci,3dm1lg,IndorilMiara,1 point,Fri Jul 17 21:20:24 2015 UTC,That's it! Thank you haha.
compsci,3dm1lg,UncleMeat,3,Fri Jul 17 21:22:20 2015 UTC,Fully homomorphic encryption can be used to execute obfuscated circuits. It's just trillions of times slower than we want it to be.
compsci,3dm1lg,devDorito,-3,Fri Jul 17 21:20:39 2015 UTC,... Due to the complexities of Neural networks I wonder if they are a 'natural' example of that set of/kind of ideas.
compsci,3dm1lg,UncleMeat,3,Fri Jul 17 22:45:33 2015 UTC,No. Definitely not. Neural networks are not magic and they have nothing to do with obfuscated circuits.
compsci,3dm1lg,zifyoip,31,Sat Jul 18 00:02:49 2015 UTC,The obvious major unsolved problem is P vs. NP.  https://en.wikipedia.org/wiki/List_of_unsolved_problems_in_computer_science
compsci,3dm1lg,pipocaQuemada,50,Fri Jul 17 11:36:02 2015 UTC,"Of course, if you're asking 'what are some good open problems to solve' on reddit, P vs NP isn't a good one to look at.  You're about as likely to be successful at it as you are to find a proof for Fermat's Last Theorem that only uses the math that Fermat had available to him at the time, or for the Goldbach conjecture.  If you're asking here, you want to find something that's relatively low-hanging fruit, not something that's nestled into the highest boughs of the world's tallest Redwood, with the scattered corpses of the many previous attempts littering the forest floor."
compsci,3dm1lg,wolfman1911,7,Fri Jul 17 12:03:39 2015 UTC,From the wiki page: It has lots of theoretical unsloved problems
compsci,3dm1lg,zifyoip,2,Fri Jul 17 11:55:46 2015 UTC,"Are there any actually unsolved problems in computer science other than that? I kind of figured that just about everything had a solution, just not necessarily one that ran in polynomial time."
compsci,3dm1lg,Lalaithion42,6,Fri Jul 17 18:17:08 2015 UTC,"Are there any actually unsolved problems in computer science other than that?   Of course. I linked to a Wikipedia article with a list.   I kind of figured that just about everything had a solution, just not necessarily one that ran in polynomial time.   Nope. The halting problem is the most famous example of a problem for which there does not exist an algorithm to solve it."
compsci,3dm1lg,zifyoip,4,Fri Jul 17 19:11:08 2015 UTC,"The algorithm exists, it just runs in O(∞)."
compsci,3dm1lg,RailsIsAGhetto,5,Fri Jul 17 23:52:41 2015 UTC,What you mean is that the problem is semidecidable. But it is not decidable.
compsci,3dm1lg,ldpreload,1 point,Sat Jul 18 00:54:20 2015 UTC,"I kind of figured that just about everything had a solution, just not necessarily one that ran in polynomial time   There's classes for polynomial time, exponential time, and times that are even worse than exponential. These all fall inside a complexity class called simply ""R"", containing all problems that can be solved in finite time. In other words, solvable problems. It turns out the vast majority of problems that you could possibly think of or that exist are not in R and are not solvable. It's actually easy to prove this."
compsci,3dm1lg,frezik,1 point,Sat Jul 18 03:04:44 2015 UTC,"It's not actually an annoying problem, though, at least from an engineering perspective. Knowing the answer almost certainly won't help us build useful systems; we already build systems (like cryptography) assuming P ≠ NP, and we already have very effective algorithms that solve NP-hard problems quickly for practical cases. Both Fedora and SUSE, for instance, found that they can make package dependency resolution faster by converting the problem to an instance of SAT and throwing a general-purpose SAT solver at it, despite the problem NP-complete. So the status quo is basically the best of both worlds.  If we find out P ≠ NP, nothing really changes in practice. If we find out P = NP, then cryptography is mathematically impossible and maybe we should all leave the internet. So solving it won't do us much good. :)"
compsci,3dm1lg,fakeplastic,12,Sat Jul 18 04:43:42 2015 UTC,"In all seriousness, naming things. Not just people who use single letter variables for everything, or other just plain bad naming conventions. That's nothing that can't be solved by laying down some guidelines.  I'm talking about everyday programmers who sometimes can't come up with the right word or phrase to describe a variable, function, or class without being confused with something else in the same system. Maybe there should be a Creative Writing class for programmers?"
compsci,3dm1lg,frezik,12,Fri Jul 17 17:19:12 2015 UTC,"In my experience, having problems naming things is a sign that the thing you are naming is not designed well. For example, if you don't follow the mantra that a function should 'do one thing', and write a function that does many things, naming it will be hard."
compsci,3dm1lg,UncleMeat,3,Fri Jul 17 18:16:40 2015 UTC,There's definitely something to that. I also think there's an impedance mismatch between the specificity of programming languages and the ambiguity of natural languages. I admit that it's a code smell 90% of the time.
compsci,3dm1lg,NewAnimal,1 point,Fri Jul 17 18:22:43 2015 UTC,Dependent typing can also help with making the naming problem easier because developers don't need to be as precise when saying what a variable refers to.
compsci,3dm1lg,fakeplastic,1 point,Fri Jul 17 21:16:22 2015 UTC,"when people say a function should ""do one thing,"" im assuming overloading is still encouraged.  i think i get ya, but whats a simple example of a function that ""does two things"" vs one thing."
compsci,3dm1lg,NewAnimal,2,Sat Jul 18 03:08:49 2015 UTC,"Get user input, process it, display results. You can cram that all into one function but what will you name it? Better to split it up into 3 or more functions that each have a clear purpose. Once you do that, naming those functions should be easy."
compsci,3dm1lg,ex_ample,1 point,Sat Jul 18 03:37:29 2015 UTC,"gotcha.  is there a name for a group of methods for a specific process?  say i have tons of methods in a class and they all do different things, but some interact with each other (like in your example). is there common practice to organizing them?  is there an umbrella label for what you'd call your example above?   it seems like people might get confused when a group of functions are in a body of other functions..  i guess clean coding and good comments?"
compsci,3dm1lg,patternmaker,1 point,Sat Jul 18 03:44:39 2015 UTC,"Get user input, process it, display results. You can cram that all into one function but what will you name it?    RemixUserInput();"
compsci,3dm1lg,ldpreload,1 point,Sun Jul 19 11:13:36 2015 UTC,"But what would you call the function that does  void* inp = get_input(stdin); void* res = process_input(inp); display_result(res);   and don't say main, because that's not always an option.    I'm not arguing against trying to achieve 1 function = 1 action, but rather that it would easily solve the problem of naming things.  also happy cake day, if that's a thing you celebrate"
compsci,3dm1lg,Winston-Green,3,Mon Jul 20 00:28:23 2015 UTC,"One reason that there are a lot of programming languages is that they take different approaches to type systems. There are good and bad things about each approach. Are there other possible approaches that combine the good and avoid the bad? See Chris Smith's ""What To Know Before Debating Type Systems"" for a good overview of the problem. Nobody knows how big an integer type should be. [Integer overflow is a pervasive problem] in C and C-derived languages, and nobody has the intuition for how to solve it, like we now do buffer overflow -- and there aren't obviously right answers. Languages like Python use arbitrary-size integers (bigints), but since those are dynamically sized, they're generally unsuitable for compiled / systems code, which is often the most security-sensitive code. Dependent types sort of have an answer here, but that answer hasn't gotten anywhere close to this sort of systems code. Proposed answers for systems languages might be serious but are indistinguishable from trolling. How do we get ourselves out of this mess, without giving up on fundamental things about the problem?"
compsci,3dm1lg,iamajs,15,Sat Jul 18 05:00:24 2015 UTC,Which way up the USB goes in.
compsci,3dm1lg,IComposeEFlats,16,Fri Jul 17 16:23:15 2015 UTC,Already been solved  https://en.wikipedia.org/wiki/USB_Type-C
compsci,3dm1lg,ex_ample,5,Fri Jul 17 17:29:20 2015 UTC,Now I only have to flip it over once each time I try to plug something in!
compsci,3dm1lg,frenris,1 point,Fri Jul 17 20:21:27 2015 UTC,"now I just have to buy all new cables and keep track of which cables go with which devices!   Yay! My life is so much ""easier"" now!"
compsci,3dm1lg,fuzzynyanko,5,Sun Jul 19 11:15:58 2015 UTC,Proof: USB cables exist in 4 dimensional space
compsci,3dm1lg,fvf,5,Sat Jul 18 01:10:39 2015 UTC,Figuring out how to determine what makes a good programmer
compsci,3dm1lg,PM_ME_UR_OBSIDIAN,2,Fri Jul 17 17:36:44 2015 UTC,"I think a better approach would be to figure out how to determine what are good programs, or software systems. I think that would be the single most helpful thing to the software industry."
compsci,3dm1lg,blufox,2,Fri Jul 17 21:10:12 2015 UTC,"How to do program verification the right way. The two schools of model checking and total functional programming seem completely disjoint.  How to do program organization the right way (Programming Language Theory). A recent breakthrough is the arrival in the mainstream of dataflow programming through ReactJS and Angular2. We still need our next big break in logic programming,  which I believe will come from build systems, but which could take twenty years to materialize. Systems security. It's intractable, plain and simple! A formal treatment would seek to comprehensively categorize threats against a specific class of system, and defend against large categories of threats."
compsci,3dm1lg,blufox,2,Fri Jul 17 18:05:16 2015 UTC,"Darcs is a version control system that is founded on theory of patches. Its theory is elegant and intuitive, and makes merges and conflict resolution quite easy in practice compared to other DVCS. However, it suffers from the exponential merge problem at certain points, which keeps it from large scale use. You can read about the exponential merge problem in the wiki, and if solved, can result in better usability, and has the potential to be used as the basis for other DVCS too."
compsci,3dm1lg,erez27,2,Fri Jul 17 20:28:37 2015 UTC,"If you are interested in more softer problems in SE, here are is one:  How do you evaluate the quality of a piece of code? Most of us can recognize a piece of bad code when we see it, but can we provide a suite of metrics that have a high signal/noise ratio so that it can be automated to some extent?"
compsci,3dm1lg,grencez,2,Fri Jul 17 20:38:27 2015 UTC,"Parsing.  It's incredibly hard to find a usable LALR(k) parser, and so we have to settle for the slower LL(k). Of course, ideally we would have a LALR(*) parser without losing any performance (compared to the equivalent k), but it's such a difficult engineering task that afaik no one's ever accomplished it (and I'm not even sure anyone's ever seriously attempted it)."
compsci,3dm1lg,erez27,3,Fri Jul 17 22:18:10 2015 UTC,"I think the main problem with parsing was the maintainability of parsers. People shouldn't have to know the theory behind a parser to use it and avoid conflicts. That said, I'm fine saying that particular problem is already solved with PEGs (Parsing Expression Grammars), which don't give you the annoying conflicts. The parser will just try the first option and then try the next one if the first fails (ambiguity is allowed). It may sound quite expensive, but it can be done in linear time using the ""packrat"" technique."
compsci,3dm1lg,grencez,1 point,Sat Jul 18 00:25:40 2015 UTC,"Google doesn't give anything good on packrat. Do you have a link?  And isn't ambiguity problematic, for example, in compilers?"
compsci,3dm1lg,aaronsherman,1 point,Sat Jul 18 06:46:25 2015 UTC,"http://bford.info/packrat/ - It's specific to PEGs.  There will still be a unique parse of any string. I think of it just as allowing ambiguity up to any finite lookahead k. This allows you to design rules without worrying about unique prefixes and where recursion is (though I guess right recursion is better, just like it would be in a program with tail-call optimization). Since there's no lookahead, there is also no need for a tokenizer! And finally, the fairly well-known ANTLR parser has started adopting some stuff from PEG, so it's safe to call it mainstream. With all that said, this paper from the ANTLR folks gives some criticism about PEGs and directly disagrees with calling parsing a solved problem. :P  I personally use http://piumarta.com/software/peg/ for parsing in my C/C++ programs. It really is the only way I can write a parser and then sleep at night knowing that other people can actually maintain it. ANTLR is probably more feature-rich, but I get by. (I haven't tried ANTLR for years, but it is quality. I just like to avoid the Java dependency)."
compsci,3dm1lg,RailsIsAGhetto,3,Sat Jul 18 17:16:08 2015 UTC,"I think the uncertainty of practical solutions optimal nature is the most vexing. For example, before Tim sort, I think the CS world was pretty certain that quicksort was as good as it was going to get. Sure there were special case sorts that got better performance on special data, but nothing behaved better on the majority of practical datasets.  It's the crafty, ""practical,"" modifier that makes the problems incredibly difficult. You have to take into account very complex context for each problem."
compsci,3dm1lg,ggchappell,1 point,Fri Jul 17 13:41:02 2015 UTC,"Timsort is still O(n) auxiliary space though, so in that sense qucksort will always be better."
compsci,3dm1lg,DealLayLolMo,1 point,Sat Jul 18 03:10:58 2015 UTC,"Here are a couple related to comparison sorting.  (1) We can think of comparison sorting as starting with all possible orderings of our set, and the repeatedly: making a comparison and then throwing out all orderings that do not match it. Do this until there is only one ordering left.  Now, the open problem: At each step, can we always choose a comparison to make, so that we will necessarily throw out at least one-third of the orderings?  We know that there are situations where we cannot guarantee that any more than one-third are thrown out. For example, say we are sorting a 3-element set {a, b, c}. Our first comparison was a < b, and the answer was true. So we now have three possible orderings: abc, acb, cab. Now, no matter what we do, we cannot guarantee that our next comparison will let us throw out more than one-third of the remaining orderings. Maybe we ask whether b < c. If the answer is false, then we only throw out abc. Etc.  (2) Is there a parallel comparison-sorting algorithm that will sort an n-item list on n processors in O(log n) time.  We need to be careful with the specification here: exactly what operations are we counting, how is the final list constructed, etc. But I imagine you get the idea. If you really want to work on this, then first do some research to get a more precise specification of the problem."
compsci,3dm1lg,Crysis473,1 point,Fri Jul 17 20:08:00 2015 UTC,A programming language that combines all the features from other programming languages.
compsci,3dm1lg,RobotoPhD,1 point,Sat Jul 18 00:57:22 2015 UTC,Quantium Computing.  AI in general.
compsci,3dm1lg,bradrlaw,0,Tue Jul 21 01:09:05 2015 UTC,I think one of the most important unsolved problems is development of a programming language / technique / algorithm / whatever that can be used to solved arbitrary problems in a way that the solution is provably correct.  We are sorely lacking any way to write code without having lots of errors (bugs).
compsci,3dm1lg,sorennordstrom,5,Fri Jul 17 15:21:06 2015 UTC,"Ada is a language that tries to achieve those goals.  I did some work a while ago in it and while it was annoying at first, but I learned to appreciate what it could do for large / complex systems."
compsci,3dm1lg,frezik,-3,Fri Jul 17 17:30:18 2015 UTC,Kids who want to be game devs.
compsci,3dqnou,prasadchelsea33,9,Sat Jul 18 14:51:34 2015 UTC,"Here is a better article, by an expert on the subject."
compsci,3dqnou,PM_ME_UR_OBSIDIAN,8,Sat Jul 18 15:45:22 2015 UTC,"All of these problems share a common characteristic that is the key to understanding the intrigue of P versus NP: In order to solve them you have to try all combinations.   That's just plain wrong. NP-complete (or NP-hard, which is something related but completely different) problems are not defined by having to check all solutions.  Just look at Branch and Bound for a counterexample. To explain it briefly, you start with a problem where decisions remain to be made (a city to visit, an item to pack, whatever). Then you generate subproblems based on the decisions that can be made based on the starting problem (branching). Then you look at all the subproblems you generated and decide algorithmically whether or not their subproblems are worth checking out (bounding). If the answer is ""no"", then the subproblem is said to be ""fathomed"" and you don't need to look at it (and its subproblems) anymore. Repeat these two steps until you fathomed the last remaining problem and return the best solution you found.  Branch and Bound algorithms can reliably and with certainty solve NP-hard problems to optimality without checking all solutions. Mind you, they can't guarantee it: if your bounding is bad, you can't exclude branches and you have to check them. But in most cases, you end up with a lot less than the entirety of the solution space in order to find the optimum."
compsci,3dqnou,Kamikaze28,1 point,Sat Jul 18 15:57:11 2015 UTC,"In addition, some problems that can be solved by trying all combinations are in P. For instance, the problem of finding the maximum element in a list of integers (check all integers in O(n) time)."
compsci,3dqnou,zzopp,12,Sun Jul 19 12:12:22 2015 UTC,"If P=NP, then a robotic  hand would be capable of doing anything an actual human hand can do. If we could find the solution to show that P=NP, we could help cure diseases like cancer and revolutionize society.    Well, that's a complete non sequitur."
compsci,3dqnou,zifyoip,2,Sat Jul 18 15:12:27 2015 UTC,"In addition to some of the points above, I'd like to mention that even if we do find that P=NP, it most likely won't be in a way that just allows us to discover optimal polynomial time algorithms to any problem in NP. It's much more likely that we would be able to say that such an algorithm exists, but finding one may be extremely difficult. Also, polynomial time algorithms with huge exponents are something we know very little about, but we do know that if they exponent is fairly large, it would still be impractical. For these reasons, a proof or disproof of the problem probably isn't going to change anything radically. However, it is likely that the math and proof tactics used to solve this problem would be new, and thus could be applied to other problems in cs and math. An interesting theoretical problem obviously, but I doubt that by solving it, we gain the ability to just find efficient polynomial time problems for everything in NP (like some problems in protein folding and robotics)."
compsci,3dqnou,cdc143,1 point,Sun Jul 19 17:49:24 2015 UTC,I think those should be two seperate points.
compsci,3dqnou,FlaconPunch,1 point,Sat Jul 18 22:53:36 2015 UTC,Neither of them follows from P = NP.
compsci,3dqnou,zifyoip,1 point,Sat Jul 18 22:59:30 2015 UTC,Wouldn't P = NP influence protein folding and help regarding cancer?  https://en.wikipedia.org/wiki/P_versus_NP_problem#Consequences_of_solution
compsci,3dqnou,FlaconPunch,1 point,Sat Jul 18 23:01:33 2015 UTC,"If we had a fast solution to NP class problems, it would make a lot of problems really easy. However,  1) Minor point, an algorithm can be both polynomial and slow.  It may be we someday discover the lower bound on NP problems is O(n277 ) - which is technically in P-time, but isn't particularly useful   2) Bigger point though is that there's no reason to think that we can't make robot hands without needing to use NP complexity algorithms. As far as folding or cancer there may be good heuristic algorithms that might be able to tackle the problems without solving them fully.   After all in P != NP then there's no way for your physical brain to use those algorithms anyway, so your hand can't possibly depend on NP algorithms to work."
compsci,3dqnou,ex_ample,1 point,Sun Jul 19 05:26:17 2015 UTC,"I'm not talking about the robot hand, purely about the protein folding."
compsci,3dqnou,FlaconPunch,0,Sun Jul 19 11:13:59 2015 UTC,"Sure, okay. If protein folding is an NP-complete problem, and P = NP leads to an efficient algorithm for solving that problem, then I guess that helps toward finding a cure for cancer. I don't actually know much about cancer research. But ""finding a cure for cancer"" itself is certainly not a problem in NP."
compsci,3dofol,Fikocuello,4,Fri Jul 17 22:54:38 2015 UTC,"The most important thing to remember is that computer science, as a field, is primarily the study of the nature of computation and computable problems from a mathematical standpoint. You will program, but it is often an afterthought and is rarely the primary focus of a course. You will probably be required to take a couple programming classes to give you a very basic understanding, but after that you'll be expected to learn how to write software in your personal time. I recommend contributing to open-source projects to help get experience with that."
compsci,3dofol,nerdshark,2,Fri Jul 17 23:45:21 2015 UTC,"Dijkstra's famous quote is relevant here: ""Computer Science is no more about computers than astronomy is about telescopes."""
compsci,3dofol,shwestrick,1 point,Sat Jul 18 03:09:24 2015 UTC,"I agree about 50%. I wouldn't say that programming is an afterthought (at least in my experience), but more of a means to an end. The professors aren't teaching programming, they're using code to illustrate their point. The best example is classes that use scheme/racket/some other LISP-based language. While they will teach you programming, that's not the point of the class."
compsci,3dofol,bahston_creme,2,Mon Jul 20 13:45:30 2015 UTC,this should help
compsci,3dofol,xinx9,2,Sat Jul 18 08:04:16 2015 UTC,the class starts at square 1 so if you're new (which i don't think you are) then it should be an easy introduction to cs classes.
compsci,3doikn,eygrr,2,Fri Jul 17 23:19:32 2015 UTC,"Matt Might's blog has a lot of posts about the general process of research, but if it were something you could learn to do effectively by just reading about it, PhD programs as they are today wouldn't have much point."
compsci,3doikn,east_lisp_junk,1 point,Sat Jul 18 03:37:20 2015 UTC,Thanks :) I'll have a read through.
compsci,3dl4xe,Bobby_McGee123,6,Fri Jul 17 03:51:15 2015 UTC,"What's your math/signal processing background?  A basic way to represent sound is using Pulse Code Modulation, where you take a sample of the amplitude of a sound wave every few ms, so the encoding is basically just the loudness of the sound at each time.  Most audio encodings then think of the PCM encoding as a vector in some high-dimensional space, and essentially look for a good basis to write that vector in (one where most coefficients are ~0). Lossy compression can define some threshold so that if a coefficient is close to 0, you just make it 0. There can also be a psychoacoustic model in there: there are certain frequencies that people don't notice differences in as well, so you can throw those away at higher thresholds. Then you only need to store the non-zero coefficients. Lossless compression can still take advantage of the fact that if all the coefficients are somewhat close to 0, then they take less bits to represent. You can also combine this with other compression techniques like Huffman coding to further reduce the number of required bits needed for any given coefficient.  Generally the good basis is some variation on a Fourier basis (i.e. you represent the sound as a combination of waves at different frequencies). If your interested in how that works, one of my professors put his course on signal processing on iTunes a couple years ago here (it helps to have a linear algebra background, and it's essential to have a calculus background to follow these lectures). It's targeted toward applications to optics, but the first 14 lectures are pretty general."
compsci,3dhqp8,ornstein-uhlenbeck,86,Thu Jul 16 11:05:11 2015 UTC,"(I'm a hobbyist so take this with a grain of salt)  Do you make a distinction between pseudo-randomness and randomness?  For instance you can use an algorithm (a PRNG) that will fit on a sheet of paper to generate a very large amount of pseudo-random numbers that will pass all statistical randomness tests, and as a consequence, you won't make any money by betting on them (as long as you don't know the generator algorithm and its seed(s)). And you won't be able to compress it by using any off the shelf compression algorithm.  But when you think about it, the data is compressible in theory, remember, the algorithm to generate the petabytes worth of seemingly random numbers fits on a piece of paper. There is a way to represent all those seemingly random data with very small number of symbols.  So if there was a compression algorithm that could reduce the data to its base generator algorithm, the data would be compressible and would violate 1. Does such an algorithm exist?  The problem then becomes: can we invent a compression algorithm that can reduce the size of data so that the data can be represented by the minimum required amount of code symbols for a given computing machine? If we can compute the minimum amount of symbols required to represent arbitrary data, we can compare that size with the size of the original data itself and make a judgement on the randomness of said data. In the case of the PRNG we discussed above, if we fed petabytes of generated random data from the algorithm, we would reach the size of the algorithm that would generate that random number sequence.  So this question asks something about the Kolmogorov complexity of the data, something which is proven to be uncomputable. I am not versed well enough in Information Theory to understand the whys or hows but my understanding is that there is no and there will be no method to definitively compute the size of the minimum amount of symbols to represent a piece of data given a computing machine.  As a result, all compression methods make underlying assumptions about the data they are going to compress. For any given compression algorithm, you can exploit those assumptions to make the algorithm fail (i.e. prevent it from compressing the compressible non-random data.)  Sure, you can go brute force and start enumerating all possible algorithms and compare their results to see if any matches your input data, but then you bump into the halting problem: you can never know if this method will terminate (find a solution); and if your data is really random, the program is not expected to terminate. It will never say ""I tried all possible algorithms and none of their outputs match your input data so your data must be random"", but it can say ""I found an algorithm to represent your input data in a compact manner"". It can tell you if your data is not random (theoretically), but it can never definitively say that the data is random."
compsci,3dhqp8,earslap,9,Thu Jul 16 12:37:55 2015 UTC,That answer ! Good work there M. Hobbyist!  *Saved it
compsci,3dhqp8,fawar,5,Thu Jul 16 13:05:10 2015 UTC,"This answer is really great, thanks.   As I said, I'm just starting to understand this stuff so I have another silly question.   If I had a sequence of random numbers and I wanted to use a Universal Turing Machine to learn the algorithm (function) which generated those random numbers and that function did not actually exist because the input sequence was true and not pseudo random, wouldn't the Turing Machine terminate on the solution where it just returns the original input (see the answer / comment by Minno)?   What you said about the halting problem makes sense ... I'm just trying to reconcile yours and Minno's answers."
compsci,3dhqp8,earslap,1 point,Thu Jul 16 13:36:04 2015 UTC,"wouldn't the Turing Machine terminate on the solution where it just returns the original input   If it bumps into an algorithm that returns the original data, and if the number of symbols required to represent that algorithm is smaller than your input data, that means (to my understanding) your data is compressible so definitely not random.  If the algorithm is larger than the input, I'm not exactly sure what happens. But my intuition says that you still can't be sure the data is random, because you don't know if you are dealing with all the data there is. For the generator algorithm, it would be trivial to generate more and more numbers until your input data size exceeds the algorithm's size, for instance. So from the perspective of shorter input, your data is random, but by iterating the algorithm a few more times to generate more input, the data becomes non-random as your new input dwarfs your algorithm.  These are stabs in the dark for me, I don't know much more about it. There are also philosophical questions that pop into mind about the nature of randomness: Perhaps there exists a ""theory of everything"", a computable algorithm that can explain all the workings of the universe; that would make all the truly random sequences pseudo-random perhaps? True randomness and computability touches on very hairy and overarching subjects I have  no experience in so I would hesitate to speculate further. If there existed an algorithm that could recreate all the universe given the initial conditions as input, it would change the course of this discussion considerably, but I don't know if there is a possibility of such an algorithm existing or if this is a reasonable question to ask. Can there exist a computable algorithm that can give us the sequences from real atmospheric noise (past, present and future), even in theory? I think the real answer to your question depends on the assumed answer to this question. I don't know the answer for sure, but it's fun to think about. In any case, I'm sorry if my rambling wasn't helpful."
compsci,3dhqp8,east_lisp_junk,3,Thu Jul 16 14:11:42 2015 UTC,"If the algorithm is larger than the input, I'm not exactly sure what happens.   The real problem is that the TM can't necessarily tell whether a short ""algorithm"" will produce the desired data (it's equivalent to deciding halting)."
compsci,3dhqp8,earslap,1 point,Thu Jul 16 14:32:19 2015 UTC,"Yes, if I understand you correctly, that is what I mentioned in my original post above (last paragraph). I'm just giving the example where we lose all hope and start to enumerate all possible algorithms one by one and am trying to explain why even that wouldn't work.  Edit: Oh ok, I think I understand; during the search, one will encounter algorithms that would never halt anyways so trying it is a dead-end to begin with."
compsci,3dhqp8,GT95,1 point,Thu Jul 16 14:49:14 2015 UTC,"As far as I know there are things related to quantum physics that are truly random (or at least everyone think so) and some of them (eg. the polarization of photons) are used in quantum criptography. So I argue that a theory of everything can do a simulation of the universe because knows how things works but can't predict what exactly happens at the level of quantum physics: it could only show a possible situation that can be different from the actual situation. Correct me if I'm wrong, I like criptography!"
compsci,3dhqp8,user_doesnt_exist,1 point,Sun Jul 19 13:50:02 2015 UTC,"Turn it in to a game, if the machine finds an algorithm that matches the numbers output so far it must guess the next n numbers until the chance of getting it correct is negligible for a truly random sequence"
compsci,3dhqp8,ex_ample,1 point,Thu Jul 16 21:56:39 2015 UTC,"It could, but that's not what you want.  For example if you have the string ""1111111111111111111111111"" your program might eventually find ""1111111111111111111111111 but you want it to find ""for(i = 0 : 25) '1';""    But the problem is as you generate new algorithms to search through some of those are going to be non-terminating. So you'll have a bunch of programs that seem to run forever, but could potentially be the right one - with no way to tell them apart."
compsci,3dhqp8,CaptainObviousMC,1 point,Sun Jul 19 05:48:58 2015 UTC,In your link to Kolmogorov Complexity it actually discusses randomness specifically
compsci,3dhqp8,loonyphoenix,1 point,Thu Jul 16 13:50:32 2015 UTC,"It will never say ""I tried all possible algorithms and none of their outputs match your input data so your data must be random"", but it can say ""I found an algorithm to represent your input data in a compact manner"". It can tell you if your data is not random (theoretically), but it can never definitively say that the data is random.   Doesn't randomness have to do with the sampling rate of compression?  For any (finite) string, there's some Turing machine for which that number will be printed by a single symbol placed on the tape. (Constructing such a machine for a given string should be relatively straight forward.)  Randomness is about what percentage of Turing machines can compress you in this manner, and what (average) size their state machines are relative to your string."
compsci,3dhqp8,darkmighty,1 point,Thu Jul 16 15:58:09 2015 UTC,"Can't you, in theory, try every possible compression algorithm that is smaller than the data set and find the one whose representation plus the resulting archive is the smallest possible representation of your data? Because not including the algorithm itself seems like cheating. Otherwise you could compress anything to be one bit long..."
compsci,3dhqp8,amateurtoss,3,Thu Jul 16 17:28:32 2015 UTC,"For a given string, if you try all Turing machines smaller than it's own length as means of compressing the string, with the intention of finding the smallest, you will run into the Halting Problem -- some programs will take very long, and no finite method exists to determine whether they eventually halt or not. You can search of 'Uncomputability of Kolmogorov complexity' for more details."
compsci,3dhqp8,green_meklar,1 point,Thu Jul 16 18:48:54 2015 UTC,A random sequence produced by a prng is compressible according to the op's definition.
compsci,3dhqp8,ditditdoh,13,Thu Jul 16 20:54:25 2015 UTC,"It's impossible to reliably detect true randomness because in principle it could be anything. You could have a sequence of a billion bits, all zero, and it might be random if you got super duper lucky and essentially 'flipped tails' a billion times in a row."
compsci,3dhqp8,kazagistar,7,Thu Jul 16 17:11:49 2015 UTC,"Within a given context, you might detect the likelihood of randomness. For instance, these words are highly unlikely to be random. Similarly, the same dice rolling the same number 99 times is more likely to be weighted than random."
compsci,3dhqp8,IComposeEFlats,3,Thu Jul 16 22:16:59 2015 UTC,Nope. Any given sequence of dice rolls is equally likely.
compsci,3dhqp8,ditditdoh,4,Thu Jul 16 23:48:16 2015 UTC,"But an even distribution of numbers is far more likely than an uneven distribution, as sample size trends towards infinity."
compsci,3dhqp8,minno,3,Fri Jul 17 03:08:26 2015 UTC,"Regardless, if a dice is rolling the same number every time, beyond a certain point often it will become more likely that it is crooked than fair."
compsci,3dhqp8,respeckKnuckles,5,Fri Jul 17 03:12:23 2015 UTC,"Any sequence generated by a truly random source has a program that can generate those same numbers in a non-random way. For example, any sequence of 10 numbers could be generated by evaluating a certain 9th-degree polynomial at x=0, 1, ... , 9."
compsci,3dhqp8,panderingPenguin,2,Thu Jul 16 12:25:59 2015 UTC,"Yes. So if the complexity of the program learnt by the Universal Turing Machine is as or more complex than the input sequence, then does that suggest the input sequence was truly random and no underlying function exists?"
compsci,3dhqp8,darkmighty,1 point,Thu Jul 16 12:28:38 2015 UTC,"Are you trying to figure out whether it's possible to create:  1) A UTM that looks at a sequence and determines whether or not it was likely to be generated randomly, or  2) A UTM that looks at a sequence and determines whether or not there was an underlying deterministic TM that generated that sequence?  If (2), then as /u/minno explained, for every possible finite sequence you could take as input, a deterministic TM could be created that could have produced that sequence. So there's no way to tell if the inferred DTM was actually the one that produced the sequence or not.  If (1), then there may be some algorithms that might look for patterns in the input and probabilistically infer generator DTMs, but again, you can never be 100% sure that the inferred DTMs are the ones that generated the inputs."
compsci,3dhqp8,Fs0i,1 point,Thu Jul 16 13:53:43 2015 UTC,"I'm trying to figure out if it is possible to create a Universal Turing Machine which determines whether or not a finite sequence is random (true random) i.e. a type of algorithmic randomness test.  Since asking the question of minno the link provided by earslap shed some light on the question - ""Kolmogorov randomness – also called algorithmic randomness – defines a string (usually of bits) as being random if and only if it is shorter than any computer program that can produce that string. To make this precise, a universal computer (or universal Turing machine) must be specified, so that ""program"" means a program for this universal machine. A random string in this sense is ""incompressible"" in that it is impossible to ""compress"" the string into a program whose length is shorter than the length of the string itself.""  My question is whether the above is achievable. The answer provided by earslap indicates that this approach suffers from the halting problem in which case it's only a possible in theory,  ""Sure, you can go brute force and start enumerating all possible algorithms and compare their results to see if any matches your input data, but then you bump into the halting problem: you can never know if this method will terminate (find a solution); and if your data is really random, the program is not expected to terminate. It will never say ""I tried all possible algorithms and none of their outputs match your input data so your data must be random"", but it can say ""I found an algorithm to represent your input data in a compact manner"". It can tell you if your data is not random (theoretically), but it can never definitively say that the data is random.""  Basically the question is ""can you create a Universal Turing Machine which determines whether or not a finite sequence is random (true random) in practice"". I hope that clarifies it a bit?"
compsci,3dhqp8,frenris,1 point,Thu Jul 16 14:06:20 2015 UTC,"You can certainly create a UTM that can determine conclusively that a finite sequence is not random. But determining whether a finite sequence is actually random feels like a harder problem to me as your Turing machine would have to check every possible non-random way of generating finite sequences (this is an infinite set as far as i can tell) to see if the sequence could be generated by any of them.  Thus since we have an infinite set to check, I don't think this question is decideable as the machine may never halt."
compsci,3dhqp8,ggchappell,1 point,Thu Jul 16 18:00:56 2015 UTC,"Some assumptions are missing here.   If we ask 'Is there a UTM that distinguishes the output of a UTM from a i.i.d random source?' than the answer is clearly no, because the random source can output whatever string the UTM outputs with non-zero probability.  OP is clearly asking for an inference instead: he want a program that infers optimally whether a string comes from a random source or from a UTM. However, this case only makes sense if we consider very small UTMs, otherwise it makes no sense -- the UTMs being considered could be ones where we have sampled from randomness previously.   So we need something like an optimal inference of whether a string 's' of length 'L' was generated by a UTM of length much smaller than 'L'. For optimal inference, we would need (1) to make assumptions about the distribution of those UTMs (2) compute all UTMs of length at most 'L' that generate the string 's'. The problem is, (2) is not achievable, so optimal inference is not achievable (i.e. the answer to the question is no).  Approximate inference can be chosen instead, which is essentially what randomness tests try to accomplish (they should output a 'yes' if the inferred probability of the source being randomness is >50%)."
compsci,3dhqp8,Chronophilia,2,Thu Jul 16 19:04:43 2015 UTC,"The question is if the program can be smaller (have less information) than the generated output - especially for an infinite series?  Consider the series   1,0,1,0,1,0,1,0,1,...   Even though the series is infinite, it doesn't contain much information (from an information theory perspective):   f (n+1) = 1 - f (n)   Any pseudo-random-number-generator has a finitely many states (for example: In your computer a RNG can only have as your ram has), and thus can't output infinitely random numbers, simply because the amount of possible states the RNG can be in is too small. It is bound to repeat at some point, when we run out of states.   But in a turing-machine we have an infinite band, so (in theory) we can have infinite states. But the important part is that we can't reduce any given series of numbers to a a RNG with a finite state size.   This impies that a ""true"" random source is impossible to reduce to such a smaller (finite) state machine.   Now the question is: Is there a turing-machine that can determine if there is a smaller state that produces all the right numbers?  For a finite series: Maybe (but there is the question if the series can be ever considered random then? What is even random in this context?)  But for an infiite series: No.   There first n bits in the output could, for example, be zero by chance, for a n that is as big as you choose. But after that there could be whatever. So without reading to the end we can't conclude randomness.  So how can a turing machine find an other turing machine that gives out all the numbers in finite time? It can't, because if the output is random there is no way to predict the next bit. So we have to read every single bit from our randomness-source (which is a black-box), and this is impossible, since the series is infinite!  Edit: Some clarifications."
compsci,3dhqp8,akeryw,1 point,Thu Jul 16 14:37:37 2015 UTC,"Thank you, this is also a very good and concise explanation."
compsci,3dhqp8,Deterministic-Chaos,2,Thu Jul 16 14:56:41 2015 UTC,Any finite sequence generated by a truly random source has a program that can generate those same numbers in a non-random way.    You forgot an extremely important word.
compsci,3dhqp8,ekspiulo,6,Thu Jul 16 16:03:23 2015 UTC,"Yes & no.  The statistical tests can be done. In fact, this is how they usually are done. Of course, we don't use Turing Machines per se. We use computer programs, but that amounts to essentially the same thing.  The incompressibility issue is more problematic. What you are talking about is Kolmogorov complexity. A random sequence is going to be one with high Kolmogorov complexity. But it is known that there is, in general, no algorithmic method for proving a lower bound on Kolmogorov complexity. Alas, your item (1) is not happening.  So, essentially, you can use a computer program -- Turing Machine, if you like -- to show that some finite sequence looks pretty-much-kinda-sorta random.  But then someone will come up with a new statistical test that the sequence fails. And that is one reason that people keep looking for new pseudorandom-number generators."
compsci,3dhqp8,goonmaster,3,Thu Jul 16 15:53:17 2015 UTC,"You can, but the definition is a bit weak. A random string is one whose Kologromov complexity is at least as large as the string's length.  Kolmogorov complexity depends a bit on your choice of encoding, but the effect of this is bounded."
compsci,3dhqp8,herbrand,1 point,Thu Jul 16 13:46:50 2015 UTC,"nine, nine, nine, nine, nine, nine...."
compsci,3dhqp8,daneelthesane,2,Thu Jul 16 20:23:44 2015 UTC,Ha ha I see you read Dilbert :)
compsci,3dhqp8,quiteamess,1 point,Fri Jul 17 04:56:48 2015 UTC,"This is not possible, it's easier to imagine if you think that any finite sequence of symbols, from any could also be the output sequence of a true random number generator.  So you'll always have this, hypothesis, these numbers are part of X algorithm or these numbers are a truly random sequence that is identical it those outputs at the given quantity of symbols, and its clearly impossible to decide without information not specified in the problem here.   For example, given the sequence Xn, where X1 = 1 and X2=4, is this the output of the function f(x) = 4x-1 or a random function? You can't decide with two values and you can't decide with any finite number of values.   If you want to decide this to a given probability, say 99% chance, suddenly this task is trivial, and that's the difference between computability and probability."
compsci,3dhqp8,bradfordmaster,1 point,Thu Jul 16 16:27:59 2015 UTC,"There exists many entropy definitions and they are not equally good for all applications. Shannon Entropy takes into account the probability of observing a specific event, so the information it encapsulates is information about the underlying probability distribution. More conservative measures, like min-entropy or collision entropy, are necessary in cryptographic applications. Measures of randomness allow us to make approximations about the data. So to answer your question, it is possible for a machine to measure entropy and make a decision as to whether or not a sequence is random based on a threshold value. It boils down to a question of - is the input random enough?"
compsci,3dhqp8,sakkara,1 point,Thu Jul 16 20:10:46 2015 UTC,"In short the answer is no. Since most people seem to have addressed this for the Kolmogorov complexity of finite strings, I will discuss your question for infinite binary sequences.  Martin-Lof's definition embodies the second criterion of randomness that you wrote. His definition formalises the idea that any effective (i.e., algorithmic) statistical test will fail to detect patterns in a random sequence. A theorem due to Claus Schnorr reveals that Martin-Lof randomness for an infinite binary sequence Z is actually equivalent to the incompressibility of each initial segment of Z. As others have described, a universal Turing machine cannot detect the incompressibility of finite strings, and so certainly cannot detect the incompressibility of the infinitely many prefixes of a sequence.  There is an interesting notion of computational complexity related to your question. Given a Martin-Lof random sequence Z, what kind of oracle is needed to detect patterns in (derandomize) Z? There are many sequences with high enough information content to do this, but some sequences (known as the K-trivials) cannot derandomize any sequence despite being incomputable. Thus they have very low computational complexity in the sense that, even if you could compute them, they wouldn't be very helpful. The K-trivials have been dubbed 'anti-random' for this reasons like this.   As a final remark about finite strings: the set of incompressible strings is undecidable. It is not difficult to show that this set is in fact immune (i.e., it does not even contain an infinite computably enumerable subset)."
compsci,3dhqp8,bradfordmaster,1 point,Thu Jul 16 21:14:34 2015 UTC,I am at a loss about how you could prove non-computability. Anyone have any ideas?
compsci,3dhqp8,zitterbewegung,1 point,Thu Jul 16 21:38:05 2015 UTC,In the context of Kolmogorov complexity Algorithmic information theory is interesting. There is also a great article by nautilus on Kolmogorov.
compsci,3dhqp8,Ishmael_Vegeta,1 point,Thu Jul 16 22:19:41 2015 UTC,"Definitely not in finite time, because the sequence could repeat after arbitrarily long, so you could construct a machine that would say ""no not random"" or ""still thinking"", but not one that could terminate and say ""yes, this is random"".  EDIT: the machine might not even be able to say ""no not random"", because it could just appear to loop, but then stop looping after some arbitrary number of loops, although the chances of this can become quite small for a large number of loops.  So really the machine could say ""probably not with p > X"""
compsci,3dhqp8,ditditdoh,1 point,Thu Jul 16 22:59:26 2015 UTC,That's not true. Even if a sequence repeats itself after some length it is still possible that the next number varies again. This should be especially the case after you already have run for an infinite amount of time since then you already have seen all possible sequences.
compsci,3dhqp8,Ishmael_Vegeta,2,Thu Jul 16 23:29:01 2015 UTC,"My point was that as soon as it says ""yes, this is random"", you could then infinitely repeat the sequence, which would make it not random. Or better yet, you could just start outputting nothing but 0's after the machine thinks it found a random sequence.  But you're right, really all it can say is ""still thinking"""
compsci,3dhqp8,kops,1 point,Fri Jul 17 00:07:14 2015 UTC,You should replace randomness with entropy in a given system which is a better term for this question. Is entropy computable? Not really.
compsci,3dhqp8,FinFihlman,1 point,Fri Jul 17 04:30:09 2015 UTC,"a better question... ""where is the boundary between complexity and randomness?"""
compsci,3dhqp8,seriousreddit,2,Thu Jul 16 17:35:59 2015 UTC,Define complexity?
compsci,3dhqp8,Hexorg,-1,Thu Jul 16 22:18:28 2015 UTC,that's the hard part isn't it!
compsci,3dhqp8,Hexorg,0,Fri Jul 17 02:37:56 2015 UTC,"If you give me any TM and claim it accepts only 'truly random' strings, I can easily generate one that it will accept but is not at all random by simulating it.  Simply run it on every string in lexicographical order (0, 1, 00, 01,  10, 11, 000, 001,...) until it accepts. Obviously this wasn't generated randomly and in fact I highly doubt it will be a martingale (0 will always be much more likely to show up than 1 given its lexicographical 'firstness').  (NB: Even if your machine doesn't always halt, this technique still works with a slight modification)."
compsci,3dhqp8,FinFihlman,-8,Thu Jul 16 15:35:08 2015 UTC,"If the sequence is finite it is always possible to compress (even a little bit).  This, though, brings up the question of what information can we know about the compression scheme.  E: If you think I'm wrong please explain why."
compsci,3dhqp8,FinFihlman,7,Thu Jul 16 12:24:32 2015 UTC,"If the sequence is finite it is always possible to compress (even a little bit).   Could you explain what you mean by that? As I interpret your statement, it's easily false by a counting argument."
compsci,3dhqp8,FinFihlman,1 point,Thu Jul 16 12:46:42 2015 UTC,"I was kinda thinking along the same lines. If you have a roulette game, and a number 20 appears several times in a row (had that happen to me), you can substitute a 20 to some key sequence that's shorter then the original sequence of 20s, and create a decompression dictionary. This adds a bit of an overhead, but if your input random had a sequence of the same numbers long enough, it'll still be compressible. I wouldn't particularly say that you can always compress it though because it requires a repeated number sequence in my example.  Another way to think about it is - a truly random number generator always has a chance of spitting a series of the same number, therefore given a large enough random sampling, you'll always have series of repeated numbers, which are compressible by substitution."
compsci,3dhqp8,seriousreddit,4,Thu Jul 16 13:56:48 2015 UTC,The definition refers to in-compressible with the same alphabet.
compsci,3dhqp8,FinFihlman,1 point,Thu Jul 16 14:09:21 2015 UTC,Oh! Got'cha. Thanks!
compsci,3dhqp8,PM_ME_UR_OBSIDIAN,1 point,Thu Jul 16 14:10:32 2015 UTC,What does this mean?
compsci,3dhqp8,seriousreddit,1 point,Thu Jul 16 15:33:20 2015 UTC,"Yeah, that's one of the ideas I had but I went a bit further and gave a general solution. See above."
compsci,3dhqp8,UncleMeat,-1,Thu Jul 16 15:33:12 2015 UTC,"One example: we can trivially use generative algorithms and all of this is of course discrete.  Suppose you have a 16 by 16 block of true random 8 bit data (=256 bytes to transmit without compression and it can hold 256^256=2^2048 unique images). You can also think of the block as a stream if it helps you.  Now we can have an algorithm that generates all possible 16 by 16 blocks and then just point to the block that holds your data. The indexed number never becomes larger than the actual data set (it's always <=) and naively, in half the cases it's smaller.  We can also use operators to form bigger numbers from smaller numbers in many of the cases and/or use variable length numbers (expressing the index 255255 requires only 3 bytes for example, if that's how we set the data format) and/or use symmetry (use a bit/byte for orientation or so) to further reduce the size of the index.  You can also move where indexing starts to prevent silly inefficiencies like using the first indexes for half empty blocks, but that's statistics and for many messages instead of a single one.  This is akin to the idea of storing data in Pi (that idea is flawed but the analogue holds) and this actually works. It's also kind of fast.  You can also expand hashes and index those, if you want to replace the generative algorithm.  ALSO:  For any finite length sequence you can always come up with a formula or algorithm that generates that sequence. Randomness is an idea, a concept that we can try to attain but we never can."
compsci,3dikyk,Kiuhnm,6,Thu Jul 16 15:46:41 2015 UTC,"The down arrow means ""use"", and the up arrow means ""verification"".  The arrows may make more sense if you consider the proof term assignment to this logic. In that case, verifications correspond to terms whose type you can check, and uses correspond to those terms whose type you may synthesize.  The rule you quote says, ""if you can use an implication and you can verify its premise, then you can use its conclusion.""   EDIT: I hope this helped, but if it did not, please feel free to ask me followup questions. I have a number of resources that may help, depending on what you need."
compsci,3dikyk,jonsterling,1 point,Thu Jul 16 17:35:09 2015 UTC,"verifications correspond to terms whose type you can check, and uses correspond to those terms whose type you may synthesize.   I don't know what check and synthesize mean in this context."
compsci,3dikyk,Kambingx,3,Thu Jul 16 18:25:26 2015 UTC,"Interpreting the inference rule as a type checking rule for a (simply-typed) lambda calculus, you get:  Γ  ⊢ e1 ↓ A → B     Γ ⊢ e2 ↑ A -------------------------------       Γ  ⊢ e1 e2 ↓ B   which can be read as: ""type checking a function application e1 e2 generates a type A → B where type checking e1 generates a B, and e2 type checks against A"".  This is a bidirectional interpretation of type checking which coincides with how you would actually implement a type checker.  The standard typing judgment  Γ ⊢ e : t   does not tell you for a specific rule whether you are checking that e has type t or that you produce or synthesize t when type checking e.  The ""verification"" and ""use"" judgments make explicit this notion.  Other examples: when type checking a variable   x:t ∈ Γ --------- Γ ⊢ x ↓ t   you produce the type of x from the context.  In contrast, when type checking a function     x:t1, Γ ⊢ e ↑ t2 ---------------------- Γ ⊢ λx:t1. e ↑ t1 → t2        you merely check that the lambda has an arrow type by checking that its body has the range type of the arrow."
compsci,3dlvuo,Lebikl,2,Fri Jul 17 09:25:51 2015 UTC,"I'll start by suggesting to have a look at /r/cscareerquestions for more specific advice on CS as a job field.  You're loving what you're doing, and there is a variety of reasons why you are struggling. Can you expand a bit on what you're doing, what problems you have a hard time to solve, and what you want to achieve ?"
compsci,3dlvuo,Gyrodiot,2,Fri Jul 17 10:06:56 2015 UTC,"From my experience, it was a pain in the ass. While in school I busted my butt in order to get good grades. That meant that I stayed up late writing code. After I got my code working I would go back in refactor to improve its functionality and/or readability. I also had no programming experience prior to getting started as a CS major where majority of my peers had some experience, so it felt like I was always playing catch-up with them. So, I always felt like I had to work harder than everyone else.  That being said, I got close to burn out. I was working and going to school. In the end, it payed off and was definitely worth all the headache and loss of personal time.   Stick with it. You are almost there."
compsci,3dlvuo,UH1868,2,Fri Jul 17 11:00:55 2015 UTC,"The hardest part of school for me was the implicit competitive nature of a CS degree. There were alot of REALLY smart people in my classes who could regurgitate textbook answers off the top of their head. I thought I was slow and not as smart as them.... but I was wrong. There is so much to learn about CS, its impossible for anyone to know everything. Just pick something that you really want to get good at (web dev, embedded, dsp, etc...), and focus on understanding it as much as possible.  School is only the beginning, and unless you want to go up higher in academia, it doesn't really matter in the long run. I've never been asked about my GPA or what I learned in school."
compsci,3dlvuo,guizian,1 point,Fri Jul 17 15:30:23 2015 UTC,"What do you love most about CS? Solving/Analyzing abstract problems or fiddling with computers and programming them? (Are you oriented more to theoretic problems or to practical software development problems?) Why does it take you more hours than the others? What are you bad at?  To become better at programming, you have to write more programs. You have to gain experience by failing more, by reading the reference manuals for the programming language you are using, it's standard library API and the operating system API. Find your motivation to dig deep into problems you encounter while writing a program. Find out why it fails, which of your assumptions about the code are wrong, which parts of the code (you copied from somewhere) do you not understand?"
compsci,3dlvuo,x-paste,1 point,Fri Jul 17 10:11:29 2015 UTC,"Your school years in CS will generally be more difficult and less fun than your years in actual productive roles. This is a combination of unfamiliarity with the tools/theory as well as a lack of experience performing the tasks (plus, it's supposed to be difficult right now, as that's what fosters learning). It's worth it in the end, so keep going!   I am not getting my what I deserve   I'm going to be blunt here, but you don't deserve anything. Neither do your peers. You work hard and you get a degree plus the all-important knowledge that comes with it. That's why you're there, and that's what you need to focus on. It is a  ""pain in the a**"" but that's life.  (Can you tell I'm a father of young boys?) ;)"
compsci,3dibji,osense,2,Thu Jul 16 14:34:14 2015 UTC,A node may also have a pointer to its parent node as well as an indicator as to whether or not the node marks the end of a word.   From the article you just linked. Have you considered adding a flag to each node saying if it's the end of a word or not?
compsci,3dibji,more_exercise,1 point,Thu Jul 16 14:56:01 2015 UTC,"That would work I suppose. I was hoping to avoid adding more fields to the nodes, but I guess this would be the most sane solution. Thanks for the suggestion!"
compsci,3di89y,greenprius,1 point,Thu Jul 16 14:07:10 2015 UTC,XPost Subreddit Link: /r/HPC
compsci,3deh8l,Butterjoy,82,Wed Jul 15 17:15:04 2015 UTC,"This is a hotly-debated topic, and I have been told that the placement of CS into a particular school/college is a largely a matter of the history of the department.  At my alma mater, the Math department was the first to teach a computer science course.  The Math department is in the school of Arts and Sciences.  So when CS became large enough to split into its own school, it stayed under Arts and Sciences.  In many other colleges, the Engineering department taught the first computer courses, and when CS split it stayed under Engineering.  To compound the issue, there are many different ""computery"" departments nowadays.  In my personal opinion, I think that Computer Science should be closely aligned with Mathematics, Management/Information Systems should be aligned with Business, and Software Development/Engineering should be aligned with Engineering."
compsci,3deh8l,testube_babies,2,Wed Jul 15 17:36:36 2015 UTC,"CSC is engineering where I went to school, but they were almost like their own sub-department in engineering, they didn't really have the same philosophies as the other engineering disciplines.  And I think this makes sense, honestly. Comp Sci is its own science, very distinct from engineering. If someone wants to learn programming, there are software engineering programs available, but I think ""software engineering"" is very distinct from ""computer science"" and it should be."
compsci,3deh8l,omniron,1 point,Thu Jul 16 02:24:08 2015 UTC,Same for my undergrad.
compsci,3deh8l,inspired2apathy,0,Thu Jul 16 02:48:40 2015 UTC,"History no doubt plays a role in this, as I've heard myself. Unfortunately, the university I currently attend insists that the analytical skills learned through Liberal Arts subjects are transferable to Computer Science. I do agree with this to a minor extent, but the correlation is weak at best. I still think CS students could learn much more effectively if they were in an environment that focused on honing analytical skills specific to mathematical subjects. Why teach ""transferable"" skills, when you can teach skills direct to the subject?"
compsci,3deh8l,wfo,29,Wed Jul 15 17:54:38 2015 UTC,"If you're actually doing the 'science' part of CS then its closest friends are Math and Philosophy, which in my experience are ALWAYS in arts and sciences, they are the prototypical science and art, respectively. If you're doing the 'engineering' part of computer engineering then sure. But you're not doing a CE degree you're doing a CS degree. It sounds like you're doing a CS major and just complaining it's not an engineering degree; well, that's not the school's fault, if you want to do engineering then do engineering and you can only talk to other engineers and look down on 'liberal arts' majors.   And really? Physics and chemistry are in arts and sciences and they are FAR more mathematical and scientific and analytic and technical than CS. CS is creative and artistic, you're building systems out of your imagination and a lot of designing things well in CS is to make them aesthetically pleasing so they seem coherent and others can understand them more easily."
compsci,3deh8l,bastard_thought,29,Wed Jul 15 23:12:20 2015 UTC,"This thread just seems like a rant / issue you have with your school. Other comments show the categorization  can be quite fluid among school systems.   Is this something you investigated before joining your school?   That is to say,  did you join specifically for CS? You must have known which school of study it was under (edit:)  and what requirements there were.  I'm sure schools make their degree requirements available."
compsci,3deh8l,com2kid,-2,Wed Jul 15 18:37:29 2015 UTC,"It is something of a rant; hence why I labeled it as ""Opinion"".  I knew which school CS belonged to before I joined my current university, but I judged that it was still the best college available to me (and I still stand by that). But despite that, I think there are areas the university could improve upon. Ergo, this ""rant""."
compsci,3deh8l,C0rinthian,7,Wed Jul 15 19:50:20 2015 UTC,"Unfortunately, the university I currently attend insists that the analytical skills learned through Liberal Arts subjects are transferable to Computer Science.   This depends.  Some philosophy courses are immediately applicable to CompSci, indeed you will occasionally an older CompSci professors who has a Philosophy degree.  (This is highly dependent upon which branch of philosophy of course!)"
compsci,3deh8l,ex_ample,7,Wed Jul 15 20:47:01 2015 UTC,"Liberal arts are really applicable for everyone. They are about how to understand and interact with other human beings, especially those who you may not share context with. That's why most programs have liberal arts as part of the core curriculum for everyone.   Also, I doubt that being part of Arts and Sciences has anything to do with the liberal arts classes you had to take. Those requirements are typically institution wide."
compsci,3deh8l,C0rinthian,2,Thu Jul 16 00:10:26 2015 UTC,"I think he's parsing it as ""liberal(arts and sciences)"" and not ""(liberal arts) and (sciences)""    I don't see why math, chemistry, physics, biology, linguistics, etc aren't a good fit for CS."
compsci,3deh8l,murkwork,1 point,Sun Jul 19 09:11:37 2015 UTC,"Yup. And I would consider computer engineering (or software engineering) to be a distinctly different discipline from Computer Science.  Engineers use physics extensively, but they're not physicists."
compsci,3deh8l,bastard_thought,15,Sun Jul 19 17:28:58 2015 UTC,"I agree with bastard_thought, sounds like you wrote this thread just to rant about your own school =\   it also limits their ability to network and socialize with students of closely-related fields   How? You would be taking different CS classes with different professors, if CS was under the Engineering school?  IMO the only thing that limits your networking and socializing is yourself. If you wanna hang out with engineers, go attend the MechE Club meetings or something. If you wanna hang out with programmers go to your local ACM chapter meetings (or found one, if your school doesn't have one).  Also, I think you're severely underestimating the link between CS and certain liberal arts majors. Of the 5 most talented programmers I know, 2 started as Philosophy majors (about as liberal arts as you can get) and either switched or added CS as a 2nd major. Only 1 of the top 5 is only Computer Science, most have a double major or minors in something ""unrelated"" (read: not really unrelated) to CS.   Lastly, if you think your exposure to non-technical people will end once you graduate you are deluding yourself. If anything it's probably a good thing that you're exposed to a lot of non-technical folks at school."
compsci,3deh8l,murkwork,5,Wed Jul 15 18:52:33 2015 UTC,Maybe OP just wants their college social life already built for them?
compsci,3deh8l,PressF1,2,Wed Jul 15 19:29:49 2015 UTC,"Hahaha perhaps yes. I think it's a bit ironic, being surrounded with purely technical folks and social lives usually don't coincide."
compsci,3deh8l,ex_ample,1 point,Wed Jul 15 19:43:56 2015 UTC,"Wouldn't that be easier to do in a school of arts and sciences though? I mean let's face it, technical people tend to have a lower average socialization skill level."
compsci,3deh8l,PressF1,1 point,Thu Jul 16 11:01:09 2015 UTC,"Wouldn't that be easier to do in a school of arts and sciences though?   I don't really know - when I was in school kids from different departments hung out together, and there was overlap in the classes taken as well.   Maybe his school things are more segregated though.  I only have sample size = 1."
compsci,3deh8l,iamanonion,1 point,Sun Jul 19 09:13:06 2015 UTC,"Even still, it seems you would have a more diverse pool of people to socialize with in a college of art & sciences than in the college of engineering."
compsci,3deh8l,ex_ample,2,Mon Jul 20 00:41:25 2015 UTC,"It's rarely in the self-interest for a School of Arts and Sciences to give up a department like CS that can raise money by writing grants. If a researcher wins a grant from the US government, the school gets some of the money to cover support costs. If CS is allowed to leave, then probably physics/bio/chem could make a similar case that they should be allowed to leave as well. Basically Arts and Sciences would risk losing all of their grant-winning departments. At some places, this is a lot of money, and it's possible the rest of the departments in Arts and Sciences might have to cut back as a result."
compsci,3deh8l,somnophobiac,1 point,Thu Jul 16 00:21:18 2015 UTC,"Unfortunately, the university I currently attend insists that the analytical skills learned through Liberal Arts subjects are transferable to Computer Science   What difference does it make? Poetry and Chemistry are both in Liberal Arts and Sciences. There probably isn't much overlap, but so what? The overall administrative department doesn't have any real effect on the ""environment"" students learn in.   Hardcore science students in will learn the math they need to know. Especially since Math is typically in liberal arts/sciences anyway. Mathematics isn't a type of engineering at all.   And again, there will be lots of overlap between science students and related engineering students (CS and CompE, Chemistry and Chemical engineering, physics and electrical and mechanical engineering, and so on.)   I don't get why this is a big deal. What department a subject is in isn't going to have that much of an impact on the curricula."
compsci,3deh8l,jay520,32,Sun Jul 19 09:07:49 2015 UTC,"Half way through my grad school, our CS dept. moved from Arts & Sciences to School of Engineering. I do agree with your opinion, but a bunch of other engg. depts think CS should not be in 'engineering' because engg. is only part of CS. In fact, if you think about pure CS, it is just math and so deserves to be arts and sciences. Industry cares a lot about Cs engg. + professors need students to implement code which creates an illusion that 'CS' is engg. heavy. But its not."
compsci,3deh8l,com2kid,-21,Wed Jul 15 17:39:12 2015 UTC,"I do agree that CS is more closely related to Math than it is to Engineering, however, if it were up to me, the Math department would not belong to Arts and Sciences. Again, it would be grouping people from subjects such as Psychology, History, and English, with people who's subject is heavily dependent on Math. It's somewhat understandable when a university is small, and cannot afford to split areas of study across many schools, but for large universities, it's a very poor categorization system."
compsci,3deh8l,Quixotic_Fool,26,Wed Jul 15 17:48:21 2015 UTC,"It can be argued that advanced math is really just applied logic, which is itself a branch of philosophy. In fact, my university has a philosophy course titled ""Mathematical Logic"" that overlaps heavily with an identically named course in our math department. I've even taken a different philosophy course on logic that essentially covered the first half of a CS course I took."
compsci,3deh8l,murkwork,13,Wed Jul 15 18:57:11 2015 UTC,"however, if it were up to me, the Math department would not belong to Arts and Sciences.   Historically Math was considered one of the arts. It used to be that a well rounded degree in the liberal arts involved mastery of mathematics as well as language.  It is sad that the same isn't expected today, on either side. :("
compsci,3deh8l,jay520,3,Wed Jul 15 20:48:45 2015 UTC,"It's because it's in vogue to hate Math right now. It's very sad, you'll never see anyone proud to be terrible at Grammar/English, but some people are very proud of the fact that they're terrible at Math."
compsci,3deh8l,murkwork,15,Thu Jul 16 23:46:26 2015 UTC,"Psychology, History, and English   Psych 101 was required by my CS curriculum, I took a higher level psych class afterwards (out of pure interest). English 101 and a higher level ""Advanced Technical Writing"" english class is also required.  It seems as though you're treating people with ""non-technical"" majors as people you have nothing in common with, as people you can learn nothing from, and as people you don't want to associate with. You are wrong on all of those counts my friend.  It sounds like your school might have an organizational headache sure, but there's no actual problem with being around non-technical folks a lot. You should embrace it and learn as much as you can, that's what college is for."
compsci,3deh8l,PressF1,1 point,Wed Jul 15 19:18:18 2015 UTC,"I never claimed there was nothing I could gain from liberal arts. In fact, I will be taking several of my free electives in humanist subjects. I simply stated that the correlation between those subjects and CS was slim, in comparison to the correlation between CS and Math-oriented subjects. You can pose the argument that liberal arts classes will further your understanding of many topics, and even be transferable (to a degree) to CS - and I will agree with you. But if there is a better alternative - grouping CS majors with other STEM majors - why be against it?"
compsci,3deh8l,acomfygeek,9,Wed Jul 15 20:07:38 2015 UTC,"Of the four areas identified under the S.T.E.M.umbrella, only one is mainly found in the engineering department (that would be the E for engineering obviously). The SScience and the Math majors (physics, biology, chemistry, mathematics, etc.) are usually found in the Arts & Science department. I'm not even sure if there exists any ""Technology majors"", so you can exclude the T. Therefore, if your goal is to group CS majors with other STEM majors, then the Arts & Sciences seem to be your best bet."
compsci,3deh8l,murkwork,7,Wed Jul 15 20:26:09 2015 UTC,"I just think CS students would benefit more if they were within their peer group   OK fine, I concede you didn't outright say there's nothing to gain, but you implied there's a proverbial cliff of a difference between humanities versus STEM and their respective correlation to CS (your words were ""slim"", ""benefit more""). To be frank, that is simply not true. I think Psychology, Philosophy, and English writing have more to do with CS than most Engineering majors.    better alternative - grouping CS majors with other STEM majors   What exactly do you think are the tangible benefits of doing this? If your CS program were under College of Engineering, what would be different? Networking and socializing are both bullshit answers to that question, you can do both of those things with STEM majors just fine  as a Pharmacy major let alone CS.  To clarify I'm not against it, tbh I couldn't care less. It just seems like such a trivial distinction to fret over."
compsci,3deh8l,ocamlmycaml,-5,Wed Jul 15 20:26:05 2015 UTC,"I think Psychology, Philosophy, and English writing have more to do with CS than most Engineering majors.   And Math?   What exactly do you think are the tangible benefits of doing this?   I do think networking and socializing are valid arguments considering our school has several organization exclusive to particular majors. But I'll pose another argument: students of the School of Arts and Sciences are assigned a different (and larger) core curriculum than other departments. Effectively, this means that CS students are required to take courses, many of which are not-at-all related to their major, but are of a better utility to Liberal Arts students. Again, I will concur here that humanist subjects can be beneficial for any major; but it's foolish to require that a CS student take as many core liberal arts classes as say, as an actual liberal arts student. It is time which could be better spent on furthering the knowledge specific to a CS degree."
compsci,3deh8l,UncleMeat,4,Wed Jul 15 20:47:02 2015 UTC,"It seems like you have issues with particular rules of your institution, and rather than go after them individually you're lumping them together under an umbrella that isn't really the issue."
compsci,3deh8l,UncleMeat,3,Thu Jul 16 11:08:41 2015 UTC,"but it's foolish to require that a CS student take as many core liberal arts classes as say, as an actual liberal arts student.   By your school's definition, a CS student is an ""actual"" liberal arts student.  Honestly, given your preference, it just seems like a bad fit between the school and you."
compsci,3deh8l,east_lisp_junk,1 point,Thu Jul 16 12:31:32 2015 UTC,"And Math?   Was I supposed to magically divine the point you were trying to make with these two words? Are you saying that because engineering and cs are both built on a math foundation, they must be more related than cs and non-math majors?  If so I disagree. Both fields are built on basic calculus but branch away pretty quickly. Around sophomore year I started doing math that my engineering friends hadn't a clue about and vice versa. I'd talk about quaternions and they'd talk about fluid mechanics and we'd have no idea what the other was talking about.   considering our school has several organization exclusive to particular majors   So what you're saying is even if CS were under the Engineering college like you want, you would still be excluded from certain networking and social events based your CS major. Really strengthens your argument here.......   I do think networking and socializing are valid arguments   Nah, sorry that's bullshit. You're probably too lethargic to make it happen and blame it on organization of colleges.   CS students are required to take courses, many of which are not-at-all related to their major   Lemme guess, you've never once submitted an application to your Dean to replace a required class with one more relevant to your major? Am I right? At my school I took a high level CS class I was interested in, in lieu of some bullshit required thing I can't even remember. I had a meeting, explained why this advanced class was way better and more relevant, had approval after 30 minutes.   but it's foolish to require that a CS student take as many core liberal arts classes as say, as an actual liberal arts student   Like others have said, you're a liberal arts student by definition of your school, so you take liberal arts core (some of which you can likely replace with CS classes if you actually make an effort to). If you aren't happy with that definition, you should have at least Googled your school before enrolling."
compsci,3deh8l,Archawn,7,Thu Jul 16 14:40:37 2015 UTC,"What about Physics, Economics, Statistics, and other departments which are heavily dependent on Math and are firmly in Arts and Sciences?"
compsci,3deh8l,FlyingBishop,5,Wed Jul 15 21:58:43 2015 UTC,Should physics be moved to engineering too? It also depends heavily on math.
compsci,3deh8l,com2kid,-7,Wed Jul 15 21:59:27 2015 UTC,"I'm not informed enough about physics to make an educate guess about which department it should belong to. But the whole grouping of the Arts with the Sciences is rather absurd. With the current state of things, English and Physics majors are treated equally under the same banner, and assigned same core requirements, when in fact, they ought to be be prescribed a curriculum that's in line with their chosen major. Sure, colleges seek to provide well-rounded education, and that's fine; but the focus should be the major, and when a student's field of study becomes eclipsed by unrelated core courses, it's a hindrance."
compsci,3deh8l,PressF1,8,Wed Jul 15 22:14:41 2015 UTC,"and when a student's field of study becomes eclipsed by unrelated core courses   That sounds like a problem when your school, not with colleges of arts and sciences in general. A buddy of mine got his BS in physics in a college of arts and sciences and had like five nontechnical classes he had to take."
compsci,3deh8l,FlyingBishop,1 point,Wed Jul 15 22:42:02 2015 UTC,"Yeah, same for me with a double A&S major (CS & math), and that was the requirement set by the university, not that individual college. Of course, I consciously chose a university that followed a more engineering-based tradition than a liberal arts one."
compsci,3deh8l,bradfordmaster,26,Fri Jul 17 14:14:24 2015 UTC,"As a math major with an academic interest in computer science, it's sad to me that CS is lumped in with engineering disciplines because I have to deal with the insane policies and bureaucracy that engineering schools come with.     I think, hands-down, Computer Science belongs in the same school/college as Mathematics.  I also think that Mathematics belongs in the same college as Physics, which belongs in the same college as Chemistry, which belongs in the same college as Biology, Astronomy, Geology and so on.  But wait, Computer Science also belongs with Computer Engineering and Electrical Engineering, which belong with Mechanical and Aerospace.  The problem is that most universities (like mine, sadface) have a (Literature + Sciences + Arts) college for historical reasons, even though the ideal split is (Engineering + Sciences) in one college and (Literature + Arts) in the other.    This all gets even fuzzier when you try to figure out where departments like Psychology, Economics, Linguistics, and Philosophy should all go.  It may help to have ""Software Engineering"" majors in the Engineering school and ""Computer Science"" majors in LSA.  But that hardly makes sense."
compsci,3deh8l,Plazmatic,7,Wed Jul 15 18:38:28 2015 UTC,"There's no ideal split. To get people who can do hardcore engineering, you want an engineering college that include sciences like you suggest.  However, people who learned in that sort of environment usually need engineers who had more exposure to the arts and literature to help them interface with the non-technical people in the world. Even so, I think hardcore engineers often benefit from the cross-pollination and aren't hurt by being lumped in with the arts."
compsci,3deh8l,Archawn,3,Wed Jul 15 19:48:05 2015 UTC,"Why are we applying trees as the only data structure here? This is compsci, we know better!"
compsci,3deh8l,ex_ample,1 point,Wed Jul 15 20:49:37 2015 UTC,Yes use an array it's far more efficient to traverse.
compsci,3deh8l,SonOfCorn,1 point,Thu Jul 16 11:11:16 2015 UTC,Totally non-tree oriented university structures are cool. They aren't a replacement for the more tree-oriented ones however.
compsci,3deh8l,VorpalAuroch,1 point,Fri Jul 17 21:55:26 2015 UTC,"I'm not convinced those high level groupings are useful at all for CS. My university had a whole separate school for computer science, and that made the most sense.  They did still have to shove economics in somewhere though, and I think it was with humanities, along with psychology and the like"
compsci,3deh8l,VorpalAuroch,1 point,Thu Jul 16 01:16:12 2015 UTC,"There is such thing as a software engineering major? That just sounds like applied CompSci, not something that deserves its own degree program."
compsci,3deh8l,ex_ample,1 point,Thu Jul 16 04:13:56 2015 UTC,"There usually isn't but I'm saying maybe there should be.  There's a big difference between someone who goes to school to become a software engineer and someone who goes to school to study CS theory.  At my school they make it hard for the latter type of person to take the classes he needs because they're spread out across schools.  Having CS in the engineering school can cause neglect of students with grad school plans, at least it does here."
compsci,3deh8l,bahston_creme,1 point,Thu Jul 16 19:25:08 2015 UTC,"This all gets even fuzzier when you try to figure out where departments like Psychology, Economics, Linguistics, and Philosophy should all go.   Those things are all obvious when you have the (Literature + Sciences + Arts), as none of those things are engineering."
compsci,3deh8l,jonadair,8,Sun Jul 19 09:15:04 2015 UTC,I'm genuinely puzzled by this question. Is this the standard thing in america to do? Put CS in with the humanities? I've never heard of such a thing over here across the pond...  Arts is very separate from CS here. It has its own school beside the mathematical sciences and physics. It's in the college of sciences and in no way overlaps with the Arts/Humanities.  Who thought up the idea of CS being naturally in the Arts in America? I've genuinely never heard of this.
compsci,3deh8l,inconspicuous_male,9,Wed Jul 15 20:39:15 2015 UTC,"Math is frequented classified with the Arts as well, since it's closest relative before CS was a field is academic philosophy."
compsci,3deh8l,IndependentBoof,-6,Wed Jul 15 21:35:44 2015 UTC,This might have made sense some 200 years ago...
compsci,3deh8l,PressF1,11,Thu Jul 16 02:34:42 2015 UTC,"It's still true. Academic mathematics is much closer to Philosophy than anything else. Many other things use mathematical tools (Physics, mainly, but everybody uses statistics), but Math, Philosophy, and Computer Science are a class of their own."
compsci,3deh8l,IndependentBoof,1 point,Thu Jul 16 02:43:14 2015 UTC,"It's arts and sciences.  So fine art, poetry, literature, philosophy as well as math, chemistry, physics... and CS.   I don't really get what the problem is.  Science is right in the title of CS, so of course it belongs with other sciences and math."
compsci,3deh8l,murkwork,8,Sun Jul 19 09:55:18 2015 UTC,Shameless plug: Northeastern University in Boston has its own College of Computer and Information Science
compsci,3deh8l,murkwork,5,Wed Jul 15 18:01:06 2015 UTC,That's what Georgia Tech did - created a College of Computing.
compsci,3deh8l,Dysvalence,1 point,Wed Jul 15 18:26:54 2015 UTC,"The Rochester Institute of Technology has a school of Computer and Information Sciences that also has IT, SE, and video game design. I guess it's a tech school thing to do"
compsci,3deh8l,moegamisama,1 point,Wed Jul 15 19:00:55 2015 UTC,"Ultimately, I think this will be (or at least should be) the direction schools go with computer science. As the subdomains of CS are rapidly expanding, I suspect that it will be more commonplace that a College of Computing will have multiple departments including Software Engineering, Computational Science, etc.  Given the common American CS curriculum, I'd say it fits better in colleges of engineering than those of Science, however, good cases can be made for CS being both science and engineering."
compsci,3deh8l,pigeon768,1 point,Thu Jul 16 00:16:51 2015 UTC,"I have an interesting (at least to me) question for you!  The original meaning of a ""computer"" was someone who computes - ie a mathematician. In a school of computing, would mathematics also be included? Math and CS are very closely related, so it seems like it would make sense."
compsci,3deh8l,Na__th__an,1 point,Thu Jul 16 11:14:01 2015 UTC,"In my opinion, no, math wouldn't belong in a college of computing. It is true that math was integral (no pun intended) to the foundation of computer science. Some elements of computer science are applied math and many CS departments grew out of math departments. However, it wouldn't be giving math the credit it deserves to say that the discipline is a subset of computing. Likewise, the logic we use in CS you could really say comes straight from philosophy but that doesn't make the entirety of the discipline of philosophy a subset of computing.   I see computing as related, but distinct from math, philosophy, science, and engineering."
compsci,3deh8l,bastard_thought,2,Thu Jul 16 16:37:38 2015 UTC,"Yeaaa! CCIS represent!   Regarding the top comment about the history of the department, one of my professors (from the College of Engineering) said that CS used to be under the engineering wing of NU and when the split happened there was apparently a bunch of bad blood between engineering and cs/math professors. Those that believed CS was enough to warrant its own school left COE, those that didn't stayed and wanted nothing to do with CCIS."
compsci,3deh8l,Na__th__an,2,Wed Jul 15 18:45:43 2015 UTC,"Hmmm as I read a lot of the other comments, people are complaining about CS being under a specific college that they aren't in and having to deal with the bureaucracy of the other college in order to take CS classes.   Sounds like people have gone to some real sucky schools that have caused these issues. Not once have I been roadblocked by bureaucracy at NU, and I took classes under 3 different schools (CCIS, Arts+Humanities, COE) so I had meetings with academic advisers and deans quite often. I even did an interdisc. independent study, which in order to get clearance for, the leaders of two schools had to meet, talk about me and the study - had it approved in under a week.   Shoutout to Asc. Dean Richard Rasala and Director Magy El-Nasr =)"
compsci,3deh8l,bastard_thought,6,Wed Jul 15 19:09:24 2015 UTC,"At the PhD level, CS can get pretty pure and this would put it with math and the sciences, especially when computational science is involved, though it's under engineering here. Honestly though, I wish people would stop being butthurt on pure vs applied or neglecting the humanities so that CS, math, science and engineering could be their own thing. Where I am its kinda pitiful that most bio, neuro, and psych majors can't do math beyond basic stat except the premeds, and this means that the classes taught are limited, and we can't get easy access to engineering labs and resources or even CS classes.  Also, computational psychology is very much a thing. I have a book on recurrent networks and statistical learning theory on the desk and it's frightening my peers."
compsci,3deh8l,sunapi386,7,Wed Jul 15 19:22:39 2015 UTC,"I'm a fan of the structure at my university. We can major in computer science through either the College of Arts and Sciences or through the College of Engineering. That way, people who are interested in, say, a CS/EE double major have a good option, and people like me who prefer to avoid laboratory science like chemistry and physics in favor of taking language and writing classes also have an option. And the best part is the CS degree requirements are identical. The only difference is what other requirements you have to take."
compsci,3deh8l,devluz,5,Wed Jul 15 19:01:32 2015 UTC,"And the best part is the CS degree requirements are identical. The only difference is what other requirements you have to take.   This is why I don't really have an opinion about any of this. Not only is it true for computer science, it's true for every other degree as well. If mechanical engineering was taught by the college of arts and science, guess what would change? You'd have to take 2 more humanities electives and 2 less courses in chemistry or biology; that's it. At the end of the day, who really cares?  Your education is determined by your department, not by the college. Unless the college goes digging around in the internals of the curriculum, (""We need you to teach the curriculum in Visual Basic so non-technical people can get computer science degrees too"") who really cares?"
compsci,3deh8l,pelvark,1 point,Thu Jul 16 03:25:59 2015 UTC,That sounds like a great compromise! I would definitely support such a system.
compsci,3deh8l,-_-_-_-__-_-_-_-,0,Wed Jul 15 20:30:13 2015 UTC,"Yeah, this is what OSU does. You can have an ABET accredited CSE degree from the college of engineering or get a Computer Information Systems degree from the college of arts and science with less of an emphasis on math."
compsci,3deh8l,c8j99zn,4,Wed Jul 15 20:16:31 2015 UTC,"Well,  those are two completely different areas of study,  so the separation makes sense."
compsci,3deh8l,jay520,0,Wed Jul 15 20:52:15 2015 UTC,"They take largely the same classes. The CIS students take a foreign language, the CSE students have more math an science credits, but the computer classes are the same."
compsci,3deh8l,xiipaoc,1 point,Wed Jul 15 23:00:21 2015 UTC,"Hm,  so it doesn't make sense now.  CSE and CIS are apples and oranges."
compsci,3deh8l,ex_ample,5,Wed Jul 15 23:34:14 2015 UTC,That's why CS at University of Waterloo falls under the Math faculty.
compsci,3deh8l,Vhyrrimyr,8,Wed Jul 15 19:40:41 2015 UTC,"I studied in Germany and I don't think you will ever see it assigned to Arts there. This seems very weird to me.  Computer Science is called Informatik (Informatics) so a mix of math and information and if you study it at a normal university is mainly theory with a few programming courses. In my opinion computer science belongs to the same place where you teach maths.   Applied Computer Science (what I studied) on the other hand is usually thought on Universities for Applied Sciences. This is the balance between science and engineering. So often connected to similar areas like Architecture and Technology fields. Still it is a lot of sciences as you are suppose to not just use the science but also extend it.  You also have even more practical ways to study it combined with a part time job in the field which then goes clearly into engineering in something I would call a technical school (still bachelor of science in the end) or professional training/apprenticeship (you won't get a degree there, sadly. Even though it is similar to what you learn in a bachelor at a technical school)."
compsci,3deh8l,ex_ample,2,Wed Jul 15 22:16:06 2015 UTC,"I agree, it seems crazy to have arts and science intertwined in any way."
compsci,3deh8l,rlamacraft,4,Wed Jul 15 23:33:54 2015 UTC,I'm curious as to how the college you are a part of affects who you network with.
compsci,3deh8l,biocomputer,7,Thu Jul 16 02:50:35 2015 UTC,"Just sharing an anecdote of my experience. I'm a dual Philosophy & CS major. I can tell you with absolute certainty that the same analytic skills applied to CS are essential to philosophy.  Arguments, at least good ones, made in Philosophy (or art criticism, literary theory, etc.) are structured in a less-formal yet rigorous way, similar to what you'd see in symbolic logic. In fact, Spinoza's The Ethics are written in a geometric proof.). You could, if you wanted, write out his arguments in formal symbolic logic to express his arguments about the fundamental nature of God.  Having education in the humanities made me realize how the skills I've picked up in CS applies to many different subjects; and even how something seemingly so far different, like art criticism, could have an impact on the way I conceptualize CS. It made me realize how Computer Science isn't just about programming; it's about taking a complex idea and breaking it down into smaller pieces. It requires creativity, expression, and abstract thinking.  So what I'm getting as it that computer science is not purely technical. It's about representation, abstraction, modeling, and a whole host of other analytical skills that are used in the humanities. It's pretty great to be in the Arts and Sciences department.  edit: also the parties are dope af"
compsci,3deh8l,amateurtoss,3,Wed Jul 15 19:33:39 2015 UTC,"It doesn't matter. The department that CS is in should have no bearing on what CS courses are offered or who CS students are encouraged to form ""peer groups"" with. The only difference is a cosmetic difference concerning what ""banner"" the major is labelled under, which has no significance beyond the surface.  At my university, the CS major is offered in both departments. Some courses seem more like math courses (algorithms) which is in the arts and sciences; other courses seem more like engineering (software development). Whether your degree focuses more on the math or engineering depends entirely on the courses you choose."
compsci,3deh8l,UpAndDownArrows,-2,Wed Jul 15 18:49:58 2015 UTC,"I'm not at liberty to say exactly how other universities function, but for my college, the significance is not purely cosmetic. Each department has it's own requirements (in addition to general requirements), and as a result, CS majors are forced to take more liberal arts courses than say, Engineering students who could instead utilize their time to study courses closer to their major."
compsci,3deh8l,mcorah,3,Wed Jul 15 20:29:18 2015 UTC,"It's debatable whether math is an Art and Science, since it's really, ultimately, a branch of philosophy, but computer science is math -- like, it's actually math -- and should presumably be organized wherever math is organized.  Which is probably not with engineering, if it's a separate thing.  But the question, I guess, is this: how separate are they, really?  At my undergrad, there was a whole division of engineering and applied sciences, and applied math was part of that while math wasn't.  (I didn't take CS in undergrad so I don't know where that was.)  But this ""division"" was really just administrative.  As an undergrad, it didn't impact my life in any way, and if my major had been something in that division (it wasn't; I majored in physics and math), it would have still not impacted my life in any way.  I networked and socialized with people from all departments.  I had math major friends; I had CS major friends; I had engineering major friends; I had Folk and Myth major friends.  Why does this odd classification actually matter at all to you?  I think that your problem is really about the way your school segregates people by major, and not about the classification itself.  Why does your school forbid you from socializing with engineers?"
compsci,3deh8l,ClubSoda,2,Wed Jul 15 21:49:30 2015 UTC,"But the question, I guess, is this: how separate are they, really? At my undergrad, there was a whole division of engineering and applied sciences, and applied math was part of that while math wasn't. (I didn't take CS in undergrad so I don't know where that was.) But this ""division"" was really just administrative.   Yeah that's the thing.  There's hardly any impact on day to day student activities between students in engineering and students in Liberal Arts and Sciences.  It's really just a question of where your paperwork gets filed."
compsci,3deh8l,kupfernikel,3,Sun Jul 19 10:34:11 2015 UTC,"It's common for most universities to assign Computer Science majors to their Arts and Sciences school under the pretense that CS is closely related to the liberal arts   That's because it is.  Philosophy is the quintessential Liberal Art and mathematics is a branch of philosophy. As such, the math department is almost always part of the School of Arts and Sciences with Philosophy.  Computer Science is a branch of Mathematics. In most older institutions, Computer Science started in the Math department before becoming it's own department. Because of that, most schools keep it in the School of Arts and Sciences with Mathematics.  Computer Science should not be part of the Engineering school; it's not an engineering discipline, it's a branch of Mathematics. It belongs wherever the Math department is. Anyone who considers CS ""engineering"" has a fundamental misunderstanding of what CS actually is.  Note: this is all assuming your school actually teaches Computer Science and doesn't just offer a glorified degree in Software Development.    Also, regardless of which school CS is in, that should have no impact on your ability to network/socialize with students in other fields (related or otherwise)"
compsci,3deh8l,mediocreHaskeller,1 point,Thu Jul 16 04:13:53 2015 UTC,"There's that, plus the fact that it's also grouped with all other sciences physics, chemistry, math, etc."
compsci,3deh8l,quezalcoatl,3,Sun Jul 19 09:56:40 2015 UTC,"I think my uni does it right, lumping us with Natural and Mathematical Sciences - so Maths, Physics and Chemistry. The degree takes a pretty theoretical look at the subject rather than an engineering one so it works well."
compsci,3deh8l,-_-_-_-__-_-_-_-,1 point,Thu Jul 16 05:36:59 2015 UTC,"That's the same as my university.  CS, math, and all the natural sciences are part of the faculty of science."
compsci,3deh8l,jacalata,6,Thu Jul 16 06:42:10 2015 UTC,"Computers were invented/discovered by mathematicians, physicists, and logicians. They tend to live in arts and sciences. Deal with it."
compsci,3deh8l,detailsguy,2,Wed Jul 15 19:26:12 2015 UTC,"My uni has it next:   study programme group: Informatics and Information Technology study domain: Science, Mathematics and Computing degrees conferred: Bachelor of Science in Engineering"
compsci,3deh8l,eric987235,2,Wed Jul 15 17:54:20 2015 UTC,"/u/Butterjoy this post is unfortunately very difficult to respond to without knowing the specifics of your school. Many schools are structured very differently. You make a lot of generalizations that do not exist. I personally believe that Computer Science is best with sciences. Are natural sciences also under the auspices of  Arts and Sciences at your school? I know at least some schools broadly combine sciences and humanities in a large school. As some have mentioned, some schools with larger programs have an independent school of computer science.  My school (RPI) has separate schools for science, humanities, and engineering. Computer Science along with Mathematics are under Science. Cognitive Science, Games, and Electronic Arts are under Humanities and Social Sciences. Computer Engineering is under Engineering. Information Technology has its own school (for bureaucratic reasons I believe). For the most part I believe this structure is quite rational.  Although some schools put Computer Science under a school that does not make sense given the greater structure, I believe that most schools have a much more rational structure than you presume. What you are experiencing is probably either an isolated problem or possibly a misunderstanding on your part."
compsci,3deh8l,mcorah,2,Wed Jul 15 21:46:19 2015 UTC,Don't confuse computer science (CS) with information technology (IT).    Computer scientists have different goals from information technologists.
compsci,3deh8l,ptmd,2,Thu Jul 16 03:44:22 2015 UTC,Thats weird. In Italy and Brazil they go with mathemathics.
compsci,3deh8l,ptmd,2,Thu Jul 16 07:52:56 2015 UTC,"...are you even in undergrad yet, or do you start in the fall?"
compsci,3deh8l,C0rinthian,3,Fri Jul 17 07:15:06 2015 UTC,"Computer science is a science, that's why it's in the Arts and Sciences school. This should be a non-issue, especially when you point out there's a distinct major (at your school) for computer engineering. I've never seen a math department part of the engineering school, most often it's grouped in with sciences when such a division exists. Furthermore, I doubt very much that CS students are hampered in their ability to socialize with students of closely related fields. Students in closely related fields tend to take similar classes, so unless your school has separate math/physics/chemistry classes tailored for and taught by specific departments I see no possible way that could be true. Your comment history makes me suspect that you're a CS-intended incoming freshman with an inflated sense of superiority to what you believe to be ""soft"" subjects and don't want yourself associated with them. Chillax dude, if you want to socialize with engineers there is literally nothing standing in your way, and no hiring manager or recruiter is going to look at a CS degree and say ""College of Arts and Sciences?! Not on my watch. Go write an essay you pleb."""
compsci,3deh8l,sillybear25,1 point,Thu Jul 16 00:59:40 2015 UTC,"Computer science is a science, that's why it's in the Arts and Sciences school.    Fuck, that just blew my mind."
compsci,3deh8l,wolfman1911,3,Thu Jul 16 02:51:17 2015 UTC,"Opinion: you are mad about something your school does and are attempting to generalise this into a systemic complaint. You don't appear to have made an effort to even bother checking how other schools do it, let alone why - a cursory Google would have brought up plenty of debates on ""CS: science or engineering???"" that you could have referred to. You should have just sent this to your student paper."
compsci,3deh8l,the_omega99,3,Thu Jul 16 01:26:27 2015 UTC,"Wait, what?  Where?  Granted, I've been out of college for 20 years, but computer science was always in the college of engineering when I was in school."
compsci,3deh8l,airercode404,2,Wed Jul 15 18:13:01 2015 UTC,"For me it was under science, which was distinct from engineering.  But arts was a completely different department."
compsci,3deh8l,VorpalAuroch,3,Wed Jul 15 20:14:21 2015 UTC,Same here. Computer Science makes a lot of sense under sciences especially if Math is also included under that same banner. The only real limitation is that CS can extend further toward liberal arts than other sciences.
compsci,3deh8l,Assumer,4,Wed Jul 15 21:26:04 2015 UTC,"Can you guarantee that the students who leave that School will deal exclusively with CS majors, or is it likely [or even inevitable] that there will be interaction with non-technicals at some point in their career?  If there is an issue with specific CS students interacting with non-technical peers in a classroom setting for a minority of their classes, is it prudent to confidently release them into a world where they'll likely take orders from non-technical superiors?"
compsci,3deh8l,VorpalAuroch,0,Wed Jul 15 18:27:21 2015 UTC,"By that logic, why not lump Engineers in with Liberal Arts students, so that they can better learn how to communicate Engineering concepts to English majors?  One of the advantage of categorizing fields of study into different schools, apart from making management easier for the college, is that students with similar interests will be under the same ""umbrella"". I think you have a misconception that this would cause complete isolation between students of different fields of study. That is not the case, because nearly every university has general ed requirements; not to mention that many students choose to participate in clubs and join organization inclusive to all majors."
compsci,3deh8l,Assumer,4,Wed Jul 15 20:19:52 2015 UTC,"They do, though not necessarily for that reason.  What do you care?  You wanted to network?  Network!"
compsci,3deh8l,VorpalAuroch,0,Wed Jul 15 21:00:58 2015 UTC,"By that logic, why not lump Engineers in with Liberal Arts students, so that they can better learn how to communicate Engineering concepts to English majors?   This is what general education requirements of undergrads are for."
compsci,3deh8l,5bits,1 point,Sun Jul 19 17:34:26 2015 UTC,"At the University of Illinois at Urbana-Champaign, things are a little weird; the CS department itself is in the College of Engineering, but CS majors are offered by both the College of Engineering (Engineering Computer Science) and the College of Liberal Arts and Sciences (Math and Computer Science or Statistics and Computer Science). The core curriculum heavily overlaps, but the LAS versions of the degree are more focused on math or statistics, while the engineering version is focused on software engineering or programming in an engineering context, depending on the track.  The physics department is similar, but the curriculum overlaps even more than CS. I think it's an odd compromise, but one that makes sense, since you could argue either way for both of them."
compsci,3deh8l,Airith,1 point,Wed Jul 15 19:35:25 2015 UTC,"That's really weird. My school has four computer science related degrees. Three of them (IT, Computer Science, which focuses on software development, and Computer Engineering, which focuses more on the low level aspects like interacting directly with the hardware) are part of the Engineering school. The last one is part of the Business school, and because of how that school is set up, it's basically a Business degree with a specialty in IBM mainframe stuff."
compsci,3deh8l,nickpeaches,1 point,Wed Jul 15 19:57:31 2015 UTC,"Your school must have some very different categorization from mine, since the college of arts and science at my university includes subjects like math, physics, biology, and statistics. For comparison, some other colleges include engineering, medicine, nursing, education, agriculture, and law. The full breakdown is here, if you want to see how they did it exactly.  So it seems to me that the college of arts and science is a very broad catch-all for most of the subjects that don't have a more specific college.  The only other college it could really make sense in would be engineering, but that would be a stretch since the college of engineering only includes the fields that can obtain a professional engineer title and software engineering is not recognized in my province (and SE is merely a specialization of CS at my university).  This is probably atypical, though, since their website says   Our college is unique in that it is one of only a few in Canada to combine arts and science course offerings within the same college. This integrated approach provides students with an invaluable, broad and in-depth perspective of the world that enhances one’s focus on individual disciplines.   Personally, I don't really see a big difference from how the colleges are divided. Plenty of engineering students take arts and science classes, for example. The division seems to be mostly administrational."
compsci,3deh8l,tomridesbikes,1 point,Wed Jul 15 20:54:59 2015 UTC,My university has it in the College of Engineering and Architecture. I really like it that way but I also can understand in having it in the arts/sciences if the school has a stronger emphasis in design and whatnot.
compsci,3deh8l,Jaesaces,1 point,Wed Jul 15 21:24:27 2015 UTC,"CS is an extremely robust subfield of Mathematics, with slightly more direct relevance to the applications than is common in pure math. As such, it belongs to Arts and Sciences, like Mathematics (and Arts more than Sciences). Computer Science is not about software.  There are related fields which are clearly engineering; more practical programming, system design, caring more about hardware, etc. These are called Computer/Software Engineering. There is a difference."
compsci,3deh8l,sketchfest,2,Wed Jul 15 21:32:17 2015 UTC,"There should be a difference, but often there is not. So long as CS programs put out mostly engineers and not mostly scientists it makes sense for them to be in engineering schools. The better solution is for more schools to offer Software Engineering degrees, since that is the type of professional they are putting out anyway."
compsci,3deh8l,kairoschris,1 point,Wed Jul 15 21:55:14 2015 UTC,"A lot of CS grads think they are engineers. In most places, they are wrong. Where they are right, the department is mislabeled."
compsci,3deh8l,mickey_kneecaps,1 point,Wed Jul 15 21:56:29 2015 UTC,I would argue that a CS department is an improperly labeled Software Engineering department (or a mashup of CS and Software Engineering that serves neither purpose properly) more often than not.
compsci,3deh8l,DongleParty,1 point,Wed Jul 15 21:58:46 2015 UTC,That is definitely possible!
compsci,3deh8l,MtSopris,1 point,Wed Jul 15 22:45:31 2015 UTC,"I disagree. My school offers both a Computer Science and a Software Engineering, and both are under the Engineering school. Both are highly applied-focused.  To me this makes no sense. We already have Software Engineering for the future software developers, CS should focus more on theory, for future researchers or scientific programmers."
compsci,3deh8l,paradinight,1 point,Wed Jul 15 22:14:00 2015 UTC,"At the University of Alberta we have a Science faculty, Engineering faculty, and an Arts Faculty. The Science faculty has a Math department and a Computing Science department. The Engineering faculty has a Computer Engineering department. This setup seems to work alright. I've had gripes with some course requirements but that's more with what one should learn while at university then specific to the CS department. CS is definitely a Science (not just because it's in the name)."
compsci,3deh8l,Rj_d,1 point,Wed Jul 15 22:59:06 2015 UTC,"Wait, what schools have math under the engineering college? I've always seen it in the liberal arts college."
compsci,3deh8l,Benno0,1 point,Wed Jul 15 23:49:05 2015 UTC,At my college (7000 student regional) the CS and IS department are part of the business school. It was pretty autonomous from what I could tell. We are ABEC accredited and only give out BS's. It was kinda cool since we had 2 floors of the business building to ourselves. Also since the only other BS in business is econ I got to walk right after my best friend who's econ.
compsci,3deh8l,ex_ample,1 point,Thu Jul 16 00:14:24 2015 UTC,"Interestingly enough, my university offers both an Engineering (CSE) and non-engineering (CIS) version of a computer science degree.  Both majors are basically handled with the same staff, and all the relevant courses are under CSE, not CIS."
compsci,3deh8l,minno,1 point,Thu Jul 16 00:57:15 2015 UTC,We have our own college of computing and informatics which is broken down into two departments by concentrations
compsci,3deh8l,reaganveg,1 point,Thu Jul 16 01:29:48 2015 UTC,"Not sure where you are but at my school both Math and Computer science are in the College of Arts and Sciences, along with many other scientific degrees."
compsci,3deh8l,minno,1 point,Thu Jul 16 01:32:52 2015 UTC,"Math majors are usually in the arts and sciences departments too, and they seem like fine peers for CS students. Not to mention that philosophers are decent company for CS types who like Logic."
compsci,3deh8l,reaganveg,1 point,Thu Jul 16 02:06:04 2015 UTC,"At my university CS is offered at both the A&S and Engineering school. The only difference between the curriculums are the graduation requirements. A&S students need to take a foreign language and liberal arts electives, whereas engineering students take physics, chemistry, or engineering-specific electives. The core CS classes are the same so both types of students will get the same CS education. Since the math majors study in the a&s school it makes sense that CS is also offered in that school. The CS curriculum is theory intensive and requires a specialization in a theoretical field so being in the arts and sciences school just makes sense to me. This does cause a lot of confusion for freshmen though."
compsci,3deh8l,ocamlmycaml,1 point,Thu Jul 16 03:03:47 2015 UTC,"Like others have pointed out, it depends on the history of the program at the university. It may also depend on the expertise and experience of the relevant CS faculty.  It may be the case that there are more engineering faculty than strictly science and maths.   Also, many schools actually offer computer science in both colleges.  There will be a CS program in the applied sciences and engineering school that focuses more on building systems, and design.  It will include more curricula from EE and CE. Then there will be a CS program in the arts and sciences school that will focus more on mathematics, logic, and theoretical computer science."
compsci,3deh8l,reaganveg,1 point,Thu Jul 16 04:00:06 2015 UTC,"Tbh to me it sounds like you are kind of judging non-technical majors. I think the art and creativity that should be required in CS is severely understated. The predominant notion right now appears to be that a good software engineer knows their stack like the back of their hand. I think that's really only part of it, and honestly think a more artistic/humanistic approach to programming can really improve many teams approach to product development.   Why else do you think software engineers are notorious for being bad at making customer-focused products?  Edit: For clarity I think colleges that take CS seriously should have one CS division in their colleges of arts and sciences and one division in engineering."
compsci,3deh8l,bastard_thought,1 point,Thu Jul 16 07:40:13 2015 UTC,"In Australia, at least at my university, it has its own sector: CSIT (computer science and information technology). It is a bachelor of science but we have our own building and are not associated with any of the arts students and don't take any arts course unless we choose to as a student elective in 3rd year. Software engineering is also in the CSIT school."
compsci,3deh8l,bastard_thought,1 point,Thu Jul 16 11:31:45 2015 UTC,"In my university CS belongs to the same faculty of science and engineering. There used to be a faculty of information sciences which housed CS, computer engineering and information systems and before that CS belonged to the science faculty.  We have a lot of courses together with computer engineering and elective math courses to together with math students. Then again I'm studying in a small university and it is possible to choose electives from pretty much any subject. Most students are naturally going to socialize with mainly computer engineering and mathematics students either way.   There's been some arguments on how technical CS should be at my university. The faculties were recently rearranged and there were proposals to further merge  CS and CE(and information systems to a certain extent). As far as I know those plans have been shot down mainly to keep CS and CE clearly separated as their own subjects. Students are of course able to pick their minors freely and can choose CE if they want to, though most tend to either pick humanist subjects, mathematics or biology/biochemistry."
compsci,3deh8l,Xanny,1 point,Thu Jul 16 15:38:03 2015 UTC,"There's a lot of overlap in computer science and computer engineering. But math and all pure science (biology, chemistry, etc) is in liberal arts and sciences, along with mathematics.   So this doesn't really make much sense.   You'll have plenty of ability to network with CompE people."
compsci,3deh8l,CommanderDerpington,1 point,Sun Jul 19 09:04:19 2015 UTC,"I think that CS is either mathematics or engineering depending on the specific subfield, so it's not totally clear which it should be with. Definitely not with liberal arts if math isn't."
compsci,3deh8l,ex_ample,4,Wed Jul 15 18:32:27 2015 UTC,Math is a liberal art though...
compsci,3deh8l,CommanderDerpington,0,Wed Jul 15 19:19:50 2015 UTC,I think that science and math belong together and separate from the humanities. They have different thought processes and methods.
compsci,3decad,Kiuhnm,1 point,Wed Jul 15 16:39:24 2015 UTC,"Projection is defined exactly how you wrote it!  The second rule is wrong because you're assuming the existence of something which might not actually exist. For example, a non-terminating program with output type A∧B might never actually construct a proof of A. Another example would be the ""abort"" term, which is associated with false-elimination and can have any type.  You only know that something of type A∧B is a pair if you constructed it yourself:  X : A       Y : B -----------------    <X,Y> : A∧B  ---------------   π_1 <X,Y> : A   However, notice that we already had the proof of X : A. This is where the PL interpretation of stepping a projection comes from, i.e. that π_1 <X,Y> steps to X."
compsci,3decad,shwestrick,1 point,Wed Jul 15 17:19:59 2015 UTC,"I don't understand this. The notation M:A∧B means ""M is a proof of A∧B"", so M must be a valid proof.  From TTFP on page 74:   Recall that we characterised proofs of the conjunction as pairs of proofs. We can read the introduction and elimination rules as expressing precisely this. The introduction rule states that all pairs of proofs are proofs of the conjunction, but leaves open the possibility of other kinds of proof. The elimination rule excludes any other sort of proof of the conjunction, since it states that we can extract two component proofs from any proof of the pair. In other words we can read the elimination rule as a ‘closure’ rule. This duality will be true for all introduction-elimination pairs."
compsci,3decad,shwestrick,1 point,Wed Jul 15 18:13:47 2015 UTC,"Here's another example of the problem. Suppose we didn't have the projection rule, but rather had the rule  <M,N> : A∧B ----------- (bad-first-projection)    M : A   Then consider this:  (λ(x : A).<x,x>) : A ⇒ A∧A       M : A --------------------------------------- (impl-elim)       (λ(x : A).<x,x>) M : A∧A       ------------------------ (bad-first-projection)              ???? : A   What term would we put here? The problem is that we have a term of type A∧A, but it is not a pair! The correct version reads like so:  (λ(x : A).<x,x>) : A ⇒ A∧A       M : A --------------------------------------- (impl-elim)       (λ(x : A).<x,x>) M : A∧A     ---------------------------- (first-projection)     π_1 ((λ(x : A).<x,x>) M) : A"
compsci,3decad,shwestrick,1 point,Wed Jul 15 18:26:34 2015 UTC,"I'd put the term M. Indeed, (λ(x : A).<x,x>) M is the pair (M,M). Why shouldn't I simplify terms when possible?  By your reasoning, 1+2 is not a number."
compsci,3dcain,xingnotzing,39,Wed Jul 15 03:46:37 2015 UTC,"A negative result (P != NP) probably wouldn't change much, though more research would be put into finding ""good enough"" approximations and super-polynomial algorithms.   A positive result could have fewer repercussions than you think. For example, if the proof is non-constructive, encryption can rest easy for a little while longer. Remember that polynomial-time does not imply ""reasonable time"". For example, say we can solve some NP-complete problem like vertex cover in O( n50 ) time.  In the event that we do find a fast algorithm for some problem, there will likely be a rush to reduce everything to this problem, and a bunch of other people finding systems that are hard to break with this algorithm (encryption will still be shaky)."
compsci,3dcain,TortugaSaurus,13,Wed Jul 15 04:28:46 2015 UTC,"A negative result (P != NP) probably wouldn't change much, though more research would be put into finding ""good enough"" approximations and super-polynomial algorithms.   I doubt a negative result would make a really significant difference there either. Those in the theory community who work on this would have to find something else to do, but pretty much everyone else in CS already behaves as though P!=NP is known. It's not of course, but we mostly work as though it is.  The people working on NP-hard optimization problems aren't (generally speaking) doing it by trying to find exact polynomial algorithms. You might use an exponential algorithm that often avoids the worst-case time (e.g., Simplex). You often use a polynomial algorithm that gives you an answer within some tolerable error margin (e.g., most interior point methods). You might work exclusively on metaheuristics, where you have very few guarantees, but the algorithms often work and you just want to make them work better or more reliably.   If it were known tomorrow that P!=NP conclusively, I think most people in those fields would celebrate the discovery just like any other computer scientist would, and then shrug and go back to doing what they've been doing all along."
compsci,3dcain,deong,8,Wed Jul 15 12:35:51 2015 UTC,"Note, too, that a non-constructive proof could show (say) that we can solve vertex cover in O( nk ) time where the value of k is unknown, but provably constant for all inputs. There would be interest in establishing bounds on k, but until we could prove that k is small, there would be no practical impact - after all, if k turns out to be not less than 10100100, then n has to be very large for the P solution to vertex cover to be cheaper than an EXPTIME solution to vertex cover."
compsci,3dcain,farnz,5,Wed Jul 15 13:19:11 2015 UTC,"Man, I never imagined proving P==NP could lead to such a depressing outcome.  for a simple way to compare the 2 you can imagine, say, nk == kn as being the point where the p-time algorithm overtakes the np one, so you basically have that k value as the minimum n before it starts being useful. n = k = 10100100 .... do we do any computations even close to that scale? even for problems with linear-time solutions?  edit: thinking on it more, that's like, all the memory/""hard drive"" space in the universe or something isn't it? Jesus.. I know it just random number you picked but something of that order would be so frustrating. I always assumed the heavens would part the moment someone proved P==NP."
compsci,3dcain,flukshun,5,Wed Jul 15 15:31:51 2015 UTC,"There are around 1080 atoms in the observable universe, so that gives a hard bound on the number of bits that could be stored by any system."
compsci,3dcain,minno,5,Wed Jul 15 18:39:26 2015 UTC,. NP=P implies proving mathematical problems is reasonably simple. That would be a major shift in Mathematics.
compsci,3dcain,nuncanada,1 point,Wed Jul 15 13:46:13 2015 UTC,"True, as finding proofs is an NP problem!"
compsci,3dcain,TortugaSaurus,1 point,Wed Jul 15 14:49:17 2015 UTC,"Well, such a 'reasonably simple' solution, might actually still be much much less viable than all known 'hard' solutions.  It might not have much impact at all.  For example, suppose that, for factoring any integer n, there was some solution which you could come to by generating digits of pi from 10100 * n to 10100 * (n +1).  This would mean that P = NP, because digits of pi can be generated in polynomial time, while integer factorization is a problem in NP...  But it would not mean anything for practical problem solving, because nobody has ever actually generated a googol digits of pi.  You would then just have this really really weird property of pi, and a really really weird method of solving NP problems that would never actually be useful to anyone...  People would spend time trying to figure out why it was the case, but it wouldn't be much of a revolution on the whole."
compsci,3dcain,Tiak,1 point,Wed Jul 15 22:35:10 2015 UTC,"A proof of P = NP would almost certainly have the immediate result of a lot of investment into finding optimizations and alternate solutions which might  be more efficient.  It probably isn't going to overturn cryptography, but it very well could overturn fields of research by the huge shift in investment."
compsci,3dcain,Tiak,10,Wed Jul 15 21:46:09 2015 UTC,"Just showing P=NP would not provide all answers, unless the proof is constructive. However, just a single algorithm that solves any of the NP complete problems would essentially solve all other problems within NP.  There are quite a few researchers working on P<?>NP question, and to give a perspective on the opposition, Don Knuth believes that P=NP though with large enough constants which may even be unknowable.  Finally, P=NP would also mean that the entire polynomial hierarchy would collapse."
compsci,3dcain,blufox,2,Wed Jul 15 04:57:54 2015 UTC,"Finally, P=NP would also mean that the entire polynomial hierarchy would collapse.   You've just pointed out the most important implication which will happen, no matter how high the constants are.  Pearson will make hundreds of millions of dollars on new textbooks."
compsci,3dcain,Tiak,1 point,Wed Jul 15 22:41:58 2015 UTC,Pearson will make hundreds of millions of dollars on new textbooks.   Don't they pretty much cycle through new textbooks every couple years anyway?
compsci,3dcain,ex_ample,1 point,Sun Jul 19 08:57:36 2015 UTC,"That's why it's so inevitable.  But, also, you stop being able to teach out of old textbooks when they contain information which is outdated...  There isn't a whole lot of information which actually becomes outdated in mathematics or CS, so it'd make a lot of hold-outs upgrade their required textbooks to the most recent edition all at once."
compsci,3dcain,Tiak,17,Sun Jul 19 09:09:29 2015 UTC,"I don't know all of the repercussions, but I do know that all encryption would be vulnerable."
compsci,3dcain,Tirelessly,25,Wed Jul 15 03:48:13 2015 UTC,Assuming it's a constructive proof. It's possible that the problem will be proved without providing the actual algorithm.
compsci,3dcain,sccrstud92,8,Wed Jul 15 04:52:38 2015 UTC,and assuming that the polynomial-time algorithms discovered aren't still impractically slow due to high constant factors in their run time or high exponents like x1000. Polynomial =/= practical.
compsci,3dcain,628318,8,Wed Jul 15 12:14:59 2015 UTC,Most of the algorithms used in encryption are not NP hard though.
compsci,3dcain,TheBlackElf,9,Wed Jul 15 08:33:15 2015 UTC,"This is not known.  They do however tend to lie in NP, so NP=P would imply they lie in P."
compsci,3dcain,_--__,6,Wed Jul 15 10:45:41 2015 UTC,"If we're pedantic about it, things like factoring aren't in NP because they're not decision problems, but it's easy enough to convert between the two that it's not super-important to draw the distinction."
compsci,3dcain,deong,4,Wed Jul 15 12:22:14 2015 UTC,"They do however tend to lie in NP   Factoring is not known to be NP-Hard. Frankly I'm not convinced it is, it doesn't look anything like the other NP-Hard problems and you can't reduce to it (it's not NP-complete). We thought PRIMES (prime recognition) was outside P until suddenly in 2002 it was shown to be in P."
compsci,3dcain,BrainInAJar,2,Wed Jul 15 13:55:27 2015 UTC,"If P=NP then all (non-trivial) problems in P (and NP) are NP-hard.  Showing a problem is not NP-hard is (in many cases) as difficult as the P vs NP problem.  Factoring is known to actually be in the intersection of NP and co-NP, and is therefore ""unlikely"" to be NP-hard (unless co-NP=NP and possibly a few other things)."
compsci,3dcain,_--__,1 point,Wed Jul 15 14:17:12 2015 UTC,"Factoring is known to actually be in the intersection of NP and co-NP   What? No it isn't, it's conjectured to be NP-intermediate. You're gonna need to link to a paper for that claim."
compsci,3dcain,BrainInAJar,2,Wed Jul 15 14:23:26 2015 UTC,"Read the wikipedia page.  Also, NP-intermediate includes problems that are in both NP and co-NP."
compsci,3dcain,_--__,1 point,Wed Jul 15 14:28:13 2015 UTC,"Also, NP-intermediate includes problems that are in both NP and co-NP.   So does P."
compsci,3dcain,BrainInAJar,2,Wed Jul 15 14:30:48 2015 UTC,Huh?  A problem being in the intersection of NP and co-NP does not preclude it from being NP-intermediate.
compsci,3dcain,_--__,1 point,Wed Jul 15 14:33:09 2015 UTC,"The Complexity Zoo claims NP ∩ coNP contains factoring. They cite ""V. R. Pratt. Every prime has a succinct certificate, SIAM Journal on Computing, 4:214-220, 1975.""."
compsci,3dcain,sehansen,1 point,Wed Jul 15 16:52:19 2015 UTC,"Yup, I'm wrong in as much as NP+coNP contains P."
compsci,3dcain,BrainInAJar,1 point,Wed Jul 15 17:03:30 2015 UTC,This is probably the biggest effect. Any encryption algorithms could basically be reverse engineered and another algorithm could decrypt it really fast
compsci,3dcain,joshgrib,41,Wed Jul 15 04:21:18 2015 UTC,"Not necessarily.  Just because something is polynomial doesn't mean it's practical.  A SAT solver that ran in O(n2100) (a so-called galactic algorithm) would be a wonderful breakthrough in terms of theory, but would be totally useless in practice and would in all likelihood still require until the heat death of the universe to crack any encryption."
compsci,3dcain,Rhomboid,21,Wed Jul 15 05:05:06 2015 UTC,"Well, certainly with that attitude, it would."
compsci,3dcain,neurone214,1 point,Wed Jul 15 05:44:42 2015 UTC,"This is not necessarily the case. It's possible that the algorithm could be too inefficient all the same. Eg, consider the case of a polynomial time algorithm that is in O(n1000) or has a timing function that might look like T(n) = 100000n2 + ..."
compsci,3dcain,the_omega99,3,Wed Jul 15 14:37:10 2015 UTC,"Even if the problems in NP can somehow be solved in polynomial time it seems likely that it will be a very large order polynomial compared to the other problems in P, meaning the formerly-NP problems would still take significantly longer to solve. The implications of this would be more academic than practical (at least for a while)."
compsci,3dcain,Skieth99999,3,Wed Jul 15 05:35:34 2015 UTC,"A critical point to note is that complexity classes indicate how a problem scales - they do not necessarily indicate how feasible it is to actually compute a solution.  As /u/Rhomboid mentions - there are (known) polynomial time algorithms that could never complete in any reasonable time even on small inputs, and, on the flip-side there are many exponential algorithms that are fast enough to be used in any conceivably practical situation.  Comments like ""encryption will be broken"" is technically true - because ""broken"" encryption is deemed to be PTIME solvable encryption, but comments like ""we can decode every encrypted message"" are not.  The take-home message is that P is only an approximation of ""feasibly solvable problems"" and a result like P=NP would probably not have any significant impact on most fields."
compsci,3dcain,_--__,8,Wed Jul 15 11:00:18 2015 UTC,"ITT: People mentioning that even if P=NP, we don't necessarily have an polynomial algorithm, if the proof of P=NP is not constructive.  This is not true. We already have algorithms for all problems in NP, that will turn out to run in polynomial time if P=NP is proved. (See e.g. Wikipedia https://en.m.wikipedia.org/wiki/P_versus_NP_problem).   The size of the polynomial degree is not going to be the problem in practice (as mentioned by others). The constant factor is huge in these algorithms, and they are thus completely impractical. But the algorithms already exist!"
compsci,3dcain,concatintersperse,2,Wed Jul 15 11:07:22 2015 UTC,"I assume you are referring to Levin's algorithm on the wikipedia page.  Does that count, though?  It only recognizes all NP languages (with poly reduction to subset-sum) in polynomial time, but it doesn't decide them.  I think the common understanding of an ""algorithm that runs in polynomial time for all NP problems"" can mean only an algorithm that decides all NP problems."
compsci,3dcain,Mr_Smartypants,6,Wed Jul 15 15:08:12 2015 UTC,"Sadly thats not true. Today we have (deterministic) algorithms for most NP problems, yes. But those run in non-polynomial time. We can analyze the runtime of those algorithms and they all are non-polynomial.  Proving that NP=P would not magically make them faster. The known algorithms would still be non-polynomial, we would just know that there are other (deterministic) algorithms that run in polynomial time."
compsci,3dcain,DebuggingPanda,4,Wed Jul 15 11:39:57 2015 UTC,"I am not talking about the existing algorithms we actually use today. They are exponential and will be exponential whatever someone proves about P and NP.   I am talking about the specific algorithm mentioned on the Wikipedia page, that is guaranteed to be polynomial once someone proves P=NP."
compsci,3dcain,concatintersperse,3,Wed Jul 15 11:42:42 2015 UTC,Or rather it is polynomial already if P=NP
compsci,3dcain,frenris,2,Wed Jul 15 11:49:03 2015 UTC,"Ok sorry, my bad. Though, I think your first comment is pretty confusing and misleading. Also: I think you're talking about this subset-sum algorithm. Better link it with anchor -- the wikipedia article is long ;) https://en.wikipedia.org/wiki/P_versus_NP_problem#Polynomial-time_algorithms"
compsci,3dcain,DebuggingPanda,2,Wed Jul 15 12:04:19 2015 UTC,"No problem. Obviously it was confusing because you misunderstood!  Yes, that algorithm. (That trick of course works for all problems in NP.)"
compsci,3dcain,concatintersperse,1 point,Wed Jul 15 12:11:11 2015 UTC,Levin search / Universal search.
compsci,3dcain,LimivorousArbour,1 point,Wed Jul 15 15:02:55 2015 UTC,"This is not true. We already have algorithms for all problems in NP, that will turn out to run in polynomial time if P=NP is proved. (See e.g. Wikipedia https://en.m.wikipedia.org/wiki/P_versus_NP_problem).    That's not true at all.  You could theoretically prove the existence of a solution without figuring out what the solution actually is.  So for example, take the number 17185259.  Now, it's pretty easy to prove that it has some number of prime factors.  Maybe it has 3, maybe 7.  We know there is some finite n that is the number of prime factors of 17185259.   But, other then factoring it there's no way to know what n is. If the number were huge you have a situation where figuring out what n actually is becomes practically impossible.   There are more complicated examples then that in mathematics.  You could have a similar situation where you can prove that the algorithm must exist, but not what it is - any more then you can prove that some large number has some number of prime factors, without knowing what they are."
compsci,3dcain,ex_ample,1 point,Sun Jul 19 08:48:18 2015 UTC,Non-Mobile link: https://en.wikipedia.org/wiki/P_versus_NP_problem.    HelperBot_® v1.0 I am a bot. Please message /u/swim1929 with any feedback and/or hate. Counter: 9
compsci,3dcain,HelperBot_,1 point,Sun Jul 19 08:48:24 2015 UTC,"In general, yes.   In the case of problems in NP, there are algorithms already (see that Wikipedia page) that run in polynomial time if P=NP."
compsci,3dcain,concatintersperse,1 point,Sun Jul 19 09:02:39 2015 UTC,"In the case of problems in NP, there are algorithms already (see that Wikipedia page) that run in polynomial time if P=NP.    If that's true why don't you just run them on various inputs and see if they run in polynomial time or not.  Then you would have experimental data that would tell you if P =/!= NP.   The way your writing it makes it sound as though a programs behavior would suddenly change once something is proven, which makes no sense at all.  The point I'm making is that it may be possible to prove that P = NP only in a hypothetical sense without actually figuring out how the algorithm would actually work.  In that situation, no computer programs would suddenly ""change"" how long it takes for them to run. Obviously, you would need to modify the programs for them to change, and if you don't know what the algorithm is to solve NP-complete problems in P time then you have nothing to modify them with."
compsci,3dcain,ex_ample,1 point,Sun Jul 19 10:40:45 2015 UTC,Please read that Wikipedia page and answer again once you have read it?
compsci,3dcain,concatintersperse,2,Sun Jul 19 11:07:17 2015 UTC,To answer your last question (whether there are people out there trying to solve it): Consider this list.
compsci,3dcain,Afritus,2,Wed Jul 15 08:49:44 2015 UTC,"Someone would get a million dollars, as others have said not much else"
compsci,3dcain,aurora-phi,2,Wed Jul 15 11:04:12 2015 UTC,"Like many already said: Encryption (note: There exist encryption techniques that would be safe to use even if P=NP). But besides encryption there are many theoretical interesting implications.   Wouldn't we still have to find better algorithms to solve those NP problems like the Travelling salesman?   First of all, to answer your question: Depends. Like some already said: If the proof P=NP includes a polytime algorithm for any NP-complete problem, then we would not have to. This is the nice thing about NP-complete: Solving one of those problems is equivalent to solving any other NP problem.   You can transform a problem-instance of one NP-complete probem into a problem-instance of any other NP-complete problem in polytime. Most NP-problems we know are in fact NP-complete. There are just a few known ones that are NP-intermediate.  One implication would be that every P problem would be also NP-complete, because one could just solve it in polytime instead of making a real transformation."
compsci,3dcain,DebuggingPanda,1 point,Wed Jul 15 11:56:48 2015 UTC,"Another possibility that hasn't been ruled out is that of a very large polytime. N11 would, for instance, give us a lot of time to think up replacement algorithms."
compsci,3dcain,cparen,1 point,Wed Jul 15 20:55:09 2015 UTC,"note: There exist encryption techniques that would be safe to use even if P=NP   No, this is wrong. One way functions can only exist if P != NP."
compsci,3dcain,BrainInAJar,2,Wed Jul 15 13:34:12 2015 UTC,"note: There exist encryption techniques that would be safe to use even if P=NP   No, this is wrong. One way functions can only exist if P != NP.   This is wrong. There are encryption techniques that don't rely on one way functions."
compsci,3dcain,cparen,1 point,Wed Jul 15 16:35:40 2015 UTC,Pedantically yes. One-time pads. But you can't generate them computationally because pseudorandom generators are also one way functions.
compsci,3dcain,BrainInAJar,1 point,Wed Jul 15 17:47:35 2015 UTC,"Perhaps I'm recalling incorrectly, but I have a vague recollection of some symmetric algorithms that didn't rely on one-way functions for security. An internet based on Kerberos rather than certificate authorities is not entirely unthinkable."
compsci,3dcain,cparen,2,Wed Jul 15 21:41:39 2015 UTC,Wouldn't N have to equal 1? Or is this not multiplication?
compsci,3dcain,GrizzlyJones,3,Wed Jul 15 21:24:36 2015 UTC,"Well, P could equal 0."
compsci,3dcain,_--__,1 point,Thu Jul 16 21:48:07 2015 UTC,"Congratulations, you just proved that P!=NP for all N>1, where shall we put your million dollars?  JK, couldn't resist, hope you don't mind :p"
compsci,3dcain,sakkara,1 point,Thu Jul 16 16:10:31 2015 UTC,Since starting noFap i'd like it directly on my unbeaten penis.
compsci,3dcain,GrizzlyJones,0,Thu Jul 16 18:19:57 2015 UTC,It is not multiplication.  It's short for POLYNOMIAL_TIME_PROBLEM == NONDETERMINISTIC_POLYNOMIAL_TIME_PROBLEM.  It basically means that you can reduce problems which scale exponentially to problems which scale according to some fixed exponent.
compsci,3dcain,Tiak,1 point,Wed Jul 15 22:55:56 2015 UTC,I think he was joking and I found it funny
compsci,3dcain,GT95,1 point,Sat Jul 18 21:42:49 2015 UTC,"One interesting thing is that if P ≠ NP, we should intuitively expect a proof of that to be hard to find, even though the proof will be easy to verify. :)  So if we are suspecting that P ≠ NP, trying to prove that is unlikely to be productive research. (And, conversely, if we have lots of trouble proving it either way, we have reason to suspect P ≠ NP.)"
compsci,3dcain,ldpreload,1 point,Wed Jul 15 15:40:35 2015 UTC,"To my understanding, solving P = NP just tells us that, NP problems can be solved in polynomial time?   Nope P=NP tells us that for every non deterministic touring machine that solves a problem in polynomial time there exists some deterministic touring machine that solves the same problem in polynomial time.  All NP problems already can be solved in polynomial time (in theory) by non deterministic touring machines.  Many NP problem instances can already be solved in polynomial time by modern computer systems with the help of heuristics. (For example Dijxtra's algorithm solves instances of the NP-hard problem ""Shortest Path"" in polynomial time).  If someone proves that P=NP than he'll probably provide an algorithm how to convert any NP-hard problem into a P problem. Chances are that this P problem is still pretty hard to solve (very very high exponent >256 ) and nothing happens at all. But imo it is much more likely that P!=NP."
compsci,3dcain,sakkara,3,Thu Jul 16 16:04:32 2015 UTC,Shortest path is not NP-hard (unless P=NP).  Dijkstra's algorithm (and many others) compute it in polynomial time for all instances (even without heuristics).
compsci,3dcain,_--__,1 point,Thu Jul 16 21:47:15 2015 UTC,Nope you can reduce the Hamiltonian path problem (which is NP-complete) to a shortest path problem by setting all weights to -1 and including negative cycles.  I agree that this was a bad example.
compsci,3dcain,sakkara,3,Thu Jul 16 21:54:00 2015 UTC,"Huh?  If you include negative cycles then there is no shortest path (I can always make a path shorter by going around the negative cycle again).  If you don't allow negative cycles, then you aren't permitting cycles, so you are looking at HP on a DAG which is not NP-hard.  I think you are confusing it with longest path - which is NP-hard with a reduction from HP."
compsci,3dcain,_--__,0,Thu Jul 16 22:10:40 2015 UTC,"In networks with edge weights that could be negative, shortest-paths problems are NP-hard.  Proof: Our proof consists of reducing the Hamilton-path problem to the shortest-paths problem. That is, we show that we could use any algorithm that can find shortest paths in networks with negative edge weights to solve the Hamilton-path problem. Given an undirected graph, we build a network with edges in both directions corresponding to each edge in the graph and with all edges having weight –1. The shortest (simple) path starting at any vertex in this network is of length 1 – V if and only if the graph has a Hamilton path. Note that this network is replete with negative cycles. Not only does every cycle in the graph correspond to a negative cycle in the network, but also every edge in the graph corresponds to a cycle of weight –2 in the network.  The implication of this construction is that the shortest-paths problem is NP-hard, because if we could develop an efficient algorithm for the shortest-paths problem in networks, then we would have an efficient algorithm for the Hamilton-path problem in graphs. ▪  Source   If you include negative cycles then there is no shortest path (I can always make a path shorter by going around the negative cycle again).   Wrong there still could be a shortest (simple) path but you can't use Dijkstra anymore."
compsci,3dcain,sakkara,2,Thu Jul 16 22:24:55 2015 UTC,"Oh I see, you're talking about the shortest simple path - in my experience the distinction is not often made (probably because it is often assumed that there are no negative cycles, so the shortest path will necessarily be simple).  Come to think of it, I guess the distinction must usually be made for the longest path problem - I should review my definitions."
compsci,3dcain,_--__,1 point,Thu Jul 16 23:21:04 2015 UTC,"To my understanding, solving P = NP just tells us that, NP problems can be solved in polynomial time?   Nope P=NP tells us that for every non deterministic touring machine that solves a problem in polynomial time there exists some deterministic touring machine that solves the same problem in polynomial time.   Huh? That's the same as saying NP problems can be solved in polynomial time, on a deterministic Turing machine.  The only thing missing from the OP's phrasing is the word ""deterministic"" but that's obviously implied.   Also Turing, not Touring.   Many NP problem instances can already be solved in polynomial time by modern computer systems with the help of heuristics. (For example Dijxtra's algorithm solves instances of the NP-hard problem ""Shortest Path"" in polynomial time).   Every problem in P is also in NP, because if you can solve it on a deterministic Turing machine, then obviously you can solve it with a non deterministic Turing machine as well in polynomial time as well.   The question is whether or not the reverse is true - is it the case that deterministic Turing machines can solve every problem that non-deterministic Turing machines can in polynomial time in polynomial time itself? Maybe they can, maybe they can't.    If someone proves that P=NP than he'll probably provide an algorithm how to convert any NP-hard problem into a P problem.   Maybe, maybe not. There may  be some way to prove that a program hypothetically must exist, but not what it is.   Also, the key isn't NP-hard, but rather NP-Complete.  If you can solve any NP-Complete problem in P time then you can solve all NP problems in P time."
compsci,3dcain,ex_ample,0,Sun Jul 19 08:45:22 2015 UTC,"Huh? That's the same as saying NP problems can be solved in polynomial time, on a deterministic Turing machine. The only thing missing from the OP's phrasing is the word ""deterministic"" but that's obviously implied.   It's the wrong definition that often leads to confusion. I wanted to provide a more accurate definition of the problem.   Every problem in P is also in NP, because if you can solve it on a deterministic Turing machine, then obviously you can solve it with a non deterministic Turing machine as well in polynomial time as well.   I think you have misinterpreted my statement. Read again and ask for clarification.   Also, the key isn't NP-hard, but rather NP-Complete. If you can solve any NP-Complete problem in P time then you can solve all NP problems in P time.   Every NP-complete problem is NP hard by definition (NP hard is as hard as or harder than NP complete). It is sufficient to show that an NP hard problem H is in P to prove P=NP because you can reduce every NP problem to H in polynomial time."
compsci,3dcain,sakkara,1 point,Sun Jul 19 09:01:03 2015 UTC,"It is sufficient to show that an NP hard problem H is in P to prove P=NP   If you can show that an NP-hard problem can be solved in P time then that specific problem would have to be NP-complete.   And therefore, what you wrote doesn't contradict what I said at all. Solve any NP-Complete problem in P and you're done. If you solve a problem that's known to be NP-Hard but not known to be NP-Complete in P time you will also prove it's NP-Completeness at the same time.   On the other hand, you could theoretically prove P = NP without being able to solve certain instances of various NP-Hard problems in P time, because not everything in NP-Hard is in NP.   There's a diagram on the wikipedia article you linked too. Might want to look at it for reference."
compsci,3dcain,ex_ample,0,Sun Jul 19 10:54:19 2015 UTC,"On the other hand, you could theoretically prove P = NP without being able to solve certain instances of various NP-Hard problems in P time, because not everything in NP-Hard is in NP. There's a diagram on the wikipedia article you linked too. Might want to look at it for reference.   Why are you telling me this? Its good to see that you understand my point. I didn't try to contradict you, i just provided prove for my statement that you tried to falsify.   If you can show that an NP-hard problem can be solved in P time then that specific problem would have to be NP-complete.   That is wrong. If i show that an NP-hard problem that is not NP complete (because its more complex) can be solved in p-time with a deterministic turing machine then i proved that a harder problem class than NP is also in P ergo P=(NP UNION something else). If that NP-hard problem happens to be NP-complete then I showed P=NP.  I get the feeling that you are trying to one up me for no apparent reason?"
compsci,3dcain,sakkara,1 point,Sun Jul 19 10:59:49 2015 UTC,we could cure cancer(protein folding).
compsci,3dcain,jithinr77,-4,Wed Jul 15 10:10:46 2015 UTC,http://i.imgur.com/6hIvsfX.gif
compsci,3dbks5,iXesh,22,Wed Jul 15 00:20:39 2015 UTC,"Structure and Interpretation of Computer Programs by Harold Abelson and Gerald Jay Sussman.  When it comes to programming, this is the book to read. The knowledge contained herein will be relevant to you no matter what programming language or concept you will use. Every chapter is full of information, well-written, with exercises that will ingrain to you the skill taught in that given chapter.  This is not a book about programming tips and tricks nor is it a cookbook.  This book is about fundamental programming principles that you will use whether you will use object oriented or functional programming and will teach you how to build the rich framework that will make your code as elegant as possible. This book teaches software engineering as an art.  It is considered to be quite advanced even if it is a freshman's book, so I suggest you just skim it at first and study the knowledge you are lacking in to understand this book.  You can read the book for free over here. You can even easily find a .pdf copy of the book online as the book is under a Creative Commons License.  You can also buy the book over here. I suggest reading the reviews in this link as they have a better write-up on why this book must be read by every computer science student."
compsci,3dbks5,atubofpudding,2,Wed Jul 15 01:05:35 2015 UTC,I remember coming across this before I started studying and never got around to reading it. Thanks for reminding me
compsci,3dbks5,leaves_of_three,5,Wed Jul 15 05:41:23 2015 UTC,And video lectures here: http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-001-structure-and-interpretation-of-computer-programs-spring-2005/video-lectures/
compsci,3dbks5,Xiphorian,1 point,Wed Jul 15 09:15:37 2015 UTC,Seconded. Definitely one of the best books you could read first.
compsci,3dbks5,PriceZombie,1 point,Tue Jul 21 07:12:46 2015 UTC,Structure and Interpretation of Computer Programs - 2nd Edition (MIT E...           Current $45.85 Amazon (New)   High $47.04 Amazon (New)   Low $41.75 Amazon (New)    $46.43 (30 Day Average)    Price History Chart and Sales Rank | FAQ
compsci,3dbks5,Probono_Bonobo,13,Wed Jul 15 01:05:44 2015 UTC,"Gödel, Escher, Bach by Douglas Hofstadter"
compsci,3dbks5,FrozenHawk42,7,Wed Jul 15 03:00:01 2015 UTC,"Just started this book a few weeks ago, it's really good, but I think it's going to take me forever to actually finish it."
compsci,3dbks5,cuntinuum,8,Wed Jul 15 06:00:43 2015 UTC,Are you mathematically inclined? You might enjoy learning some graph theory and other discrete math and proof basics. Practice in that now will serve you later in algorithms class(and any other theoretical cs class) as well as in interviews. It can be really fun too! I'd recommend Rosen's Discrete math or other similar survey texts.
compsci,3dbks5,cuntinuum,1 point,Wed Jul 15 04:09:25 2015 UTC,"Not the best mathematically, but it can't help to give it a read and see how I find it right?"
compsci,3dbks5,MtSopris,3,Wed Jul 15 05:39:54 2015 UTC,Absolutely. I think you'll find discrete math has a very different flavor from calculus. It requires a very distinct form of intuition that you might have even if you don't excel in calculus.
compsci,3dbks5,flebron,1 point,Wed Jul 15 05:43:03 2015 UTC,Is it more logical thinking as opposed to mathematically thinking?   Or am I completely off with that overlook of it?
compsci,3dbks5,MtSopris,7,Wed Jul 15 05:44:12 2015 UTC,"In short, yes it is more logical. But you must remember, mathematical thinking IS logical thinking.   At higher levels of mathematics (not the mundane formulaic stuff they give you throughout elementary and high school), or as some would call it ""actual/genuine"" maths, one must reason their way through abstract landscapes using both logic and intuition as a guide.  This is what it means to DO maths. It's not always as straightforward and mechanical as elementary calculus and algebra are. In fact, it's most often the opposite.  That is why many mathematicians don't hesitate to profess the artistic quality of mathematics. As it takes more than just following a recipe to discover/invent new concepts."
compsci,3dbks5,grandzooby,3,Wed Jul 15 06:58:35 2015 UTC,"You can start reading a bit about algorithms and data structures, with the classic Introduction to Algorithms, MIT Press. No need to do the exercises right now if you're just starting, but you can progressively do them as you go on studying. I bought my copy just before starting university, and I have it to this day, several years after finishing."
compsci,3dbks5,pickledRedOnions,1 point,Wed Jul 15 04:28:39 2015 UTC,"Will do man, I've seen a couple things by MIT press and they're written phenomenally from memory. Will be sure to give this a read"
compsci,3dbks5,firecopy,3,Wed Jul 15 05:43:10 2015 UTC,"I'd recommend either Gensler's Introduction to Logic, and/or Hammock's Book of Proof. The latter is available for free online.  Really focus on logic. Symbolic in particular.    I'd also encourage you to get ahold of Schaums 2000 Problems Solved in Discrete Mathematics. Work through the book alongside a textbook on discrete maths (Epps or Rosen for example).  Don't be surprised if you have to skip around to match the organization of your textbook."
compsci,3dbks5,firecopy,3,Wed Jul 15 07:06:07 2015 UTC,"I really enjoyed Gary Flake's, ""The Computational Beauty of Nature"": http://www.amazon.com/The-Computational-Beauty-Nature-Explorations/dp/0262561271  And Melanie Mitchell's, ""Complexity, A Guided Tour"": http://www.amazon.com/Complexity-Guided-Tour-Melanie-Mitchell/dp/0199798109"
compsci,3dbks5,lukekarasa,2,Wed Jul 15 07:22:09 2015 UTC,"Design patterns, Elements of reusable object oriented software: GoF"
compsci,3dbks5,PlainclothesmanBaley,2,Wed Jul 15 18:05:54 2015 UTC,"Code: The Hidden Language of Computer Hardware and Software  This book is a fun read, and made me appreciate computers and computer science."
compsci,3dbks5,Flangecakes,1 point,Thu Jul 16 02:11:10 2015 UTC,"Been skeptical about the quality of this book for a while, will be sure to give it a buy"
compsci,3d9mz4,greenprius,1 point,Tue Jul 14 16:08:19 2015 UTC,What level of training would I need to work on supercomputers in this capacity?
compsci,3d9422,thezbk,3,Tue Jul 14 13:43:38 2015 UTC,"Linear algebra, discrete math, probability and statistics are common to all three, but usually at or near the grad level. Those are all prerequisites for machine learning so it makes sense.  Data science is like a fusion of DB administration, data analysis, ML and back-end software engineering. What would distinguish it is the fact it's more interdisciplinary and also shallower than the other two fields. For example Data Scientists might use NLP at their job but they aren't learning the cutting edge necessarily. It's more of an applied science field like engineering except they concern themselves with engineering ways to use data. Unfortunately there isn't really a set curriculum for that field, they take anyone from Math/Stats majors, to CS majors, to Economists if they know how to do the work.  AI is an umbrella term--it covers so many subfields. I'd say Data Science borrows from it simply because they tend to use ML. However, NLP is a proper subset of AI I'd say. AI pretty much uses all the applied math fields that exist in one of it's subfields or another. You'd need to clarify what you're interested in within AI to really get a good answer from me or others I'd wager.  NLP takes all the core computer science and machine learning stuff, but slaps some computational linguistics in to the mix. A course on compilers and programming language design would probably help, but there are courses on computational linguistics. My experience in grad school was they just called the courses what you'd expect. E.g., ""Natural Language Processing I"" or ""Computational Linguistics"", etc.  Of course all fields can gain some insight from looking at others. In computer vision for example they look at the how the human brain recognizes objects to get inspiration for new methods. Likewise in NLP you might want to learn more about traditional linguistics."
compsci,3d9422,antisyzygy,2,Tue Jul 14 23:01:35 2015 UTC,"The only one of these I have experience with is AI, particularly in the area of computer vision. Mathematically, stats and linear algebra are big ones. Programming skills aren't too important (with regards to stuff like software engineering).  You'd probably use a mathematically oriented language or library, such as MATLAB, Octave, Python (with NumPy), Scala (with Breeze), etc.  A good understanding of algorithms and analysis is particularly important, since processing images requires dealing with large data sets (both from the size of the image and from image count when using machine learning algorithms). As a result, having an efficient algorithm can matter tremendously."
compsci,3d9422,the_omega99,2,Tue Jul 14 15:29:54 2015 UTC,"You should be asking your advisor this question, to be honest. Presumably, he/she would know your course catalog better than we would."
compsci,3d9422,philly_fan_in_chi,2,Tue Jul 14 16:18:30 2015 UTC,I am asking for shortlisting grad schools. So I don't have an advisers yet.
compsci,3d9422,KasonBirdman,2,Tue Jul 14 16:48:42 2015 UTC,"NLP: expressive or descriptive logics, linguistics, conceptual graphs, ontology, topology Data Science: statistics/prob, linear alg, relational models/databases, non-relational databases  AI on the other hand I would argue is an umbrella term that the other two fall under, but it's hard to know precisely what someone is talking about these days when they say AI because it is such a profoundly complex and integrated field.   It depends what you're more interested in. Pick a subject, grab an introductory book, and from there you should be able to see what sort of requisite knowledge is required."
compsci,3d9422,n0ty0urtypic4lguy,1 point,Tue Jul 14 17:31:02 2015 UTC,"Linear Algebra. Probability and Statistics. Discrete Mathematics. Analysis of Algorithms. Automata Theory. Data Science is root for your question. Under Data Science is Natural Language Processing and Artificial Intelligence, Machine Learning etc. I'm actually studying all about Natural Language Processing this semester and gonna pass a research about it, but i'm reading some statistics books because without enough background with Statistics and other math courses. It'll eat you alive i promise. But i think you pursue Artificial Intelligence and Data Science. Natural Language Processing is harder for me because you have to understand even the basic parts of speech and sentence, parse trees. It makes me sick, but its awesome in someways. If you want to revise the Siri and other speech recognition software then go with Natural Language Processing.   Artificial Intelligence is next on my list after studying this NLP. Its awesome. It also requires great Math knowledge. Especially if you want to go deep on Artificial Neural Networks. You can do something what my Senior have done. He create a Mario game that completes the stages without playing it. The idea there is you deal with the data from the game, it manipulates the data and learn from it from the computer mistakes. It takes a lot of tries but after dealing with the information the computer memorize how the game is played and completes it perfectly."
compsci,3d9422,CapslockEngaged123,1 point,Wed Jul 15 11:40:46 2015 UTC,"Math.  Lots and lots of math.  You will get a lot of use out of serious (proof based or at least not introductory) courses in probability theory, statistics, linear algebra, the design and analysis of algorithms, complexity theory, information theory, graph theory, and possibly some continuous math like real analysis, especially if you are doing machine learning.  Definitely the first four I listed are essential no matter what you are doing.  The others will be tremendously useful as well and you'll want some understanding of them, just maybe not beyond the introductory level.  If you haven't done any proof-based mathematics, you really should take at least one course like that.  AI has a lot of formalism that you don't see elsewhere in an undergrad CS curriculum except in theoretical CS classes like complexity theory and the like."
compsci,3d65ys,oldSoul12345,14,Mon Jul 13 20:50:56 2015 UTC,"I have way too many bookmarks and resources when it comes to programming. I just sort each language or type in each board to check for reference.   Organized board of all my resources using Papaly. For example, my Web Development Board"
compsci,3d65ys,Googk,1 point,Tue Jul 14 00:02:15 2015 UTC,That's an awesome collection ! Thanks for sharing.
compsci,3d65ys,A-healthier-me,1 point,Tue Jul 14 03:18:27 2015 UTC,This is perfect! I was actually working on a personal project that was essentially this. I'm glad someone has made something similar.
compsci,3d65ys,dagit,3,Tue Jul 14 15:43:00 2015 UTC,http://steshaw.org/plt/
compsci,3d65ys,bradrlaw,3,Tue Jul 14 03:55:48 2015 UTC,"It kind of depends... Do you want to know about the latest, bleeding edge, possibly / possibly not next big thing? Or do you want to stay up to date on where the trends are going to maximize your current marketability?  Are you interested in the latest academic research?  I think by the time something is on most of the subreddits listed it is pretty much already mainstream.  So if you want to be ahead of the curve you have to look elsewhere and I don't think that is easy to do from one spot.    For some raw metrics, toibe is decent: http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html  Would be nice if there was similar list for frameworks / toolkits.  Edit: As far as blogs I follow /r/compsci, /r/androiddev hackernews slashdot (really gone downhill but occasionally a good article) CrunchBase (good to see where the dollars are flowing to tech startups) TechCrunch (general industry trends)"
compsci,3d65ys,r0bbbo,3,Tue Jul 14 06:20:06 2015 UTC,https://lobste.rs/
compsci,3d65ys,PM_ME_UR_OBSIDIAN,6,Tue Jul 14 16:30:08 2015 UTC,"/r/compsci, /r/programming, /r/sysadmin. This is pretty much all you'll ever need to stay up to date.  For personal/spiritual growth, I like reading theoretical computer science like the blogs of Jeremy Kun or Bartosz Milewski."
compsci,3d65ys,Baconaise,3,Tue Jul 14 00:43:08 2015 UTC,https://www.reddit.com/r/programming+compsci+sysadmin
compsci,3d65ys,iHubble,3,Tue Jul 14 14:37:50 2015 UTC,"Woah, didn't know I could combine subreddits. That is sick."
compsci,3d65ys,aamo,2,Tue Jul 14 15:31:11 2015 UTC,"if you think thats cool, check out multi-reddits - http://www.redditblog.com/2013/06/browse-future-of-reddit-re-introducing.html"
compsci,3d65ys,Baconaise,1 point,Tue Jul 14 15:44:43 2015 UTC,I honestly hate everything about multireddits. I made one and it disappeared and then that bar pops up every now and again and I just want to ad block it. They needed to just build it in as a new feature not a slapped onto the page forced to look at the stupid arrow bar on the left slider tab shit thing.
compsci,3d65ys,Baconaise,1 point,Thu Jul 16 21:51:53 2015 UTC,I makes it convenient for me because I bookmakred that and while I don't want to be subscribed to programming because it has some pretty off topic and advice animal stuff I want to check in occasionally.
compsci,3d65ys,zem,2,Tue Jul 14 17:08:04 2015 UTC,"i follow james hague religiously. he makes me think about what i am doing and what i should have in mind while doing it.  this one is probably my favourite post, but they're pretty much all good."
compsci,3d65ys,muchcharles,2,Tue Jul 14 08:12:21 2015 UTC,http://lambda-the-ultimate.org/ http://lwn.net/
compsci,3d65ys,UpBoat420,2,Tue Jul 14 08:43:14 2015 UTC,your daily SICP reading session
compsci,3d65ys,shooshx,3,Tue Jul 14 19:26:47 2015 UTC,joelonsoftware has not been updated with programming related content regularly for years now and codinghorror has never actually written anything that is not overly rehearsed fluff.  Here's a good one for you: http://eli.thegreenplace.net/
compsci,3d65ys,MattEZQ,1 point,Tue Jul 14 07:25:53 2015 UTC,Reddit can be a great resource if you subscribe to the right subs. You can use metareddit to find subreddits related to your field(s)
compsci,3d65ys,jongallant,1 point,Mon Jul 13 23:59:47 2015 UTC,"I made a multi-reddit that has a focus on game development.  If anyone is interested, you can always add other subreddits of your choosing.  http://www.reddit.com/user/jongallant/m/programming"
compsci,3d65ys,michaelmalak,0,Tue Jul 14 11:12:10 2015 UTC,Meetup.com
compsci,3d7iq6,captainjimboba,6,Tue Jul 14 03:08:03 2015 UTC,Doesn't Java already have libraries for this? Not that anyone would use them...
compsci,3d7iq6,secretpandalord,7,Tue Jul 14 05:06:13 2015 UTC,"Engines and other systems can have control software just like we write now, often in C. The real question for starship control is, where will we get the Spice..."
compsci,3d7iq6,philthechill,5,Tue Jul 14 18:56:38 2015 UTC,It'd be pure haskell. Pun intended
compsci,3d7iq6,monumentshorts,5,Tue Jul 14 05:11:52 2015 UTC,DCPU-16 assembly.
compsci,3d7iq6,ThisIsADogHello,3,Tue Jul 14 05:36:06 2015 UTC,I found this.
compsci,3d7iq6,WhackAMoleE,2,Tue Jul 14 07:20:22 2015 UTC,"On a starship, propulsion, shields, life support and weapons would need to be really robust, multiple backup systems and a implementation in a language that gives us a robust and strong type system and quick and effective exception handling mechanisms.   For such magnitude of critical systems I'd go away from C, memory problems can't be avoided with that amount of code and could pose a problem. ADA is probably a good choice, robust, good exception handling, fast, and afaik a little bit more abstract than C. Current european spaceships use ADA extensively, I'm not sure about NASA.   For entertainment and other minor, non-critical functions I'd go for something easy to iterate over, maybe something like python or even javascript."
compsci,3d7iq6,MarceColl,3,Tue Jul 14 09:02:32 2015 UTC,"memory problems aren't the only culprit, there are also very though hardware and time restrictions. C is in fact used a lot for mission critical code because of these reasons:  http://programmers.stackexchange.com/questions/159637/what-is-the-mars-curiosity-rovers-software-built-in"
compsci,3d7iq6,MartenBE,2,Tue Jul 14 09:35:57 2015 UTC,"Interesting, I would have thought reliability to be a lot more important than speed in this case, but I guess NASA tests the software throughly. I'm not sure how ADA compares to C in speed.  Edit: Yeah, this post sheds some light on the subject. Really interesting read."
compsci,3d7iq6,MarceColl,1 point,Tue Jul 14 09:55:20 2015 UTC,Thank u both!
compsci,3d7iq6,MarceColl,1 point,Wed Jul 15 23:27:37 2015 UTC,Can you post a link/source for European use of ADA? Nice comment.
compsci,3d7iq6,robertmeta,1 point,Wed Jul 15 23:26:42 2015 UTC,My dad used to work for a company here in Barcelona called GTD that does a lot of software for the ESA and they used ADA a lot. They also did a lot of avionics for defence with ADA too because of its robustness. Sorry for not having a more demonstrable source!  edit: this is their webpage GTD and their space webpage SPACE
compsci,3d7iq6,Hougaiidesu,1 point,Thu Jul 16 06:52:50 2015 UTC,That's perfect thanks! It's good to see something besides C++ being used.
compsci,3d0yef,math238,59,Sun Jul 12 16:39:06 2015 UTC,"The halting problem is probably the single most famous CompSci proof out there. It's pretty cool.  I'm also a fan of inductive proofs in general, which I would consider ""computer science""-ey. Like, the inductive proof that every other integer is even."
compsci,3d0yef,cstoner,1 point,Sun Jul 12 19:08:20 2015 UTC,Agreed. The proof of the undecidability of the halting problem is so elegant.
compsci,3d0yef,maladat,29,Mon Jul 13 18:20:12 2015 UTC,"I kind of like the proof of the (various forms of the) pumping lemma, because you can do it with pictures, and it actually involves 'pumping'."
compsci,3d0yef,Oreska,6,Sun Jul 12 17:59:20 2015 UTC,People actually like the pumping lemma?
compsci,3d0yef,ansc,9,Mon Jul 13 14:04:24 2015 UTC,"Also, while working on the proof, you get to say ""and now it's time to clap pump point you up!""  During exams though, it's better to do this in your head to avoid awkward stares from your classmates..."
compsci,3d0yef,mdempsky,17,Mon Jul 13 06:53:42 2015 UTC,I like the idea of reduction proofs in general.  Another one I like is the proof that SAT is NP-complete without reducing it to another NP-complete problem but by showing how to transform any turing machine into a SAT problem in polynomial time.
compsci,3d0yef,Coloneljesus,41,Mon Jul 13 00:02:52 2015 UTC,Proof of the lower-bound on comparison-based sorting algorithms.
compsci,3d0yef,sumnuyungi,3,Sun Jul 12 17:13:43 2015 UTC,That one is sick. I really like information-theoretic or combinatorial proofs in general.
compsci,3d0yef,PM_ME_UR_OBSIDIAN,11,Sun Jul 12 23:07:42 2015 UTC,IP=PSPACE is fantastic !
compsci,3d0yef,HurlSly,4,Sun Jul 12 18:05:17 2015 UTC,"IP=PSPACE is fantastic !   sounds interesting, could you elaborate?"
compsci,3d0yef,msm_,11,Sun Jul 12 18:10:54 2015 UTC,"IP is interactive proof, you have a deterministic Turing machine and a potentially unreliable, but omnipotent 'prover'. In polynomial time the TM can ask (different) questions of the prover to try to ascertain if it's lying. Turns out an IP system can solve (in poly time) any problem in PSPACE."
compsci,3d0yef,BrainInAJar,1 point,Sun Jul 12 22:46:18 2015 UTC,Here is a little introduction on the subject by Scott Aaronson.
compsci,3d0yef,HurlSly,13,Mon Jul 13 09:42:54 2015 UTC,The proof that unsolvable problems exist using Cantor's Theorem
compsci,3d0yef,rondoisthebest,10,Sun Jul 12 22:28:54 2015 UTC,"When you're talking about proofs in Computer Science, it seems to me you're talking about formal Mathematical proofs generally speaking. How are you separating math proofs from cs proofs? Gödel's Incompleteness Theorem is a logical proof that changed my view of the world when I finally grasped the implications.  Also, The orange crate packing problem aka Kepler's Sphere Packing problem required multiple gigs of code to solve and was a major breakthrough."
compsci,3d0yef,something_cleverer,1 point,Mon Jul 13 06:30:54 2015 UTC,ELI19?
compsci,3d0yef,mck1117,3,Mon Jul 13 08:23:20 2015 UTC,"Gödel's Incompleteness Theorem is a proof in formal logic, than any formal logic system is either incomplete or incorrect or uselessly simple. It doesn't say which, but if a formal logic system is incorrect it's useless, which means we'll have to choose to believe we'll never have a complete understanding of any of our mathematical systems.  If we can't complete our understanding of maths, what right do we have to assume we can complete our understanding of physics or chemistry or anything really? The mysteries are infinite."
compsci,3d0yef,something_cleverer,2,Tue Jul 14 02:27:53 2015 UTC,http://cstheory.stackexchange.com/questions/10387/beautiful-results-in-tcs
compsci,3d0yef,vznvzn,3,Mon Jul 13 02:15:50 2015 UTC,"Proof that BPP is in PH, from the field of Computational complexity. The proof appears in a book by Sanjeev Arora and Boaz Barak (link)."
compsci,3d0yef,ehudt,3,Sun Jul 12 18:07:52 2015 UTC,Cook's Theorem is lovely.
compsci,3d0yef,therico,1 point,Mon Jul 13 05:55:45 2015 UTC,Came here to say this.
compsci,3d0yef,gimme_treefiddy,5,Mon Jul 13 15:09:27 2015 UTC,The ones you do as homework. :)
compsci,3d0yef,jasenmh,2,Sun Jul 12 18:11:27 2015 UTC,Curry Howard Isomorphism. The proof that proofs are programs.
compsci,3d0yef,pedroabreu,5,Wed Jul 15 01:00:27 2015 UTC,Dijkstra's proof that go-tos are unnecessary (part of his argument that they are harmful). http://www.u.arizona.edu/~rubinson/copyright_violations/Go_To_Considered_Harmful.html
compsci,3d0yef,michaelquinlan,3,Sun Jul 12 21:44:15 2015 UTC,A short innocuous paper that gave us structured programming.
compsci,3d0yef,Devvils,1 point,Mon Jul 13 02:39:04 2015 UTC,Dijkstra is full of gold
compsci,3d0yef,andrewff,4,Mon Jul 13 03:15:34 2015 UTC,"Maybe the simplex algorithm for linear programming , and A* search,"
compsci,3d0yef,Devvils,1 point,Mon Jul 13 02:45:02 2015 UTC,simplex algorithm is amazing
compsci,3d0yef,kdma,1 point,Mon Jul 13 21:11:25 2015 UTC,"If you're into ML, the proof and result of the ""no free lunch theorem"" is significant."
compsci,3d0yef,Jonno_FTW,1 point,Mon Jul 13 11:54:11 2015 UTC,"It's probably not one of the ""best"" proofs in CS, but I enjoyed the proof that no online scheduling algorithm can do better than 1/4 of the utility a clairvoyant scheduler achieves."
compsci,3d0yef,isofx,1 point,Tue Jul 14 08:31:47 2015 UTC,Edgar Dijkstra about Pattern Recognition and Shortest Paths.
compsci,3d1dhj,Young_Galileo,16,Sun Jul 12 18:44:35 2015 UTC,"Usually when the coding seems easy it is either a simple project/changes and/or is being managed by a good lead/team who has done a lot of the hard design work before you start coding.  It may not be as easy as you think it is as some coders I worked with struggle with simple tasks and usually fail to consider the ""unhappy path""   Knowing a how to write some code and a few frameworks doesn't prepare you for putting together complex systems - to get to that position you need lots experience of coding.    Other areas you might want investigate Testing, Support, Business Analysis"
compsci,3d1dhj,AStrangeStranger,23,Sun Jul 12 19:58:46 2015 UTC,"A majority of the vocational jobs coming off the back of a CS degree in ""development"" in some sense. Do you mean a specific type of development that you dislike? Despite being an enthusiastic CS major, the sort of front end web development you're doing would bore me to tears.   I did a bunch of internships in telecommunications, and then did a graduate programme in banking. Both involved generic, uninspiring code written to bug fix C++ apps, frontend and back. I ended up burning out really quickly and returning to uni for a PhD. Now I work in an R&D department on AI algorithms, and the work I do actually matters to society. I still spend the majority of my working days staring at C++ (plus other languages) but my job satisfaction is vastly improved.  It's great that you've figured out so early that front end web dev isn't for you. Why not take a look at the elective classes you will choose later on during your degree and try to learn a bit about the topics they cover? That might help you figure out if there are specific things within the vast area that is CS that you might enjoy more.  Also, if there's a choice, I'd highly recommend switching to a CS degree rather than a Software Engineering degree - in my opinion, the latter tends to result in dull jobs."
compsci,3d1dhj,helpmefindthisbug,4,Sun Jul 12 19:46:38 2015 UTC,"What is your impression of the market for PhDs?  I am doing my masters right now, and have considered it."
compsci,3d1dhj,zzing,3,Sun Jul 12 23:03:59 2015 UTC,"PhDs with hands-on development experience and deep knowledge of machine learning, statistics, or natural language processing have great employment prospective as data scientists."
compsci,3d1dhj,omon-ra,1 point,Mon Jul 13 08:07:53 2015 UTC,I have been leaning towards machine learning.
compsci,3d1dhj,zzing,2,Mon Jul 13 09:09:58 2015 UTC,Could you elaborate as to why the PhD could be a liability for non-academic jobs? I've never heard this before.
compsci,3d1dhj,thejesteroftortuga,11,Sun Jul 12 23:45:42 2015 UTC,There may be other reasons but I've heard that it often marks you as overqualified which can be a bit suspicious. A potential employer could wonder why someone with such qualification is applying for some standard development job/why they don't have any previous work experience outside of academia.
compsci,3d1dhj,stardek,1 point,Mon Jul 13 01:44:30 2015 UTC,"I am more than a bit biased as I am just about to start a PhD, but I don't get the impression that a PhD in CS is much of a liability right now. There aren't enough faculty jobs to go around, but there seems to be more than enough demand in industry."
compsci,3d1dhj,mcorah,1 point,Mon Jul 13 01:54:19 2015 UTC,There's a famous quote about CS having as much to do with computers as telescopes do with astronomy. But nonacademic jobs are mostly about building and operating things that work. PhD doesn't teach that.
compsci,3d1dhj,Z47,1 point,Mon Jul 13 03:44:34 2015 UTC,This discussion has happened lots. Usually the people who have actually done a PhD come in and say that they have had absolutely no trouble at all getting non-academic jobs.
compsci,3d1dhj,eygrr,0,Mon Jul 13 12:28:45 2015 UTC,"/u/stardek is partially right, there is another issue that i've seen and heard here in the US.  there's a clear perception of CS PhD holders as being incapable of writing good, clear, ""proper"" code. as in, their code is shit. bad variable names, no understanding of Software Engineering principles (patterns, functional composition, etc...) or they're too interested in 'theory' and unable to complete projects in time & budget/schedule."
compsci,3d1dhj,MachinShin2006,1 point,Mon Jul 13 20:10:44 2015 UTC,That is what I have heard.  I want to be able to do things beyond the typical coding monkey (even the typical coding at a place like Google) - but I definitely do not have sufficient industry coding experience.
compsci,3d1dhj,zzing,1 point,Mon Jul 13 04:11:49 2015 UTC,"It really depends on what your PhD subject is. Personally, doing a PhD opened a lot of doors, and after it I left academia I got a development job. I have a MSci in Software Engineering and my PhD subject was Human-Computer Interaction. I don't think it closes as many doors as it opens."
compsci,3d1dhj,VerticalDepth,2,Mon Jul 13 00:00:57 2015 UTC,"Despite what some others have said, the market is great for PhDs right now, at least in the south of England. I have never come across a company unwilling to consider me because I'm overqualified, and because of my specific expertise I've had a considerable number of offers from companies that do really interesting stuff.   Technology startups are constantly looking for someone to be a principal developer on their core product algorithms. The really big companies (who hire brilliant people rather than trying to fill specific roles) consistently express an interest in hearing from PhD graduates. And if you've done anything even tangentially related to machine learning in your PhD, it'll be hard to resist a lucrative career in quantitative finance. (I still get emails once every week or two.)  You still need really solid development ability however, so my 2 years of prior industry experience really helped a lot - most job interviews still had a whiteboard coding portion and general SE questions.  Of course, IF MONEY IS YOUR MAIN MOTIVATOR, DO NOT DO A PHD. You will never make up for the lost earnings you could get by, say, working in a bank for those 3 years. There is only one valid reason for doing a PhD imo, and that is an overwhelming interest in the subject matter."
compsci,3d1dhj,helpmefindthisbug,1 point,Tue Jul 14 08:58:53 2015 UTC,Another thing to consider is I am just into my mid-thirties. I will probably have a masters under my belt in the next year or so.   I have also considered moving countries (I am in Canada). One thing I do know is that I would stay at my current university for a PhD. I did that for my masters due to the professor I know.
compsci,3d1dhj,zzing,1 point,Mon Jul 13 17:24:30 2015 UTC,"Thanks for the advice, ill definitely consult my program advisor about switching into CS. Also I was just reading a book on IBM Watson and AI / Machine-human interaction seemed like topics id be interested in. Cool coincidence"
compsci,3d1dhj,morto00x,2,Mon Jul 13 19:38:45 2015 UTC,You should check out The Great Mind Challenge: Watson Edition. Participating in the competition could give you some good experience if you are interested in machine learning.
compsci,3d1dhj,Camelope,9,Sun Jul 12 23:05:27 2015 UTC,"I'm using my CS degree for Cyber Security. It's a good mix of development (fixing vulnerable code, writing libraries for internal security use, etc.) and also stuff like pentesting (using burp suite, sqlmap, etc) to identify vulnerabilities, in addition to actually researching them and keeping up with the latest zero days and the like. I initially started doing iOS automation testing and was, indeed, bored to tears.  Other options are things like project managers, technology consultant, DBA, etc that all require theoretical knowledge and have less to do with development."
compsci,3d1dhj,moop__,2,Mon Jul 13 03:43:49 2015 UTC,^ This is what I'm doing too.  Also look into enterprise architecture if you're into really big picture stuff.
compsci,3d1dhj,Groumph09,3,Sun Jul 12 20:43:53 2015 UTC,"I have yet to meet an EA without at least 5+ years of experience as a developer, business analyst or project management.  EA might be something further in his/her future."
compsci,3d1dhj,kecos,1 point,Sun Jul 12 21:55:22 2015 UTC,How do you get into something like this? I just graduated with a CS degree and would love to do cyber security.
compsci,3d1dhj,Camelope,3,Mon Jul 13 02:22:12 2015 UTC,"My company is pretty chill and my manager really wanted us (us being the team of college interns basically) to be able to do what we wanted. So after being bored with iOS automation, I just kept laying down that I was interested in security and when I came back for another summer internship, he moved me in!  My experience may be atypical, but if you get hired into a company and are really interested in security, it can't help to drop that to every important person you know! Maybe be like ""hey did you hear about xyz exploit?"" or ""does this section of the codebase use input validation?"" etc. Good luck!"
compsci,3d1dhj,kecos,1 point,Mon Jul 13 02:49:22 2015 UTC,"That's interesting, I'll have to give that a try. Is there anything I can do as a side project on my own that says ""hey, i'm really interested in this topic""?"
compsci,3d1dhj,Camelope,2,Mon Jul 13 04:08:18 2015 UTC,"I've lately been trying to find one of my own. I did some crypto stuff in python for one of my classes. Particularly difficult was a cryptographic block device driver. Otherwise I'm just hoping I'll get some inspiration and start poking around. Kali Linux has many useful (and, very dangerous) tools that you might want to look into playing with. Not everything there is necessary but if you set up a safe environment and start playing around with the various tools like hydra, sqlmap, aircrack, etc, it couldn't hurt. Well, it can hurt, but seriously, be VERY careful. These tools cause a lot of noise and if you hit a site that has someone watching, you could get boned by the law."
compsci,3d1dhj,mcorah,5,Mon Jul 13 04:27:22 2015 UTC,"Something to consider is that you don't necessarily have to do what's popular or look like everyone else. I did my undergrad specifically with the interest of going into robotics. Because of that I developed a skill set very different from what is most popular right now.  So, my encouragement is to think a lot about exactly what you want to do and what in CS or software development really interests you, and that may or may not involve writing all that much code. My experience at career fairs and the like was that although many of the more popular companies had zero interest in my resume those with related interests quickly dispense with the pleasantries.   So there really is no need to try to develop a generic programmer skill-set even though there is a lot of demand for that. Learn to do exactly what you want to do in your career and related companies will recognize your talents. The only thing to consider is that the more specific your skill-set the less control you will have of where you work."
compsci,3d1dhj,omon-ra,5,Mon Jul 13 05:02:01 2015 UTC,"What other career options are there in CS/software engineering?   Sounds like FAQ.   QA or SDET, Test Lead/Manager later DevOps, IT Manager later Program Management (check Microsoft's job postings) Some kind of integration work - professional services, internal automation (sharepoint and so on). these jobs are heavy on ""business side"", communications, and understanding of a product and light(er) on coding. Product Management after you gain knowledge of specific business area Technical writing Teaching - create training courses, educate employees in large corporations etc., mostly on internal software and procedures Teaching - CS teacher in high school DBA, SQL ""DBA""-kind of work with big data infrastructure, hadoop etc. Data science/analysis Tech support Watch ""Office space"" 5 times, take a construction gig, never look back."
compsci,3d1dhj,el_benhameen,3,Mon Jul 13 04:01:03 2015 UTC,"Product management: design and drive the things that other people implement. Follow market trends, interact with the people who buy your thing, figure out how to market that thing, etc.  Project management: drive the dev team to implement the things that product management designs. Manage requirements and the development schedule, define technical implementations of features, make sure all the pieces of the puzzle fit together.  QA: make sure that the things that the product manager designed and the project manager implemented work well, match the spec, and will make sense to the people who buy the things.   Founder: all of the above, plus more, with pants on fire.  (*YMMV. There are probably PMs who don't work on marketing and project mangers who don't define technical implementations. Cool.)"
compsci,3d1dhj,mc8675309,3,Mon Jul 13 08:28:59 2015 UTC,"I'll make two points, you're getting the easy tasks now, they do get harder, particularly when you get into design issues. The second is that there's more to software engineering than web apps. I enjoy systems work working on writing servers and algorithms work analyzing data.   In the mean time remember that if there's interesting work to do then it's not going to the newest person."
compsci,3d1dhj,Girth,3,Sun Jul 12 20:44:36 2015 UTC,On mobile so I don't know how to properly post this but here is the best response I ever saw about what you can do with a degree in computer science.  http://www.reddit.com/r/cscareerquestions/comments/36kbe3/z/creq1x8
compsci,3d1dhj,Make3,3,Mon Jul 13 03:08:54 2015 UTC,"Why, research of course. Work on projects that push the boundaries of understanding. I work in deep learning, & really like it."
compsci,3d1dhj,PastyPilgrim,2,Mon Jul 13 03:48:13 2015 UTC,"You can switch from Software Engineering to Computer Science. Software Engineering is a lot of learning frameworks and the development process, but Computer Science is all math and science. With CS, you can do research, teach, develop backend, security, etc."
compsci,3d1dhj,bottar,1 point,Mon Jul 13 12:58:28 2015 UTC,"Sales. It seems weird, but if you're a good salesperson with good CS understanding you have a big leg up. I wouldn't have thought of it myself, but I went to school with a couple guys that ended up in sales instead of software development and worked with some of these unicorns. It's a unique position that can be advantageous."
compsci,3d1dhj,Akayllin,1 point,Sun Jul 12 22:54:59 2015 UTC,Id love to teach it
compsci,3d1dhj,Jrummmmy,1 point,Mon Jul 13 02:20:11 2015 UTC,some of the best and brightest seem to end up in security!
compsci,3d1dhj,Stopher,1 point,Mon Jul 13 03:59:20 2015 UTC,I see a lot of people go into project management. High paying gig.
compsci,3d1dhj,PressF1,1 point,Mon Jul 13 04:03:42 2015 UTC,"More than likely you are in that position at the start up because you are in your first year of undergrad. If it took more skill to do, they would've looked for someone who has more than 1 year of undergrad as their experience. No company would put a first year undergrad in a position with much responsibility or particularly difficult work unless that student had proven to be exceptional.  There are many topics in CS, for example: Data analysis, machine learning, systems design, networking, security, encryption, business intelligence, back-end development, simulation, etc."
compsci,3d1dhj,tnqri,1 point,Mon Jul 13 06:14:08 2015 UTC,"How about IT consulting? This is a broad field that can be pretty much anything, from coming up with plans to revamp a company's entire IT architecture, to extracting insights from a company's data (data mining) to helping a company come up with an effective approach to managing it's employees' mobile devices."
