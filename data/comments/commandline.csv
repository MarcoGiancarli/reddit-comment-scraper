commandline,3e2c3r,speckz,15,Tue Jul 21 12:30:13 2015 UTC,ntpdate -s time.nist.gov  would be considered a one liner too.
commandline,3e2c3r,NPVT,5,Tue Jul 21 14:58:45 2015 UTC,"And a lot clearer as to what your goal is, too."
commandline,3e2c3r,cpbills,1 point,Tue Jul 21 16:37:44 2015 UTC,"Well, there is some cool value in building and sending your own UDP packet from the command line, and then parsing the reply packet."
commandline,3e2c3r,Malor,1 point,Tue Jul 21 18:22:30 2015 UTC,"Definitely would help if this was more readable, at least."
commandline,3e2c3r,Shurane,1 point,Wed Jul 22 05:41:20 2015 UTC,"Cool yes.  Value no.  At the risk of sounding like management there is  no ""added value""  doing this.  If I caught one of my juniors doing it they have to wear the dunce cap."
commandline,3e2c3r,sirspidermonkey,1 point,Wed Jul 22 05:05:17 2015 UTC,"Building arbitrary packets from the command line?  While this example isn't all that great, the technique could be useful to have in the toolbox.  example: waking a remote PC by creating and sending magic packets, no additional software required."
commandline,3e2c3r,Malor,2,Wed Jul 22 05:43:07 2015 UTC,Doesn't work for me.  I get back an error message from date about a long number not being a file or a directory.
commandline,3e2c3r,Malor,2,Tue Jul 21 13:49:13 2015 UTC,"What OS? I get this:  07:17 AM Tue Jul 21 john@Johns-MacBook-Pro.local 1/2021 bash [~]$ date -r$((16#`printf ""\xb%-47.s""|nc -uw1 ntp.metas.ch 123|xxd -s40 -l4 -p`-2208988800)) Tue Jul 21 07:17:28 PDT 2015"
commandline,3e2c3r,power78,2,Tue Jul 21 14:18:26 2015 UTC,"Debian, the Jessie release.  It fails both with zsh (my default) and with bash.  Here's the exact error message:  date: 1437488582: No such file or directory"
commandline,3e2c3r,Malor,2,Tue Jul 21 14:22:22 2015 UTC,"Ah it looks like the date command differs on OSX. Here is the one for linux:  -r, --reference=FILE     display the last modification time of FILE    while the one for OSX:  usage: date [-jnu] [-d dst] [-r seconds]   Note the -r parameter. I am not the author though."
commandline,3e2c3r,power78,2,Tue Jul 21 14:29:15 2015 UTC,"You are correct.  After digging a little in the man page, this seems to work:  date --date=@$((16#`printf ""\xb%-47.s""|nc -uw1 ntp.metas.ch 123|xxd -s40 -l4 -p`-2208988800))   Basically: replace the -r with --date=@  edit: also works fine on zsh."
commandline,3dxqnk,HS8290HS,5,Mon Jul 20 12:06:17 2015 UTC,This is a very cool tool. I look forward to trying it out.
commandline,3dxqnk,lorddarkflare,10,Mon Jul 20 14:02:14 2015 UTC,"I also made a curl/wget alternative, but r/software deleted my link. And now sourceforge is down and took my link with them :(  But there is still a partial github mirror: https://github.com/benibela/xidel  Special thing is: It is a sed/awk/xpath/xmlstarlet/jq alternative, too, and Turing complete.    E.g.  xidel http://www.example.org/pagewithlogin.html -f 'form(//form, ""user=foo&pass=bar""})' -f .class-of-links-you-want-to-download --download '{//title}.html'   to login on a page, find some links and save each link to a file with the page title. And since it is a single call, it will handle cookies, referrers or hidden input fields on the login form automatically."
commandline,3dxqnk,BeniBela,3,Mon Jul 20 15:38:42 2015 UTC,I can't stop reading that as h-titty-pie.
commandline,3dxqnk,BloodyThorn,2,Mon Jul 20 20:09:47 2015 UTC,"I read it as HTTP IE , I'm not going anywhere near that."
commandline,3dxqnk,Jonne,2,Tue Jul 21 06:45:54 2015 UTC,"While a really good alternative, I do not agree with the software authors notion of it being a ""replacement"", as it does not replace said tools in any way, but merely complements them. Still, great to know about this!"
commandline,3dualq,everythingembedded,2,Sun Jul 19 15:23:08 2015 UTC,Doesn't ctrl-c/v always work in fields regardless?
commandline,3dualq,power78,1 point,Sun Jul 19 17:40:43 2015 UTC,"Unfortunately not. For example, some terminals don't support Ctrl-C/V. Some other apps use different shortcuts. Some apps don't like copy&paste of data, and this trick makes it seem like you are entering data."
commandline,3dualq,d3adA1m,2,Sun Jul 19 22:26:36 2015 UTC,Sometimes terminals will use ctrl+shift+v/c. Scroll wheel click as well.
commandline,3dq5p0,happytux,8,Sat Jul 18 10:47:43 2015 UTC,"""old school command prompts""... sigh kids today."
commandline,3dq5p0,mclellac,3,Sat Jul 18 20:02:09 2015 UTC,srsly
commandline,3dq5p0,madwilliamflint,4,Sat Jul 18 22:21:58 2015 UTC,"Reminds me of uplink (Another great hacking game, but more hollywood-like, and old as fuck)  I'm definitely going to get this, it looks like a great game. I wonder if it'll include a real IRC client, because that's what all the real hax0rz use."
commandline,3dq5p0,5225225,2,Sat Jul 18 17:43:34 2015 UTC,"Looks like it's Windows only, despite being featured on tuxdiary. I suspect they may have confused it with a rogue-like game with the same name, HackNet.  EDIT: Turns out it was assumed that the game would be compatible with SteamPlay, which appears to be not the case, so yeah ... Windows only."
commandline,3dq5p0,geirha,4,Sat Jul 18 19:01:23 2015 UTC,"Nah,  it's the right game.  Bottom of the article - coming to linux on steam next month"
commandline,3dq5p0,Onelow,2,Sat Jul 18 20:40:06 2015 UTC,"Yeah, pretty embarrassing mistake - I tweeted the game devs to confirm."
commandline,3dq5p0,alexgmcm,1 point,Sat Jul 18 19:34:18 2015 UTC,"What is this, a fork of nethack?"
commandline,3dq5p0,turdBouillon,1 point,Sat Jul 18 22:32:46 2015 UTC,Nethack is a dungeon game.   It sounds like this one is an actual simulation of hacking on a network.
commandline,3dq5p0,Malor,1 point,Tue Jul 21 18:25:55 2015 UTC,"Since no one responded immediately I followed the link and read several words myself. It is in fact yet another fork of nethack, so it is another Rougue-like and has nothing to do with ""hacking""."
commandline,3dq5p0,turdBouillon,2,Tue Jul 21 18:38:43 2015 UTC,"We may confusing what we're talking about.  I'm talking about the OP.  From that article:   Exploring the volatile nature of personal privacy, the prevalence of corporate greed, and the hidden powers of hackers on the internet, Hacknet delivers a true hacking simulation, while offering a support system that allows total beginners get a grasp of the real-world applications and commands found throughout the game."
commandline,3dq5p0,Malor,1 point,Tue Jul 21 19:01:23 2015 UTC,"Looks like you're right, I was going off the link in /u/geirha 's comment: http://splitreflection.com/cal/HackNet.html"
commandline,3dq5p0,turdBouillon,2,Tue Jul 21 19:38:22 2015 UTC,"Well, currently steam only lists it as a Windows game: Steam search for ""hacknet"". (Screenshot for the lazy)  But maybe it'll support SteamPlay by the time its released? I can't find any information about that."
commandline,3dq5p0,geirha,2,Sun Jul 19 03:18:27 2015 UTC,"Yes, most probably it will be released for Windows only."
commandline,3dq5p0,madwilliamflint,1 point,Sun Jul 19 08:50:47 2015 UTC,"How are ""Hack RUN"" and ""Hack Run ZERO""?  I've had my eye on them for a little while."
commandline,3dq5p0,Rose_Tint_My_World,2,Sun Jul 19 09:10:33 2015 UTC,"I've got Hack RUN and Hack Run ZERO on my iPhone and am pretty entertained with them.  I got them as free apps of of the day games, not sure I'd pay much for them, but they're a fun hack-type puzzle game for when you're stuck at the DMV and need a fun thought-provoking distraction"
commandline,3dtpjj,lrvick,4,Sun Jul 19 10:45:34 2015 UTC,Might as well be telling people to delete system32.
commandline,3dtpjj,gamecheet,1 point,Sun Jul 19 10:47:57 2015 UTC,Ha. I hope most people would know better than to blindly run unverified scripts from untrusted sources on the internet. If you -actually- run it as-is you will be educated on why this is a terrible idea.
commandline,3dtpjj,gamecheet,1 point,Sun Jul 19 11:00:45 2015 UTC,I thought for a second it might be something to tell you not to do that. I'm glad it is.
commandline,3dtpjj,mobilediesel,4,Sun Jul 19 12:34:30 2015 UTC,One thing that might be helpful is telling people what this actually is. It appears to be a script/API for setting up accounts? For what? An online service? Easier setup for our own local machines/networks?
commandline,3dtpjj,aneryx,1 point,Sun Jul 19 10:56:36 2015 UTC,The current barrier to entry is intentional. We cater to the curious.
commandline,3dtpjj,AyrA_ch,6,Sun Jul 19 11:16:47 2015 UTC,That sounds very elitist.
commandline,3dtpjj,Bratmon,2,Sun Jul 19 13:51:07 2015 UTC,We are pretty chill. Hoping it would sound like a challenge to inspect the code. _^
commandline,3dtpjj,AyrA_ch,4,Sun Jul 19 17:46:18 2015 UTC,"Don't trust us? Good! You probably don't know us (yet) so you shouldn't.  To help address this we GPG sign this shell-setup script so you can verify it has not been changed by a third party before you run it   Just for everyone to consider, until you have a method, that is 100% guaranteed to yield the public key of the signer, PGP signatures are completely useless.  I often have people asking me, why I do not sign my E-mails. Well, the reason is, it is useless. A third party can easily replace the signature with his own and replace the published key with his own to fool you. Until you do not have a secondary channel to get the key safely, don't rely on the keys.  In the script I see lines like this: gpg --recv-keys 0xD2C4C74D8FAA96F5. Don't you think if somebody can replace the signature in transit he can also replace that line to match his signature. You would verify the key with the given command and be happy, that it seems valid. Bers part of it, you will trust that key in the future."
commandline,3dtpjj,AyrA_ch,1 point,Sun Jul 19 13:53:31 2015 UTC,"I feel like you might be letting perfect be the enemy of good here.  No cryptography is infallible, it's a question of how much time and effort an attacker is willing to put forth.  And PGP vastly increases the amount of effort required."
commandline,3dtpjj,lolzballs,2,Sun Jul 19 14:35:00 2015 UTC,"It is rather trivial to switch the signature with my own. If I can switch the signature, I can also switch the verify command provided to match my signature."
commandline,3dtpjj,AyrA_ch,1 point,Sun Jul 19 19:05:21 2015 UTC,Throwing in a random key is one thing but you can't easily forge web of trust on public key servers.
commandline,3dtpjj,AyrA_ch,2,Sun Jul 19 17:43:55 2015 UTC,"But if you can easily replace the signature, you can also replace the line they provide you to check the key.  PGP only secures a document if you trust the key already. If the key is unknown to you, there is no good reason to trust it at all if you cannot verify it has not been replaced."
commandline,3dtpjj,AyrA_ch,1 point,Sun Jul 19 19:04:39 2015 UTC,"If you are using https, you can't replace the line, unless you have some shady certificates accepted."
commandline,3dtpjj,lolzballs,3,Sun Jul 19 21:56:23 2015 UTC,"Then the server should step up the SSL game because there is a lot going wrong at the moment.   It currently is vulnerable to the POODLE attack It does not mitigates CRIME attacks Certificates use SHA1 which has been deprecated and will stop working completely in a few years. They should replace it The server accepts RC4 which is considered weak The server does not supports forward secrecy. If you crack open one connection, you have them all. The server sends the Root certificate with the chain, which it should not The server accepts SSL3, which is considered insecure. RC4 (the weakest cipher) is on top of the supported cipher list. The strongest ciphers should be on top. TLS compression is enabled Secure Client-Initiated Renegotiation is enabled. This allows a single client to DoS the servers with minimal effort regarding CPU and traffic. Session resumption is disabled or not available. Server seems to use Tornado 4.1. 4.2.1 is the newest version. Upgrading might mitigate some problems already.   Detailed results here  In other words, don't trust the SSL connection too much."
commandline,3dtpjj,AlissaSquared,2,Sun Jul 19 22:25:30 2015 UTC,"Thanks so much for identifying these. Our small web side of things has not gotten much love, and needs it. We will file these into issues, and if you feel like submitting PRs for any of them that would be awesome. Or jump on IRC and lets discuss."
commandline,3dtpjj,AyrA_ch,1 point,Sun Jul 19 22:53:05 2015 UTC,"I actually recommend you to put something like nginx in front of it, that handles all the SSL stuff. Configuration for an A+ rating is rather easy  If you do not want to read the full article, here is the config  ssl_ciphers ""EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH""; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; add_header Strict-Transport-Security ""max-age=63072000; includeSubdomains; preload""; add_header X-Frame-Options DENY; add_header X-Content-Type-Options nosniff; ssl_session_tickets off; # Requires nginx >= 1.5.9 ssl_stapling on; # Requires nginx >= 1.3.7 ssl_stapling_verify on; # Requires nginx => 1.3.7"
commandline,3dtpjj,outadoc,1 point,Sun Jul 19 23:44:21 2015 UTC,"Nginx adds a lot of extra complexity for this use case, however I honestly had no idea tornado was this bad at SSL when I hacked this out.  If tornado can't be made to pass all these though, then yeah, bundling nginx will have to happen."
commandline,3dtpjj,AlissaSquared,2,Sun Jul 19 23:46:18 2015 UTC,"You can have nginx as a simple reverse proxy, this way you can completely disable SSL on tornado and use plain HTTP in between nginx and tornado. When you deliver static content as well (for example images or a static html file) you can route it around tornado and give it the directory with the files in it, this way you have less overhead from python. We do this too at the company I work at and it delivers great performance."
commandline,3dtpjj,outadoc,1 point,Sun Jul 19 23:52:31 2015 UTC,"That is almost exactly how I had it setup in the past actually, and how I normally deploy such things... but I opted to eliminate it in this instance order to simplify the deployment as Tornado had direct SSL and there are no fully static file paths. Not running an SSL test before going to production with the tornado-only setup was poor judgement on my part.  I am unwilling to sacrifice security for simplicity so I'll figure out how to containerize all that neatly again if Tornado's SSL setup proves untenable."
commandline,3dtpjj,tehdog,2,Sun Jul 19 23:58:54 2015 UTC,/u/lulzballs already submitted a PR for fixing POODLE which is now in production.  https://github.com/hashbang/hashbang.sh/pull/52
commandline,3dtpjj,paraluna,1 point,Sun Jul 19 23:41:45 2015 UTC,Ahem... lulzballs.
commandline,3dtpjj,paraluna,1 point,Mon Jul 20 01:19:58 2015 UTC,We could probably ask users to come online to IRC and have them talk to us about it there. I'll talk to other people about it later.
commandline,3dtpjj,AlissaSquared,1 point,Sun Jul 19 20:50:36 2015 UTC,"PGP keys are nice and fine to verify stuff once you trust the key. To allow people to trust the key, provide a secondary channel to users. to download the certificate. To make it harder for a third party to replace the keys you can also provide a different file each time, in other words, make some changes to the file (even if only a comment containing the timestamp) and sign the file individually. This way somebody would need to constantly replace the key every time the site is called.  An alternative would be to sign the code with the SSL certificate instead.  EDIT: I just noticed, the idea of your site is not very popular on reddit"
commandline,3dpczf,-smerf-,3,Sat Jul 18 04:03:37 2015 UTC,You mean via w3m-img? I think for that the WINDOWID environment variable has to be set to something...
commandline,3dpczf,dluco,3,Sat Jul 18 08:10:52 2015 UTC,"You'd probably have to forward the xterm itself. But at that point you might as well use a graphical browser. The -X option to ssh enables X11 forwarding, while -Y enables trusted X11 forwarding (apparently bypasses some sort of security checks -- what exactly, I'm not sure)."
commandline,3do00j,lc929,9,Fri Jul 17 20:47:48 2015 UTC,"I always like using the exec command to enable logging. At the top of the script, I'll include something like the following:  exec 1> log/out.log.$(date +%F) exec 2> log/err.log.$(date +%F)   This will re-direct all stdout/stderr to log files, so I don't have to continually re-direct it throughout the script. I can then check the err file at the end if I want to report any errors. You can also use tee with it, so it will send it to both the log and stdout when running it manually."
commandline,3do00j,monkey_fish,1 point,Sat Jul 18 00:20:17 2015 UTC,"that's indeed an useful way to add logging. what if I want to have stdout and stderr in the same file, i.e. the same order I see it on the console?"
commandline,3do00j,lewurm,2,Sat Jul 18 08:21:49 2015 UTC,You can do   exec 2>&1    and that will redirect it to whatever 1 is pointed to.
commandline,3do00j,monkey_fish,1 point,Sat Jul 18 14:59:17 2015 UTC,"Separate the date call into a variable, so you can be sure it is the same for both exec. Then use append redirection (>>).    Since few tools write to stdout and stderr at the same time, the resulting file should be quite readable if you have only one task running at a time. Getting readable, non-interleaved output out of things like xargs -n1 -P4 will be tricky as always."
commandline,3do00j,mioelnir,1 point,Sat Jul 18 12:16:12 2015 UTC,Yeah - good move on the date and calling it once.
commandline,3do00j,monkey_fish,4,Sat Jul 18 15:00:04 2015 UTC,handling output of a command as if it were a file  e.g. compare two files but ignore commented lines:  diff <( grep -v '^#' /file/a ) <( grep -v '^#' /file/b )
commandline,3do00j,phryneas,2,Sun Jul 19 00:06:57 2015 UTC,"called ""process substitution"" it's really neat"
commandline,3do00j,Plasma_eel,7,Mon Jul 20 03:29:58 2015 UTC,"All are in windows:  The .. and . commands  doskey ..=cd.. doskey .=dir $*   You never have to type cd.. again, instead .. is enough to go up a level. Typing . will show you the directory content ($* will pass arguments to the command)  empty file creator (alias for touch)  copy nul test.txt type nul>>test.txt   Creates an empty file (echo would write a line break to it)  The second variant is longer, but does not erases files if they exist already.  Text editor  copy con test.txt   Poor mans text editor. Creates a file and writes anything from stdin into that file, until you hit [CTRL]+[Z]. Great because there is no built-in command line text editor on 64 bit Windows systems  Calculator  set /A 10+0x10+010   Works as a calculator and stores the result in test. If you omit test= then the value is printed to the console. It understands decimal, octal and hexadecimal. (The result in the example is 34). Result is always given as decimal. It knows order of precedence and also has bitwise and logical operators. Any string is interpreted as environment variable and is converted to a numeral and then used in the expression. So if you have run set test=2 earlier, set /A test+5 will give you 7.  Create file of X byte size  fsutil file createnew <filename> <length>   Does not looks special and requires administrative rights, but it creates sparse files, so the creation is instant, even for very large files (works on network storage).  Linuxify  prompt [%USERNAME%@%COMPUTERNAME%]$S$P$G$S$$$S   Not meant to be directly entered every time, but useful as environment variable. It changes how windows displays paths in the console to a linux style prompt which looks like this: [Administrator@GLADOS] C:\Users\Administrator\Desktop> $. If you sneak a $T in it, then it also shows you the current time, when the prompt was printed, so you basically get a free ""idle time"" reminder.  Duplication  start   Many people do not know, but running start without arguments, starts a new copy of cmd.exe in the directory you are with all environment settings you have made (including the prompt from above). Useful if you want to test something but do not want to destroy your scrollback or mangle your environment settings from the parent console.  Map folders and unmappable network drives  subst <letter>: <path>   Subst creates a drive letter at user level and maps it to the specified folder. Ideal, if you need a folder represented as directory. The folder name can also be a UNC path to a network share, which is useful, if your administrator has blocked the ""map network drive"" feature. The drive is constantly shown as ""disconnected"" but it is fully accessible. Also great if you want to have a cmd process at a network location, because cmd.exe does not supports UNC paths.  Find strings  findstr [/S] <string> <filename>   While findis highly limited, findstr searches with regular expressions, multiple strings can be defined. Supplying /S will search for the file name (which supports wildcards) in subdirectories as well. Prints the filename and the line containing the string.  Unicode  CHCP 65001   Switches the codepage to UTF-8. Your console might run havoc if you do not set a truetype font. Wider chars (for example japanese) still wont show, but greek and cyrillic work fine.  Macros in general  You can create a text file with each line containing name=value associations and have that loaded using doskey /MACROFILE=filename. This gives you the possibility to add aliases to your command line which use environment variables, which in turn allows you to do all sort of crazy stuff:  rmcd=SET QQ=%CD% $T CD.. $T RD /S /Q %QQ% $T SET QQ=   Deletes the current directory you are in.  This is possible, because using a macro file will not parse variables when loading it."
commandline,3do00j,AyrA_ch,-1,Sat Jul 18 00:29:51 2015 UTC,"For empty file creation, I use:  Windows:  :con > myfile   Unix:  > myfile"
commandline,3do00j,shalpin,1 point,Sun Jul 19 04:37:09 2015 UTC,the windows method does not works for me.  A line beginning with a colon is considered a label and not evaluated. You sure you use this method?
commandline,3do00j,AyrA_ch,1 point,Sun Jul 19 10:41:31 2015 UTC,"Hmm. Sorry, you are right, I'm wrong. I'm sure I've used something with con in the past to get empty files, but I can't find anything now that works the way I thought it did."
commandline,3do00j,shalpin,1 point,Sun Jul 19 14:40:17 2015 UTC,you sure you did not use the nul device?  Con always reads from stdin which would not stop until ^Z is received.
commandline,3do00j,AyrA_ch,2,Sun Jul 19 19:07:45 2015 UTC,"Forgot to type ""sudo"" before a command  that requires it? sudo !!There you go.  Wanna execute multiple commands in succsession? Seperate them with &&."
commandline,3do00j,Goethe2go,4,Sat Jul 18 13:49:21 2015 UTC,"I wasn't exactly like ""wow! this is great!"" but here's one I use from time to time:  :> file   instead of  cat /dev/null > file   And I think that pretty much covers most responses you should get for intermediate level shell scripting - switching from externals and UUO's to built-ins.  Favourite tricks though, I generally expand them out with options and put them into my .bashrc file as a function.  The one I use most often is probably my password and passphrase generators - on hosts where I'm not allowed to install pwgen or apg.  So dig around some dotfiles on github and you'll come across some gems.  /edit: come to think of it, my late greybeard team leader was blown away by this trick that I use all the time:  tr "","" ""\n""   ""I've been a nix sysadmin for over 30 years... why didn't I think of that?!"""
commandline,3do00j,whetu,3,Fri Jul 17 22:56:02 2015 UTC,You don't even need the : command. Just the redirection by itself is enough to truncate the file  > file
commandline,3do00j,KnowsBash,1 point,Fri Jul 17 23:03:16 2015 UTC,"...and if you're encountering permission denied errors trying to empty the file, the following will sometimes work.   echo """" | sudo tee /dir/dir/file"
commandline,3do00j,aliensiduction,1 point,Sat Jul 18 08:59:02 2015 UTC,"tr "","" ""\n""   When do you use it? It's kind of a simple sed, right?"
commandline,3do00j,FedeMP,3,Sat Jul 18 15:14:47 2015 UTC,"Last time I mentioned this use of tr, it devolved into others having a stupid shit fight over tr vs sed.  tr won the day, I don't remember exactly how though because as I say, it was a stupid argument.  My attitude is that they're different tools that can be used for the same job.  I prefer tr for this simple task, if you prefer sed, that's your business.  I do recall one person went to the effort to do a performance comparison using a csv file with tens of thousands of lines.  sed came second.  I think the main point made by those arguing for tr was that using sed for this tiny simple job was overkill.  It's also technically silly to say that it's a simple sed because you can say that about almost any program that you pipe to. It's actually a translation of a character into a newline.  It turns out that my need to parse comma separated lines is actually pretty common.  Quite often I'll break the line down using this, do some other processing, and form the line back up with an opposing tr ""\n"" "",""  Others would probably fuck around with setting and unsetting IFS instead.  As an example, I'm in the middle of a project to cleanup our sudoers files across a few hundred hosts, so there's a lot of this going on:  grep [searchterm] *sudoers | grep Cmnd | cut -d ""="" -f2- | tr "","" ""\n"" | sed 's/^ //' | sort | uniq | grep -v usr | tr ""\n"" "",""   In that example, I'm searching for the Cmnd_Alias lines for a particular group across all the sudoers files (which have been pre-collected), cutting out the commands listed after the = sign (i.e. Cmnd_Alias ALIAS =), translating the commas into newlines, using sed to remove any start-of-line blankspace, sorting, uniq'ing, filtering, and then re-merging it back to a comma separated list.  For one-off usage though, off the top of my head, I routinely use it for parsing the output of id, specifically against Active Directory accounts to make the long list of groups more readable, sortable and grepable.  e.g.  id someaccount | tr "","" ""\n"" | grep -i somesearchterm   The other common usage I have for it is similar to id: getent  getent group somegroup | cut -d: -f4- | tr "","" ""\n"""
commandline,3do00j,whetu,1 point,Sat Jul 18 23:39:58 2015 UTC,"Great answer. I didn't know about tr and I see it has it uses.  About your CSV example, how do you determine when each row ends? Without a file to test, I guess you would end up with something like  foo,5,,bar,6   Is it right? Do you run another tr to replace the two commas with a new line again?"
commandline,3do00j,FedeMP,1 point,Sun Jul 19 02:28:31 2015 UTC,"I didn't know about tr   Oh, wow!  OK, so I think the most common usage of tr that you'll find is for converting case i.e.  tr '[:upper:]' '[:lower:]' <<< something   More often you'll see it in the arguably uglier format:  tr [A-Z] [a-z]    About your CSV example, how do you determine when each row ends?   I'm not entirely sure I understand the question.  If you're wanting to process each line in a file and restore it to a csv with the lines in place, you'd do a while read or for loop.  Line by line: deconstruct, process, reconstruct.  Otherwise, if I'm dumping out a comma seperated line to process and then merge back, you can throw in a grep . to remove any unwanted blank newlines, and that prevents the double comma situation.  The other thing I have to point out is that merging back to a comma separated line winds up with a trailing comma, which can be simply dealt to if need be."
commandline,3do00j,whetu,1 point,Sun Jul 19 07:51:36 2015 UTC,"More often you'll see it in the arguably uglier format:  tr [A-Z] [a-z]    And arguably more wrong, if you have any single-letter files in $PWD (the arguments should be quoted because they're both valid globs)  However I prefer the latter format. I think it's a little easier to skim read. It also doesn't have the potential to mislead -- ""upper"" and ""lower"" refer to the upper- and lowercase characters a-z, but not to ａ−ｚ or áćéíḱĺḿńó etc. tr works in bytes, not characters, but if you didn't know that it could be a source of confusion."
commandline,3do00j,UnchainedMundane,-1,Sun Jul 19 13:30:55 2015 UTC,":> file   instead of     cat /dev/null > file    Alternatively,   touch file"
commandline,3do00j,ertlun,6,Fri Jul 17 23:50:12 2015 UTC,Difference is that your last example won't empty out a file.   touch file
commandline,3do00j,ide_cdrom,1 point,Sat Jul 18 00:09:14 2015 UTC,"Oh, didn't think of that."
commandline,3do00j,ertlun,2,Sat Jul 18 02:06:31 2015 UTC,"> foobar   Or  :> foobar   Will both create empty file foobar if it doesn't exist, otherwise truncate it to zero bytes.  touch foo   Will create empty file foobar if it doesn't exist, otherwise update the timestamp on foobar."
commandline,3do00j,Dman222123222,1 point,Sat Jul 18 00:07:55 2015 UTC,> file   Is to empty it of its content. touch will not do this
commandline,3do00j,msween00,1 point,Sat Jul 18 00:08:30 2015 UTC,"I don't know about intermediate, but I think these are cool: On windows, have a script set the prompt, e.g.:  @echo off prompt %DATE:~4,2%/%DATE:~7,2%/%DATE:~10,4%$S$T$S$P$_$G$S @echo on   and set the registry entry HKCU\Software\Microsoft\Command Processor\Autorun point to it. Now every command window has that prompt - Never be squidged up on the right hand side, with no space to type anything, ever again (it's the $_ that does this, a newline, so your prompt is always on the left with lots of space).  In bash .... <<< ""$myvar"" to read from a variable as you would from a file.  Editing ~/.ssh/config so that you can ssh easily to a systems with nice names, even if the name service is borked,  or you have to go through multi-hops  ssh -L, ssh -R commands and corkscrew  mosh. ssh alternative that makes slow connections workable.  ansible ... for doing things on several systems at once. No config of the remote system required, just ssh.  i3 window manager. Ok, it's not command line, but it means that you can do everything from the keyboard and make your command line environment more pleasant.  vimperator in firefox, bash set -o vi, and vim itself, because using the mouse takes a toll on your fingers if you are an old gipper and it's nice to be able to use your 'finger memory' in different apps."
commandline,3do00j,shalpin,-6,Sun Jul 19 04:30:33 2015 UTC,Take the time and read the entire manual. You will find some really neat stuff.
commandline,3dpnwa,zwashburn,2,Sat Jul 18 06:04:45 2015 UTC,"Not batch, but powershell  $EmailFrom = “yourgmailadress@gmail.com” $EmailTo = “destination@somedomain.com” $Subject = “The subject of your email” $Body = “What do you want your email to say” $SMTPServer = “smtp.gmail.com” $SMTPClient = New-Object Net.Mail.SmtpClient($SmtpServer, 587) $SMTPClient.EnableSsl = $true $SMTPClient.Credentials = New-Object System.Net.NetworkCredential(“usr”, “pass”); $SMTPClient.Send($EmailFrom, $EmailTo, $Subject, $Body)"
commandline,3dpnwa,nemec,1 point,Sat Jul 18 07:17:51 2015 UTC,How could i add a txt file to this? (i need to email an txt file either as an attachment or as the body somehow)
commandline,3dpnwa,nemec,3,Sat Jul 18 07:22:47 2015 UTC,http://www.techrepublic.com/blog/windows-and-office/send-an-email-with-an-attachment-using-powershell/
commandline,3dpnwa,AyrA_ch,3,Sat Jul 18 07:25:12 2015 UTC,THANKS!   Never thought to look into power shell!
commandline,3dpnwa,GoodShitLollypop,3,Sat Jul 18 07:28:13 2015 UTC,Don't forget to replace the weird quotes “” with normal double quotes if you copy the snippet.
commandline,3dpnwa,vrsuresh,1 point,Sat Jul 18 08:28:37 2015 UTC,Powershell will blow your mind. It was first conceived as a way to script literally anything you can do in the GUI.  Welcome to the club and don't let snobs of other CLIs get you down. Powershell knowledge is extremely valuable in the marketplace.
commandline,3dl71j,Categoria,2,Fri Jul 17 04:11:11 2015 UTC,"Nice idea. I came up with a shell script for this functionality:  #!/bin/sh pathtest() { [ -d ""$1"" -o -f ""$1"" ] && echo ""$1"" || return 1; } while read line; do     trimmed=""$(echo ""$line"")""     pathtest ""$trimmed"" && continue     for word in $trimmed; do         pathtest ""$word""     done done   And being shell, you can simply paste it inline (albeit a pretty long line!). Something like:  vim ""$(git status | while read l; do t=""$(echo ""$l"")""; [ -d ""$t"" -o -f ""$t"" ] && echo ""$t"" && continue; for w in $t; do [ -d ""$w"" -o -f ""$w"" ] && echo ""$w""; done; done | dmenu)"""
commandline,3dl71j,qwertyboy,2,Fri Jul 17 17:20:29 2015 UTC,"Very nice, but this made me google like for an hour for a stupid vanilla default terminal dmenu equvilant. Thanks alot! :)"
commandline,3dl71j,a_dog_and_his_gun,1 point,Sun Jul 19 10:00:33 2015 UTC,"You are most welcome.  As for a dmenu equivalent without X, I usually use slmenu, but there are quite a few alternatives out there."
commandline,3dl71j,qwertyboy,2,Sun Jul 19 13:18:21 2015 UTC,"trimmed=""$(echo ""$line"")""    Oh come on, that's just perverse :P  Also, I don't think it's necessary -- read doesn't include the trailing linefeed."
commandline,3dl71j,UnchainedMundane,1 point,Sun Jul 19 13:37:54 2015 UTC,"Thank you, you are absolutely right. In my defence I will note that perversity is its own merit, and that I've probably added it while composing this ""masterpiece"", before adding the read loop, and never tried to get rid of it.  So now it's even shorter:  pathtest() { [ -d ""$1"" -o -f ""$1"" ] && echo ""$1"" || return 1; } while read line; do     pathtest ""$line"" && continue     for word in $line; do         pathtest ""$word""     done done   And the one-liner:  while read l; do [ -d ""$l"" -o -f ""$l"" ] && echo ""$l"" && continue; for w in $l; do [ -d ""$w"" -o -f ""$w"" ] && echo ""$w""; done; done   Also, for completeness, one might add an exit 0 or a true at the end. If one cares about return codes, that is :)"
commandline,3dl71j,qwertyboy,1 point,Sun Jul 19 17:42:02 2015 UTC,"First time Go user here. I installed Go and set $GOPATH to /home/ja/go. I cloned source code to /home/ja/go/src and issued go test && go build && go install inside path-extractor direcotory. No errors so far. There was /home/ja/pkg/linux_386/path-extractor.a created. However, /home/ja/go/bin directory was still empty. I tried to run go install inside src/path-extractor/path-extractor but I got this error:  pe.go:3:8: cannot find package ""github.com/edi9999/path-extractor"" in any of:         /usr/lib/go/src/pkg/github.com/edi9999/path-extractor (from $GOROOT)         /home/ja/go/src/github.com/edi9999/path-extractor (from $GOPATH)   I had to create src/github.com/edi9999 directory and copy an entire path-extractor source code directory to it and then execute go install inside src/github.com/edi9999/path-extractor/path-extractor. Did I do something wrong? According to https://github.com/edi9999/path-extractor/blob/master/README.md it would be enough to clone a repository and just install everything right away."
commandline,3dl71j,avg_user,1 point,Fri Jul 17 11:34:29 2015 UTC,"Hi, you're right, you have to clone inside $GOPATH/src/github.com/edi9999/path-extractor, I will update the readme later today.`   I'm not aware of a simpler way to do it, as I'm new to go.  docker (https://docs.docker.com/linux/step_one/)  and  fzf (https://github.com/junegunn/fzf/blob/master/install)  both use an installation script   docker uses the package manager of the running platform (apt-get, yum, ...) fzf downloads the binary from an other repository.  I don't really like both methods because:   I don't want to maintain apt-get, yum, ... packages (like docker) I don't really want to maintain a repository with binary files (like fzf)   Maybe one of you knows better how to distribute a go cli app ?"
commandline,3dl71j,edi9999,1 point,Fri Jul 17 11:53:25 2015 UTC,"go get github.com/edi9999/path-extractor/path-extractor   Does the job, why bothering with scripts?  If you want to provide binaries, have a look to https://github.com/laher/goxc, and publish with GitHub releases."
commandline,3dl71j,_Soulou,1 point,Fri Jul 17 12:07:55 2015 UTC,"I've just updated the README, thanks a lot for the help."
commandline,3dl71j,edi9999,1 point,Sat Jul 18 08:59:59 2015 UTC,It ignores files without extension.  ls foo bar.txt zet.txt  ls | path-extractor bar.txt zet.txt
commandline,3dl71j,FedeMP,1 point,Fri Jul 17 20:38:09 2015 UTC,"Yes, this is because pe does not take access to the filesystem. It searches filenames the same way a human would do.  Maybe I could arrange it so that it knows better how to  parse the results of ls or other common commands"
commandline,3dl71j,edi9999,1 point,Sat Jul 18 08:52:40 2015 UTC,"I hope so, cause I really like your simpler approach, different from fpp."
commandline,3dhviu,speckz,1 point,Thu Jul 16 12:06:39 2015 UTC,"Cute! I can see an advantage where it's less load to have a terminal than a browser window.  Is there a way that I can pipe the particular article/comment I'm reading to somewhere more useful? I have FBCMD, t, sendmail ...."
commandline,3d9bsq,LtCdr_Worf,8,Tue Jul 14 14:47:13 2015 UTC,"It looks like you are not using a real hyphen in -s, but some other visually similar character."
commandline,3d9bsq,UnchainedMundane,5,Tue Jul 14 14:50:30 2015 UTC,Seconded - where it says ln: –s: No such file or directory that suggests it's taken the –s as a filename.
commandline,3d9bsq,Dankleton,2,Tue Jul 14 14:53:14 2015 UTC,"Thanks a lot guys, it seems that was the problem. It seem to have accepted the syntax once i made that change to ln -s, however i can't see it actually working, as in the files aren't showing being copied to the local directory. Ho can i check it went through OK or is it possible to remove the symbolic link and try again?"
commandline,3d9bsq,UnchainedMundane,4,Tue Jul 14 14:59:03 2015 UTC,"I don't understand what you mean, what program are you using to do copying?"
commandline,3d9bsq,UnchainedMundane,2,Tue Jul 14 15:04:50 2015 UTC,"sorry, i mean the files aren't showing up in the local directory"
commandline,3d9bsq,UnchainedMundane,4,Tue Jul 14 15:15:00 2015 UTC,"Your command creates a symbolic link at /Volumes/luckyserver/VIDEO/Shaders/LogikMatchboxShaderCollection/shaders (or if that was a directory already, /Volumes/luckyserver/VIDEO/Shaders/LogikMatchboxShaderCollection/shaders/Logik), and points that link at /usr/discreet/presets/2016.0.1/matchbox/shaders/Logik  Now that I read those paths I think you might have put the arguments in the wrong order, since the /Volumes one sounds like it is the remote drive. It's safe to just delete the symbolic link that was created in the wrong place, then swap the arguments to ln and try again."
commandline,3d9bsq,rtaibah,2,Tue Jul 14 15:25:42 2015 UTC,"fantastic, looks like you are right. how exactly should i remove the wrong symbolic link i have now created? (got anything to do with rm?)"
commandline,3d9bsq,insipid,4,Tue Jul 14 15:38:09 2015 UTC,"Yeah, it can be treated as a normal file in some respects so a plain rm will do it. No need for -r or -f."
commandline,3d9bsq,IgnotisAnonymous,2,Tue Jul 14 15:47:10 2015 UTC,"You've been a fantastic help. it has work i can see the linked files. i've just got to correct the directory as the software that is looking for these files is being very particular about the location. I've got everything i need, thanks again"
commandline,3d4gsf,speckz,20,Mon Jul 13 13:18:13 2015 UTC,I find OMZ wicked bloated and gross. I am a major proponent for Prezto now.
commandline,3d4gsf,NeilHanlon,9,Mon Jul 13 14:11:38 2015 UTC,"I call it ""bloat-my-zsh"". It's sad how accurate it is."
commandline,3d4gsf,mkaito,8,Mon Jul 13 14:30:07 2015 UTC,"when you pop a shell and you have to wait 3 secs and then it tells you to update, I'll have already hit ctrl-c 5 times."
commandline,3d4gsf,gamecheet,1 point,Mon Jul 13 16:13:32 2015 UTC,"I am running on shitty laptop and zsh, with oh-my-zsh starts practically instantly for me."
commandline,3d4gsf,IceDane,0,Wed Jul 15 12:56:01 2015 UTC,"Both of them turned me away from ZSH. I just want something simple, with nothing extra. Now, I'm using vanilla Fish."
commandline,3d4gsf,IgnotisAnonymous,1 point,Tue Jul 14 22:23:52 2015 UTC,Check out antigen or zgen. Zsh is love.
commandline,3d4gsf,gamecheet,1 point,Wed Jul 15 13:45:13 2015 UTC,Fish isn't even sh/poisx compliant. Tis a terrible shell
commandline,3d4gsf,NeilHanlon,1 point,Wed Jul 15 01:07:45 2015 UTC,"POSIX noncompliance is an improvement to me. Fish drops some legacy stuff and spruces the shell up. It can also still run any bash/sh script you give it, using either shebangs (which you should be using anyway) or invoking bash/sh. No, it's not quite what you're used to. But, for me, it's a great experience and a shell I won't switch away from any time soon."
commandline,3d4gsf,IgnotisAnonymous,1 point,Wed Jul 15 10:59:22 2015 UTC,"To each his own, I guess.  (FYI: shebangs make the script execute using that shell, so fish isn't executing the scripts)"
commandline,3d4gsf,NeilHanlon,1 point,Wed Jul 15 11:28:32 2015 UTC,"I get that. So does invoking bash. My point is that there's no concern about whether a script will work. It can be made to work easily. (That is, unless it actually modifies the running shell)"
commandline,3d4gsf,IgnotisAnonymous,1 point,Thu Jul 16 01:29:28 2015 UTC,True true.
commandline,3d4gsf,NeilHanlon,7,Thu Jul 16 01:31:01 2015 UTC,I prefer the good old grml-zsh-config. Not that bloated like oh-my-zsh and still looks like a console ;)
commandline,3d4gsf,alexruf,3,Mon Jul 13 18:43:11 2015 UTC,I would only load whatever you really need from oh my zsh (via something like antigen) and avoid it otherwise. It's incredibly bloated.
commandline,3d4gsf,paraluna,5,Mon Jul 13 17:30:54 2015 UTC,"Check out Prezto (https://github.com/sorin-ionescu/prezto)  Much, much better."
commandline,3d4gsf,NeilHanlon,1 point,Mon Jul 13 17:54:43 2015 UTC,"Nice, I'm going to check that out."
commandline,3d4gsf,paraluna,3,Mon Jul 13 18:16:02 2015 UTC,"This article is hilarious to me. I've been to downvote hell before for speaking my mind about the zsh-fad but here I go again, I never learn.   I've been using the shell for more than 15 years now. Mostly Bash and that is what I'll keep on using for the foreseeable future.   These ""features"" that zsh zaelots are so proud of are hardly a reason to switch from the most commonly known and available shell standard in *nix systems.   Truth is that bourne shell is defined in the POSIX standard, and yes standards are a good thing when you're in something as easily fragmented as open source. Bash is a fairly large extension of the bourne shell but it still retains that style of coding and those features. Plus most distros link sh to some sort of bash anyways.   So let's break this article down.   They start with prompts, something that first lured me into trying zsh when I was still a teenager, but that phase blew over quickly. After over 15 years of shell use here's what my prompt looks like today.   PS1='[\!/$?]@\h:\W $ '   For those not familiar with bash this is a prompt that shows my current history position, that is the number my current command will receive in the history(3) list so I can easily repeat it at a later point. The next digit is the last return code from the previous command I executed, something I often found myself asking $? for before I included it in my prompt.   After that is a basic hostname and dollar sign.   That's it. After working professionally with *nix systems for 11 years and working in the terminal for over 15 that is what I came up with. No colors, no dates, no magic.   I wouldn't mind my current username in there but I really have not had a pressing need for it.   I won't even go into color schemes, if you're so eager to customize your prompt with colors then do that, bash has colors too.   File tabbing, yeah sure, you can do that in bash and in fact most distro packages include some sort of bash completion file to aide bash users with the commands. So nothing new here.   I remember during my short stint with zsh setting it up to tab complete all my ssh_config hosts, then I went back to bash and realized I could do the same there using the complete(builtin).   Zsh plugins all look like excuses not to write a cli tool or an alias to me, so really not much to say about them either. Completely unnecessary.   ""Frecent"" folders... yes people have written some neat bash functions to do this but again, why would you want to? Even the author says it works ""almost"" every time. Not something I want to experience in my shell, something working almost every time. If I make a mistake in my shell I want it to be my mistake, not some overblown programs.   So with this said, you would be hard pressed to find an argument for using zsh other than ""a little competition is good for you""."
commandline,3d4gsf,stemid85,2,Tue Jul 14 06:52:54 2015 UTC,"So with this said, you would be hard pressed to find an argument for using zsh other than ""a little competition is good for you"".    As if that's not a good argument.  The rest of your arguments are basically the ""I don't need it, therefore neither should anyone else"" kind of fallacy.  Regarding bash as /bin/sh, Debian links it to dash which is a pure POSIX shell (minus multi-byte character set support). Presumably, so do most Debian derivatives. So the notion that most /bin/sh links to bash is no longer true for Linux. And, as a professional, surely you know that it was never true for other *nix systems to begin with.  The zsh dialect of the shell language has a massive advantage in scripting: by default, it disables field splitting and globbing headaches with unquoted variables, thereby solving one of POSIX's biggest design flaws. It has a ${=variable} parameter substitution to split fields as needed, and ${~variable} to do pathname expansion (globbing) as needed. Why other shells haven't implemented some mode that copies this, I have no idea. (Doing IFS='' and set -o noglob in other shells gives you the same effect, but it's not quite as practical without those handy parameter substitution operators.)  Bash is also incredibly sluggish. Just about anything else runs shell code at least five times as fast, including zsh."
commandline,3d4gsf,McDutchie,1 point,Tue Jul 14 11:32:15 2015 UTC,"The argument is not as much ""I don't need it"" as ""Bash can already do that but why bother?"".   I'm trying to speak as someone who relies on the shell for paying the rent, and I've been through phases where I wanted to pimp my shell and pimp my desktop but in the end there's no productive use to any of that.   I can't speak on the scripting advantages in zsh, in fact I remember this being an argument for zsh when I first tried it so I'm sure you're right about a lot of that.   So bottom line is that I would love to see a change in the entire ecosystem to something that is faster and better designed than what we currently have. I'm sure I'll have to eat my words if I say that I can't see it happening without bash compatibility to ease the transition. Only time will tell."
commandline,3d4gsf,stemid85,1 point,Tue Jul 14 14:49:24 2015 UTC,"I've been to downvote hell before for speaking my mind about the zsh-fad   This post?  I would hardly call that downvote hell, and it's not because you spoke your mind about zsh, it's because you're so mature for choosing bash and all the zsh users are just victims of a fad. That's pompous.  Besides, you can customize your prompt just as easily in bash. I don't know why you think zsh has anything to do with that, and I've seen plenty of riced bash PS1s on various linux blogs. If you think zsh is about prompt customization it's probably because you haven't actually seen what zsh can do.   File tabbing, yeah sure, you can do that in bash and in fact most distro packages include some sort of bash completion file to aide bash users with the commands. So nothing new here.    This is IMO one of the biggest strengths of zsh and you can't do it with bash.  https://asciinema.org/a/4zjgj2lhukt6awu0r33c1qx52 -- bash and zsh aren't even similar in this regard. This is using ""menu-complete"", which more closely emulates zsh's behaviour than ""complete"". In zsh I can navigate a large list of files using the arrow keys, while in bash I have to choose between being blind to the completion options (and unable to use the arrows to navigate them), or being unable to navigate them at all.  Having the completion menu highlighted in the LS_COLORS is also a great help because you can easily distinguish between different types of directory entry at a glance. Grouping the completions is a nice touch.  Another of my favourite zsh features is autopushd, turning cd into a silent pushd. It essentially gives you a navigation history, and it even persists across shell sessions. cd - is crippled in comparison.  The correction is nice. Not something to rely on but if I type ""pamcan"" instead of ""pacman"" it's nice for it to ask if I want to correct to ""pacman"", rather than making me edit the previous line and find and fix the transposed letter. It's fine to let programs do the heavy lifting here, when they ask you nicely.  As for bash being ubiquitous, using zsh doesn't take away from your ability to use bash, any more than using openbox takes away from your ability to use metacity.  I can't speak on ""frecent"" and such things because that's really not my idea of a good time.  edit: Oh yeah, how do you live without **/*(.) and such? That example is zsh's equivalent to find . -mindepth 1 -type f -name '[!.]*', but it's so much more convenient to use (especially because you don't need to think about print0 etc). As far as I can tell from the man page, bash's extglobs don't have an equivalent to any of that stuff."
commandline,3d4gsf,UnchainedMundane,6,Wed Jul 15 23:44:30 2015 UTC,"There's no need to learn zsh. In fact, the only shell you need to know is sh. Every other command interpreter has to be compatible with the Bourne Shell, after that, it's really just personal preference.  Plus, addons like Oh-My-Zsh don't do anything to improve the capabilities of the user.  Edit: just to clarify, my issue is mostly with the assertion made by the title. That, and it's usually a bad idea to pipe from wget/curl directly to any command interpreter."
commandline,3d4gsf,deux3xmachina,3,Mon Jul 13 14:44:37 2015 UTC,"There's no need to learn zsh. In fact, the only shell you need to know is sh. Every other command interpreter has to be compatible with the Bourne Shell, after that, it's really just personal preference.   But some people, for reasons I don't understand, like shells like Fish, which are explicitly not sh-compatible.   Edit: just to clarify, my issue is mostly with the assertion made by the title. That, and it's usually a bad idea to pipe from wget/curl directly to any command interpreter.   If it makes you feel better, that script amounts to:  git clone --depth=1 https://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh mv ~/.zshrc ~/.zshrc.pre-oh-my-zsh cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc sed -i -e ""/^export ZSH=/ c\\ export ZSH=~/.oh-my-zsh "" ~/.zshrc   So if you don't want to trust the install script, know that it changes your shell's rc script to run untrusted code. :)"
commandline,3d4gsf,greyfade,8,Mon Jul 13 20:37:58 2015 UTC,Holy shit. Fish isn't sh-compatible? Why would anyone do that?
commandline,3d4gsf,deux3xmachina,5,Mon Jul 13 21:52:59 2015 UTC,"I have no idea. Since I found out, I've never taken a second glance at it. I recall the FAQ or design doc used to say something about it--something about POSIX being unimportant--but I can't find it now."
commandline,3d4gsf,greyfade,4,Mon Jul 13 22:08:14 2015 UTC,"maybe in an attempt to fix what's broken with posixy shells? No matter how you slice it, sh stinks as fuck both in limited features (where are muh arrays?) and insane defaults (omnipotent IFS and word splitting at the drop of the hat being few).  I use bash and won't touch sh with a 10 foot pole. Shoddy word splitting instead of tidy arrays? Thanks but no thanks."
commandline,3d4gsf,Vaphell,3,Tue Jul 14 00:42:28 2015 UTC,"BASH is literally the Bourne Again SHell. It's just an improvement of sh, but still compatible with it. You don't have to use sh, but it's the base of most other shells used, and most are backwards compatible."
commandline,3d4gsf,deux3xmachina,4,Tue Jul 14 00:53:18 2015 UTC,"i know what bash is. Either way I make a heavy, indiscriminate use of bashisms that try to harden shell scripting to make it safer and more maintainable so my scripts are as uposixy as they get and i couldn't care less about compatibility and compliance with the standard. I know the vast majority of pain can be traced back to posix so i don't see posix as a good thing. If they dropped the warts like word splitting by default, being the source of untold number of bugs, necessitating untold number of shoddy hacks around it, i wouldn't shed a tear.  Why is posix not expanding the standard to make it right at home in 21st, unicode aware century? (eg ${#string} is codepoints, but printf '%*s' $width is bytes - thanks for being useless, printf)  On a similar note I think py3 is fucking awesome and python2 ""i don't need anything better"" people annoy the fuck out of me."
commandline,3d4gsf,Vaphell,1 point,Tue Jul 14 02:16:11 2015 UTC,"If they dropped the warts like word splitting by default, being the source of untold number of bugs, necessitating untold number of shoddy hacks around it, i wouldn't shed a tear.   zsh has done just that."
commandline,3d4gsf,McDutchie,3,Tue Jul 14 11:39:53 2015 UTC,"It's actually a very nice shell. I've used it as my default for a couple of years, and nothing else I've used, even with loads of tweaking, has come close to being as comfortable and efficient as fish is 'out-of-the-box', in terms of being an interactive shell. It has blazing-fast, history-and-manpage-aware tab completion, that is previewed for you automatically, live, on the line, in a way that is not visually distracting.  As far as scripting, it's a much more sane language; breaking POSIX-compatibility allows for a better language design. Unfortunately, I almost never used fish in that capacity for anything more than 7 lines long because it's not portable; anything important, I just wrote it in sh anyway. It's also not like the interoperability is a big issue. As long as a script has #! at the top of it, execution is deferred to the appropriate shell.  I recommend giving it a shot, just to see how the other half lives. :)"
commandline,3d4gsf,warreq,3,Tue Jul 14 05:58:39 2015 UTC,"Well, that's actually a pretty great insight. Though I've given most shells I've heard of a test drive, and so far, I just can't beat tcsh as far as personal preference goes.   Learning C/C++ and having a shell with a similar syntax is really quite nice. I just never saw that fish wasn't compatible with sh, which does really ruin portability. Though I guess portability isn't a major concern for most desktop users."
commandline,3d4gsf,deux3xmachina,2,Tue Jul 14 07:15:14 2015 UTC,If you curl | sh I don't think you get to call yourself a command line power user
commandline,3d4gsf,UnchainedMundane,1 point,Wed Jul 15 23:54:00 2015 UTC,If only a tool were capable of instilling users with enough base-knowledge that they could simply use it and become power users...
commandline,3d4gsf,cpbills,5,Mon Jul 13 21:08:32 2015 UTC,There is. It's called man.
commandline,3d4gsf,mclellac,2,Mon Jul 13 22:14:30 2015 UTC,"I guess we need to work on a reading comprehension tool, for the ones who seem to have a difficult time with man.  But that would be the tool to make power users, for sure."
commandline,3d4gsf,cpbills,2,Mon Jul 13 22:19:44 2015 UTC,"Exactly, Man isn't an easy read unless you already have some general knowledge with the specific commands. I use it all the time now but when I first entered the world of *nix I found man utterly confusing.  edit man would be perfect if it was similar to powershell's man/get-help tools"
commandline,3d4gsf,OriginalBeing,1 point,Tue Jul 14 05:45:05 2015 UTC,"How does using an automated tool make you a power user? If anything, it makes you the opposite."
commandline,3cyw2k,danwin,4,Sun Jul 12 01:07:09 2015 UTC,There's also pt/the_platinum_searcher.
commandline,3cyw2k,paraluna,1 point,Sun Jul 12 01:31:07 2015 UTC,What's the difference between this and ag?
commandline,3cyw2k,elpix,4,Mon Jul 13 00:14:22 2015 UTC,What is this? This website is far from being informative.
commandline,3cyw2k,Nowaker,2,Sun Jul 12 03:58:08 2015 UTC,....a school for ANTS?
commandline,3cyw2k,apanzerj,2,Sun Jul 12 05:58:05 2015 UTC,Wtf is ACK?
commandline,3cyw2k,anomalous_cowherd,2,Sun Jul 12 06:44:40 2015 UTC,It's http://beyondgrep.com/
commandline,3cyw2k,RalphCorderoy,1 point,Sun Jul 12 08:56:29 2015 UTC,"Ah, OK. I remember looking at that ages ago now.  Thanks for supplying a bit of context."
commandline,3cyw2k,anomalous_cowherd,1 point,Sun Jul 12 09:13:59 2015 UTC,Or even http://betterthangrep.com/
commandline,3cyw2k,ptman,3,Sun Jul 12 13:13:57 2015 UTC,git-grep     Fast. Built into grep.   Shouldn't it be Build into git?
commandline,3cyw2k,vifon,2,Sun Jul 12 07:06:49 2015 UTC,built*
commandline,3cyw2k,contact_lens_linux,1 point,Sun Jul 12 14:38:30 2015 UTC,"Indeed, my bad."
commandline,3cyw2k,vifon,1 point,Sun Jul 12 14:47:49 2015 UTC,Yes.
commandline,3cyw2k,demonstar55,1 point,Sun Jul 12 07:41:14 2015 UTC,Phbbt!
commandline,3cyw2k,tonymcd,1 point,Sun Jul 12 10:10:02 2015 UTC,"And how do you search let(:pain a folder. Tried with :Ag ""let(:pa""without success. Any ideas ?"
commandline,3cyw2k,Heliobb,2,Sun Jul 12 10:34:41 2015 UTC,"Probably takes a regexp, Have you tried let\(:pa ?"
commandline,3cyw2k,ptman,1 point,Sun Jul 12 13:15:50 2015 UTC,"great it's work with :Ag ""let\(:pa"" /myfolder"
commandline,3cyw2k,Heliobb,1 point,Sun Jul 12 21:59:15 2015 UTC,"You mentioned ack.vim but, of course, there is also ack plugin for Emacs."
commandline,3czg0s,lc929,5,Sun Jul 12 04:31:51 2015 UTC,"one for sed & one for awk.   Since we usually use them together it makes sense to treat them as one subject, but there are many cases where you only use one. All of the linux classes I've taught, we covered them in the same ""chapter"" but they were separate sections (covered together in the labs)"
commandline,3czg0s,aikidoka,1 point,Sun Jul 12 05:58:31 2015 UTC,thanks! i'll put them under shell scripts in their own folders as you suggested.
commandline,3czg0s,mtelesha,3,Sun Jul 12 06:46:57 2015 UTC,AWK is an actual programming language. SED is a great tool.  Here is a link to awk games  Most people use 1% of what AWK can actually do
commandline,3czg0s,stemid85,3,Mon Jul 13 01:44:39 2015 UTC,"All of the above. Definitely have a section for them because they even have their own books. But they will be used in shell scripts, and they will also be used in one-liners."
commandline,3czg0s,stemid85,1 point,Sun Jul 12 06:21:55 2015 UTC,thanks! I'll place them under shell script within their own folders.
commandline,3czg0s,hybby,3,Sun Jul 12 06:46:39 2015 UTC,Check out Bash FAQ on Greg's Wiki and the Bash hackers wiki. For shell scripting it seems more fitting to categorize by purpose than tool.
commandline,3czg0s,mikelieman,2,Sun Jul 12 07:38:06 2015 UTC,"they're separate programs but are frequently dealt with together. for example, in this O'Reilly book  however they are definitely distinct enough to warrant their own webpage each :)"
commandline,3czg0s,mtelesha,0,Mon Jul 13 00:00:52 2015 UTC,Each program is it's own man page.
commandline,3czg0s,zubinmadon,0,Sun Jul 12 08:13:39 2015 UTC,AWK isn't a program it is a language.
commandline,3czg0s,mtelesha,2,Mon Jul 13 01:46:04 2015 UTC,awk (all lowercase) is a program....
commandline,3czg0s,zubinmadon,0,Mon Jul 13 04:16:58 2015 UTC,Okay funny funny. It is Awk capital first OR all capitals and it is a language.  http://www.ibm.com/developerworks/library/l-awk1/  Please turn in your Command line Nerd Card.  https://en.wikipedia.org/wiki/AWK
commandline,3czg0s,mtelesha,1 point,Mon Jul 13 13:44:50 2015 UTC,"And 'awk' all lowercase is indeed a program, in fact, it's right there in your second link:   When written in all lowercase letters, as awk, it refers to the Unix or Plan 9 program that runs scripts written in the AWK programming language."
commandline,3czg0s,mtelesha,1 point,Mon Jul 13 18:10:57 2015 UTC,From my Link :P   AWK is an interpreted programming language designed for text processing and typically used as a data extraction and reporting tool. It is a standard feature of most Unix-like operating systems.
commandline,3czg0s,mtelesha,1 point,Mon Jul 13 19:49:51 2015 UTC,Also from the man page for AWK   awk - pattern-directed scanning and processing language
commandline,3czg0s,zubinmadon,0,Mon Jul 13 19:50:46 2015 UTC,You again lose all Unix creed.  A program is the script that is interpreted by the language. You can have python programs or C programs. AWK is the initial letters of the authors of the programming language.  Sorry but it is AWK and it is a language. It is not a line editor like Ed or sed.
commandline,3czg0s,mtelesha,1 point,Mon Jul 13 18:36:09 2015 UTC,"Sure, AWK (or Awk, or awk) refers to a language. Nobody's disputing that, sorry if I was unclear about that. I was originally just trying to explain that /u/mikelieman was not incorrect in their statement above.  See, while it can refer to a language, 'awk' in lowercase is indeed also a program--it's the interpreter that interprets the awk language. In fact, try it now, you can run it at your unix commandline. Try typing 'awk' (no quotes) and hitting enter at the command line. With no other input you'll get some usage guidelines. You just ran the awk program.  This is just like 'python' is both a language and a program, again a program that interprets the python language. You can run this program too, it'll take you into an interactive python interpreter -- type 'exit()' (no quotes) to exit.  I realize that in the case of programming languages it's confusing that something can be both a language and a program, however it's not very uncommon, especially with interpreted languages."
commandline,3czg0s,UnchainedMundane,0,Mon Jul 13 20:08:44 2015 UTC,"They are just awk scripts just like they are python programs, BUT awk AWK = the language read the man page or awk-info.com.  By your definition python and C and C++ are programs, but they aren't and neither is Awk."
commandline,3czg0s,mtelesha,1 point,Tue Jul 14 02:25:16 2015 UTC,"By his definition python is a program but C and C++ are not. gcc and g++, however, are.  What lies at /bin/awk (or /usr/bin/awk depending on your distribution), is it a program? If it's a program, what is its name?"
commandline,3czg0s,mtelesha,-1,Tue Jul 14 14:04:06 2015 UTC,TIL perl is both a language and a program???? Los of command line fu is certain on someone!
commandline,3cw2w5,nullde,7,Sat Jul 11 06:52:14 2015 UTC,"The tools OP mentioned are, for the most part, unnecessary.  I'd highly recommend GNU Stow for managing your Dot files. It's portable (I'm using it to manage my files on Debian and OS X), extremely simple, and you can pick and choose which files you want to use on whatever system your importing them onto, so only the necessary files get symlinked.  http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html"
commandline,3cw2w5,BoredOfCanada,3,Sat Jul 11 20:05:26 2015 UTC,"Seconded; don't understand the downvote. My dotfiles repo has bin (platform-independent scripts), dotfiles (which would have .vimrc and such), and platform-specific directories: darwin10.8.0, SunOS, linux-gnu (that correspond to $OSTYPE).  Stow links its arguments into the parent directory. When I'm on a new machine, I clone the dotfiles repo and run this:  ln -s dotfiles/bin bin # do this first if you expect collisions cd dotfiles stow -v --ignore=bin -S dotfiles -S $OSTYPE   So, I can have scripts in darwin10.8.0/bin that are kept separately from bin, but end up in the same place."
commandline,3cw2w5,Skewness,2,Sat Jul 11 20:42:19 2015 UTC,Stow is one of my favorite tools. I'm always shocked to discover the lengths people will go to automate their dot files when they could just stow them.  Obligatory link to my dotfiles repo.
commandline,3cw2w5,criswell,1 point,Sun Jul 12 01:07:30 2015 UTC,"I'm another fan of Stow-like symlink managers, and several are listed in the canonical collection of dotfile utilities at https://dotfiles.github.io/ - #awesomelist"
commandline,3cw2w5,ahazred8vt,0,Wed Jul 15 09:04:47 2015 UTC,"Well, with homeshick I can do the same but without installing Stow and just with bash and git."
commandline,3cw2w5,socium,2,Tue Jul 14 08:16:31 2015 UTC,"A side note: the authors dotfile management tool - dotbot - is pretty awesome. I've been using it for a number of months now and if you don't already version control your dotfiles, I'd recommend you pick it up."
commandline,3cw2w5,alexwh,1 point,Sat Jul 11 14:01:58 2015 UTC,"Requires python though.  I think it would be better if a configuration management for bash required nothing but bash and POSIX tools.  Having your dotfiles in a git repo is easy enough to not require big complex extra tools. Mine involves simply versioning ~/.config and running a ~15 lines script to symlink the configuration files that use ~/ instead of ~/.config for their settings.  Why would I want to have a separate ""~/.dotfiles"" directory when ""~/.config"" is already a standard for storing user settings without polluting $HOME."
commandline,3cw2w5,ferk,1 point,Tue Jul 14 10:58:34 2015 UTC,"Requiring python isn't really that much of an issue. A large majority already have it installed, and when they don't, you'll need to be installing git anyway too.  I see the function of XDG_CONFIG_HOME as more like a good default that applications should use, not the user. Versioning ~/.config is just as bad as versioning ~ in my opinion (git clean, etc.). It's best to keep git repos in their own folder. Plus, what about the plethora of applications that do not read their config from XDG_CONFIG_HOME by default?"
commandline,3cw2w5,alexwh,1 point,Tue Jul 14 12:20:44 2015 UTC,"You only need git when you want to keep the files versioned. In some machines (mostly ones not owned by me) I don't want/need this and I just unpack the tar.gz from github into ~/.config then run ~/config/symlink.sh to have the files I want symlinked to $HOME (the script won't overwrite the original config files with a symlink unless given the argument so the only thing I need to do is not deleting the ones I want to keep)  I have my same dotfiles also on Windows installations running cygwin, I don't normally install commandline python on Windows.  git clean removes untracked files. It won't remove ignored files or untracked directories unless you explicitly ask for it. And if you do ask for it then it's your own fault.  I  have a ""*"" in my ~/.config/.gitignore so that nothing is tagged as untracked unless it's in a folder I explicitly want to track. You could actually give an use to this git feature by keeping a tracked directory with untracked files if you actually want git clean to remove configuration you don't want for whatever reason (cleaning caches?)."
commandline,3cw2w5,ferk,2,Tue Jul 14 14:37:55 2015 UTC,I guess I should break out a .secret_stuff file that isn't checked in and call that from the top of my .bash_profile. Keep that outside of the directory with the rest of the version controlled dotfiles so I don't commit it on accident.
commandline,3cw2w5,WallyMetropolis,2,Sat Jul 11 14:52:22 2015 UTC,Definitely if you have a home shared across machines. Put separate .env.$HOSTNAME files together and automatically pull in the right one from .bashrc
commandline,3cw2w5,Skewness,1 point,Sat Jul 11 20:50:42 2015 UTC,"Oh, that's a nice idea too, I'll probably start doing this. I just meant for security reasons, I don't know that I want to check some things into git"
commandline,3cw2w5,WallyMetropolis,2,Sun Jul 12 02:07:14 2015 UTC,"I don't know that I want to check some things into git   That's sensible. known_hosts in .ssh are likely OK if you enable HashKnownHosts. However, the practical paranoid ought to ignore any .gnupg directories."
commandline,3cw2w5,Skewness,2,Sun Jul 12 06:08:11 2015 UTC,I didn't know about HashKnownHosts. Thanks again.
commandline,3cw2w5,WallyMetropolis,1 point,Sun Jul 12 06:27:10 2015 UTC,"At the end of my bashrc I have something like:  # Source additional config files from custom directory (aliases, completions, etc) for src in ~/.config/sh/*.sh do     [[ -f ""$src"" ]] && . ""$src"" done   This way I only need to put files inside ~/.config/sh for them to be loaded. I keep my ~/.config versioned, but I only track the files I really want to share between computers, so I can simply have different files in there for different machines.  Also I can save keys or special strings that I want to keep untracked into environment variables that later get used by other scripts that I may, perhaps, decide to track in git.  Also, you can use https://gitlab.com instead of github so that you can have repositories that are not open to the public."
commandline,3cw2w5,ferk,1 point,Tue Jul 14 11:15:13 2015 UTC,What kind of stuff do you need to keep secret which would go in your .bash_profile?
commandline,3cw2w5,UnchainedMundane,2,Tue Jul 14 14:56:18 2015 UTC,It's common e.g. with Django to set secret keys as environment variables:  http://stackoverflow.com/questions/14786072/keep-secret-keys-out-with-environment-variables
commandline,3cw2w5,WallyMetropolis,2,Tue Jul 14 15:02:44 2015 UTC,Ah. I don't use Django but that wouldn't sit well with me - I wouldn't feel safe passing a secret key to every program I run when they don't need it. Crash reports and such might send that secret key to a developer somewhere and make it public by accident. (Or so my paranoid self thinks)
commandline,3cw2w5,UnchainedMundane,1 point,Tue Jul 14 15:08:20 2015 UTC,"The author /u/anishathalye is on Reddit.  Just a tiny correction. Footnote #1 says ""a software bug that was introduced in the late 1990s"" but that should be the late 1960s. Depending on which ""version 2"" of Unix Pike is talking about it's either late 60s or early 70s.  https://en.wikipedia.org/wiki/Research_Unix"
commandline,3cw2w5,holyteach,1 point,Sat Jul 11 16:14:08 2015 UTC,"Woah, good catch. Thanks for pointing that out; I fixed it now."
commandline,3cw2w5,anishathalye,1 point,Sat Jul 11 19:20:18 2015 UTC,"Never mind the forking. This tutorial is helpful because it introduces git submodules, which are key if you want to stir in one repo's .vimrc, another repo's tmux, and yet another repo's zsh customizations."
commandline,3cw2w5,Skewness,1 point,Sat Jul 11 20:53:34 2015 UTC,More utilities should use the XDG specified .config directory so that a single directory can be backed up easily.
commandline,3cw2w5,thekaleb,-1,Mon Jul 13 03:36:54 2015 UTC,This is such an overkill and reinventing the wheel..
commandline,3cw2w5,pentag0,-2,Sat Jul 11 19:04:02 2015 UTC,"Some developers believe that “dotfiles are meant to be forked”. I disagree.  Dotfiles are supposed to contain your personal settings – what works for someone else isn’t necessarily optimal for you. If certain configurations worked for everybody, those settings would have been built into programs as defaults.   Does this guy know what forking is? This is exactly why you should fork them."
commandline,3cw2w5,UnchainedMundane,6,Sat Jul 11 08:42:28 2015 UTC,"If you read the whole paragraph instead of only half of it, it makes sense:   Dotfiles are supposed to contain your personal settings – what works for someone else isn’t necessarily optimal for you. If certain configurations worked for everybody, those settings would have been built into programs as defaults. Blindly cloning someone else’s dotfiles, especially without having an understanding of how everything works, is not the optimal approach.   He's not saying use somebody else's repo as-is, he's saying that cloning somebody else's repo as a starting point is not as good as doing it yourself.  He's right.  If you review the popular dotfiles out there, you see all kinds of things that make sense for that particular person but not people in general.  They are great to look at to see what's possible and to crib from, but taking the entire repo as a base?  That's not sensible."
commandline,3cw2w5,JimDabell,0,Sat Jul 11 09:50:38 2015 UTC,"I clipped out the bit about cloning because I assumed he was conflating forking with cloning (since it looks similar when you do it on github).  I think that if someone has settings that look pretty and you want to grab them there's no problem with that, and the purpose of forking it is to fit it into your system and your workflow. If you don't yet have dotfiles of your own it's probably nice to have a starting point."
commandline,3cw2w5,UnchainedMundane,6,Sat Jul 11 10:39:21 2015 UTC,"I think that if someone has settings that look pretty and you want to grab them there's no problem with that   Sure, on a piecemeal basis.  Like the article says:    That being said, I am a big fan of sharing dotfiles and taking inspiration from others’ configurations. My own dotfiles have been open sourced, and parts of my configuration are inspired by other people’s dotfiles. However, my dotfiles are my own personal settings, and I understand every bit of code and configuration in there. That is important. There are some people who have forked my dotfiles, but I do not recommend that approach. Copying parts of my configuration, however, is encouraged! It’s best when you understand what you are using – that’s why I’ve tried to keep my dotfiles organized and well-commented.    Taking things from other people's repos is great.  Cloning the whole thing is not.   If you don't yet have dotfiles of your own it's probably nice to have a starting point.   But you already do – the system defaults.  All you are really doing by cloning somebody else's dotfile repo is swapping the system defaults – which are typically distilled from years of practical experience by many people – for one person's defaults, which are their personal preferences made with no consideration for your needs.  Essentially, when you clone an entire repo as a starting point, you are saying that the person who's repo you are cloning is better at choosing defaults than the people who built the software, for every single piece of software.  That's not plausible, and you're better off starting with the system defaults and cribbing from other people's repos for individual settings."
commandline,3cw2w5,JimDabell,2,Sat Jul 11 10:53:21 2015 UTC,"Though for some things, such as vim, there are some options that are off by default that really should be on by default, such as syntax highlighting.   Though you shouldn't just copy paste other people's dotfiles, you should at least look at the most common options, because sometimes useful options are left disabled due to reasons that don't matter to you (performance, compatibility)"
commandline,3cti10,speckz,1 point,Fri Jul 10 17:25:06 2015 UTC,"The motto of the library is “Never write shell scripts again”   I do not ever want to see this achieve its goal.  It's got some nice ideas but I think actual shell scripts are going to be better at anything that this library could be used for. Plus, you can pass data between shell scripts and python scripts easily, so if you have anything complex you need to write in python you can write it in python and have a little wrapper in shell.  I'm always suspicious of the motivations of projects like this too. It gives me the impression that they're not good at shell languages and gave up trying to learn them, so tried to drag some features back with them to python."
commandline,3cti10,UnchainedMundane,1 point,Sat Jul 11 06:14:44 2015 UTC,"they're not good at shell languages and gave up trying to learn them   I think many people simply find it ugly or not worth of attention since it's not suited for complex algorithms.  To be fair, POSIX shell syntax has a lot of nasty quirks.  However, I still find it essential and extremely useful mainly because of how widespread and portable it is.  Python is not really such an essential piece in an OS as POSIX shell is, so it's likely you won't find it in every system, not to mention additional libraries like plumbum. I won't be able to use such scripts when I ssh into my Android phone, my OpenWrt router or other lightweight systems not prepared to run python."
